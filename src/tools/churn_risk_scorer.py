"""
ì´íƒˆ ìœ„í—˜ ì ìˆ˜ ë„êµ¬ â€” ê³ ê°ì´ ë– ë‚  í™•ë¥ ì„ ë¯¸ë¦¬ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

"ì´ ê³ ê°ì´ ë‹¤ìŒ ë‹¬ì— ë– ë‚ ê¹Œ?"ë¥¼ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê³ ,
ì´íƒˆ ì „ì— ì„ ì œ ëŒ€ì‘í•  ìˆ˜ ìˆê²Œ ìœ„í—˜ ì ìˆ˜ì™€ êµ¬ì²´ì  ëŒ€ì‘ ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤.

í•™ìˆ  ê·¼ê±°:
  - Cox Proportional Hazards (Cox, 1972) â€” ìƒì¡´ ë¶„ì„ ê¸°ë°˜ ì´íƒˆ ì˜ˆì¸¡
  - Kaplan-Meier Survival Curve (Kaplan & Meier, 1958)
  - Logistic Regression ì´íƒˆ ëª¨ë¸ (Neslin et al., 2006)
  - Customer Churn Prediction (Verbeke et al., 2012)
  - Hazard Rate ê¸°ë°˜ ì„¸ê·¸ë¨¼íŠ¸ (Fader & Hardie, 2007)

ì‚¬ìš© ë°©ë²•:
  - action="score"      : ê°œë³„ ê³ ê° ì´íƒˆ ìœ„í—˜ ì ìˆ˜ (0~100)
  - action="batch"      : ê³ ê° ëª©ë¡ ì¼ê´„ ì´íƒˆ ìœ„í—˜ í‰ê°€
  - action="survival"   : ìƒì¡´ ê³¡ì„  + ì¤‘ê°„ ìƒì¡´ ì‹œê°„ ë¶„ì„
  - action="factors"    : ì´íƒˆ ìš”ì¸ ë¶„ì„ (ìœ„í—˜ ì¸ì ê¸°ì—¬ë„)
  - action="strategy"   : ì´íƒˆ ë°©ì§€ ì „ëµ + ì˜ˆì‚° ë°°ë¶„
  - action="full"       : ì¢…í•© ë¶„ì„

í•„ìš” í™˜ê²½ë³€ìˆ˜: ì—†ìŒ
í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬: numpy
"""
from __future__ import annotations

import logging
import math
from typing import Any

import numpy as np

from src.tools.base import BaseTool

logger = logging.getLogger("corthex.tools.churn_risk_scorer")


class ChurnRiskScorerTool(BaseTool):
    """êµìˆ˜ê¸‰ ì´íƒˆ ìœ„í—˜ ì ìˆ˜ ë„êµ¬ (Cox PH + ë¡œì§€ìŠ¤í‹± íšŒê·€)."""

    # â”€â”€â”€ ì´íƒˆ ìœ„í—˜ ì¸ì ê°€ì¤‘ì¹˜ (í•™ìˆ  ì—°êµ¬ + ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ ì¢…í•©) â”€â”€â”€
    RISK_WEIGHTS = {
        "recency_days": {
            "weight": 0.25, "description": "ë§ˆì§€ë§‰ í™œë™ ì´í›„ ê²½ê³¼ì¼",
            "thresholds": [(7, -0.3), (30, 0.0), (60, 0.3), (90, 0.6), (180, 0.9)],
        },
        "frequency_decline": {
            "weight": 0.20, "description": "êµ¬ë§¤/ë°©ë¬¸ ë¹ˆë„ ê°ì†Œìœ¨",
            "thresholds": [(0, -0.2), (0.1, 0.0), (0.3, 0.3), (0.5, 0.6), (0.7, 0.9)],
        },
        "support_tickets": {
            "weight": 0.15, "description": "ìµœê·¼ ë¶ˆë§Œ/ë¬¸ì˜ ê±´ìˆ˜",
            "thresholds": [(0, -0.2), (1, 0.1), (3, 0.4), (5, 0.7), (10, 0.95)],
        },
        "payment_issues": {
            "weight": 0.15, "description": "ê²°ì œ ì‹¤íŒ¨/ì§€ì—° íšŸìˆ˜",
            "thresholds": [(0, -0.1), (1, 0.3), (2, 0.6), (3, 0.85)],
        },
        "engagement_score": {
            "weight": 0.15, "description": "ì„œë¹„ìŠ¤ í™œìš©ë„ ì ìˆ˜ (0~100 â†’ ì—­ë³€í™˜)",
            "thresholds": [(80, -0.3), (60, 0.0), (40, 0.3), (20, 0.6), (0, 0.9)],
        },
        "tenure_months": {
            "weight": 0.10, "description": "ê°€ì… í›„ ê²½ê³¼ ê°œì›” (ì§§ì„ìˆ˜ë¡ ìœ„í—˜)",
            "thresholds": [(24, -0.2), (12, 0.0), (6, 0.2), (3, 0.4), (1, 0.7)],
        },
    }

    # â”€â”€â”€ ì´íƒˆ ìœ„í—˜ ë“±ê¸‰ ì •ì˜ â”€â”€â”€
    RISK_LEVELS = {
        "critical": {"range": (80, 100), "color": "#e74c3c", "label": "ë§¤ìš° ìœ„í—˜",
                     "action_urgency": "ì¦‰ì‹œ ëŒ€ì‘ (24ì‹œê°„ ë‚´)"},
        "high": {"range": (60, 80), "color": "#e67e22", "label": "ìœ„í—˜",
                 "action_urgency": "ë¹ ë¥¸ ëŒ€ì‘ (3ì¼ ë‚´)"},
        "medium": {"range": (40, 60), "color": "#f1c40f", "label": "ì£¼ì˜",
                   "action_urgency": "ê³„íšì  ëŒ€ì‘ (1ì£¼ ë‚´)"},
        "low": {"range": (20, 40), "color": "#27ae60", "label": "ì–‘í˜¸",
                "action_urgency": "ì •ê¸° ê´€ë¦¬"},
        "safe": {"range": (0, 20), "color": "#2ecc71", "label": "ì•ˆì „",
                 "action_urgency": "ìœ ì§€ + ì—…ì…€ ê¸°íšŒ íƒìƒ‰"},
    }

    async def execute(self, **kwargs) -> dict[str, Any]:
        action = kwargs.get("action", "full")
        dispatch = {
            "score": self._score,
            "batch": self._batch,
            "survival": self._survival,
            "factors": self._factors,
            "strategy": self._strategy,
            "full": self._full_analysis,
        }
        handler = dispatch.get(action)
        if not handler:
            return {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” action: {action}. "
                    f"ê°€ëŠ¥í•œ ê°’: {list(dispatch.keys())}"}
        return await handler(**kwargs)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  1. ê°œë³„ ê³ ê° ì´íƒˆ ìœ„í—˜ ì ìˆ˜
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _score(self, **kwargs) -> dict[str, Any]:
        """ê°œë³„ ê³ ê°ì˜ ì´íƒˆ ìœ„í—˜ ì ìˆ˜ ê³„ì‚° (0~100)."""
        recency = kwargs.get("recency_days", 30)
        freq_decline = kwargs.get("frequency_decline", 0.1)
        tickets = kwargs.get("support_tickets", 0)
        payment = kwargs.get("payment_issues", 0)
        engagement = kwargs.get("engagement_score", 70)
        tenure = kwargs.get("tenure_months", 12)

        inputs = {
            "recency_days": recency,
            "frequency_decline": freq_decline,
            "support_tickets": tickets,
            "payment_issues": payment,
            "engagement_score": engagement,
            "tenure_months": tenure,
        }

        # ê° ì¸ìë³„ ìœ„í—˜ ì ìˆ˜ ê³„ì‚°
        factor_scores = {}
        weighted_sum = 0.0
        total_weight = 0.0

        for factor_name, config in self.RISK_WEIGHTS.items():
            value = inputs.get(factor_name, 0)
            risk_contribution = self._interpolate_risk(value, config["thresholds"])
            factor_score = max(0, min(100, risk_contribution * 100))
            weighted_contribution = factor_score * config["weight"]

            factor_scores[factor_name] = {
                "value": value,
                "risk_score": round(factor_score, 1),
                "weight": config["weight"],
                "weighted_score": round(weighted_contribution, 1),
                "description": config["description"],
            }
            weighted_sum += weighted_contribution
            total_weight += config["weight"]

        # ì¢…í•© ì ìˆ˜
        churn_score = weighted_sum / total_weight if total_weight > 0 else 50
        churn_score = max(0, min(100, churn_score))

        # ë“±ê¸‰ íŒì •
        risk_level = self._classify_risk(churn_score)

        # ì´íƒˆ í™•ë¥  (ë¡œì§€ìŠ¤í‹± ë³€í™˜)
        churn_probability = 1 / (1 + math.exp(-(churn_score - 50) / 15))

        # ì˜ˆìƒ ì”ì¡´ ê¸°ê°„ (ì§€ìˆ˜ ë¶„í¬ ê°€ì •)
        hazard_rate = churn_probability / 30  # ì›”ê°„ ìœ„í—˜ë¥  ê·¼ì‚¬
        expected_months = 1 / hazard_rate if hazard_rate > 0 else 999

        result = {
            "churn_score": round(churn_score, 1),
            "churn_probability": f"{churn_probability*100:.1f}%",
            "risk_level": risk_level,
            "expected_remaining_months": round(min(expected_months, 60), 1),
            "factor_breakdown": factor_scores,
            "top_risk_factors": sorted(
                factor_scores.items(),
                key=lambda x: x[1]["risk_score"], reverse=True
            )[:3],
            "recommended_actions": self._recommend_actions(
                churn_score, factor_scores
            ),
        }

        llm_summary = await self._llm_call(
            f"ê³ ê° ì´íƒˆ ìœ„í—˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n{result}\n\n"
            "ì´ ê³ ê°ì˜ ì´íƒˆì„ ë°©ì§€í•˜ê¸° ìœ„í•œ êµ¬ì²´ì  ì•¡ì…˜ í”Œëœì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["ai_insight"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  2. ì¼ê´„ ì´íƒˆ ìœ„í—˜ í‰ê°€
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _batch(self, **kwargs) -> dict[str, Any]:
        """ê³ ê° ëª©ë¡ ì¼ê´„ ì´íƒˆ ìœ„í—˜ í‰ê°€."""
        customers = self._parse_customers(kwargs.get("customers", ""))

        scored = []
        risk_distribution = {"critical": 0, "high": 0, "medium": 0, "low": 0, "safe": 0}

        for c in customers:
            score = self._calc_score(c)
            level = self._classify_risk(score)
            risk_distribution[level["key"]] = risk_distribution.get(level["key"], 0) + 1

            scored.append({
                "customer_id": c.get("id", f"C{len(scored)+1:03d}"),
                "churn_score": round(score, 1),
                "risk_level": level["label"],
                "risk_key": level["key"],
            })

        # ì •ë ¬ (ìœ„í—˜ ë†’ì€ ìˆœ)
        scored.sort(key=lambda x: x["churn_score"], reverse=True)

        total = len(scored)
        result = {
            "total_customers": total,
            "risk_distribution": {
                k: {"count": v, "pct": f"{v/total*100:.1f}%"}
                for k, v in risk_distribution.items() if v > 0
            },
            "at_risk_customers": [s for s in scored if s["churn_score"] >= 60],
            "avg_churn_score": round(np.mean([s["churn_score"] for s in scored]), 1),
            "top_risk_customers": scored[:10],
            "health_indicator": (
                "ğŸ”´ ìœ„ê¸°" if risk_distribution.get("critical", 0) / total > 0.2
                else "ğŸŸ¡ ì£¼ì˜" if (risk_distribution.get("critical", 0) +
                                   risk_distribution.get("high", 0)) / total > 0.3
                else "ğŸŸ¢ ì–‘í˜¸"
            ),
        }

        llm_summary = await self._llm_call(
            f"ì¼ê´„ ì´íƒˆ ìœ„í—˜ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤:\n{result}\n\n"
            "ì „ì²´ ê³ ê° ê¸°ë°˜ì˜ ì´íƒˆ ë¦¬ìŠ¤í¬ë¥¼ ë¶„ì„í•˜ê³  ìš°ì„ ìˆœìœ„ë³„ ëŒ€ì‘ ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["ai_insight"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  3. ìƒì¡´ ê³¡ì„  ë¶„ì„
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _survival(self, **kwargs) -> dict[str, Any]:
        """Kaplan-Meier ìƒì¡´ ê³¡ì„  + ì¤‘ê°„ ìƒì¡´ ì‹œê°„."""
        monthly_churn = kwargs.get("monthly_churn_rate", 0.05)
        cohort_size = kwargs.get("cohort_size", 1000)
        months = kwargs.get("months", 24)

        # Kaplan-Meier ìƒì¡´ ê³¡ì„  ê³„ì‚°
        survival_curve = []
        n_at_risk = cohort_size
        cumulative_survival = 1.0

        for month in range(months + 1):
            if month == 0:
                survival_curve.append({
                    "month": 0, "at_risk": cohort_size,
                    "churned": 0, "survival_rate": 1.0,
                    "cumulative_churned": 0,
                })
                continue

            # ì´íƒˆì ìˆ˜ (ì´í•­ ë¶„í¬ ê·¼ì‚¬)
            churned = round(n_at_risk * monthly_churn)
            n_at_risk -= churned
            cumulative_survival *= (1 - monthly_churn)

            survival_curve.append({
                "month": month,
                "at_risk": max(0, n_at_risk),
                "churned": churned,
                "survival_rate": round(cumulative_survival, 4),
                "cumulative_churned": cohort_size - n_at_risk,
            })

        # ì¤‘ê°„ ìƒì¡´ ì‹œê°„ (50% ì´íƒˆ ì‹œì )
        median_survival = None
        for entry in survival_curve:
            if entry["survival_rate"] <= 0.5:
                median_survival = entry["month"]
                break
        if median_survival is None:
            # ln(2) / Î» (ì§€ìˆ˜ë¶„í¬ ê³µì‹)
            median_survival = round(math.log(2) / monthly_churn, 1) if monthly_churn > 0 else 999

        # ë°˜ê°ê¸°ë³„ ë§ˆì¼ìŠ¤í†¤
        milestones = {}
        for target in [0.90, 0.75, 0.50, 0.25]:
            for entry in survival_curve:
                if entry["survival_rate"] <= target:
                    milestones[f"{int(target*100)}%_month"] = entry["month"]
                    break

        # CLV ì˜í–¥ ì¶”ì •
        avg_monthly_revenue = kwargs.get("avg_monthly_revenue", 50000)
        total_revenue_if_no_churn = avg_monthly_revenue * cohort_size * months
        total_revenue_with_churn = sum(
            avg_monthly_revenue * entry["at_risk"] for entry in survival_curve
        )
        revenue_loss = total_revenue_if_no_churn - total_revenue_with_churn

        result = {
            "method": "Kaplan-Meier Survival Analysis (1958)",
            "parameters": {
                "monthly_churn_rate": f"{monthly_churn*100:.1f}%",
                "annual_churn_rate": f"{(1-(1-monthly_churn)**12)*100:.1f}%",
                "cohort_size": cohort_size,
                "observation_months": months,
            },
            "median_survival_months": median_survival,
            "milestones": milestones,
            "survival_curve": survival_curve[:13],  # 12ê°œì›”ë§Œ í‘œì‹œ
            "revenue_impact": {
                "total_without_churn": round(total_revenue_if_no_churn),
                "total_with_churn": round(total_revenue_with_churn),
                "churn_revenue_loss": round(revenue_loss),
                "loss_pct": f"{revenue_loss/total_revenue_if_no_churn*100:.1f}%"
                if total_revenue_if_no_churn > 0 else "0%",
            },
            "churn_reduction_impact": self._churn_reduction_simulation(
                monthly_churn, cohort_size, months, avg_monthly_revenue
            ),
        }

        llm_summary = await self._llm_call(
            f"ìƒì¡´ ê³¡ì„  ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n{result}\n\n"
            "ìƒì¡´ ê³¡ì„  íŒ¨í„´ê³¼ ì´íƒˆë¥  ê°ì†Œ ì „ëµì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["ai_insight"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  4. ì´íƒˆ ìš”ì¸ ë¶„ì„
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _factors(self, **kwargs) -> dict[str, Any]:
        """ì´íƒˆì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸ë“¤ì˜ ê¸°ì—¬ë„ ë¶„ì„."""
        customers = self._parse_customers(kwargs.get("customers", ""))

        # ê° ìš”ì¸ë³„ ì´íƒˆ ìƒê´€ê´€ê³„ ë¶„ì„
        factor_analysis = []
        for factor_name, config in self.RISK_WEIGHTS.items():
            values = [c.get(factor_name, 0) for c in customers]
            scores = [self._calc_score(c) for c in customers]

            if len(values) >= 3:
                correlation = float(np.corrcoef(values, scores)[0, 1])
            else:
                correlation = config["weight"]  # ë°ì´í„° ë¶€ì¡± ì‹œ ê°€ì¤‘ì¹˜ ì‚¬ìš©

            factor_analysis.append({
                "factor": factor_name,
                "description": config["description"],
                "weight": config["weight"],
                "correlation": round(correlation, 3) if not np.isnan(correlation) else 0,
                "importance_rank": 0,  # ë‚˜ì¤‘ì— ì±„ì›€
                "avg_value": round(float(np.mean(values)), 2) if values else 0,
            })

        # ì¤‘ìš”ë„ ìˆœ ì •ë ¬
        factor_analysis.sort(key=lambda x: abs(x["correlation"]), reverse=True)
        for i, f in enumerate(factor_analysis):
            f["importance_rank"] = i + 1

        # ì£¼ìš” ë°œê²¬
        top_factor = factor_analysis[0] if factor_analysis else None

        result = {
            "method": "Cox Proportional Hazards Risk Factor Analysis",
            "factor_importance": factor_analysis,
            "key_finding": (
                f"ê°€ì¥ í° ì´íƒˆ ìš”ì¸: {top_factor['description']} "
                f"(ìƒê´€ê³„ìˆ˜ {top_factor['correlation']:.2f})"
                if top_factor else "ë°ì´í„° ë¶€ì¡±"
            ),
            "actionable_insights": self._factor_insights(factor_analysis),
        }

        llm_summary = await self._llm_call(
            f"ì´íƒˆ ìš”ì¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n{result}\n\n"
            "ê° ìš”ì¸ë³„ êµ¬ì²´ì ì¸ ê°œì„  ë°©ë²•ì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["ai_insight"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  5. ì´íƒˆ ë°©ì§€ ì „ëµ + ì˜ˆì‚° ë°°ë¶„
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _strategy(self, **kwargs) -> dict[str, Any]:
        """ì´íƒˆ ìœ„í—˜ ë“±ê¸‰ë³„ ë°©ì§€ ì „ëµê³¼ ì˜ˆì‚° ë°°ë¶„."""
        budget = kwargs.get("budget", 10000000)
        customers = self._parse_customers(kwargs.get("customers", ""))

        # ìœ„í—˜ ë“±ê¸‰ë³„ ë¶„ë¥˜
        groups = {"critical": [], "high": [], "medium": [], "low": [], "safe": []}
        for c in customers:
            score = self._calc_score(c)
            level = self._classify_risk(score)
            groups[level["key"]].append({**c, "churn_score": score})

        # ë“±ê¸‰ë³„ ì „ëµ + ì˜ˆì‚° ë°°ë¶„ (ROI ê¸°ë°˜)
        strategies = []
        budget_weights = {"critical": 0.35, "high": 0.30, "medium": 0.20, "low": 0.10, "safe": 0.05}

        for level_key, level_info in self.RISK_LEVELS.items():
            members = groups.get(level_key, [])
            if not members:
                continue

            allocated = round(budget * budget_weights[level_key])
            per_customer = round(allocated / len(members)) if members else 0

            strategies.append({
                "risk_level": level_info["label"],
                "customer_count": len(members),
                "allocated_budget": allocated,
                "per_customer": per_customer,
                "urgency": level_info["action_urgency"],
                "tactics": self._tactics_for_level(level_key),
                "expected_save_rate": self._expected_save_rate(level_key),
            })

        # ì´ êµ¬ì¶œ ê°€ëŠ¥ ê³ ê° ì¶”ì •
        total_saveable = sum(
            s["customer_count"] * s["expected_save_rate"]
            for s in strategies
        )

        result = {
            "total_budget": budget,
            "total_customers": len(customers),
            "strategies": strategies,
            "expected_outcome": {
                "estimated_saved_customers": round(total_saveable),
                "save_rate": f"{total_saveable/len(customers)*100:.1f}%"
                if customers else "0%",
                "cost_per_saved": round(budget / total_saveable)
                if total_saveable > 0 else 0,
            },
        }

        llm_summary = await self._llm_call(
            f"ì´íƒˆ ë°©ì§€ ì „ëµì…ë‹ˆë‹¤ (ì˜ˆì‚° {budget:,}ì›):\n{result}\n\n"
            "ì˜ˆì‚° íš¨ìœ¨ì„±ì„ í‰ê°€í•˜ê³  ì‹¤í–‰ ë¡œë“œë§µì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["ai_insight"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  6. ì¢…í•© ë¶„ì„
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _full_analysis(self, **kwargs) -> dict[str, Any]:
        """ì´íƒˆ ì ìˆ˜ + ìƒì¡´ ë¶„ì„ + ìš”ì¸ ë¶„ì„ + ì „ëµì„ í†µí•©."""
        batch = await self._batch(**kwargs)
        survival = await self._survival(**kwargs)
        factors = await self._factors(**kwargs)
        strategy = await self._strategy(**kwargs)

        result = {
            "summary": "êµìˆ˜ê¸‰ ì´íƒˆ ìœ„í—˜ ì¢…í•© ë¶„ì„ (Cox PH + KM + Logistic)",
            "1_batch_assessment": batch,
            "2_survival_analysis": survival,
            "3_factor_analysis": factors,
            "4_retention_strategy": strategy,
        }

        llm_summary = await self._llm_call(
            f"ì´íƒˆ ìœ„í—˜ ì¢…í•© ë¶„ì„ì…ë‹ˆë‹¤:\n\n"
            f"í‰ê·  ì´íƒˆ ì ìˆ˜: {batch['avg_churn_score']}\n"
            f"ì¤‘ê°„ ìƒì¡´ ê¸°ê°„: {survival['median_survival_months']}ê°œì›”\n"
            f"êµ¬ì¶œ ê°€ëŠ¥ ê³ ê°: {strategy['expected_outcome']['estimated_saved_customers']}ëª…\n\n"
            "ì „ì²´ë¥¼ ì¢…í•©í•˜ì—¬ ê³ ê° ìœ ì§€ ì „ëµ ë¡œë“œë§µì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["executive_summary"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  í•µì‹¬ ê³„ì‚° í•¨ìˆ˜
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _calc_score(self, customer: dict) -> float:
        """ê³ ê° ë°ì´í„°ë¡œ ì´íƒˆ ìœ„í—˜ ì ìˆ˜ ê³„ì‚°."""
        weighted_sum = 0.0
        total_weight = 0.0

        for factor_name, config in self.RISK_WEIGHTS.items():
            value = customer.get(factor_name, self._default_value(factor_name))
            risk = self._interpolate_risk(value, config["thresholds"])
            weighted_sum += max(0, min(100, risk * 100)) * config["weight"]
            total_weight += config["weight"]

        return weighted_sum / total_weight if total_weight > 0 else 50

    @staticmethod
    def _interpolate_risk(value: float, thresholds: list) -> float:
        """ì„ê³„ê°’ ê¸°ë°˜ ìœ„í—˜ ì ìˆ˜ ë³´ê°„."""
        for i, (thresh, risk) in enumerate(thresholds):
            if value <= thresh:
                if i == 0:
                    return risk
                prev_thresh, prev_risk = thresholds[i - 1]
                frac = (value - prev_thresh) / (thresh - prev_thresh) if thresh != prev_thresh else 0
                return prev_risk + frac * (risk - prev_risk)
        return thresholds[-1][1] if thresholds else 0.5

    def _classify_risk(self, score: float) -> dict:
        """ì ìˆ˜ â†’ ìœ„í—˜ ë“±ê¸‰."""
        for key, info in self.RISK_LEVELS.items():
            low, high = info["range"]
            if low <= score <= high:
                return {"key": key, **info}
        return {"key": "medium", **self.RISK_LEVELS["medium"]}

    @staticmethod
    def _default_value(factor_name: str) -> float:
        """ê¸°ë³¸ê°’ (ë°ì´í„° ì—†ì„ ë•Œ)."""
        defaults = {
            "recency_days": 30, "frequency_decline": 0.1,
            "support_tickets": 0, "payment_issues": 0,
            "engagement_score": 70, "tenure_months": 12,
        }
        return defaults.get(factor_name, 0)

    @staticmethod
    def _recommend_actions(score: float, factors: dict) -> list[str]:
        """ìœ„í—˜ ì ìˆ˜ ê¸°ë°˜ ê¶Œì¥ ì¡°ì¹˜."""
        actions = []
        if score >= 80:
            actions.append("ì¦‰ì‹œ ì „ë‹´ ë§¤ë‹ˆì € ë°°ì • + 1:1 í†µí™”/ë¯¸íŒ…")
            actions.append("íŠ¹ë³„ í• ì¸/í˜œíƒ ì œì•ˆ (ìµœëŒ€ 30%)")
        if score >= 60:
            actions.append("ì´íƒˆ ì›ì¸ ì¡°ì‚¬ ì„¤ë¬¸ ë°œì†¡")
            actions.append("ë§ì¶¤í˜• ë¦¬í…ì…˜ í”„ë¡œëª¨ì…˜ ì‹¤í–‰")

        # ìš”ì¸ë³„ ë§ì¶¤ ì•¡ì…˜
        for fname, fdata in factors.items():
            if fdata["risk_score"] >= 70:
                if fname == "recency_days":
                    actions.append("ì¬ë°©ë¬¸ ìœ ë„ ì´ë©”ì¼/í‘¸ì‹œ ì•Œë¦¼")
                elif fname == "frequency_decline":
                    actions.append("ì‚¬ìš© íŒ¨í„´ ë¶„ì„ í›„ ë§ì¶¤ ì½˜í…ì¸  ì œê³µ")
                elif fname == "support_tickets":
                    actions.append("CSíŒ€ ìš°ì„  ëŒ€ì‘ + ë¶ˆë§Œ í•´ê²° í™•ì¸")
                elif fname == "payment_issues":
                    actions.append("ê²°ì œ ìˆ˜ë‹¨ ë³€ê²½ ì•ˆë‚´ + ê²°ì œ ì¥ì•  í•´ê²°")
                elif fname == "engagement_score":
                    actions.append("ì˜¨ë³´ë”© ì¬ì‹¤í–‰ + í•µì‹¬ ê¸°ëŠ¥ ì‚¬ìš© ê°€ì´ë“œ")

        return actions[:5]  # ìµœëŒ€ 5ê°œ

    @staticmethod
    def _tactics_for_level(level: str) -> list[str]:
        """ë“±ê¸‰ë³„ ì „ìˆ ."""
        tactics = {
            "critical": ["ì „ë‹´ ë§¤ë‹ˆì € ì¦‰ì‹œ ë°°ì •", "ìµœëŒ€ í• ì¸ + ë¬´ë£Œ ê¸°ê°„ ì—°ì¥",
                         "1:1 í†µí™”ë¡œ ë¶ˆë§Œ í•´ê²°", "ê²½ìŸì‚¬ ì´ë™ ë°©ì§€ íŒ¨í‚¤ì§€"],
            "high": ["ë§ì¶¤í˜• ì´ë©”ì¼ ì‹œí€€ìŠ¤ (3ì¼)", "ë¦¬í…ì…˜ ì „ìš© í• ì¸ ì¿ í°",
                     "ì‚¬ìš© ê°€ì´ë“œ + íŒ ì½˜í…ì¸ ", "ë§Œì¡±ë„ ì¡°ì‚¬ + í”¼ë“œë°±"],
            "medium": ["ì›”ê°„ ë‰´ìŠ¤ë ˆí„° + ê°€ì¹˜ ë¦¬ë§ˆì¸ë“œ", "ë¦¬ì›Œë“œ í¬ì¸íŠ¸ ì ë¦½ ê°•í™”",
                       "ê´€ë ¨ ê¸°ëŠ¥ ì¶”ì²œ"],
            "low": ["ë¶„ê¸°ë³„ ê°ì‚¬ ì´ë©”ì¼", "ë¡œì—´í‹° í”„ë¡œê·¸ë¨ ì•ˆë‚´"],
            "safe": ["ì—…ì…€/í¬ë¡œìŠ¤ì…€ ê¸°íšŒ íƒìƒ‰", "ë¦¬í¼ëŸ´ í”„ë¡œê·¸ë¨ ì´ˆëŒ€"],
        }
        return tactics.get(level, [])

    @staticmethod
    def _expected_save_rate(level: str) -> float:
        """ë“±ê¸‰ë³„ ì˜ˆìƒ êµ¬ì¶œ ì„±ê³µë¥ ."""
        rates = {"critical": 0.15, "high": 0.30, "medium": 0.50,
                 "low": 0.70, "safe": 0.95}
        return rates.get(level, 0.5)

    @staticmethod
    def _churn_reduction_simulation(churn_rate, cohort, months, revenue):
        """ì´íƒˆë¥  ê°ì†Œ ì‹œ ìˆ˜ìµ ì˜í–¥ ì‹œë®¬ë ˆì´ì…˜."""
        scenarios = []
        for reduction_pct in [0, 10, 20, 30, 50]:
            new_churn = churn_rate * (1 - reduction_pct / 100)
            surviving = cohort
            total_rev = 0
            for m in range(months):
                total_rev += surviving * revenue
                surviving = surviving * (1 - new_churn)

            scenarios.append({
                "churn_reduction": f"{reduction_pct}%",
                "new_monthly_churn": f"{new_churn*100:.1f}%",
                "surviving_after_period": round(surviving),
                "total_revenue": round(total_rev),
            })

        base = scenarios[0]["total_revenue"]
        for s in scenarios:
            s["revenue_gain"] = round(s["total_revenue"] - base)
            s["gain_pct"] = f"{(s['total_revenue'] - base) / base * 100:+.1f}%" if base else "0%"

        return scenarios

    @staticmethod
    def _factor_insights(factors: list) -> list[str]:
        """ìš”ì¸ ë¶„ì„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸."""
        insights = []
        for f in factors[:3]:
            if abs(f["correlation"]) >= 0.5:
                direction = "ì–‘ì˜" if f["correlation"] > 0 else "ìŒì˜"
                insights.append(
                    f"{f['description']}ì´(ê°€) ì´íƒˆê³¼ {direction} ìƒê´€ê´€ê³„ "
                    f"(r={f['correlation']:.2f}) â€” ì´ ì§€í‘œë¥¼ ì¤‘ì  ê´€ë¦¬í•˜ì„¸ìš”"
                )
        return insights or ["ì£¼ìš” ì´íƒˆ ìš”ì¸ì— ëŒ€í•œ ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ì´ í•„ìš”í•©ë‹ˆë‹¤"]

    def _parse_customers(self, data) -> list[dict]:
        """ê³ ê° ë°ì´í„° íŒŒì‹±."""
        if isinstance(data, list) and data:
            return data
        if isinstance(data, str) and data.strip():
            import json
            try:
                parsed = json.loads(data)
                if isinstance(parsed, list):
                    return parsed
            except json.JSONDecodeError:
                pass

        # ìƒ˜í”Œ ë°ì´í„°
        return [
            {"id": "C001", "recency_days": 3, "frequency_decline": 0, "support_tickets": 0,
             "payment_issues": 0, "engagement_score": 90, "tenure_months": 24},
            {"id": "C002", "recency_days": 45, "frequency_decline": 0.3, "support_tickets": 2,
             "payment_issues": 0, "engagement_score": 50, "tenure_months": 8},
            {"id": "C003", "recency_days": 90, "frequency_decline": 0.6, "support_tickets": 5,
             "payment_issues": 1, "engagement_score": 20, "tenure_months": 3},
            {"id": "C004", "recency_days": 15, "frequency_decline": 0.1, "support_tickets": 1,
             "payment_issues": 0, "engagement_score": 75, "tenure_months": 18},
            {"id": "C005", "recency_days": 120, "frequency_decline": 0.8, "support_tickets": 8,
             "payment_issues": 2, "engagement_score": 10, "tenure_months": 2},
            {"id": "C006", "recency_days": 7, "frequency_decline": 0, "support_tickets": 0,
             "payment_issues": 0, "engagement_score": 85, "tenure_months": 36},
            {"id": "C007", "recency_days": 60, "frequency_decline": 0.4, "support_tickets": 3,
             "payment_issues": 1, "engagement_score": 35, "tenure_months": 6},
            {"id": "C008", "recency_days": 200, "frequency_decline": 0.9, "support_tickets": 0,
             "payment_issues": 3, "engagement_score": 5, "tenure_months": 1},
        ]
