"""
í˜ì–´ íŠ¸ë ˆì´ë”© ë¶„ì„ ë„êµ¬ (Pair Analyzer) â€” ë‘ ì¢…ëª© ê°„ ìƒê´€ê´€ê³„ + ì°¨ìµê±°ë˜ ê¸°íšŒ íƒìƒ‰.

"ì‚¼ì„±ì „ì-SKí•˜ì´ë‹‰ìŠ¤ì²˜ëŸ¼ ê°™ì´ ì›€ì§ì´ëŠ” ì¢…ëª©ì„ ì°¾ê³ ,
ì°¨ì´ê°€ ë²Œì–´ì§€ë©´ ë§¤ë§¤ ê¸°íšŒë¥¼ í¬ì°©"í•©ë‹ˆë‹¤.

í•™ìˆ  ê·¼ê±°:
  - í†µê³„ì  ì°¨ìµê±°ë˜ (Gatev, Goetzmann & Rouwenhorst, 2006)
  - ê³µì ë¶„ ë¶„ì„ (Engle-Granger Cointegration)
  - í‰ê·  íšŒê·€ ì „ëµ (Mean Reversion)

ì‚¬ìš© ë°©ë²•:
  - action="full"        : ì¢…í•© í˜ì–´ ë¶„ì„ (ìƒê´€+ìŠ¤í”„ë ˆë“œ+ì‹ í˜¸)
  - action="correlation"  : ë‘ ì¢…ëª© ìƒê´€ê´€ê³„ ë¶„ì„
  - action="spread"       : ìŠ¤í”„ë ˆë“œ(ê°€ê²©ì°¨ì´) ë¶„ì„
  - action="signal"       : ë§¤ë§¤ ì‹ í˜¸ (ì§„ì…/ì²­ì‚° íƒ€ì´ë°)
  - action="scan"         : í˜ì–´ í›„ë³´ ìë™ íƒìƒ‰ (ëŒ€í˜•ì£¼ ì¤‘)

í•„ìš” í™˜ê²½ë³€ìˆ˜: ì—†ìŒ
í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬: pykrx, pandas, numpy
"""
from __future__ import annotations

import asyncio
import logging
import math
from datetime import datetime, timedelta
from typing import Any

import numpy as np

from src.tools.base import BaseTool

logger = logging.getLogger("corthex.tools.pair_analyzer")


def _import_pykrx():
    try:
        from pykrx import stock
        return stock
    except ImportError:
        return None


class PairAnalyzerTool(BaseTool):
    """í˜ì–´ íŠ¸ë ˆì´ë”© ë¶„ì„ ë„êµ¬ â€” ìƒê´€ê´€ê³„ + ìŠ¤í”„ë ˆë“œ + ë§¤ë§¤ ì‹ í˜¸."""

    async def execute(self, **kwargs: Any) -> str:
        action = kwargs.get("action", "full")
        actions = {
            "full": self._full_pair,
            "correlation": self._correlation,
            "spread": self._spread_analysis,
            "signal": self._pair_signal,
            "scan": self._pair_scan,
        }
        handler = actions.get(action)
        if handler:
            return await handler(kwargs)
        return f"ì•Œ ìˆ˜ ì—†ëŠ” action: {action}. full, correlation, spread, signal, scan ì¤‘ í•˜ë‚˜."

    # â”€â”€ ê³µí†µ: ë‘ ì¢…ëª© ê°€ê²© ë°ì´í„° ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€

    async def _load_pair(self, kwargs: dict) -> tuple:
        stock = _import_pykrx()
        if stock is None:
            return None, None, None, None, "pykrx í•„ìš”"

        import pandas as pd

        stock_a = kwargs.get("name_a", "") or kwargs.get("stock_a", "")
        stock_b = kwargs.get("name_b", "") or kwargs.get("stock_b", "")

        # "ì‚¼ì„±ì „ì,SKí•˜ì´ë‹‰ìŠ¤" í˜•íƒœë„ ì§€ì›
        names = kwargs.get("names", "") or kwargs.get("query", "")
        if names and not stock_a:
            parts = [n.strip() for n in str(names).split(",") if n.strip()]
            if len(parts) >= 2:
                stock_a, stock_b = parts[0], parts[1]

        if not stock_a or not stock_b:
            return None, None, None, None, (
                "ë‘ ì¢…ëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n"
                "ì˜ˆ: names='ì‚¼ì„±ì „ì,SKí•˜ì´ë‹‰ìŠ¤' ë˜ëŠ” name_a='ì‚¼ì„±ì „ì', name_b='SKí•˜ì´ë‹‰ìŠ¤'"
            )

        days = int(kwargs.get("days", 365))
        end = datetime.now().strftime("%Y%m%d")
        start = (datetime.now() - timedelta(days=days)).strftime("%Y%m%d")

        ticker_a = await self._resolve_ticker(stock, stock_a)
        ticker_b = await self._resolve_ticker(stock, stock_b)
        if not ticker_a:
            return None, None, None, None, f"'{stock_a}' ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        if not ticker_b:
            return None, None, None, None, f"'{stock_b}' ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        try:
            df_a = await asyncio.to_thread(stock.get_market_ohlcv_by_date, start, end, ticker_a)
            df_b = await asyncio.to_thread(stock.get_market_ohlcv_by_date, start, end, ticker_b)
        except Exception as e:
            return None, None, None, None, f"ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}"

        if df_a.empty or df_b.empty or len(df_a) < 30 or len(df_b) < 30:
            return None, None, None, None, "ë°ì´í„° ë¶€ì¡± (ìµœì†Œ 30ì¼)"

        # ê³µí†µ ë‚ ì§œë§Œ
        common = df_a.index.intersection(df_b.index)
        prices_a = df_a.loc[common, "ì¢…ê°€"]
        prices_b = df_b.loc[common, "ì¢…ê°€"]

        return stock_a, stock_b, prices_a, prices_b, None

    async def _resolve_ticker(self, stock, name: str) -> str | None:
        try:
            today = datetime.now().strftime("%Y%m%d")
            tickers = await asyncio.to_thread(stock.get_market_ticker_list, today, market="ALL")
            for t in tickers:
                if await asyncio.to_thread(stock.get_market_ticker_name, t) == name:
                    return t
        except Exception:
            pass
        return None

    # â”€â”€ 1. ì¢…í•© í˜ì–´ ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _full_pair(self, kwargs: dict) -> str:
        name_a, name_b, pa, pb, err = await self._load_pair(kwargs)
        if err:
            return err

        # ìƒê´€ê´€ê³„
        corr = pa.corr(pb)

        # ì •ê·œí™” ê°€ê²© ë¹„ìœ¨ (ìŠ¤í”„ë ˆë“œ)
        ratio = pa / pb
        spread = (ratio - ratio.mean()) / ratio.std()

        # ë°˜ê°ê¸° (Mean Reversion Half-Life)
        half_life = self._calc_half_life(spread)

        # í˜„ì¬ ìŠ¤í”„ë ˆë“œ ìƒíƒœ
        current_z = spread.iloc[-1]

        # ìˆ˜ìµë¥  ìƒê´€ê´€ê³„
        ret_a = pa.pct_change().dropna()
        ret_b = pb.pct_change().dropna()
        common_idx = ret_a.index.intersection(ret_b.index)
        ret_corr = ret_a[common_idx].corr(ret_b[common_idx])

        results = [f"{'='*55}"]
        results.append(f"ğŸ“Š í˜ì–´ ë¶„ì„: {name_a} â†” {name_b}")
        results.append(f"{'='*55}\n")

        results.append(f"â–¸ ê°€ê²© ìƒê´€ê´€ê³„: {corr:.3f} ({'ê°•í•œ ì–‘ì˜ ìƒê´€' if corr > 0.7 else 'ì•½í•œ ìƒê´€' if corr > 0.3 else 'ë¬´ìƒê´€'})")
        results.append(f"â–¸ ìˆ˜ìµë¥  ìƒê´€ê´€ê³„: {ret_corr:.3f}")
        results.append(f"â–¸ í‰ê·  íšŒê·€ ë°˜ê°ê¸°: {half_life:.0f}ì¼" if half_life > 0 else "â–¸ í‰ê·  íšŒê·€ ë°˜ê°ê¸°: N/A")

        results.append(f"\nâ–¸ ìŠ¤í”„ë ˆë“œ (Z-score):")
        results.append(f"  í˜„ì¬: {current_z:.2f}")
        results.append(f"  í‰ê· : 0.00 / í‘œì¤€í¸ì°¨ Â±1.00")
        results.append(f"  ìµœëŒ€: {spread.max():.2f} / ìµœì†Œ: {spread.min():.2f}")

        # ë§¤ë§¤ ì‹ í˜¸
        if current_z > 2.0:
            signal = "ğŸ”´ ê°•í•œ ë§¤ë„ A / ë§¤ìˆ˜ B (ìŠ¤í”„ë ˆë“œ ê·¹ë‹¨ í™•ëŒ€)"
        elif current_z > 1.0:
            signal = "ğŸŸ¡ ë§¤ë„ A / ë§¤ìˆ˜ B (ìŠ¤í”„ë ˆë“œ í™•ëŒ€)"
        elif current_z < -2.0:
            signal = "ğŸ”´ ê°•í•œ ë§¤ìˆ˜ A / ë§¤ë„ B (ìŠ¤í”„ë ˆë“œ ê·¹ë‹¨ ì¶•ì†Œ)"
        elif current_z < -1.0:
            signal = "ğŸŸ¡ ë§¤ìˆ˜ A / ë§¤ë„ B (ìŠ¤í”„ë ˆë“œ ì¶•ì†Œ)"
        else:
            signal = "âšª ì¤‘ë¦½ (ìŠ¤í”„ë ˆë“œ ì •ìƒ ë²”ìœ„)"

        results.append(f"\nâ–¸ í˜ì–´ íŠ¸ë ˆì´ë”© ì‹ í˜¸: {signal}")
        results.append(f"\nâ–¸ í˜„ì¬ê°€:")
        results.append(f"  {name_a}: {int(pa.iloc[-1]):,}ì›")
        results.append(f"  {name_b}: {int(pb.iloc[-1]):,}ì›")
        results.append(f"  ë¹„ìœ¨ (A/B): {ratio.iloc[-1]:.4f}")

        raw_text = "\n".join(results)
        analysis = await self._llm_call(
            system_prompt=(
                "ë‹¹ì‹ ì€ í†µê³„ì  ì°¨ìµê±°ë˜(Statistical Arbitrage) ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                "í˜ì–´ íŠ¸ë ˆì´ë”© ë¶„ì„ ê²°ê³¼ë¥¼ í•´ì„í•˜ê³ , êµ¬ì²´ì ì¸ ì§„ì…/ì²­ì‚° ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”. "
                "Gatev et al.(2006) ì—°êµ¬ë¥¼ ì°¸ê³ í•˜ì„¸ìš”. í•œêµ­ì–´."
            ),
            user_prompt=raw_text,
            caller_model=kwargs.get("_caller_model"), caller_temperature=kwargs.get("_caller_temperature"),
        )
        return f"{raw_text}\n\n{'='*55}\nğŸ“ êµìˆ˜ê¸‰ í˜ì–´ ë¶„ì„\n{'='*55}\n{analysis}"

    # â”€â”€ 2. ìƒê´€ê´€ê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _correlation(self, kwargs: dict) -> str:
        name_a, name_b, pa, pb, err = await self._load_pair(kwargs)
        if err:
            return err

        corr = pa.corr(pb)
        ret_a = pa.pct_change().dropna()
        ret_b = pb.pct_change().dropna()
        common = ret_a.index.intersection(ret_b.index)
        ret_corr = ret_a[common].corr(ret_b[common])

        # ë¡¤ë§ ìƒê´€ê´€ê³„ (60ì¼)
        import pandas as pd
        rolling_corr = ret_a[common].rolling(60).corr(ret_b[common]).dropna()

        results = [f"ğŸ“Š ìƒê´€ê´€ê³„: {name_a} â†” {name_b}"]
        results.append(f"\nê°€ê²© ìƒê´€ê´€ê³„: {corr:.3f}")
        results.append(f"ìˆ˜ìµë¥  ìƒê´€ê´€ê³„: {ret_corr:.3f}")
        if not rolling_corr.empty:
            results.append(f"60ì¼ ë¡¤ë§ ìƒê´€ (í˜„ì¬): {rolling_corr.iloc[-1]:.3f}")
            results.append(f"60ì¼ ë¡¤ë§ ìƒê´€ (í‰ê· ): {rolling_corr.mean():.3f}")
            results.append(f"60ì¼ ë¡¤ë§ ìƒê´€ (ìµœì €): {rolling_corr.min():.3f}")

        if corr > 0.8:
            results.append(f"\nâ†’ ë§¤ìš° ë†’ì€ ìƒê´€ê´€ê³„ â€” í˜ì–´ íŠ¸ë ˆì´ë”©ì— ì í•©")
        elif corr > 0.5:
            results.append(f"\nâ†’ ì¤‘ê°„ ìƒê´€ê´€ê³„ â€” ì¡°ê±´ë¶€ í˜ì–´ ê°€ëŠ¥")
        else:
            results.append(f"\nâ†’ ë‚®ì€ ìƒê´€ê´€ê³„ â€” í˜ì–´ íŠ¸ë ˆì´ë”© ë¶€ì í•©")

        return "\n".join(results)

    # â”€â”€ 3. ìŠ¤í”„ë ˆë“œ ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _spread_analysis(self, kwargs: dict) -> str:
        name_a, name_b, pa, pb, err = await self._load_pair(kwargs)
        if err:
            return err

        ratio = pa / pb
        spread = (ratio - ratio.mean()) / ratio.std()
        half_life = self._calc_half_life(spread)

        results = [f"ğŸ“Š ìŠ¤í”„ë ˆë“œ ë¶„ì„: {name_a}/{name_b}"]
        results.append(f"\në¹„ìœ¨ (A/B):")
        results.append(f"  í˜„ì¬: {ratio.iloc[-1]:.4f}")
        results.append(f"  í‰ê· : {ratio.mean():.4f}")
        results.append(f"  Â±1Ïƒ: {ratio.mean()-ratio.std():.4f} ~ {ratio.mean()+ratio.std():.4f}")
        results.append(f"\nZ-score: {spread.iloc[-1]:.2f}")
        results.append(f"ë°˜ê°ê¸°: {half_life:.0f}ì¼" if half_life > 0 else "ë°˜ê°ê¸°: N/A")

        # ìŠ¤í”„ë ˆë“œ ì´ë ¥ (Â±2Ïƒ ì´íƒˆ íšŸìˆ˜)
        extreme = (spread.abs() > 2).sum()
        results.append(f"\nÂ±2Ïƒ ì´íƒˆ íšŸìˆ˜: {extreme}íšŒ (ì „ì²´ {len(spread)}ì¼ ì¤‘)")

        return "\n".join(results)

    # â”€â”€ 4. ë§¤ë§¤ ì‹ í˜¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _pair_signal(self, kwargs: dict) -> str:
        name_a, name_b, pa, pb, err = await self._load_pair(kwargs)
        if err:
            return err

        ratio = pa / pb
        spread = (ratio - ratio.mean()) / ratio.std()
        z = spread.iloc[-1]

        results = [f"ğŸ“Š í˜ì–´ íŠ¸ë ˆì´ë”© ì‹ í˜¸: {name_a} â†” {name_b}"]
        results.append(f"\ní˜„ì¬ Z-score: {z:.2f}")

        if z > 2.0:
            results.append(f"ğŸ”´ ê°•í•œ ì‹ í˜¸: {name_a} ë§¤ë„ + {name_b} ë§¤ìˆ˜")
            results.append(f"  (ìŠ¤í”„ë ˆë“œê°€ +2Ïƒ ì´ˆê³¼ â€” í‰ê· ìœ¼ë¡œ íšŒê·€í•  ê°€ëŠ¥ì„± ë†’ìŒ)")
        elif z > 1.0:
            results.append(f"ğŸŸ¡ ì•½í•œ ì‹ í˜¸: {name_a} ë§¤ë„ + {name_b} ë§¤ìˆ˜ ê³ ë ¤")
        elif z < -2.0:
            results.append(f"ğŸ”´ ê°•í•œ ì‹ í˜¸: {name_a} ë§¤ìˆ˜ + {name_b} ë§¤ë„")
            results.append(f"  (ìŠ¤í”„ë ˆë“œê°€ -2Ïƒ ë¯¸ë§Œ â€” í‰ê· ìœ¼ë¡œ íšŒê·€í•  ê°€ëŠ¥ì„± ë†’ìŒ)")
        elif z < -1.0:
            results.append(f"ğŸŸ¡ ì•½í•œ ì‹ í˜¸: {name_a} ë§¤ìˆ˜ + {name_b} ë§¤ë„ ê³ ë ¤")
        else:
            results.append(f"âšª ì¤‘ë¦½ â€” í¬ì§€ì…˜ ì—†ìŒ (ìŠ¤í”„ë ˆë“œ ì •ìƒ ë²”ìœ„)")

        results.append(f"\nì§„ì… ê¸°ì¤€: Z > +2.0 or Z < -2.0")
        results.append(f"ì²­ì‚° ê¸°ì¤€: Zê°€ 0 ë³µê·€")
        results.append(f"ì†ì ˆ ê¸°ì¤€: Z > +3.0 or Z < -3.0")

        return "\n".join(results)

    # â”€â”€ 5. í˜ì–´ í›„ë³´ ìë™ íƒìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _pair_scan(self, kwargs: dict) -> str:
        stock = _import_pykrx()
        if stock is None:
            return "pykrx í•„ìš”"

        import pandas as pd
        end = datetime.now().strftime("%Y%m%d")
        start = (datetime.now() - timedelta(days=180)).strftime("%Y%m%d")

        # ì‹œì´ ìƒìœ„ 20ì¢…ëª©
        try:
            cap_df = await asyncio.to_thread(stock.get_market_cap_by_ticker, end, market="KOSPI")
            top = cap_df.nlargest(20, "ì‹œê°€ì´ì•¡").index.tolist()
        except Exception:
            return "ì‹œê°€ì´ì•¡ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨"

        prices = {}
        names = {}
        for t in top:
            try:
                nm = await asyncio.to_thread(stock.get_market_ticker_name, t)
                ohlcv = await asyncio.to_thread(stock.get_market_ohlcv_by_date, start, end, t)
                if not ohlcv.empty and len(ohlcv) > 30:
                    prices[t] = ohlcv["ì¢…ê°€"]
                    names[t] = nm
            except Exception:
                continue

        if len(prices) < 2:
            return "ì¶©ë¶„í•œ ì¢…ëª© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        price_df = pd.DataFrame(prices).dropna()
        corr_matrix = price_df.corr()

        # ìƒê´€ê´€ê³„ ë†’ì€ í˜ì–´ ì°¾ê¸°
        pairs = []
        tickers = list(prices.keys())
        for i in range(len(tickers)):
            for j in range(i + 1, len(tickers)):
                c = corr_matrix.loc[tickers[i], tickers[j]]
                if c > 0.7:
                    pairs.append((names[tickers[i]], names[tickers[j]], c))

        pairs.sort(key=lambda x: x[2], reverse=True)

        results = [f"ğŸ“Š í˜ì–´ íŠ¸ë ˆì´ë”© í›„ë³´ íƒìƒ‰ (KOSPI ëŒ€í˜•ì£¼)"]
        results.append(f"\nìƒê´€ê´€ê³„ 0.7 ì´ìƒ í˜ì–´ ({len(pairs)}ìŒ ë°œê²¬):")
        results.append(f"\n{'ì¢…ëª© A':>10} â†” {'ì¢…ëª© B':>10} | ìƒê´€ê³„ìˆ˜")
        results.append("-" * 40)
        for a, b, c in pairs[:15]:
            results.append(f"  {a:>8} â†” {b:>8} | {c:.3f}")

        if not pairs:
            results.append("  (ìƒê´€ê´€ê³„ 0.7 ì´ìƒ í˜ì–´ ì—†ìŒ)")

        return "\n".join(results)

    # â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def _calc_half_life(spread) -> float:
        """í‰ê·  íšŒê·€ ë°˜ê°ê¸° (Ornstein-Uhlenbeck ëª¨ë¸)."""
        try:
            lag = spread.shift(1).dropna()
            delta = spread.diff().dropna()
            common = lag.index.intersection(delta.index)
            if len(common) < 10:
                return -1
            x = lag[common].values
            y = delta[common].values
            # OLS: delta_S = theta * (mu - S) + epsilon
            # ê°„ë‹¨íˆ delta_S = beta * S_lag + alpha
            beta = np.cov(x, y)[0, 1] / np.var(x) if np.var(x) > 0 else 0
            if beta >= 0:
                return -1  # í‰ê·  íšŒê·€ ì•„ë‹˜
            return -np.log(2) / beta
        except Exception:
            return -1
