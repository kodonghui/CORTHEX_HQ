"""
ì‹œìž¥ ê°ì„± ë¶„ì„ ë„êµ¬ (Sentiment Scorer) â€” ë‰´ìŠ¤/ê³µì‹œ í…ìŠ¤íŠ¸ ê°ì„± ì ìˆ˜ ë§¤ê¸°ê¸°.

"ì´ ì¢…ëª©ì— ëŒ€í•œ ì‹œìž¥ ë¶„ìœ„ê¸°ê°€ ì¢‹ì€ê°€ ë‚˜ìœê°€?"ë¥¼ NLPë¡œ ì¸¡ì •í•©ë‹ˆë‹¤.

í•™ìˆ  ê·¼ê±°:
  - NLP ê°ì„±ë¶„ì„ (FinBERT, Loughran-McDonald Dictionary)
  - ë‰´ìŠ¤ ê°ì„±ê³¼ ì£¼ê°€ ìˆ˜ìµë¥  ìƒê´€ê´€ê³„ (Tetlock, 2007)
  - ì†Œì…œë¯¸ë””ì–´ ê°ì„±ê³¼ ì£¼ê°€ ì˜ˆì¸¡ (Bollen et al., 2011)

ì‚¬ìš© ë°©ë²•:
  - action="full"     : ì¢…í•© ê°ì„± ë¶„ì„ (ë‰´ìŠ¤ + ê³µì‹œ + ì¢…í•©)
  - action="news"     : ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ê°ì„± ë¶„ì„
  - action="market"   : ì‹œìž¥ ì „ì²´ ë¶„ìœ„ê¸° (ê³µí¬/íƒìš• ì§€ìˆ˜)
  - action="keyword"  : í‚¤ì›Œë“œë³„ ê°ì„± íŠ¸ë Œë“œ

í•„ìš” í™˜ê²½ë³€ìˆ˜: NAVER_CLIENT_ID, NAVER_CLIENT_SECRET (ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰)
í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬: aiohttp
"""
from __future__ import annotations

import asyncio
import logging
import math
import os
import re
from datetime import datetime, timedelta
from typing import Any

from src.tools.base import BaseTool

logger = logging.getLogger("corthex.tools.sentiment_scorer")


# í•œêµ­ì–´ ê¸ˆìœµ ê°ì„± ì‚¬ì „ (Loughran-McDonald í•œêµ­ì–´ ë²„ì „ + ì¶”ê°€)
POSITIVE_WORDS = {
    "ìƒìŠ¹", "ê¸‰ë“±", "í˜¸ì¡°", "ì„±ìž¥", "ê°œì„ ", "í‘ìž", "ìµœê³ ", "ê¸°ëŒ€", "í˜¸ì‹¤ì ",
    "ì„œí”„ë¼ì´ì¦ˆ", "ëŒíŒŒ", "ë°˜ë“±", "íšŒë³µ", "í™•ëŒ€", "ìˆ˜í˜œ", "í˜¸ìž¬", "ê°•ì„¸",
    "ì‹ ê³ ê°€", "ë§¤ìˆ˜", "ì¶”ì²œ", "ëª©í‘œê°€ìƒí–¥", "ì‹¤ì ê°œì„ ", "í„´ì–´ë¼ìš´ë“œ", "ìˆ˜ì£¼",
    "ê³„ì•½", "í•©ì˜", "ìŠ¹ì¸", "íŠ¹í—ˆ", "í˜ì‹ ", "ì¸ìˆ˜", "íˆ¬ìž", "í™•ìž¥",
}

NEGATIVE_WORDS = {
    "í•˜ë½", "ê¸‰ë½", "ë¶€ì§„", "ê°ì†Œ", "ì ìž", "ìµœì €", "ìš°ë ¤", "ì•…ìž¬", "ì‹¤ì ë¶€ì§„",
    "ì‡¼í¬", "ì´íƒˆ", "í­ë½", "ìœ„ì¶•", "ì¶•ì†Œ", "ë¦¬ìŠ¤í¬", "ì•½ì„¸", "ì‹ ì €ê°€",
    "ë§¤ë„", "í•˜í–¥", "ëª©í‘œê°€í•˜í–¥", "ì‹¤ì ì•…í™”", "ë¶€ì‹¤", "ì†ì‹¤", "ì œìž¬",
    "ì†Œì†¡", "íŒŒì‚°", "í•´ê³ ", "ì² ìˆ˜", "ì¤‘ë‹¨", "ë…¼ëž€", "ì˜í˜¹",
}


class SentimentScorerTool(BaseTool):
    """ì‹œìž¥ ê°ì„± ë¶„ì„ ë„êµ¬ â€” ë‰´ìŠ¤ ê¸°ë°˜ ê¸ì •/ë¶€ì • ê°ì„± ì ìˆ˜."""

    async def execute(self, **kwargs: Any) -> str:
        query = kwargs.get("query", "")
        if query and not kwargs.get("name"):
            kwargs["name"] = query

        action = kwargs.get("action", "full")
        actions = {
            "full": self._full_sentiment,
            "news": self._news_sentiment,
            "market": self._market_sentiment,
            "keyword": self._keyword_sentiment,
        }
        handler = actions.get(action)
        if handler:
            return await handler(kwargs)
        return f"ì•Œ ìˆ˜ ì—†ëŠ” action: {action}. full, news, market, keyword ì¤‘ í•˜ë‚˜."

    # â”€â”€ ë‰´ìŠ¤ ê²€ìƒ‰ (ë„¤ì´ë²„ API) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _search_news(self, query: str, count: int = 30) -> list[dict]:
        """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        client_id = os.getenv("NAVER_CLIENT_ID", "")
        client_secret = os.getenv("NAVER_CLIENT_SECRET", "")

        if not client_id or not client_secret:
            return []

        try:
            import aiohttp
        except ImportError:
            return []

        url = "https://openapi.naver.com/v1/search/news.json"
        headers = {
            "X-Naver-Client-Id": client_id,
            "X-Naver-Client-Secret": client_secret,
        }
        params = {"query": query, "display": count, "sort": "date"}

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, params=params) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return data.get("items", [])
        except Exception as e:
            logger.warning("ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: %s", e)

        return []

    @staticmethod
    def _clean_html(text: str) -> str:
        """HTML íƒœê·¸ ì œê±°."""
        return re.sub(r"<[^>]+>", "", text).replace("&quot;", '"').replace("&amp;", "&")

    def _score_text(self, text: str) -> tuple[float, list[str], list[str]]:
        """í…ìŠ¤íŠ¸ì˜ ê°ì„± ì ìˆ˜ (-1 ~ +1) ê³„ì‚°. (ì ìˆ˜, ê¸ì •ë‹¨ì–´ë“¤, ë¶€ì •ë‹¨ì–´ë“¤) ë°˜í™˜."""
        positive_found = [w for w in POSITIVE_WORDS if w in text]
        negative_found = [w for w in NEGATIVE_WORDS if w in text]
        pos_count = len(positive_found)
        neg_count = len(negative_found)
        total = pos_count + neg_count
        if total == 0:
            return 0.0, [], []
        score = (pos_count - neg_count) / total
        return score, positive_found, negative_found

    # â”€â”€ 1. ì¢…í•© ê°ì„± ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _full_sentiment(self, kwargs: dict) -> str:
        name = kwargs.get("name", "")
        if not name:
            return "ì¢…ëª©ëª…(name)ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: name='ì‚¼ì„±ì „ìž'"

        news = await self._search_news(f"{name} ì£¼ì‹", 30)

        if not news:
            # ë‰´ìŠ¤ API ì—†ìœ¼ë©´ LLMìœ¼ë¡œ ê°ì„± ë¶„ì„
            analysis = await self._llm_call(
                system_prompt=(
                    "ë‹¹ì‹ ì€ ê¸ˆìœµ ì‹œìž¥ ê°ì„± ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. "
                    f"'{name}'ì— ëŒ€í•œ ìµœê·¼ ì‹œìž¥ ë¶„ìœ„ê¸°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. "
                    "ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ë¹„ìœ¨, ì£¼ìš” ì´ìŠˆ, ê°ì„± ì ìˆ˜(0~100)ë¥¼ ì œì‹œí•˜ì„¸ìš”. í•œêµ­ì–´."
                ),
                user_prompt=f"{name}ì˜ ìµœê·¼ ì‹œìž¥ ê°ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
                caller_model=kwargs.get("_caller_model"),
            )
            return f"ðŸ“Š {name} ì‹œìž¥ ê°ì„± ë¶„ì„ (LLM ê¸°ë°˜)\n\n{analysis}"

        # ë‰´ìŠ¤ ê°ì„± ë¶„ì„
        scores = []
        pos_total = []
        neg_total = []
        headlines = []

        for item in news:
            title = self._clean_html(item.get("title", ""))
            desc = self._clean_html(item.get("description", ""))
            text = f"{title} {desc}"
            score, pos, neg = self._score_text(text)
            scores.append(score)
            pos_total.extend(pos)
            neg_total.extend(neg)
            emoji = "ðŸŸ¢" if score > 0.2 else "ðŸ”´" if score < -0.2 else "âšª"
            headlines.append(f"  {emoji} {title[:50]}")

        avg_score = sum(scores) / len(scores) if scores else 0
        pos_pct = sum(1 for s in scores if s > 0.1) / len(scores) * 100 if scores else 0
        neg_pct = sum(1 for s in scores if s < -0.1) / len(scores) * 100 if scores else 0
        neu_pct = 100 - pos_pct - neg_pct

        # ê°ì„± ì ìˆ˜ë¥¼ 0~100ìœ¼ë¡œ ì •ê·œí™”
        sentiment_100 = int((avg_score + 1) * 50)

        results = [f"{'='*55}"]
        results.append(f"ðŸ“Š {name} ì‹œìž¥ ê°ì„± ë¶„ì„ ({len(news)}ê±´ ë‰´ìŠ¤)")
        results.append(f"{'='*55}\n")
        results.append(f"â–¸ ì¢…í•© ê°ì„± ì ìˆ˜: {sentiment_100}/100 ì ")

        if sentiment_100 >= 70:
            results.append(f"  â†’ ðŸŸ¢ ë§¤ìš° ê¸ì •ì  (ê°•í•œ ë§¤ìˆ˜ ë¶„ìœ„ê¸°)")
        elif sentiment_100 >= 55:
            results.append(f"  â†’ ðŸŸ¢ ê¸ì •ì  (ë§¤ìˆ˜ ìš°ìœ„)")
        elif sentiment_100 >= 45:
            results.append(f"  â†’ âšª ì¤‘ë¦½ (ê´€ë§)")
        elif sentiment_100 >= 30:
            results.append(f"  â†’ ðŸ”´ ë¶€ì •ì  (ë§¤ë„ ìš°ìœ„)")
        else:
            results.append(f"  â†’ ðŸ”´ ë§¤ìš° ë¶€ì •ì  (ê°•í•œ ë§¤ë„ ë¶„ìœ„ê¸°)")

        results.append(f"\nâ–¸ ê°ì„± ë¹„ìœ¨: ê¸ì • {pos_pct:.0f}% / ì¤‘ë¦½ {neu_pct:.0f}% / ë¶€ì • {neg_pct:.0f}%")

        # ìžì£¼ ë‚˜ì˜¤ëŠ” í‚¤ì›Œë“œ
        from collections import Counter
        pos_counter = Counter(pos_total)
        neg_counter = Counter(neg_total)
        if pos_counter:
            results.append(f"\nâ–¸ ê¸ì • í‚¤ì›Œë“œ: {', '.join(f'{w}({c})' for w, c in pos_counter.most_common(5))}")
        if neg_counter:
            results.append(f"â–¸ ë¶€ì • í‚¤ì›Œë“œ: {', '.join(f'{w}({c})' for w, c in neg_counter.most_common(5))}")

        results.append(f"\nâ–¸ ìµœê·¼ ë‰´ìŠ¤ í—¤ë“œë¼ì¸:")
        results.extend(headlines[:10])

        raw_text = "\n".join(results)
        analysis = await self._llm_call(
            system_prompt=(
                "ë‹¹ì‹ ì€ ê¸ˆìœµ NLP ê°ì„±ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. "
                "ë‰´ìŠ¤ ê¸°ë°˜ ê°ì„± ë¶„ì„ ê²°ê³¼ë¥¼ í•´ì„í•˜ê³ , "
                "ê°ì„± ì§€í‘œê°€ ì£¼ê°€ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì˜ˆì¸¡í•˜ì„¸ìš”. "
                "Tetlock(2007)ì˜ ì—°êµ¬ë¥¼ ì°¸ê³ í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”. í•œêµ­ì–´."
            ),
            user_prompt=raw_text,
            caller_model=kwargs.get("_caller_model"),
        )
        return f"{raw_text}\n\n{'='*55}\nðŸŽ“ êµìˆ˜ê¸‰ ê°ì„± ë¶„ì„\n{'='*55}\n{analysis}"

    # â”€â”€ 2. ë‰´ìŠ¤ ê°ì„± ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _news_sentiment(self, kwargs: dict) -> str:
        return await self._full_sentiment(kwargs)

    # â”€â”€ 3. ì‹œìž¥ ì „ì²´ ë¶„ìœ„ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _market_sentiment(self, kwargs: dict) -> str:
        analysis = await self._llm_call(
            system_prompt=(
                "ë‹¹ì‹ ì€ ì‹œìž¥ ì‹¬ë¦¬ ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. "
                "í˜„ìž¬(2026ë…„ 2ì›”) í•œêµ­ ì£¼ì‹ì‹œìž¥ì˜ ê³µí¬/íƒìš• ì§€ìˆ˜ë¥¼ 0~100ìœ¼ë¡œ ë§¤ê¸°ê³ , "
                "KOSPI, ì›ë‹¬ëŸ¬ í™˜ìœ¨, ê¸ˆë¦¬, ì™¸ì¸ ë§¤ë§¤ ë™í–¥ì„ ì¢…í•©í•˜ì—¬ "
                "ì‹œìž¥ ì „ì²´ ë¶„ìœ„ê¸°ë¥¼ ë¶„ì„í•˜ì„¸ìš”. êµ¬ì²´ì ì¸ ìˆ«ìžë¡œ. í•œêµ­ì–´."
            ),
            user_prompt="í˜„ìž¬ í•œêµ­ ì£¼ì‹ì‹œìž¥ ê³µí¬/íƒìš• ì§€ìˆ˜ì™€ ì‹œìž¥ ë¶„ìœ„ê¸° ë¶„ì„",
            caller_model=kwargs.get("_caller_model"),
        )
        return f"ðŸ“Š ì‹œìž¥ ì „ì²´ ê°ì„± ë¶„ì„ (ê³µí¬/íƒìš• ì§€ìˆ˜)\n\n{analysis}"

    # â”€â”€ 4. í‚¤ì›Œë“œ ê°ì„± íŠ¸ë Œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _keyword_sentiment(self, kwargs: dict) -> str:
        keyword = kwargs.get("name", "") or kwargs.get("keyword", "") or kwargs.get("query", "")
        if not keyword:
            return "í‚¤ì›Œë“œë¥¼ ìž…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: keyword='ë°˜ë„ì²´'"

        news = await self._search_news(keyword, 20)
        if not news:
            analysis = await self._llm_call(
                system_prompt=f"'{keyword}' í‚¤ì›Œë“œì— ëŒ€í•œ ìµœê·¼ ì‹œìž¥ ê°ì„± íŠ¸ë Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. í•œêµ­ì–´.",
                user_prompt=f"'{keyword}' ê°ì„± ë¶„ì„",
                caller_model=kwargs.get("_caller_model"),
            )
            return f"ðŸ“Š '{keyword}' ê°ì„± íŠ¸ë Œë“œ (LLM ê¸°ë°˜)\n\n{analysis}"

        scores = []
        for item in news:
            text = self._clean_html(f"{item.get('title', '')} {item.get('description', '')}")
            score, _, _ = self._score_text(text)
            scores.append(score)

        avg = sum(scores) / len(scores) if scores else 0
        score_100 = int((avg + 1) * 50)

        return f"ðŸ“Š '{keyword}' ê°ì„± ì ìˆ˜: {score_100}/100 ({len(news)}ê±´ ë¶„ì„)\nâ†’ {'ê¸ì •' if score_100 > 55 else 'ë¶€ì •' if score_100 < 45 else 'ì¤‘ë¦½'}"
