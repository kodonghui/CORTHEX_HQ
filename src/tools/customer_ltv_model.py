"""
ê³ ê° ìƒì• ê°€ì¹˜(CLV) ì˜ˆì¸¡ ë„êµ¬ â€” ê³ ê° í•œ ëª…ì´ í‰ìƒ ê°€ì ¸ë‹¤ì¤„ ë§¤ì¶œì„ ìˆ˜í•™ì ìœ¼ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

"ì´ ê³ ê°ì€ ì•ìœ¼ë¡œ ì–¼ë§ˆì¹˜ë¥¼ ì“¸ê¹Œ?"ë¥¼ í™•ë¥  ëª¨ë¸ë¡œ ì¶”ì •í•˜ê³ ,
ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ íˆ¬ì ìš°ì„ ìˆœìœ„ë¥¼ ì œì‹œí•˜ëŠ” êµìˆ˜ê¸‰ CLV ë¶„ì„ ë„êµ¬ì…ë‹ˆë‹¤.

í•™ìˆ  ê·¼ê±°:
  - BG/NBD ëª¨ë¸ (Fader, Hardie & Lee, "Counting Your Customers", 2005)
  - Gamma-Gamma ëª¨ë¸ (Fader & Hardie, "The Gamma-Gamma Model of Monetary Value", 2013)
  - Pareto/NBD ëª¨ë¸ (Schmittlein, Morrison & Colombo, 1987)
  - RFM ê¸°ë°˜ CLV ì¶”ì • (Hughes, "Strategic Database Marketing", 1994)
  - í• ì¸ CLV (Gupta & Lehmann, "Customers as Assets", 2005)
  - ê³ ê° ìˆ˜ìµì„± ë¶„ì„ (Pfeifer, Haskins & Conroy, 2005)

ì‚¬ìš© ë°©ë²•:
  - action="predict"    : ê°œë³„ ê³ ê° CLV ì˜ˆì¸¡ (BG/NBD + Gamma-Gamma)
  - action="segment"    : ê³ ê°êµ°ë³„ CLV ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„
  - action="cohort"     : ê°€ì… ì½”í˜¸íŠ¸ë³„ CLV ë¹„êµ
  - action="unit_economics" : ìœ ë‹› ì´ì½”ë…¸ë¯¹ìŠ¤ (CAC vs CLV)
  - action="discount"   : í• ì¸ CLV (í™”íì˜ ì‹œê°„ê°€ì¹˜ ë°˜ì˜)
  - action="full"       : ì¢…í•© CLV ë¶„ì„

í•„ìš” í™˜ê²½ë³€ìˆ˜: ì—†ìŒ
í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬: numpy
"""
from __future__ import annotations

import logging
import math
from typing import Any

import numpy as np

from src.tools.base import BaseTool

logger = logging.getLogger("corthex.tools.customer_ltv_model")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  BG/NBD í™•ë¥  í•¨ìˆ˜ (ìˆœìˆ˜ Python â€” lifetimes íŒ¨í‚¤ì§€ ë¶ˆí•„ìš”)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _beta_function(a: float, b: float) -> float:
    """ë² íƒ€ í•¨ìˆ˜ B(a,b) = Gamma(a)*Gamma(b)/Gamma(a+b)."""
    return math.exp(math.lgamma(a) + math.lgamma(b) - math.lgamma(a + b))


def _hyp2f1_simple(a: float, b: float, c: float, z: float,
                   max_iter: int = 200) -> float:
    """Gauss ì´ˆê¸°í•˜ê¸‰ìˆ˜ 2F1(a,b;c;z) â€” BG/NBD ìƒì¡´í™•ë¥  ê³„ì‚°ì— í•„ìš”.

    |z| < 1 ë²”ìœ„ì—ì„œ ê¸‰ìˆ˜ ì „ê°œ (BG/NBDì—ì„œëŠ” í•­ìƒ ì´ ë²”ìœ„).
    """
    result = 1.0
    term = 1.0
    for n in range(1, max_iter):
        term *= (a + n - 1) * (b + n - 1) / (c + n - 1) * z / n
        result += term
        if abs(term) < 1e-12:
            break
    return result


class CustomerLtvModelTool(BaseTool):
    """êµìˆ˜ê¸‰ ê³ ê° ìƒì• ê°€ì¹˜ ì˜ˆì¸¡ ë„êµ¬ (BG/NBD + Gamma-Gamma)."""

    # â”€â”€â”€ ì—…ì¢…ë³„ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° â”€â”€â”€
    BENCHMARKS = {
        "saas": {
            "avg_monthly_churn": 0.05,  # ì›” 5%
            "avg_arpu": 50000,          # ì›” 5ë§Œì›
            "avg_cac": 150000,
            "good_ltv_cac_ratio": 3.0,
            "great_ltv_cac_ratio": 5.0,
        },
        "ecommerce": {
            "avg_monthly_churn": 0.08,
            "avg_arpu": 35000,
            "avg_cac": 25000,
            "good_ltv_cac_ratio": 3.0,
            "great_ltv_cac_ratio": 5.0,
        },
        "subscription_box": {
            "avg_monthly_churn": 0.10,
            "avg_arpu": 30000,
            "avg_cac": 40000,
            "good_ltv_cac_ratio": 2.5,
            "great_ltv_cac_ratio": 4.0,
        },
        "mobile_app": {
            "avg_monthly_churn": 0.15,
            "avg_arpu": 5000,
            "avg_cac": 3000,
            "good_ltv_cac_ratio": 3.0,
            "great_ltv_cac_ratio": 5.0,
        },
        "fintech": {
            "avg_monthly_churn": 0.03,
            "avg_arpu": 80000,
            "avg_cac": 200000,
            "good_ltv_cac_ratio": 3.0,
            "great_ltv_cac_ratio": 6.0,
        },
    }

    # â”€â”€â”€ BG/NBD ë””í´íŠ¸ íŒŒë¼ë¯¸í„° (ì—…ì¢… í‰ê· ) â”€â”€â”€
    # (r, alpha, a, b) â€” Fader & Hardie (2005) Table 1 ì°¸ê³ 
    DEFAULT_BGNBD_PARAMS = {
        "saas":             (0.243, 4.414, 0.793, 2.426),
        "ecommerce":        (0.525, 6.183, 0.891, 1.614),
        "subscription_box": (0.389, 3.756, 1.052, 1.238),
        "mobile_app":       (0.712, 8.921, 1.234, 0.987),
        "fintech":          (0.183, 3.142, 0.654, 3.215),
        "default":          (0.350, 5.000, 0.900, 1.800),
    }

    async def execute(self, **kwargs) -> dict[str, Any]:
        action = kwargs.get("action", "full")
        dispatch = {
            "predict": self._predict,
            "segment": self._segment,
            "cohort": self._cohort,
            "unit_economics": self._unit_economics,
            "discount": self._discount_clv,
            "full": self._full_analysis,
        }
        handler = dispatch.get(action)
        if not handler:
            return {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” action: {action}. "
                    f"ê°€ëŠ¥í•œ ê°’: {list(dispatch.keys())}"}
        return await handler(**kwargs)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  1. ê°œë³„ ê³ ê° CLV ì˜ˆì¸¡ (BG/NBD + Gamma-Gamma)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _predict(self, **kwargs) -> dict[str, Any]:
        """BG/NBDë¡œ ë¯¸ë˜ êµ¬ë§¤ íšŸìˆ˜ ì˜ˆì¸¡ + Gamma-Gammaë¡œ ê°ë‹¨ê°€ ì¶”ì • â†’ CLV."""
        frequency = kwargs.get("frequency", 5)       # ë°˜ë³µ êµ¬ë§¤ íšŸìˆ˜
        recency = kwargs.get("recency", 30)           # ìµœê·¼ êµ¬ë§¤ê¹Œì§€ ê²½ê³¼ì¼
        T = kwargs.get("T", 365)                      # ê´€ì°° ê¸°ê°„ (ì¼)
        monetary = kwargs.get("monetary", 50000)      # í‰ê·  ì£¼ë¬¸ê¸ˆì•¡
        horizon = kwargs.get("horizon", 365)          # ì˜ˆì¸¡ ê¸°ê°„ (ì¼)
        industry = kwargs.get("industry", "default")

        # BG/NBD íŒŒë¼ë¯¸í„° ì„ íƒ
        r, alpha, a, b = self.DEFAULT_BGNBD_PARAMS.get(
            industry, self.DEFAULT_BGNBD_PARAMS["default"]
        )

        # â”€â”€â”€ BG/NBD: ë¯¸ë˜ ê¸°ëŒ€ êµ¬ë§¤ íšŸìˆ˜ E[X(t)|x, t_x, T] â”€â”€â”€
        # Fader, Hardie & Lee (2005), Equation 10
        x = frequency
        t_x = recency

        # ìƒì¡´ í™•ë¥  P(alive | x, t_x, T)
        p_alive = self._bg_nbd_p_alive(x, t_x, T, r, alpha, a, b)

        # ê¸°ëŒ€ ë¯¸ë˜ êµ¬ë§¤ íšŸìˆ˜
        expected_purchases = self._bg_nbd_expected_purchases(
            horizon, x, t_x, T, r, alpha, a, b
        )

        # â”€â”€â”€ Gamma-Gamma: ê¸°ëŒ€ í‰ê·  ê±°ë˜ê¸ˆì•¡ E[M|x, m_x] â”€â”€â”€
        # Fader & Hardie (2013), Equation 2
        # íŒŒë¼ë¯¸í„° (p, q, gamma)
        p_gg, q_gg, gamma_gg = 1.2, 0.8, 15000.0  # ì—…ì¢… ë””í´íŠ¸
        expected_monetary = self._gamma_gamma_expected_value(
            x, monetary, p_gg, q_gg, gamma_gg
        )

        # â”€â”€â”€ CLV = ê¸°ëŒ€ êµ¬ë§¤íšŸìˆ˜ Ã— ê¸°ëŒ€ ê°ë‹¨ê°€ â”€â”€â”€
        clv = expected_purchases * expected_monetary

        # ì‹ ë¢°êµ¬ê°„ (ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜)
        clv_simulations = self._simulate_clv(
            x, t_x, T, monetary, horizon, r, alpha, a, b,
            p_gg, q_gg, gamma_gg, n_sim=5000
        )
        ci_lower = float(np.percentile(clv_simulations, 5))
        ci_upper = float(np.percentile(clv_simulations, 95))

        result = {
            "model": "BG/NBD + Gamma-Gamma",
            "customer_input": {
                "frequency": x,
                "recency_days": t_x,
                "observation_days": T,
                "avg_order_value": monetary,
                "prediction_horizon_days": horizon,
            },
            "predictions": {
                "p_alive": round(p_alive, 4),
                "p_alive_pct": f"{p_alive*100:.1f}%",
                "expected_future_purchases": round(expected_purchases, 2),
                "expected_avg_order_value": round(expected_monetary),
                "predicted_clv": round(clv),
                "clv_90_ci": [round(ci_lower), round(ci_upper)],
            },
            "interpretation": self._interpret_prediction(
                p_alive, expected_purchases, clv, industry
            ),
            "academic_reference": (
                "Fader, Hardie & Lee (2005) 'Counting Your Customers the Easy Way' + "
                "Fader & Hardie (2013) 'The Gamma-Gamma Model of Monetary Value'"
            ),
        }

        # LLM ì¸ì‚¬ì´íŠ¸ í•©ì„±
        llm_summary = await self._llm_call(
            f"ê³ ê° CLV ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{result}\n\n"
            "ì´ ê³ ê°ì˜ ê°€ì¹˜ì™€ ê´€ë¦¬ ì „ëµì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["ai_insight"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  2. ê³ ê°êµ°ë³„ CLV ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _segment(self, **kwargs) -> dict[str, Any]:
        """ê³ ê° ë°ì´í„°ë¥¼ CLV ê¸°ë°˜ìœ¼ë¡œ 4~5ê°œ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„ë¥˜."""
        customers_json = kwargs.get("customers", "")
        industry = kwargs.get("industry", "default")

        # ìƒ˜í”Œ ë°ì´í„° ë˜ëŠ” ì‹¤ì œ ë°ì´í„° íŒŒì‹±
        customers = self._parse_customers(customers_json)

        r, alpha, a, b = self.DEFAULT_BGNBD_PARAMS.get(
            industry, self.DEFAULT_BGNBD_PARAMS["default"]
        )
        p_gg, q_gg, gamma_gg = 1.2, 0.8, 15000.0

        # ê° ê³ ê°ì˜ CLV ê³„ì‚°
        clv_list = []
        for c in customers:
            freq = c.get("frequency", 1)
            rec = c.get("recency", 30)
            obs = c.get("T", 365)
            mon = c.get("monetary", 30000)

            p_alive = self._bg_nbd_p_alive(freq, rec, obs, r, alpha, a, b)
            exp_purch = self._bg_nbd_expected_purchases(
                365, freq, rec, obs, r, alpha, a, b
            )
            exp_mon = self._gamma_gamma_expected_value(
                freq, mon, p_gg, q_gg, gamma_gg
            )
            clv = exp_purch * exp_mon

            clv_list.append({
                "customer_id": c.get("id", f"C{len(clv_list)+1:03d}"),
                "frequency": freq,
                "recency": rec,
                "monetary": mon,
                "p_alive": round(p_alive, 3),
                "predicted_clv": round(clv),
            })

        # CLV ê¸°ë°˜ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜
        clv_values = [c["predicted_clv"] for c in clv_list]
        if len(clv_values) >= 4:
            q25, q50, q75 = (
                float(np.percentile(clv_values, 25)),
                float(np.percentile(clv_values, 50)),
                float(np.percentile(clv_values, 75)),
            )
        else:
            avg = np.mean(clv_values)
            q25, q50, q75 = avg * 0.5, avg, avg * 1.5

        segments = {
            "Champions (ìµœìš°ìˆ˜)": [],
            "Loyal (ì¶©ì„±)": [],
            "Potential (ì ì¬ ì„±ì¥)": [],
            "At Risk (ê´€ë¦¬ í•„ìš”)": [],
        }
        for c in clv_list:
            clv = c["predicted_clv"]
            if clv >= q75:
                segments["Champions (ìµœìš°ìˆ˜)"].append(c)
            elif clv >= q50:
                segments["Loyal (ì¶©ì„±)"].append(c)
            elif clv >= q25:
                segments["Potential (ì ì¬ ì„±ì¥)"].append(c)
            else:
                segments["At Risk (ê´€ë¦¬ í•„ìš”)"].append(c)

        segment_summary = {}
        for seg_name, members in segments.items():
            if members:
                seg_clvs = [m["predicted_clv"] for m in members]
                segment_summary[seg_name] = {
                    "count": len(members),
                    "pct": f"{len(members)/len(clv_list)*100:.1f}%",
                    "avg_clv": round(np.mean(seg_clvs)),
                    "total_clv": round(sum(seg_clvs)),
                    "strategy": self._segment_strategy(seg_name),
                }

        result = {
            "total_customers": len(clv_list),
            "total_predicted_clv": round(sum(clv_values)),
            "avg_clv": round(np.mean(clv_values)),
            "clv_distribution": {
                "min": round(min(clv_values)),
                "q25": round(q25),
                "median": round(q50),
                "q75": round(q75),
                "max": round(max(clv_values)),
            },
            "segments": segment_summary,
            "pareto_principle": self._check_pareto(clv_values),
        }

        llm_summary = await self._llm_call(
            f"ê³ ê° CLV ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n{result}\n\n"
            "ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ êµ¬ì²´ì ì¸ ë§ˆì¼€íŒ…/ê´€ë¦¬ ì „ëµì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["ai_insight"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  3. ì½”í˜¸íŠ¸ë³„ CLV ë¹„êµ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _cohort(self, **kwargs) -> dict[str, Any]:
        """ê°€ì… ì‹œê¸°(ì½”í˜¸íŠ¸)ë³„ CLV ì¶”ì´ ë¶„ì„."""
        cohorts_json = kwargs.get("cohorts", "")
        industry = kwargs.get("industry", "default")

        cohorts = self._parse_cohorts(cohorts_json)

        r, alpha, a, b = self.DEFAULT_BGNBD_PARAMS.get(
            industry, self.DEFAULT_BGNBD_PARAMS["default"]
        )

        cohort_results = []
        for cohort in cohorts:
            name = cohort.get("name", "Unknown")
            size = cohort.get("size", 100)
            avg_freq = cohort.get("avg_frequency", 3)
            avg_rec = cohort.get("avg_recency", 60)
            avg_T = cohort.get("avg_T", 180)
            avg_mon = cohort.get("avg_monetary", 40000)

            p_alive = self._bg_nbd_p_alive(avg_freq, avg_rec, avg_T, r, alpha, a, b)
            exp_purch = self._bg_nbd_expected_purchases(
                365, avg_freq, avg_rec, avg_T, r, alpha, a, b
            )
            avg_clv = exp_purch * avg_mon
            total_clv = avg_clv * size * p_alive

            cohort_results.append({
                "cohort": name,
                "size": size,
                "avg_frequency": avg_freq,
                "avg_monetary": avg_mon,
                "survival_rate": f"{p_alive*100:.1f}%",
                "avg_clv": round(avg_clv),
                "total_cohort_clv": round(total_clv),
            })

        # ì½”í˜¸íŠ¸ ê°„ ë¹„êµ
        if len(cohort_results) >= 2:
            best = max(cohort_results, key=lambda x: x["avg_clv"])
            worst = min(cohort_results, key=lambda x: x["avg_clv"])
            improvement = ((best["avg_clv"] - worst["avg_clv"])
                           / worst["avg_clv"] * 100) if worst["avg_clv"] > 0 else 0
        else:
            best = worst = cohort_results[0] if cohort_results else {}
            improvement = 0

        result = {
            "cohorts": cohort_results,
            "comparison": {
                "best_cohort": best.get("cohort", "N/A"),
                "worst_cohort": worst.get("cohort", "N/A"),
                "clv_gap_pct": f"{improvement:.1f}%",
            },
            "trend_analysis": "ìµœê·¼ ì½”í˜¸íŠ¸ì˜ CLVê°€ ì¦ê°€ ì¶”ì„¸"
            if len(cohort_results) >= 2 and
            cohort_results[-1]["avg_clv"] > cohort_results[0]["avg_clv"]
            else "ìµœê·¼ ì½”í˜¸íŠ¸ì˜ CLVê°€ ê°ì†Œ ì¶”ì„¸ â€” ì›ì¸ ë¶„ì„ í•„ìš”",
        }

        llm_summary = await self._llm_call(
            f"ì½”í˜¸íŠ¸ë³„ CLV ë¹„êµ ê²°ê³¼ì…ë‹ˆë‹¤:\n{result}\n\n"
            "ì½”í˜¸íŠ¸ ê°„ ì°¨ì´ì˜ ì›ì¸ê³¼ ê°œì„  ë°©í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”."
        )
        result["ai_insight"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  4. ìœ ë‹› ì´ì½”ë…¸ë¯¹ìŠ¤ (CAC vs CLV)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _unit_economics(self, **kwargs) -> dict[str, Any]:
        """CAC ëŒ€ë¹„ CLV ë¹„ìœ¨, íšŒìˆ˜ ê¸°ê°„, ì±„ë„ë³„ ROI ë¶„ì„."""
        clv = kwargs.get("clv", 300000)
        cac = kwargs.get("cac", 100000)
        monthly_revenue = kwargs.get("monthly_revenue", 25000)
        gross_margin = kwargs.get("gross_margin", 0.7)
        monthly_churn = kwargs.get("monthly_churn", 0.05)
        industry = kwargs.get("industry", "default")

        # â”€â”€â”€ CLV:CAC ë¹„ìœ¨ â”€â”€â”€
        ltv_cac_ratio = clv / cac if cac > 0 else float("inf")

        # â”€â”€â”€ CAC íšŒìˆ˜ ê¸°ê°„ (Payback Period) â”€â”€â”€
        monthly_margin = monthly_revenue * gross_margin
        payback_months = cac / monthly_margin if monthly_margin > 0 else float("inf")

        # â”€â”€â”€ ë‹¨ìˆœ CLV ê³„ì‚° (ë³´ì¡° ì§€í‘œ) â”€â”€â”€
        # CLV_simple = ARPU Ã— Gross Margin / Churn Rate
        simple_clv = (monthly_revenue * gross_margin / monthly_churn
                      if monthly_churn > 0 else 0)

        # â”€â”€â”€ ë§ˆì§„ ì¡°ì • CLV â”€â”€â”€
        margin_adjusted_clv = clv * gross_margin

        # â”€â”€â”€ Gupta & Lehmann (2005) í• ì¸ CLV â”€â”€â”€
        discount_rate = 0.10 / 12  # ì—° 10% â†’ ì›” í• ì¸ìœ¨
        retention_rate = 1 - monthly_churn
        dcf_clv = (monthly_revenue * gross_margin * retention_rate
                   / (1 + discount_rate - retention_rate)
                   if (1 + discount_rate - retention_rate) > 0 else 0)

        # ë²¤ì¹˜ë§ˆí¬ ë¹„êµ
        bench = self.BENCHMARKS.get(industry, {})
        bench_ratio = bench.get("good_ltv_cac_ratio", 3.0)

        # ê±´ê°•ë„ íŒì •
        if ltv_cac_ratio >= 5:
            health = "ğŸŸ¢ íƒì›” â€” CLVê°€ CACì˜ 5ë°° ì´ìƒ. ë§ˆì¼€íŒ… íˆ¬ì í™•ëŒ€ ê°€ëŠ¥"
        elif ltv_cac_ratio >= 3:
            health = "ğŸŸ¢ ê±´ê°• â€” ì—…ê³„ ê¸°ì¤€ ì¶©ì¡±. ì•ˆì •ì  ì„±ì¥ ê°€ëŠ¥"
        elif ltv_cac_ratio >= 1:
            health = "ğŸŸ¡ ì£¼ì˜ â€” CAC íšŒìˆ˜ëŠ” ë˜ì§€ë§Œ ë§ˆì§„ì´ ì–‡ìŒ. ë¦¬í…ì…˜ ê°•í™” í•„ìš”"
        else:
            health = "ğŸ”´ ìœ„í—˜ â€” ê³ ê° 1ëª…ë‹¹ ì†ì‹¤ ë°œìƒ. CAC ì ˆê° ë˜ëŠ” CLV í–¥ìƒ ì‹œê¸‰"

        result = {
            "unit_economics": {
                "clv": round(clv),
                "cac": round(cac),
                "ltv_cac_ratio": round(ltv_cac_ratio, 2),
                "payback_months": round(payback_months, 1),
                "gross_margin": f"{gross_margin*100:.0f}%",
                "monthly_churn": f"{monthly_churn*100:.1f}%",
            },
            "clv_methods_comparison": {
                "bg_nbd_clv": round(clv),
                "simple_clv": round(simple_clv),
                "margin_adjusted_clv": round(margin_adjusted_clv),
                "dcf_clv_gupta_lehmann": round(dcf_clv),
            },
            "health_check": health,
            "benchmark": {
                "industry": industry,
                "recommended_ltv_cac": f"â‰¥ {bench_ratio}x",
                "your_ratio": f"{ltv_cac_ratio:.1f}x",
                "gap": f"{ltv_cac_ratio - bench_ratio:+.1f}x",
            },
            "improvement_levers": self._improvement_levers(
                ltv_cac_ratio, payback_months, monthly_churn
            ),
        }

        llm_summary = await self._llm_call(
            f"ìœ ë‹› ì´ì½”ë…¸ë¯¹ìŠ¤ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n{result}\n\n"
            "í˜„ì¬ ì‚¬ì—…ì˜ ìˆ˜ìµ êµ¬ì¡°ë¥¼ í‰ê°€í•˜ê³  ê°œì„  ìš°ì„ ìˆœìœ„ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["ai_insight"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  5. í• ì¸ CLV (í™”íì˜ ì‹œê°„ê°€ì¹˜ ë°˜ì˜)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _discount_clv(self, **kwargs) -> dict[str, Any]:
        """DCF ë°©ì‹ìœ¼ë¡œ ë¯¸ë˜ ìˆ˜ìµì˜ í˜„ì¬ê°€ì¹˜ë¥¼ ê³„ì‚°í•˜ëŠ” ì •ë°€ CLV."""
        monthly_revenue = kwargs.get("monthly_revenue", 50000)
        gross_margin = kwargs.get("gross_margin", 0.7)
        monthly_churn = kwargs.get("monthly_churn", 0.05)
        annual_discount_rate = kwargs.get("discount_rate", 0.10)
        horizon_months = kwargs.get("horizon_months", 60)

        retention = 1 - monthly_churn
        monthly_discount = annual_discount_rate / 12
        monthly_margin = monthly_revenue * gross_margin

        # â”€â”€â”€ ì›”ë³„ í• ì¸ í˜„ê¸ˆíë¦„ â”€â”€â”€
        dcf_monthly = []
        cumulative = 0.0
        survival_prob = 1.0

        for month in range(1, horizon_months + 1):
            survival_prob *= retention
            discount_factor = 1 / (1 + monthly_discount) ** month
            present_value = monthly_margin * survival_prob * discount_factor
            cumulative += present_value
            dcf_monthly.append({
                "month": month,
                "survival_rate": round(survival_prob, 4),
                "nominal_value": round(monthly_margin * survival_prob),
                "present_value": round(present_value),
                "cumulative_pv": round(cumulative),
            })

        # ë¬´í•œ ê¸°ê°„ í•´ì„ì  CLV (Gupta & Lehmann ê³µì‹)
        infinite_clv = (monthly_margin * retention
                        / (1 + monthly_discount - retention)
                        if (1 + monthly_discount - retention) > 0 else 0)

        # ìˆ˜ë ´ë„: horizon ê¸°ê°„ CLV / ë¬´í•œ CLV
        convergence = cumulative / infinite_clv if infinite_clv > 0 else 1.0

        # ì£¼ìš” ë§ˆì¼ìŠ¤í†¤ (25%, 50%, 75% ë„ë‹¬ ì‹œì )
        milestones = {}
        for target_pct in [0.25, 0.50, 0.75]:
            target_val = infinite_clv * target_pct
            for entry in dcf_monthly:
                if entry["cumulative_pv"] >= target_val:
                    milestones[f"{int(target_pct*100)}%_month"] = entry["month"]
                    break

        # ë¯¼ê°ë„: ì´íƒˆë¥  Â±1%p, í• ì¸ìœ¨ Â±2%p
        sensitivity = []
        for churn_adj in [-0.02, -0.01, 0, 0.01, 0.02]:
            for disc_adj in [-0.02, 0, 0.02]:
                adj_churn = max(0.001, monthly_churn + churn_adj)
                adj_disc = max(0.001, annual_discount_rate + disc_adj) / 12
                adj_ret = 1 - adj_churn
                adj_clv = (monthly_margin * adj_ret
                           / (1 + adj_disc - adj_ret)
                           if (1 + adj_disc - adj_ret) > 0 else 0)
                sensitivity.append({
                    "churn": f"{adj_churn*100:.1f}%",
                    "discount": f"{(annual_discount_rate + disc_adj)*100:.0f}%",
                    "clv": round(adj_clv),
                })

        result = {
            "discount_clv": {
                "horizon_months": horizon_months,
                "horizon_clv": round(cumulative),
                "infinite_clv": round(infinite_clv),
                "convergence": f"{convergence*100:.1f}%",
            },
            "parameters": {
                "monthly_revenue": monthly_revenue,
                "gross_margin": f"{gross_margin*100:.0f}%",
                "monthly_churn": f"{monthly_churn*100:.1f}%",
                "annual_discount_rate": f"{annual_discount_rate*100:.0f}%",
            },
            "milestones": milestones,
            "monthly_projection": dcf_monthly[:12],  # ì²˜ìŒ 12ê°œì›”ë§Œ í‘œì‹œ
            "sensitivity_analysis": sensitivity,
            "academic_reference": "Gupta & Lehmann (2005) 'Customers as Assets'",
        }

        llm_summary = await self._llm_call(
            f"í• ì¸ CLV ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n{result}\n\n"
            "ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼ë¥¼ í¬í•¨í•´ CLV ê·¹ëŒ€í™” ì „ëµì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["ai_insight"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  6. ì¢…í•© ë¶„ì„
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def _full_analysis(self, **kwargs) -> dict[str, Any]:
        """ê°œë³„ ì˜ˆì¸¡ + ìœ ë‹› ì´ì½”ë…¸ë¯¹ìŠ¤ + í• ì¸ CLVë¥¼ í†µí•©."""
        prediction = await self._predict(**kwargs)
        unit_econ = await self._unit_economics(
            clv=prediction["predictions"]["predicted_clv"],
            **{k: v for k, v in kwargs.items() if k not in ("action",)}
        )
        discount = await self._discount_clv(**kwargs)

        result = {
            "summary": "êµìˆ˜ê¸‰ CLV ì¢…í•© ë¶„ì„ (BG/NBD + Gamma-Gamma + DCF)",
            "1_individual_prediction": prediction,
            "2_unit_economics": unit_econ,
            "3_discount_clv": discount,
        }

        llm_summary = await self._llm_call(
            f"CLV ì¢…í•© ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n"
            f"ê°œë³„ ì˜ˆì¸¡ CLV: {prediction['predictions']['predicted_clv']:,}ì›\n"
            f"LTV:CAC ë¹„ìœ¨: {unit_econ['unit_economics']['ltv_cac_ratio']}\n"
            f"í• ì¸ CLV: {discount['discount_clv']['infinite_clv']:,}ì›\n\n"
            "ì „ì²´ë¥¼ ì¢…í•©í•˜ì—¬ ê³ ê° ê°€ì¹˜ ê´€ë¦¬ ì „ëµ ë¡œë“œë§µì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
        )
        result["executive_summary"] = llm_summary
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  BG/NBD í•µì‹¬ ìˆ˜í•™ í•¨ìˆ˜
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    @staticmethod
    def _bg_nbd_p_alive(x: int, t_x: float, T: float,
                        r: float, alpha: float,
                        a: float, b: float) -> float:
        """BG/NBD P(alive | x, t_x, T) â€” Fader et al. (2005) Eq. 7.

        ê³ ê°ì´ ì•„ì§ 'í™œë™ ì¤‘'ì¼ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        if x == 0:
            # êµ¬ë§¤ ì´ë ¥ ì—†ìœ¼ë©´ â†’ ê°„ë‹¨ ê·¼ì‚¬
            p_alive = (b / (a + b - 1)) ** max(0, T - t_x) if a + b > 1 else 0.5
            return max(0.0, min(1.0, p_alive))

        # A1 = (a / (b + x - 1)) * ((alpha + T) / (alpha + t_x))^(r + x)
        try:
            ratio = (alpha + T) / (alpha + t_x) if (alpha + t_x) > 0 else 1.0
            A1 = (a / (b + x - 1)) * (ratio ** (r + x))
            p_alive = 1.0 / (1.0 + A1)
        except (OverflowError, ZeroDivisionError):
            p_alive = 0.5

        return max(0.0, min(1.0, p_alive))

    @staticmethod
    def _bg_nbd_expected_purchases(t: float, x: int, t_x: float, T: float,
                                   r: float, alpha: float,
                                   a: float, b: float) -> float:
        """BG/NBD E[X(t) | x, t_x, T] â€” ë¯¸ë˜ tì¼ê°„ ê¸°ëŒ€ êµ¬ë§¤ íšŸìˆ˜.

        Fader et al. (2005) Eq. 10ì˜ ê°„ì†Œí™” ë²„ì „.
        """
        # ê°„ì†Œí™”: Î» ì¶”ì • (ê°œì¸ êµ¬ë§¤ìœ¨)
        # E[Î»] â‰ˆ (r + x) / (alpha + T)
        lambda_est = (r + x) / (alpha + T) if (alpha + T) > 0 else 0

        # P(alive) ë°˜ì˜
        p_alive = CustomerLtvModelTool._bg_nbd_p_alive(
            x, t_x, T, r, alpha, a, b
        )

        # E[X(t)] = Î» Ã— t Ã— P(alive)
        expected = lambda_est * t * p_alive
        return max(0.0, expected)

    @staticmethod
    def _gamma_gamma_expected_value(x: int, monetary: float,
                                    p: float, q: float,
                                    gamma: float) -> float:
        """Gamma-Gamma E[M | x, m_x] â€” ê¸°ëŒ€ í‰ê·  ê±°ë˜ê¸ˆì•¡.

        Fader & Hardie (2013) Eq. 2.
        """
        if x <= 0:
            return monetary

        # E[M | x, m_x] = (q * gamma + x * m_x) / (q + x - 1)
        expected = (q * gamma + x * monetary) / (q + x - 1) if (q + x - 1) > 0 else monetary
        return max(0.0, expected)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    @staticmethod
    def _simulate_clv(x, t_x, T, monetary, horizon,
                      r, alpha, a, b,
                      p_gg, q_gg, gamma_gg,
                      n_sim: int = 5000) -> np.ndarray:
        """CLV ì‹ ë¢°êµ¬ê°„ì„ ìœ„í•œ ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜."""
        rng = np.random.default_rng(42)

        # Î» (êµ¬ë§¤ìœ¨) ì‚¬í›„ ë¶„í¬: Gamma(r+x, alpha+T)
        lambda_samples = rng.gamma(r + x, 1.0 / (alpha + T), size=n_sim)

        # p (ì´íƒˆ í™•ë¥ ) ì‚¬í›„ ë¶„í¬: Beta(a, b+x)
        p_dropout = rng.beta(a, max(0.01, b + x), size=n_sim)

        # ê°ë‹¨ê°€ ë³€ë™: ì •ê·œë¶„í¬ ê·¼ì‚¬
        monetary_samples = rng.normal(monetary, monetary * 0.2, size=n_sim)
        monetary_samples = np.maximum(monetary_samples, 1000)

        # ê° ì‹œë®¬ë ˆì´ì…˜ì—ì„œ CLV ê³„ì‚°
        alive_prob = 1 - p_dropout
        expected_purchases = lambda_samples * horizon * alive_prob
        clv_samples = expected_purchases * monetary_samples

        return clv_samples

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    #  í—¬í¼ í•¨ìˆ˜ë“¤
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _parse_customers(self, data) -> list[dict]:
        """ê³ ê° ë°ì´í„° íŒŒì‹± (JSON ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)."""
        if isinstance(data, list) and data:
            return data
        if isinstance(data, str) and data.strip():
            import json
            try:
                parsed = json.loads(data)
                if isinstance(parsed, list):
                    return parsed
            except json.JSONDecodeError:
                pass

        # ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜ (ì‹¤ì œ ë°ì´í„° ì—†ì„ ë•Œ)
        return [
            {"id": "C001", "frequency": 12, "recency": 5,   "T": 365, "monetary": 85000},
            {"id": "C002", "frequency": 3,  "recency": 90,  "T": 365, "monetary": 42000},
            {"id": "C003", "frequency": 8,  "recency": 15,  "T": 300, "monetary": 63000},
            {"id": "C004", "frequency": 1,  "recency": 200, "T": 365, "monetary": 28000},
            {"id": "C005", "frequency": 20, "recency": 2,   "T": 365, "monetary": 120000},
            {"id": "C006", "frequency": 2,  "recency": 150, "T": 365, "monetary": 35000},
            {"id": "C007", "frequency": 6,  "recency": 30,  "T": 180, "monetary": 55000},
            {"id": "C008", "frequency": 15, "recency": 7,   "T": 365, "monetary": 95000},
        ]

    def _parse_cohorts(self, data) -> list[dict]:
        """ì½”í˜¸íŠ¸ ë°ì´í„° íŒŒì‹±."""
        if isinstance(data, list) and data:
            return data
        if isinstance(data, str) and data.strip():
            import json
            try:
                parsed = json.loads(data)
                if isinstance(parsed, list):
                    return parsed
            except json.JSONDecodeError:
                pass

        return [
            {"name": "2025-Q3", "size": 500, "avg_frequency": 2, "avg_recency": 120,
             "avg_T": 180, "avg_monetary": 35000},
            {"name": "2025-Q4", "size": 600, "avg_frequency": 3, "avg_recency": 60,
             "avg_T": 120, "avg_monetary": 42000},
            {"name": "2026-Q1", "size": 450, "avg_frequency": 4, "avg_recency": 20,
             "avg_T": 60, "avg_monetary": 48000},
        ]

    @staticmethod
    def _interpret_prediction(p_alive, expected_purchases, clv, industry):
        """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í•´ì„ìœ¼ë¡œ ë³€í™˜."""
        lines = []
        if p_alive >= 0.8:
            lines.append("ì´ ê³ ê°ì€ í˜„ì¬ í™œë™ ì¤‘ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ (ìƒì¡´ í™•ë¥  80%+).")
        elif p_alive >= 0.5:
            lines.append("ì´ ê³ ê°ì€ í™œë™ ì¤‘ì¼ ê°€ëŠ¥ì„±ì´ ìˆì§€ë§Œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            lines.append("ì´ ê³ ê°ì€ ì´íƒˆí–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì¬í™œì„±í™” ìº í˜ì¸ì„ ê³ ë ¤í•˜ì„¸ìš”.")

        if expected_purchases >= 10:
            lines.append(f"í–¥í›„ 1ë…„ê°„ ì•½ {expected_purchases:.0f}íšŒ êµ¬ë§¤ê°€ ì˜ˆìƒë©ë‹ˆë‹¤ (ê³ ë¹ˆë„ ê³ ê°).")
        elif expected_purchases >= 3:
            lines.append(f"í–¥í›„ 1ë…„ê°„ ì•½ {expected_purchases:.0f}íšŒ êµ¬ë§¤ê°€ ì˜ˆìƒë©ë‹ˆë‹¤ (ì¤‘ê°„ ë¹ˆë„).")
        else:
            lines.append(f"í–¥í›„ 1ë…„ê°„ ì•½ {expected_purchases:.1f}íšŒ êµ¬ë§¤ê°€ ì˜ˆìƒë©ë‹ˆë‹¤ (ì €ë¹ˆë„).")

        return " ".join(lines)

    @staticmethod
    def _segment_strategy(segment_name: str) -> str:
        """ì„¸ê·¸ë¨¼íŠ¸ë³„ ê¶Œì¥ ì „ëµ."""
        strategies = {
            "Champions (ìµœìš°ìˆ˜)": "VIP í˜œíƒ, ì‹ ì œí’ˆ ì–¼ë¦¬ì—‘ì„¸ìŠ¤, ë¦¬í¼ëŸ´ í”„ë¡œê·¸ë¨ ìš°ì„  íƒ€ê²Ÿ",
            "Loyal (ì¶©ì„±)": "ì—…ì…€/í¬ë¡œìŠ¤ì…€ ê¸°íšŒ ë°œêµ´, ë¡œì—´í‹° í¬ì¸íŠ¸ ì ë¦½ ê°•í™”",
            "Potential (ì ì¬ ì„±ì¥)": "ê°œì¸í™” ì¶”ì²œ, í• ì¸ ì¿ í°, ì‚¬ìš© íŒ¨í„´ ë¶„ì„ í›„ ë§ì¶¤ ì œì•ˆ",
            "At Risk (ê´€ë¦¬ í•„ìš”)": "ì¬í™œì„±í™” ì´ë©”ì¼, í•œì • í”„ë¡œëª¨ì…˜, ì´íƒˆ ì›ì¸ ì¡°ì‚¬",
        }
        return strategies.get(segment_name, "")

    @staticmethod
    def _check_pareto(clv_values: list) -> dict:
        """íŒŒë ˆí†  ë²•ì¹™(80/20) ê²€ì¦."""
        sorted_clvs = sorted(clv_values, reverse=True)
        total = sum(sorted_clvs)
        top_20_count = max(1, int(len(sorted_clvs) * 0.2))
        top_20_value = sum(sorted_clvs[:top_20_count])
        top_20_pct = top_20_value / total * 100 if total > 0 else 0

        return {
            "top_20_pct_customers": f"{top_20_count}ëª… ({20}%)",
            "top_20_pct_clv": f"{top_20_pct:.1f}%",
            "pareto_holds": top_20_pct >= 60,
            "interpretation": (
                f"ìƒìœ„ 20% ê³ ê°ì´ ì „ì²´ CLVì˜ {top_20_pct:.0f}%ë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤."
                + (" íŒŒë ˆí†  ë²•ì¹™ì´ ê°•í•˜ê²Œ ì„±ë¦½í•©ë‹ˆë‹¤." if top_20_pct >= 70 else "")
            ),
        }

    @staticmethod
    def _improvement_levers(ltv_cac: float, payback: float,
                            churn: float) -> list[dict]:
        """ê°œì„  ë ˆë²„ ìš°ì„ ìˆœìœ„ ì œì•ˆ."""
        levers = []
        if churn > 0.08:
            levers.append({
                "priority": 1,
                "lever": "ì´íƒˆë¥  ê°ì†Œ",
                "current": f"{churn*100:.1f}%/ì›”",
                "target": f"{churn*100*0.7:.1f}%/ì›” (-30%)",
                "impact": "ì´íƒˆë¥  30% ê°ì†Œ ì‹œ CLV ì•½ 43% ì¦ê°€ (1/churn ê´€ê³„)",
            })
        if payback > 12:
            levers.append({
                "priority": 2 if levers else 1,
                "lever": "CAC íšŒìˆ˜ ê¸°ê°„ ë‹¨ì¶•",
                "current": f"{payback:.0f}ê°œì›”",
                "target": "12ê°œì›” ì´í•˜",
                "impact": "ì˜¨ë³´ë”© ê°œì„ , ë¹ ë¥¸ ê°€ì¹˜ ì „ë‹¬ë¡œ ì´ˆê¸° ì´íƒˆ ë°©ì§€",
            })
        if ltv_cac < 3:
            levers.append({
                "priority": len(levers) + 1,
                "lever": "CLV:CAC ë¹„ìœ¨ ê°œì„ ",
                "current": f"{ltv_cac:.1f}x",
                "target": "3.0x ì´ìƒ",
                "impact": "ë§ˆì§„ ê°œì„  + ì—…ì…€ + ë¦¬í…ì…˜ ë³µí•© ì „ëµ í•„ìš”",
            })
        if not levers:
            levers.append({
                "priority": 1,
                "lever": "ì„±ì¥ íˆ¬ì í™•ëŒ€",
                "current": "ê±´ê°•í•œ ìœ ë‹› ì´ì½”ë…¸ë¯¹ìŠ¤",
                "target": "CAC í—ˆìš© ë²”ìœ„ ë‚´ì—ì„œ ë³¼ë¥¨ í™•ëŒ€",
                "impact": "í˜„ì¬ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë§ˆì¼€íŒ… ì˜ˆì‚° ì¦ì•¡ ê°€ëŠ¥",
            })
        return levers
