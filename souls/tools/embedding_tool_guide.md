# embedding_tool — 임베딩 도구 가이드

## 이 도구는 뭔가요?
텍스트를 AI가 이해할 수 있는 숫자 벡터(숫자 배열)로 변환하는 도구입니다.
쉽게 말해, "비슷한 의미의 글은 비슷한 숫자로 표현된다"는 원리를 이용합니다.
두 문장이 얼마나 비슷한지 유사도를 계산하거나, 여러 텍스트를 의미가 비슷한 것끼리 자동으로 그룹으로 묶어주는 기능도 있습니다.

## 어떤 API를 쓰나요?
- **OpenAI Embeddings API** (모델: `text-embedding-3-small`)
- 비용: **유료** (매우 저렴 — 약 $0.02/1M 토큰, 100만 글자 기준 약 25원)
- 필요한 키: `OPENAI_API_KEY`

## 사용법

### action=embed (단일 텍스트 벡터 변환)
```
action=embed, text="벡터로 변환할 텍스트", model="text-embedding-3-small"
```
- 하나의 텍스트를 숫자 벡터(1536차원)로 변환합니다
- model: 임베딩 모델 (기본값: text-embedding-3-small)
- 반환: 벡터 차원 수, 텍스트 길이, 벡터 미리보기(앞 5개 숫자)

**예시:**
- `action=embed, text="인공지능 투자 분석"` → 1536차원 벡터 생성

### action=similarity (두 텍스트 유사도 계산)
```
action=similarity, text_a="첫 번째 텍스트", text_b="두 번째 텍스트"
```
- 두 텍스트를 각각 벡터로 변환한 뒤, 코사인 유사도(cosine similarity, 방향이 얼마나 같은지)를 계산합니다
- 유사도 해석: 90%+ 매우 유사 / 70%+ 상당히 유사 / 50%+ 보통 / 30%+ 약간 유사 / 30% 미만 관련 없음
- 반환: 유사도 점수(0~1), 백분율, 해석

**예시:**
- `action=similarity, text_a="삼성전자 주가 분석", text_b="삼성전자 투자 리포트"` → 약 0.85 (상당히 유사)
- `action=similarity, text_a="삼성전자 주가 분석", text_b="오늘 점심 뭐 먹지"` → 약 0.15 (관련 없음)

### action=batch (여러 텍스트 일괄 변환)
```
action=batch, texts=["텍스트1", "텍스트2", "텍스트3"]
```
- 여러 텍스트를 한 번에 벡터로 변환합니다 (하나씩 하는 것보다 효율적)
- texts: JSON 배열 형식 또는 쉼표 구분 문자열
- 반환: 처리된 텍스트 수, 벡터 차원, 총 사용 토큰

**예시:**
- `action=batch, texts=["AI 투자", "부동산 투자", "금 투자", "채권 투자"]` → 4개 텍스트 일괄 벡터화

### action=cluster (텍스트 그룹핑)
```
action=cluster, texts=["텍스트1", "텍스트2", ...], threshold=0.7
```
- 여러 텍스트를 의미가 비슷한 것끼리 자동으로 그룹으로 묶어줍니다
- threshold: 같은 그룹으로 묶을 유사도 기준 (기본값 0.7 = 70% 이상 유사하면 같은 그룹)
- 반환: 그룹 수, 각 그룹에 포함된 텍스트 목록

**예시:**
- `action=cluster, texts=["삼성전자 실적", "SK하이닉스 실적", "네이버 웹툰", "카카오 웹소설", "삼성 반도체", "SK 메모리"]` → 반도체 그룹 + 콘텐츠 그룹으로 자동 분류

## 이 도구를 쓰는 에이전트들

### 1. 기술개발처장 (CTO, cto_manager)
**언제 쓰나?** 에이전트 응답 품질 분석, 유사 프롬프트 감지, 텍스트 기반 기능 테스트
**어떻게 쓰나?**
- similarity로 에이전트 응답이 기대 응답과 얼마나 유사한지 품질 측정
- cluster로 사용자 질문을 카테고리별로 자동 분류하여 라우팅(배분) 개선

**실전 시나리오:**
> CEO가 "비서실장이 질문을 잘 분류하는지 확인해줘" 라고 하면:
> 1. 최근 질문 목록을 `action=cluster`로 그룹핑
> 2. 실제 배분 결과와 비교하여 잘못 분류된 질문 식별
> 3. 프롬프트 개선 제안

### 2. AI 모델 Specialist (ai_model_specialist)
**언제 쓰나?** 벡터 검색(RAG) 성능 테스트, 임베딩 모델 성능 비교, 지식베이스 품질 검증
**어떻게 쓰나?**
- embed로 텍스트를 벡터화하여 vector_knowledge 도구와 연동
- similarity로 검색 쿼리(질문)와 저장된 문서 간의 관련도 측정
- batch로 대량 문서를 벡터화하여 지식베이스 구축

**실전 시나리오:**
> CEO가 "지식베이스 검색이 부정확한데 확인해봐" 라고 하면:
> 1. 검색 쿼리와 반환된 문서의 `action=similarity` 점수 확인
> 2. 유사도가 낮으면 문서 청크(조각) 크기 조정 필요
> 3. 개선 후 재테스트

## 주의사항
- 한국어 텍스트는 영어보다 토큰을 더 많이 사용합니다 (비용이 약간 더 듦)
- cluster 액션은 텍스트 수가 많을수록 API 호출이 늘어납니다 (N개 텍스트 = 1번의 일괄 임베딩 호출)
- 벡터 차원은 모델에 따라 다릅니다 (text-embedding-3-small = 1536차원)
- 이 도구는 벡터를 "반환"만 합니다. 벡터를 저장하고 검색하려면 vector_knowledge 도구를 사용하세요
