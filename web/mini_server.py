"""
CORTHEX HQ - Mini Server (ê²½ëŸ‰ ì„œë²„)

Oracle Cloud ë¬´ë£Œ ì„œë²„(1GB RAM)ì—ì„œ ëŒ€ì‹œë³´ë“œë¥¼ ì„œë¹„ìŠ¤í•˜ê¸° ìœ„í•œ ê²½ëŸ‰ ì„œë²„.
ì „ì²´ ë°±ì—”ë“œì˜ í•µì‹¬ APIë§Œ ì œê³µí•˜ì—¬ ëŒ€ì‹œë³´ë“œ UIê°€ ì •ìƒ ì‘ë™í•˜ë„ë¡ í•¨.
í…”ë ˆê·¸ë¨ ë´‡ë„ ì—¬ê¸°ì„œ 24ì‹œê°„ êµ¬ë™ë©ë‹ˆë‹¤.
"""
import asyncio
import json
import logging
import os
import sys
import time
import uuid as _uuid
import urllib.request
import urllib.error
from datetime import datetime, timezone, timedelta
from pathlib import Path

# DB ëª¨ë“ˆì„ ê°™ì€ í´ë”ì—ì„œ ì„í¬íŠ¸
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from db import (
    init_db, save_message, create_task, get_task as db_get_task,
    update_task, list_tasks, toggle_bookmark as db_toggle_bookmark,
    get_dashboard_stats, save_activity_log, list_activity_logs,
    save_archive, list_archives, get_archive as db_get_archive,
    save_setting, load_setting, get_today_cost,
    save_conversation_message, load_conversation_messages, clear_conversation_messages,
    delete_task as db_delete_task, bulk_delete_tasks, bulk_archive_tasks,
    set_task_tags, mark_task_read, bulk_mark_read,
)
try:
    from ai_handler import (
        init_ai_client, is_ai_ready, ask_ai, select_model,
        classify_task, get_available_providers,
        _load_tool_schemas,  # ë„êµ¬ ìŠ¤í‚¤ë§ˆ ë¡œë”© (function callingìš©)
        batch_submit, batch_check, batch_retrieve,  # Batch API
        batch_submit_grouped,  # í”„ë¡œë°”ì´ë”ë³„ ê·¸ë£¹ ë°°ì¹˜ ì œì¶œ (ë°°ì¹˜ ì²´ì¸ìš©)
    )
except ImportError:
    def init_ai_client(): return False
    def is_ai_ready(): return False
    async def ask_ai(*a, **kw): return {"error": "ai_handler ë¯¸ì„¤ì¹˜"}
    def select_model(t, override=None): return override or "claude-haiku-4-5-20251001"
    async def classify_task(t): return {"agent_id": "chief_of_staff", "reason": "ai_handler ë¯¸ì„¤ì¹˜", "cost_usd": 0}
    def get_available_providers(): return {"anthropic": False, "google": False, "openai": False}
    def _load_tool_schemas(allowed_tools=None): return {}
    async def batch_submit(*a, **kw): return {"error": "ai_handler ë¯¸ì„¤ì¹˜"}
    async def batch_check(*a, **kw): return {"error": "ai_handler ë¯¸ì„¤ì¹˜"}
    async def batch_retrieve(*a, **kw): return {"error": "ai_handler ë¯¸ì„¤ì¹˜"}
    async def batch_submit_grouped(*a, **kw): return [{"error": "ai_handler ë¯¸ì„¤ì¹˜"}]

# Python ì¶œë ¥ ë²„í¼ë§ ë¹„í™œì„±í™” (systemdì—ì„œ ë¡œê·¸ê°€ ë°”ë¡œ ë³´ì´ë„ë¡)
os.environ["PYTHONUNBUFFERED"] = "1"

# ì§„ë‹¨ ì •ë³´ ìˆ˜ì§‘ìš©
_diag: dict = {"env_loaded": False, "env_file": "", "env_count": 0,
               "tg_import": False, "tg_import_error": "",
               "tg_token_found": False, "tg_started": False, "tg_error": ""}


def _log(msg: str) -> None:
    """ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥ (stdout + stderr ì–‘ìª½ì— flush)."""
    print(msg, flush=True)
    sys.stderr.write(msg + "\n")
    sys.stderr.flush()


def _load_env_file() -> None:
    """í™˜ê²½ë³€ìˆ˜ íŒŒì¼ì„ ì§ì ‘ ì½ì–´ì„œ os.environì— ì„¤ì •."""
    env_paths = [
        Path("/home/ubuntu/corthex.env"),        # ì„œë²„ ë°°í¬ í™˜ê²½
        Path(__file__).parent.parent / ".env.local",  # ë¡œì»¬ ê°œë°œ í™˜ê²½
        Path(__file__).parent.parent / ".env",        # ë¡œì»¬ í´ë°±
    ]
    for env_path in env_paths:
        _log(f"[ENV] í™•ì¸: {env_path} (ì¡´ì¬: {env_path.exists()})")
        if env_path.exists():
            try:
                loaded = 0
                for line in env_path.read_text(encoding="utf-8").splitlines():
                    line = line.strip()
                    if not line or line.startswith("#"):
                        continue
                    if "=" in line:
                        key, _, value = line.partition("=")
                        key = key.strip()
                        value = value.strip()
                        if key:
                            os.environ[key] = value
                            loaded += 1
                _diag["env_loaded"] = True
                _diag["env_file"] = str(env_path)
                _diag["env_count"] = loaded
                tg = os.getenv("TELEGRAM_BOT_TOKEN", "")
                _diag["tg_token_found"] = bool(tg)
                _log(f"[ENV] âœ… {loaded}ê°œ ë¡œë“œ: {env_path}")
                _log(f"[ENV] TG_TOKEN: {bool(tg)} (ê¸¸ì´:{len(tg)})")
            except Exception as e:
                _log(f"[ENV] âŒ ì‹¤íŒ¨: {e}")
            break


_load_env_file()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€ (src/ ëª¨ë“ˆ ì„í¬íŠ¸ìš©)
_PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if _PROJECT_ROOT not in sys.path:
    sys.path.insert(0, _PROJECT_ROOT)

try:
    import yaml
except ImportError:
    yaml = None  # PyYAML ë¯¸ì„¤ì¹˜ ì‹œ graceful fallback

# â”€â”€ ToolPool ì§€ì—° ë¡œë”© â”€â”€
_tool_pool = None  # None=ë¯¸ì´ˆê¸°í™”, False=ì‹¤íŒ¨, ToolPoolì¸ìŠ¤í„´ìŠ¤=ì„±ê³µ

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Body, Request
from fastapi.responses import HTMLResponse, FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import Optional

logger = logging.getLogger("corthex.mini_server")

# â”€â”€ í…”ë ˆê·¸ë¨ ë´‡ (ì„ íƒì  ë¡œë“œ) â”€â”€
_telegram_available = False
try:
    from telegram import Update, BotCommand
    from telegram.ext import (
        Application,
        CommandHandler,
        MessageHandler,
        ContextTypes,
        filters,
    )
    _telegram_available = True
    _diag["tg_import"] = True
    _log("[TG] python-telegram-bot ì„í¬íŠ¸ ì„±ê³µ âœ…")
except ImportError as e:
    _diag["tg_import_error"] = str(e)
    _log(f"[TG] python-telegram-bot ì„í¬íŠ¸ ì‹¤íŒ¨ âŒ: {e}")

KST = timezone(timedelta(hours=9))

app = FastAPI(title="CORTHEX HQ Mini Server")

# â”€â”€ HTML ì„œë¹™ â”€â”€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
TEMPLATE_DIR = os.path.join(BASE_DIR, "templates")

def get_build_number() -> str:
    """ë¹Œë“œ ë²ˆí˜¸ ë°˜í™˜.
    ì‹¤ì œ ë¹Œë“œ ë²ˆí˜¸ëŠ” GitHub Actions ë°°í¬ ì‹œ deploy.ymlì´ HTMLì— ì§ì ‘ ì£¼ì…í•¨.
    ì´ í•¨ìˆ˜ëŠ” ë¡œì»¬ ê°œë°œ í™˜ê²½(ë°°í¬ ì „)ì—ì„œë§Œ ì‚¬ìš©ë˜ëŠ” í´ë°± ê°’ì„ ë°˜í™˜."""
    return "dev"

# â”€â”€ ì„¤ì • íŒŒì¼ì—ì„œ ì—ì´ì „íŠ¸/ë„êµ¬ ì •ë³´ ë¡œë“œ â”€â”€
CONFIG_DIR = Path(BASE_DIR).parent / "config"

def _load_config(name: str) -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ. JSONì„ ë¨¼ì € ì‹œë„í•˜ê³ , ì—†ìœ¼ë©´ YAMLë¡œ ì‹œë„."""
    # 1ìˆœìœ„: JSON íŒŒì¼ (deploy.ymlì´ ë°°í¬ ì‹œ YAML â†’ JSONìœ¼ë¡œ ë³€í™˜í•´ë‘ )
    json_path = CONFIG_DIR / f"{name}.json"
    if json_path.exists():
        try:
            raw = json.loads(json_path.read_text(encoding="utf-8"))
            logger.info("%s.json ë¡œë“œ ì„±ê³µ", name)
            return raw
        except Exception as e:
            logger.warning("%s.json ë¡œë“œ ì‹¤íŒ¨: %s", name, e)

    # 2ìˆœìœ„: YAML íŒŒì¼ (PyYAML í•„ìš”)
    yaml_path = CONFIG_DIR / f"{name}.yaml"
    if yaml is not None and yaml_path.exists():
        try:
            raw = yaml.safe_load(yaml_path.read_text(encoding="utf-8"))
            logger.info("%s.yaml ë¡œë“œ ì„±ê³µ", name)
            return raw
        except Exception as e:
            logger.warning("%s.yaml ë¡œë“œ ì‹¤íŒ¨: %s", name, e)

    logger.warning("%s ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ (ë¹ˆ ì„¤ì • ì‚¬ìš©)", name)
    return {}


def _load_agents() -> dict:
    """ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ì •ë³´(allowed_tools, capabilities ë“±)ë¥¼ ë¡œë“œ."""
    raw = _load_config("agents")
    lookup: dict[str, dict] = {}
    for a in raw.get("agents", []):
        lookup[a["agent_id"]] = a
    return lookup


def _load_tools() -> list[dict]:
    """ë„êµ¬ ëª©ë¡ì„ ë¡œë“œ."""
    raw = _load_config("tools")
    return raw.get("tools", [])

# ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½: í•„ìš”í•œ ì •ë³´ë§Œ ìºì‹œ)
_AGENTS_DETAIL: dict[str, dict] = _load_agents()
_TOOLS_LIST: list[dict] = _load_tools()

# â”€â”€ ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬ (ëŸ°íƒ€ì„ ë°ì´í„°) â”€â”€
DATA_DIR = Path(BASE_DIR).parent / "data"
DATA_DIR.mkdir(exist_ok=True)
KNOWLEDGE_DIR = Path(BASE_DIR).parent / "knowledge"
ARCHIVE_DIR = Path(BASE_DIR).parent / "archive"


def _load_data(name: str, default=None):
    """DBì—ì„œ ì„¤ì • ë°ì´í„° ë¡œë“œ. DBì— ì—†ìœ¼ë©´ ê¸°ì¡´ JSON íŒŒì¼ í™•ì¸ í›„ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜."""
    # 1ìˆœìœ„: SQLite DB
    db_val = load_setting(name)
    if db_val is not None:
        return db_val
    # 2ìˆœìœ„: ê¸°ì¡´ JSON íŒŒì¼ (ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜)
    path = DATA_DIR / f"{name}.json"
    if path.exists():
        try:
            val = json.loads(path.read_text(encoding="utf-8"))
            save_setting(name, val)  # DBë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
            return val
        except Exception:
            pass
    return default if default is not None else {}


def _save_data(name: str, data) -> None:
    """DBì— ì„¤ì • ë°ì´í„° ì €ì¥."""
    save_setting(name, data)


def _save_config_file(name: str, data: dict) -> None:
    """ì„¤ì • ë³€ê²½ì„ DBì— ì €ì¥. (ì¬ë°°í¬í•´ë„ ìœ ì§€ë¨)"""
    save_setting(f"config_{name}", data)


@app.get("/", response_class=HTMLResponse)
async def index():
    html_path = os.path.join(TEMPLATE_DIR, "index.html")
    with open(html_path, "r", encoding="utf-8") as f:
        html_content = f.read()

    # BUILD_NUMBER_PLACEHOLDERë¥¼ ì‹¤ì œ ë¹Œë“œ ë²ˆí˜¸ë¡œ ì¹˜í™˜
    build_number = get_build_number()
    html_content = html_content.replace("BUILD_NUMBER_PLACEHOLDER", build_number)

    return HTMLResponse(content=html_content)


@app.get("/deploy-status.json")
async def deploy_status():
    """ë°°í¬ ìƒíƒœ JSON (deploy.ymlì´ /var/www/html/ì— ìƒì„±í•œ íŒŒì¼ ì½ê¸°)."""
    import json as _json
    for path in ["/var/www/html/deploy-status.json", os.path.join(BASE_DIR, "deploy-status.json")]:
        if os.path.exists(path):
            try:
                with open(path, "r") as f:
                    return _json.load(f)
            except Exception:
                pass
    return {"build": get_build_number(), "time": datetime.now(KST).isoformat(), "status": "success", "commit": ""}


# â”€â”€ ì—ì´ì „íŠ¸ ëª©ë¡ â”€â”€
AGENTS = [
    {"agent_id": "chief_of_staff", "name_ko": "ë¹„ì„œì‹¤ì¥", "role": "manager", "division": "secretary", "status": "idle", "model_name": "claude-sonnet-4-5-20250929"},
    {"agent_id": "report_specialist", "name_ko": "ì´ê´„ ë³´ì¢Œê´€", "role": "specialist", "division": "secretary", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "schedule_specialist", "name_ko": "ì „ëµ ë³´ì¢Œê´€", "role": "specialist", "division": "secretary", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "relay_specialist", "name_ko": "ì†Œí†µ ë³´ì¢Œê´€", "role": "specialist", "division": "secretary", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "cto_manager", "name_ko": "ê¸°ìˆ ê°œë°œì²˜ì¥ (CTO)", "role": "manager", "division": "leet_master.tech", "status": "idle", "model_name": "claude-sonnet-4-5-20250929"},
    {"agent_id": "frontend_specialist", "name_ko": "í”„ë¡ íŠ¸ì—”ë“œ Specialist", "role": "specialist", "division": "leet_master.tech", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "backend_specialist", "name_ko": "ë°±ì—”ë“œ/API Specialist", "role": "specialist", "division": "leet_master.tech", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "infra_specialist", "name_ko": "DB/ì¸í”„ë¼ Specialist", "role": "specialist", "division": "leet_master.tech", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "ai_model_specialist", "name_ko": "AI ëª¨ë¸ Specialist", "role": "specialist", "division": "leet_master.tech", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "cso_manager", "name_ko": "ì‚¬ì—…ê¸°íšì²˜ì¥ (CSO)", "role": "manager", "division": "leet_master.strategy", "status": "idle", "model_name": "claude-sonnet-4-5-20250929"},
    {"agent_id": "market_research_specialist", "name_ko": "ì‹œì¥ì¡°ì‚¬ Specialist", "role": "specialist", "division": "leet_master.strategy", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "business_plan_specialist", "name_ko": "ì‚¬ì—…ê³„íšì„œ Specialist", "role": "specialist", "division": "leet_master.strategy", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "financial_model_specialist", "name_ko": "ì¬ë¬´ëª¨ë¸ë§ Specialist", "role": "specialist", "division": "leet_master.strategy", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "clo_manager", "name_ko": "ë²•ë¬´Â·IPì²˜ì¥ (CLO)", "role": "manager", "division": "leet_master.legal", "status": "idle", "model_name": "claude-sonnet-4-5-20250929"},
    {"agent_id": "copyright_specialist", "name_ko": "ì €ì‘ê¶Œ Specialist", "role": "specialist", "division": "leet_master.legal", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "patent_specialist", "name_ko": "íŠ¹í—ˆ/ì•½ê´€ Specialist", "role": "specialist", "division": "leet_master.legal", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "cmo_manager", "name_ko": "ë§ˆì¼€íŒ…Â·ê³ ê°ì²˜ì¥ (CMO)", "role": "manager", "division": "leet_master.marketing", "status": "idle", "model_name": "claude-sonnet-4-5-20250929"},
    {"agent_id": "survey_specialist", "name_ko": "ì„¤ë¬¸/ë¦¬ì„œì¹˜ Specialist", "role": "specialist", "division": "leet_master.marketing", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "content_specialist", "name_ko": "ì½˜í…ì¸  Specialist", "role": "specialist", "division": "leet_master.marketing", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "community_specialist", "name_ko": "ì»¤ë®¤ë‹ˆí‹° Specialist", "role": "specialist", "division": "leet_master.marketing", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "cio_manager", "name_ko": "íˆ¬ìë¶„ì„ì²˜ì¥ (CIO)", "role": "manager", "division": "finance.investment", "status": "idle", "model_name": "claude-sonnet-4-5-20250929"},
    {"agent_id": "market_condition_specialist", "name_ko": "ì‹œí™©ë¶„ì„ Specialist", "role": "specialist", "division": "finance.investment", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "stock_analysis_specialist", "name_ko": "ì¢…ëª©ë¶„ì„ Specialist", "role": "specialist", "division": "finance.investment", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "technical_analysis_specialist", "name_ko": "ê¸°ìˆ ì ë¶„ì„ Specialist", "role": "specialist", "division": "finance.investment", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "risk_management_specialist", "name_ko": "ë¦¬ìŠ¤í¬ê´€ë¦¬ Specialist", "role": "specialist", "division": "finance.investment", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "cpo_manager", "name_ko": "ì¶œíŒÂ·ê¸°ë¡ì²˜ì¥ (CPO)", "role": "manager", "division": "publishing", "status": "idle", "model_name": "claude-sonnet-4-5-20250929"},
    {"agent_id": "chronicle_specialist", "name_ko": "íšŒì‚¬ì—°ëŒ€ê¸° Specialist", "role": "specialist", "division": "publishing", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "editor_specialist", "name_ko": "ì½˜í…ì¸ í¸ì§‘ Specialist", "role": "specialist", "division": "publishing", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
    {"agent_id": "archive_specialist", "name_ko": "ì•„ì¹´ì´ë¸Œ Specialist", "role": "specialist", "division": "publishing", "status": "idle", "model_name": "claude-haiku-4-5-20251001"},
]

# â”€â”€ WebSocket ê´€ë¦¬ â”€â”€
connected_clients: list[WebSocket] = []


@app.websocket("/ws")
async def websocket_endpoint(ws: WebSocket):
    await ws.accept()
    connected_clients.append(ws)
    try:
        # ì—°ê²° ì‹œ ì´ˆê¸° ìƒíƒœ ì „ì†¡
        now = datetime.now(KST).strftime("%H:%M:%S")
        await ws.send_json({
            "event": "activity_log",
            "data": {
                "agent_id": "chief_of_staff",
                "message": "ì‹œìŠ¤í…œ ì—°ê²° ì™„ë£Œ. ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.",
                "level": "info",
                "time": now,
            }
        })
        while True:
            data = await ws.receive_text()
            msg = json.loads(data)
            # ë©”ì‹œì§€ë¥¼ ë°›ìœ¼ë©´ DBì— ì €ì¥ + ì‘ë‹µ
            if msg.get("type") == "command":
                cmd_text = (msg.get("content") or msg.get("text", "")).strip()
                use_batch = msg.get("batch", False)
                if cmd_text:
                    # DBì— ë©”ì‹œì§€ + ì‘ì—… ì €ì¥
                    task = create_task(cmd_text, source="websocket_batch" if use_batch else "websocket")
                    save_message(cmd_text, source="websocket",
                                 task_id=task["task_id"])
                    # ì‘ì—… ì ‘ìˆ˜ ì´ë²¤íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                    mode_label = "ğŸ“¦ ë°°ì¹˜" if use_batch else "âš¡ ì‹¤ì‹œê°„"
                    log_entry = save_activity_log(
                        "chief_of_staff",
                        f"[ì›¹] {mode_label} ëª…ë ¹ ì ‘ìˆ˜: {cmd_text[:50]}{'...' if len(cmd_text) > 50 else ''} (#{task['task_id']})",
                    )
                    for c in connected_clients[:]:
                        try:
                            await c.send_json({"event": "task_accepted", "data": task})
                            await c.send_json({"event": "activity_log", "data": log_entry})
                        except Exception:
                            pass

                    # ë°°ì¹˜ ëª¨ë“œ: ìœ„ì„ ì²´ì¸ ì „ì²´ë¥¼ Batch APIë¡œ ì‹¤í–‰
                    if use_batch and is_ai_ready():
                        update_task(task["task_id"], status="pending",
                                    result_summary="ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] ì‹œì‘ ì¤‘...")
                        # ë°°ì¹˜ ì²´ì¸ ì‹œì‘ (ë¶„ë¥˜ â†’ ì „ë¬¸ê°€ â†’ ì¢…í•©ë³´ê³ ì„œ â†’ CEO ì „ë‹¬)
                        chain_result = await _start_batch_chain(cmd_text, task["task_id"])
                        if "error" in chain_result:
                            await ws.send_json({
                                "event": "result",
                                "data": {
                                    "content": f"âŒ ë°°ì¹˜ ì²´ì¸ ì‹œì‘ ì‹¤íŒ¨: {chain_result['error']}",
                                    "sender_id": "chief_of_staff",
                                    "handled_by": "ë¹„ì„œì‹¤ì¥",
                                    "time_seconds": 0,
                                    "cost": 0,
                                }
                            })
                        else:
                            chain_id = chain_result.get("chain_id", "?")
                            step = chain_result.get("step", "?")
                            mode = chain_result.get("mode", "single")
                            mode_label = "ë¸Œë¡œë“œìºìŠ¤íŠ¸ (6ê°œ ë¶€ì„œ)" if mode == "broadcast" else "ë‹¨ì¼ ë¶€ì„œ ìœ„ì„"
                            await ws.send_json({
                                "event": "result",
                                "data": {
                                    "content": (
                                        f"ğŸ“¦ **ë°°ì¹˜ ì²´ì¸ ì‹œì‘ë¨**\n\n"
                                        f"- ëª¨ë“œ: {mode_label}\n"
                                        f"- í˜„ì¬ ë‹¨ê³„: {step}\n"
                                        f"- ì²´ì¸ ID: `{chain_id[:30]}`\n\n"
                                        f"ìœ„ì„ ì²´ì¸ ì „ì²´ê°€ Batch APIë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤ (ë¹„ìš© ~50% ì ˆê°).\n"
                                        f"ê° ë‹¨ê³„ ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ë˜ë©°, "
                                        f"ìµœì¢… ë³´ê³ ì„œê°€ ì™„ì„±ë˜ë©´ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                                    ),
                                    "sender_id": "chief_of_staff",
                                    "handled_by": "ë¹„ì„œì‹¤ì¥",
                                    "time_seconds": 0,
                                    "cost": 0,
                                }
                            })
                        continue

                    # ì‹¤ì‹œê°„ ëª¨ë“œ: AI ì¦‰ì‹œ ì²˜ë¦¬
                    if is_ai_ready():
                        update_task(task["task_id"], status="running")
                        result = await _process_ai_command(cmd_text, task["task_id"])
                        if "error" in result:
                            await ws.send_json({
                                "event": "result",
                                "data": {"content": f"âŒ {result['error']}", "sender_id": result.get("agent_id", "chief_of_staff"), "handled_by": result.get("handled_by", "ë¹„ì„œì‹¤ì¥"), "time_seconds": 0, "cost": 0}
                            })
                        else:
                            await ws.send_json({
                                "event": "result",
                                "data": {
                                    "content": result.get("content", ""),
                                    "sender_id": result.get("agent_id", "chief_of_staff"),
                                    "handled_by": result.get("handled_by", "ë¹„ì„œì‹¤ì¥"),
                                    "delegation": result.get("delegation", ""),
                                    "time_seconds": result.get("time_seconds", 0),
                                    "cost": result.get("total_cost_usd", result.get("cost_usd", 0)),
                                    "model": result.get("model", ""),
                                    "routing_method": result.get("routing_method", ""),
                                }
                            })
                    else:
                        update_task(task["task_id"], status="completed",
                                    result_summary="AI ë¯¸ì—°ê²° â€” ì ‘ìˆ˜ë§Œ ì™„ë£Œ",
                                    success=1, time_seconds=0.1)
                        await ws.send_json({
                            "event": "result",
                            "data": {
                                "content": "AIê°€ ì•„ì§ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ANTHROPIC_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.",
                                "sender_id": "chief_of_staff",
                                "time_seconds": 0.1,
                                "cost": 0,
                            }
                        })
    except WebSocketDisconnect:
        connected_clients.remove(ws)
    except Exception:
        if ws in connected_clients:
            connected_clients.remove(ws)


# â”€â”€ API ì—”ë“œí¬ì¸íŠ¸ â”€â”€

@app.get("/api/auth/status")
async def auth_status(request: Request):
    if _check_auth(request):
        return {"bootstrap_mode": False, "role": "ceo", "authenticated": True}
    # ë¹„ë°€ë²ˆí˜¸ê°€ ê¸°ë³¸ê°’ì´ê³  ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ë¶€íŠ¸ìŠ¤íŠ¸ë© ëª¨ë“œ
    stored_pw = load_setting("admin_password")
    if (not stored_pw or stored_pw == "corthex2026") and not _sessions:
        return {"bootstrap_mode": True, "role": "ceo", "authenticated": True}
    return {"bootstrap_mode": False, "role": "viewer", "authenticated": False}


@app.get("/api/agents")
async def get_agents():
    """ì—ì´ì „íŠ¸ ëª©ë¡ ë°˜í™˜ (ì˜¤ë²„ë¼ì´ë“œëœ model_name, reasoning_effort í¬í•¨)."""
    result = []
    overrides = _load_data("agent_overrides", {})
    for a in AGENTS:
        agent = dict(a)
        aid = agent["agent_id"]
        detail = _AGENTS_DETAIL.get(aid, {})
        # ì˜¤ë²„ë¼ì´ë“œëœ ëª¨ë¸ëª… ë°˜ì˜
        if aid in overrides and "model_name" in overrides[aid]:
            agent["model_name"] = overrides[aid]["model_name"]
        elif detail.get("model_name"):
            agent["model_name"] = detail["model_name"]
        # ì¶”ë¡  ë ˆë²¨ ë°˜ì˜
        agent["reasoning_effort"] = ""
        if aid in overrides and "reasoning_effort" in overrides[aid]:
            agent["reasoning_effort"] = overrides[aid]["reasoning_effort"]
        elif detail.get("reasoning_effort"):
            agent["reasoning_effort"] = detail["reasoning_effort"]
        result.append(agent)
    return result


@app.get("/api/agents/{agent_id}")
async def get_agent(agent_id: str):
    for a in AGENTS:
        if a["agent_id"] == agent_id:
            # agents.yamlì—ì„œ ìƒì„¸ ì •ë³´ ë³´ì¶© (allowed_tools, capabilities ë“±)
            detail = _AGENTS_DETAIL.get(agent_id, {})
            # ì†Œìš¸ ë¡œë“œ ìš°ì„ ìˆœìœ„: 1) DB ì˜¤ë²„ë¼ì´ë“œ â†’ 2) souls/*.md íŒŒì¼ â†’ 3) agents.yaml
            soul_override = load_setting(f"soul_{agent_id}")
            if soul_override is not None:
                system_prompt = soul_override
            else:
                # souls/agents/{agent_id}.md íŒŒì¼ì—ì„œ ì†Œìš¸ ë¡œë“œ
                soul_md = Path(BASE_DIR).parent / "souls" / "agents" / f"{agent_id}.md"
                if soul_md.exists():
                    try:
                        system_prompt = soul_md.read_text(encoding="utf-8")
                    except Exception:
                        system_prompt = detail.get("system_prompt", "")
                else:
                    system_prompt = detail.get("system_prompt", "")
            return {
                **a,
                "system_prompt": system_prompt,
                "capabilities": detail.get("capabilities", []),
                "allowed_tools": detail.get("allowed_tools", []),
                "subordinate_ids": detail.get("subordinate_ids", []),
                "superior_id": detail.get("superior_id", ""),
                "temperature": detail.get("temperature", 0.3),
                "reasoning_effort": detail.get("reasoning_effort", ""),
            }
    return {"error": "not found"}


@app.get("/api/tools")
async def get_tools():
    return _TOOLS_LIST


@app.get("/api/dashboard")
async def get_dashboard():
    now = datetime.now(KST).isoformat()
    stats = get_dashboard_stats()
    return {
        "total_agents": len(AGENTS),
        "active_agents": stats["running_count"],
        "idle_agents": len(AGENTS) - stats["running_count"],
        "total_tasks_today": stats["today_task_count"],
        "today_completed": stats["today_completed"],
        "today_failed": stats["today_failed"],
        "total_cost": stats["total_cost"],
        "total_tokens": stats["total_tokens"],
        "system_status": "busy" if stats["running_count"] > 0 else "idle",
        "uptime": now,
        "agents": AGENTS,
        "recent_completed": stats["recent_completed"],
        # API í‚¤ ì—°ê²° ìƒíƒœ â€” í”„ë¡œë°”ì´ë”ë³„ í´ë¼ì´ì–¸íŠ¸ í™•ì¸
        "api_keys": {
            "anthropic": get_available_providers().get("anthropic", False),
            "google": get_available_providers().get("google", False),
            "openai": get_available_providers().get("openai", False),
            "notion": bool(os.getenv("NOTION_API_KEY", "")),
            "telegram": bool(os.getenv("TELEGRAM_BOT_TOKEN", "")),
        },
    }


@app.get("/api/budget")
async def get_budget():
    limit = float(load_setting("daily_budget_usd") or 7.0)
    today = get_today_cost()
    return {
        "daily_limit": limit, "daily_used": today,
        "today_cost": today,
        "remaining": round(limit - today, 6),
        "exceeded": today >= limit,
        "monthly_limit": 300.0, "monthly_used": today,
    }


@app.get("/api/model-mode")
async def get_model_mode():
    """í˜„ì¬ ëª¨ë¸ ëª¨ë“œ ì¡°íšŒ (auto/manual)."""
    mode = load_setting("model_mode") or "auto"
    override = load_setting("model_override") or "claude-sonnet-4-5-20250929"
    return {"mode": mode, "override": override}


@app.put("/api/model-mode")
async def set_model_mode(request: Request):
    """ëª¨ë¸ ëª¨ë“œ ë³€ê²½."""
    body = await request.json()
    mode = body.get("mode", "auto")
    save_setting("model_mode", mode)
    if mode == "manual" and "override" in body:
        save_setting("model_override", body["override"])
    return {"success": True, "mode": mode}


@app.get("/api/quality")
async def get_quality():
    return {"average_score": 0, "total_evaluated": 0, "rules": []}


# â”€â”€ í”„ë¦¬ì…‹ ê´€ë¦¬ â”€â”€

@app.get("/api/presets")
async def get_presets():
    return _load_data("presets", [])


@app.post("/api/presets")
async def save_preset(request: Request):
    """í”„ë¦¬ì…‹ ì €ì¥."""
    body = await request.json()
    presets = _load_data("presets", [])
    name = body.get("name", "")
    # ê°™ì€ ì´ë¦„ì´ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
    presets = [p for p in presets if p.get("name") != name]
    presets.append(body)
    _save_data("presets", presets)
    return {"success": True}


@app.delete("/api/presets/{name}")
async def delete_preset(name: str):
    """í”„ë¦¬ì…‹ ì‚­ì œ."""
    presets = _load_data("presets", [])
    presets = [p for p in presets if p.get("name") != name]
    _save_data("presets", presets)
    return {"success": True}


# â”€â”€ ì„±ëŠ¥/ì‘ì—… (ì½ê¸° ì „ìš© â€” ì‹¤ì œ ë°ì´í„°ëŠ” í’€ ì„œë²„ì—ì„œ ìƒì„±) â”€â”€

@app.get("/api/performance")
async def get_performance():
    """ì—ì´ì „íŠ¸ë³„ ì‹¤ì œ ì„±ëŠ¥ í†µê³„ë¥¼ DBì—ì„œ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from db import get_connection
    conn = get_connection()
    try:
        # DBì—ì„œ ì—ì´ì „íŠ¸ë³„ ì‘ì—… í†µê³„ ì§‘ê³„
        rows = conn.execute("""
            SELECT agent_id,
                   COUNT(*) as total_tasks,
                   SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as completed,
                   SUM(CASE WHEN success = 0 THEN 1 ELSE 0 END) as failed,
                   COALESCE(SUM(cost_usd), 0) as total_cost,
                   COALESCE(AVG(time_seconds), 0) as avg_time,
                   COALESCE(SUM(tokens_used), 0) as total_tokens
            FROM tasks
            WHERE agent_id IS NOT NULL AND agent_id != ''
            GROUP BY agent_id
            ORDER BY total_tasks DESC
        """).fetchall()

        # ì—ì´ì „íŠ¸ ì´ë¦„/ì—­í•  ë§µ êµ¬ì¶•
        agent_map = {a["agent_id"]: a for a in AGENTS}

        agents_perf = []
        total_llm_calls = 0
        total_cost = 0.0

        for row in rows:
            aid = row["agent_id"]
            info = agent_map.get(aid, {})
            total = row["total_tasks"]
            completed = row["completed"] or 0
            rate = round(completed / total * 100, 1) if total > 0 else 0

            agents_perf.append({
                "agent_id": aid,
                "name_ko": info.get("name_ko", aid),
                "role": info.get("role", "unknown"),
                "division": info.get("division", ""),
                "llm_calls": total,
                "tasks_completed": completed,
                "tasks_failed": row["failed"] or 0,
                "success_rate": rate,
                "cost_usd": round(row["total_cost"], 6),
                "avg_execution_seconds": round(row["avg_time"], 2),
                "total_tokens": row["total_tokens"] or 0,
            })
            total_llm_calls += total
            total_cost += row["total_cost"]

        # DBì— ì‘ì—…ì´ ì•„ì§ ì—†ìœ¼ë©´ ì—ì´ì „íŠ¸ ëª©ë¡ë§Œ ë¹ˆ ê°’ìœ¼ë¡œ ë°˜í™˜
        if not agents_perf:
            for a in AGENTS:
                agents_perf.append({
                    "agent_id": a["agent_id"],
                    "name_ko": a["name_ko"],
                    "role": a["role"],
                    "division": a.get("division", ""),
                    "llm_calls": 0,
                    "tasks_completed": 0,
                    "tasks_failed": 0,
                    "success_rate": 0,
                    "cost_usd": 0,
                    "avg_execution_seconds": 0,
                    "total_tokens": 0,
                })

        return {
            "agents": agents_perf,
            "total_llm_calls": total_llm_calls,
            "total_cost_usd": round(total_cost, 6),
        }
    except Exception as e:
        logger.error("ì„±ëŠ¥ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: %s", e)
        # ì—ëŸ¬ ì‹œì—ë„ ì—ì´ì „íŠ¸ ëª©ë¡ì€ ë³´ì—¬ì£¼ê¸°
        return {
            "agents": [{"agent_id": a["agent_id"], "name_ko": a["name_ko"],
                        "role": a["role"], "llm_calls": 0, "tasks_completed": 0,
                        "success_rate": 0, "cost_usd": 0, "avg_execution_seconds": 0}
                       for a in AGENTS],
            "total_llm_calls": 0,
            "total_cost_usd": 0,
        }
    finally:
        conn.close()


@app.get("/api/tasks")
async def get_tasks(keyword: str = "", status: str = "", bookmarked: bool = False,
                    limit: int = 50, archived: bool = False, tag: str = ""):
    tasks = list_tasks(keyword=keyword, status=status,
                       bookmarked=bookmarked, limit=limit,
                       archived=archived, tag=tag)
    return tasks


@app.get("/api/tasks/{task_id}")
async def get_task(task_id: str):
    task = db_get_task(task_id)
    if not task:
        return {"error": "not found"}
    return task


@app.post("/api/tasks/{task_id}/bookmark")
async def bookmark_task(task_id: str):
    new_state = db_toggle_bookmark(task_id)
    return {"bookmarked": new_state}


@app.delete("/api/tasks/{task_id}")
async def delete_task_api(task_id: str):
    """ì‘ì—… ì‚­ì œ."""
    db_delete_task(task_id)
    return {"success": True}


@app.put("/api/tasks/{task_id}/tags")
async def update_task_tags(task_id: str, request: Request):
    """ì‘ì—… íƒœê·¸ ì—…ë°ì´íŠ¸."""
    body = await request.json()
    tags = body.get("tags", [])
    set_task_tags(task_id, tags)
    return {"success": True, "tags": tags}


@app.put("/api/tasks/{task_id}/read")
async def mark_task_read_api(task_id: str, request: Request):
    """ì‘ì—… ì½ìŒ/ì•ˆì½ìŒ í‘œì‹œ."""
    body = await request.json()
    is_read = body.get("is_read", True)
    mark_task_read(task_id, is_read)
    return {"success": True, "is_read": is_read}


@app.post("/api/tasks/bulk")
async def bulk_task_action(request: Request):
    """ì‘ì—… ì¼ê´„ ì²˜ë¦¬ (ì‚­ì œ/ì•„ì¹´ì´ë¸Œ/ì½ìŒ ë“±)."""
    body = await request.json()
    action = body.get("action", "")
    task_ids = body.get("task_ids", [])
    if not task_ids:
        return {"success": False, "error": "task_idsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    if action == "delete":
        count = bulk_delete_tasks(task_ids)
        return {"success": True, "action": "delete", "affected": count}
    elif action == "archive":
        count = bulk_archive_tasks(task_ids, archive=True)
        return {"success": True, "action": "archive", "affected": count}
    elif action == "unarchive":
        count = bulk_archive_tasks(task_ids, archive=False)
        return {"success": True, "action": "unarchive", "affected": count}
    elif action == "read":
        count = bulk_mark_read(task_ids, is_read=True)
        return {"success": True, "action": "read", "affected": count}
    elif action == "unread":
        count = bulk_mark_read(task_ids, is_read=False)
        return {"success": True, "action": "unread", "affected": count}
    else:
        return {"success": False, "error": f"ì•Œ ìˆ˜ ì—†ëŠ” ì•¡ì…˜: {action}"}


# â”€â”€ ë°°ì¹˜ ëª…ë ¹ (ì—¬ëŸ¬ ëª…ë ¹ í•œë²ˆì— ì‹¤í–‰) â”€â”€

_batch_queue: list[dict] = []  # ë°°ì¹˜ ëŒ€ê¸°ì—´ (ë¡œì»¬ ìˆœì°¨/ë³‘ë ¬ ì‹¤í–‰ìš©)
_batch_running = False
_batch_api_queue: list[dict] = []  # Batch API ëŒ€ê¸°ì—´ (í”„ë¡œë°”ì´ë” ë°°ì¹˜ ì œì¶œìš©)


@app.get("/api/batch/queue")
async def get_batch_queue():
    """ë°°ì¹˜ ëŒ€ê¸°ì—´ ì¡°íšŒ."""
    return {"queue": _batch_queue, "running": _batch_running}


@app.post("/api/batch")
async def submit_batch(request: Request):
    """ë°°ì¹˜ ëª…ë ¹ ì œì¶œ â€” ì—¬ëŸ¬ ëª…ë ¹ì„ í•œë²ˆì— ì ‘ìˆ˜í•©ë‹ˆë‹¤."""
    body = await request.json()
    commands = body.get("commands", [])
    mode = body.get("mode", "sequential")  # sequential ë˜ëŠ” parallel

    if not commands:
        return {"success": False, "error": "ëª…ë ¹ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    batch_id = f"batch_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}"
    batch_items = []
    for i, cmd in enumerate(commands):
        item = {
            "batch_id": batch_id,
            "index": i,
            "command": cmd if isinstance(cmd, str) else cmd.get("command", ""),
            "status": "pending",
            "result": None,
            "task_id": None,
        }
        batch_items.append(item)
        _batch_queue.append(item)

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë°°ì¹˜ ì‹¤í–‰
    asyncio.create_task(_run_batch(batch_id, batch_items, mode))

    return {"success": True, "batch_id": batch_id, "count": len(commands), "mode": mode}


async def _run_batch(batch_id: str, items: list, mode: str):
    """ë°°ì¹˜ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    global _batch_running
    _batch_running = True

    try:
        if mode == "parallel":
            # ë³‘ë ¬ ì‹¤í–‰
            tasks = []
            for item in items:
                tasks.append(_run_batch_item(item))
            await asyncio.gather(*tasks)
        else:
            # ìˆœì°¨ ì‹¤í–‰
            for item in items:
                await _run_batch_item(item)
    finally:
        _batch_running = False
        # ì™„ë£Œëœ ë°°ì¹˜ í•­ëª©ì€ 10ë¶„ í›„ ì •ë¦¬
        await asyncio.sleep(600)
        for item in items:
            if item in _batch_queue:
                _batch_queue.remove(item)


async def _run_batch_item(item: dict):
    """ë°°ì¹˜ ë‚´ ê°œë³„ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    item["status"] = "running"
    try:
        task = create_task(item["command"], source="batch")
        item["task_id"] = task["task_id"]

        # AI ì²˜ë¦¬ (_process_ai_commandê³¼ ë™ì¼í•œ ë¡œì§)
        result = await _process_ai_command(item["command"], source="batch")

        item["status"] = "completed"
        item["result"] = result.get("content", "")[:200] if isinstance(result, dict) else str(result)[:200]
    except Exception as e:
        item["status"] = "failed"
        item["result"] = str(e)[:200]


@app.delete("/api/batch/queue")
async def clear_batch_queue():
    """ë°°ì¹˜ ëŒ€ê¸°ì—´ì„ ë¹„ì›ë‹ˆë‹¤."""
    global _batch_queue
    _batch_queue = [item for item in _batch_queue if item.get("status") == "running"]
    return {"success": True}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â”€â”€ AI Batch API ì‹œìŠ¤í…œ (PENDING ì¶”ì  + ìë™ ê²°ê³¼ ìˆ˜ì§‘) â”€â”€
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# CEOê°€ ì—¬ëŸ¬ ëª…ë ¹ì„ AI Batch APIë¡œ ë³´ë‚´ë©´:
#   1) ê° ëª…ë ¹ì´ PENDING ìƒíƒœë¡œ DBì— ì €ì¥ë¨
#   2) í”„ë¡œë°”ì´ë”ì˜ Batch APIì— í•œêº¼ë²ˆì— ì œì¶œ (ì‹¤ì‹œê°„ë³´ë‹¤ ~50% ì €ë ´)
#   3) ë°±ê·¸ë¼ìš´ë“œ í´ëŸ¬ê°€ 60ì´ˆë§ˆë‹¤ ìƒíƒœë¥¼ í™•ì¸
#   4) ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„í•˜ì—¬ ë³´ê³ ì„œ ì‘ì„±
#   5) WebSocketìœ¼ë¡œ CEOì—ê²Œ ì‹¤ì‹œê°„ ì•Œë¦¼

_batch_poller_task = None  # ë°°ì¹˜ í´ëŸ¬ ë£¨í”„ íƒœìŠ¤í¬


@app.post("/api/batch/ai")
async def submit_ai_batch(request: Request):
    """AI Batch APIë¡œ ì—¬ëŸ¬ ìš”ì²­ì„ í•œêº¼ë²ˆì— ì œì¶œí•©ë‹ˆë‹¤.

    ìš”ì²­ body:
    {
        "requests": [
            {"message": "ì‚¼ì„±ì „ì ë¶„ì„í•´ì¤˜", "system_prompt": "...", "agent_id": "cio_manager"},
            {"message": "íŠ¹í—ˆ ê²€ìƒ‰í•´ì¤˜", "system_prompt": "...", "agent_id": "clo_manager"},
        ],
        "model": "claude-sonnet-4-5-20250929",  // ê¸°ë³¸ ëª¨ë¸ (ì„ íƒ)
        "auto_delegate": true  // ê²°ê³¼ë¥¼ ì—ì´ì „íŠ¸ì—ê²Œ ìë™ ìœ„ì„í• ì§€ (ê¸°ë³¸: true)
    }

    ì‘ë‹µ: {"batch_id": "...", "count": N, "status": "submitted"}
    """
    body = await request.json()
    requests_list = body.get("requests", [])
    model = body.get("model")
    auto_delegate = body.get("auto_delegate", True)

    if not requests_list:
        return {"success": False, "error": "ìš”ì²­ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    # ê° ìš”ì²­ì— custom_id ìë™ ë¶€ì—¬
    now_str = datetime.now(KST).strftime('%Y%m%d_%H%M%S')
    for i, req in enumerate(requests_list):
        if "custom_id" not in req:
            req["custom_id"] = f"batch_{now_str}_{i}"
        # ì—ì´ì „íŠ¸ ì†Œìš¸(ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)ì„ ìë™ìœ¼ë¡œ ë¡œë“œ
        agent_id = req.get("agent_id")
        if agent_id and not req.get("system_prompt"):
            req["system_prompt"] = _load_agent_prompt(agent_id)

    # Batch API ì œì¶œ
    result = await batch_submit(requests_list, model=model)

    if "error" in result:
        return {"success": False, "error": result["error"]}

    batch_id = result["batch_id"]
    provider = result["provider"]

    # DBì— PENDING ìƒíƒœë¡œ ì €ì¥
    pending_data = {
        "batch_id": batch_id,
        "provider": provider,
        "model": model,
        "status": "pending",
        "auto_delegate": auto_delegate,
        "submitted_at": datetime.now(KST).isoformat(),
        "requests": [
            {
                "custom_id": r.get("custom_id"),
                "message": r.get("message", "")[:200],
                "agent_id": r.get("agent_id", ""),
            }
            for r in requests_list
        ],
        "results": [],
    }

    # ê¸°ì¡´ pending_batches ëª©ë¡ì— ì¶”ê°€
    pending_batches = load_setting("pending_batches") or []
    pending_batches.append(pending_data)
    save_setting("pending_batches", pending_batches)

    # ê° ìš”ì²­ì„ taskë¡œë„ ìƒì„± (PENDING ìƒíƒœ)
    for req in requests_list:
        task = create_task(
            req.get("message", "ë°°ì¹˜ ìš”ì²­"),
            source="batch_api",
            agent_id=req.get("agent_id", "chief_of_staff"),
        )
        update_task(task["task_id"], status="pending",
                    result_summary=f"[PENDING] ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ (batch_id: {batch_id[:20]}...)")

    # WebSocket ì•Œë¦¼
    for c in connected_clients[:]:
        try:
            await c.send_json({
                "event": "batch_submitted",
                "data": {
                    "batch_id": batch_id,
                    "provider": provider,
                    "count": len(requests_list),
                },
            })
        except Exception:
            pass

    _log(f"[BATCH] AI ë°°ì¹˜ ì œì¶œ ì™„ë£Œ: {batch_id} ({len(requests_list)}ê°œ ìš”ì²­, {provider})")

    # í´ëŸ¬ê°€ ì•ˆ ëŒê³  ìˆìœ¼ë©´ ì‹œì‘
    _ensure_batch_poller()

    return {
        "success": True,
        "batch_id": batch_id,
        "provider": provider,
        "count": len(requests_list),
        "status": "submitted",
    }


@app.get("/api/batch/pending")
async def get_pending_batches():
    """PENDING ìƒíƒœì¸ ë°°ì¹˜ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    pending_batches = load_setting("pending_batches") or []
    # pendingê³¼ processingë§Œ ë°˜í™˜
    active = [b for b in pending_batches if b.get("status") in ("pending", "processing")]
    return {"pending": active, "total": len(pending_batches)}


@app.post("/api/batch/check/{batch_id}")
async def check_batch_status(batch_id: str):
    """íŠ¹ì • ë°°ì¹˜ì˜ ìƒíƒœë¥¼ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤."""
    pending_batches = load_setting("pending_batches") or []
    batch_info = next((b for b in pending_batches if b["batch_id"] == batch_id), None)

    if not batch_info:
        return {"error": f"ë°°ì¹˜ '{batch_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    provider = batch_info["provider"]
    status_result = await batch_check(batch_id, provider)

    if "error" in status_result:
        return status_result

    # ìƒíƒœ ì—…ë°ì´íŠ¸
    batch_info["status"] = status_result["status"]
    batch_info["progress"] = status_result.get("progress", {})
    save_setting("pending_batches", pending_batches)

    # ì™„ë£Œë˜ì—ˆìœ¼ë©´ ê²°ê³¼ ìˆ˜ì§‘
    if status_result["status"] == "completed":
        await _collect_batch_results(batch_info, pending_batches)

    return status_result


@app.post("/api/batch/resume")
async def resume_all_pending():
    """ëª¨ë“  PENDING ë°°ì¹˜ì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê³ , ì™„ë£Œëœ ê²ƒì€ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    pending_batches = load_setting("pending_batches") or []
    active = [b for b in pending_batches if b.get("status") in ("pending", "processing")]

    if not active:
        return {"message": "ì²˜ë¦¬ ì¤‘ì¸ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤", "checked": 0}

    checked = 0
    collected = 0
    for batch_info in active:
        batch_id = batch_info["batch_id"]
        provider = batch_info["provider"]

        status_result = await batch_check(batch_id, provider)
        if "error" not in status_result:
            batch_info["status"] = status_result["status"]
            batch_info["progress"] = status_result.get("progress", {})
            checked += 1

            if status_result["status"] == "completed":
                await _collect_batch_results(batch_info, pending_batches)
                collected += 1

    save_setting("pending_batches", pending_batches)
    return {"checked": checked, "collected": collected, "remaining": len(active) - collected}


@app.get("/api/batch/history")
async def get_batch_history():
    """ëª¨ë“  ë°°ì¹˜ì˜ íˆìŠ¤í† ë¦¬ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (ì™„ë£Œëœ ê²ƒ í¬í•¨)."""
    all_batches = load_setting("pending_batches") or []
    return {"batches": all_batches[-50:], "total": len(all_batches)}  # ìµœê·¼ 50ê°œë§Œ


async def _collect_batch_results(batch_info: dict, all_batches: list):
    """ì™„ë£Œëœ ë°°ì¹˜ì˜ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ê³ , í•„ìš”ì‹œ ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„í•©ë‹ˆë‹¤."""
    batch_id = batch_info["batch_id"]
    provider = batch_info["provider"]

    _log(f"[BATCH] ê²°ê³¼ ìˆ˜ì§‘ ì‹œì‘: {batch_id}")

    # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    result = await batch_retrieve(batch_id, provider)
    if "error" in result:
        _log(f"[BATCH] ê²°ê³¼ ìˆ˜ì§‘ ì‹¤íŒ¨: {result['error']}")
        return

    results = result.get("results", [])
    batch_info["results"] = results
    batch_info["status"] = "completed"
    batch_info["completed_at"] = datetime.now(KST).isoformat()

    # ì´ ë¹„ìš© ê³„ì‚°
    total_cost = sum(r.get("cost_usd", 0) for r in results if r.get("cost_usd"))
    batch_info["total_cost_usd"] = round(total_cost, 6)

    save_setting("pending_batches", all_batches)

    # ì—ì´ì „íŠ¸ì—ê²Œ ìë™ ìœ„ì„ (auto_delegate=trueì¸ ê²½ìš°)
    if batch_info.get("auto_delegate"):
        req_map = {r["custom_id"]: r for r in batch_info.get("requests", [])}
        for res in results:
            if res.get("error"):
                continue
            custom_id = res.get("custom_id", "")
            req_info = req_map.get(custom_id, {})
            agent_id = req_info.get("agent_id")
            message = req_info.get("message", "")

            if agent_id and res.get("content"):
                # ê²°ê³¼ë¥¼ í™œë™ ë¡œê·¸ì— ê¸°ë¡
                agent_name = _AGENT_NAMES.get(agent_id, agent_id)
                log_entry = save_activity_log(
                    agent_id,
                    f"[ë°°ì¹˜ ì™„ë£Œ] {agent_name}: {message[:40]}... â†’ {res['content'][:60]}..."
                )
                for c in connected_clients[:]:
                    try:
                        await c.send_json({"event": "activity_log", "data": log_entry})
                    except Exception:
                        pass

                # ì•„ì¹´ì´ë¸Œì— ì €ì¥
                division = _AGENT_DIVISION.get(agent_id, "secretary")
                now_str = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
                archive_content = f"# [ë°°ì¹˜] [{agent_name}] {message[:60]}\n\n{res['content']}"
                save_archive(
                    division=division,
                    filename=f"batch_{agent_id}_{now_str}.md",
                    content=archive_content,
                    agent_id=agent_id,
                )

    # WebSocketìœ¼ë¡œ ì™„ë£Œ ì•Œë¦¼
    for c in connected_clients[:]:
        try:
            await c.send_json({
                "event": "batch_completed",
                "data": {
                    "batch_id": batch_id,
                    "provider": provider,
                    "count": len(results),
                    "total_cost_usd": total_cost,
                    "succeeded": sum(1 for r in results if not r.get("error")),
                    "failed": sum(1 for r in results if r.get("error")),
                },
            })
        except Exception:
            pass

    _log(f"[BATCH] ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ: {batch_id} ({len(results)}ê°œ, ${total_cost:.4f})")


async def _flush_batch_api_queue():
    """ë°°ì¹˜ ëŒ€ê¸°ì—´ì— ìŒ“ì¸ ìš”ì²­ì„ Batch APIì— ì œì¶œí•©ë‹ˆë‹¤."""
    global _batch_api_queue
    if not _batch_api_queue:
        return {"message": "ëŒ€ê¸°ì—´ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    queue_copy = list(_batch_api_queue)
    _batch_api_queue = []

    _log(f"[BATCH] ëŒ€ê¸°ì—´ {len(queue_copy)}ê±´ â†’ Batch API ì œì¶œ ì¤‘...")

    # ê° ìš”ì²­ì— ì—ì´ì „íŠ¸ ë¼ìš°íŒ… (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê²°ì •)
    for req in queue_copy:
        if not req.get("system_prompt"):
            routing = await _route_task(req.get("message", ""))
            agent_id = routing.get("agent_id", "chief_of_staff")
            req["agent_id"] = agent_id
            req["system_prompt"] = _load_agent_prompt(agent_id)

    # Batch API ì œì¶œ
    result = await batch_submit(queue_copy)

    if "error" in result:
        _log(f"[BATCH] ì œì¶œ ì‹¤íŒ¨: {result['error']}")
        # ì‹¤íŒ¨í•˜ë©´ ë‹¤ì‹œ ëŒ€ê¸°ì—´ì— ë„£ê¸°
        _batch_api_queue.extend(queue_copy)
        return result

    batch_id = result["batch_id"]
    provider = result["provider"]

    # DBì— PENDING ìƒíƒœë¡œ ì €ì¥
    pending_data = {
        "batch_id": batch_id,
        "provider": provider,
        "status": "pending",
        "auto_delegate": True,
        "submitted_at": datetime.now(KST).isoformat(),
        "requests": [
            {
                "custom_id": r.get("custom_id", r.get("task_id", "")),
                "message": r.get("message", "")[:200],
                "agent_id": r.get("agent_id", ""),
                "task_id": r.get("task_id", ""),
            }
            for r in queue_copy
        ],
        "results": [],
    }

    pending_batches = load_setting("pending_batches") or []
    pending_batches.append(pending_data)
    save_setting("pending_batches", pending_batches)

    # ê° taskë¥¼ PENDING ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
    for req in queue_copy:
        task_id = req.get("task_id")
        if task_id:
            update_task(task_id, status="pending",
                        result_summary=f"[PENDING] Batch API ì œì¶œë¨ ({batch_id[:20]}...)")

    # WebSocket ì•Œë¦¼
    for c in connected_clients[:]:
        try:
            await c.send_json({
                "event": "batch_submitted",
                "data": {"batch_id": batch_id, "provider": provider, "count": len(queue_copy)},
            })
        except Exception:
            pass

    _ensure_batch_poller()
    _log(f"[BATCH] Batch API ì œì¶œ ì™„ë£Œ: {batch_id} ({len(queue_copy)}ê±´, {provider})")
    return result


@app.post("/api/batch/flush")
async def flush_batch_queue():
    """ë°°ì¹˜ ëŒ€ê¸°ì—´ì— ìŒ“ì¸ ìš”ì²­ì„ ì¦‰ì‹œ Batch APIì— ì œì¶œí•©ë‹ˆë‹¤."""
    if not _batch_api_queue:
        return {"success": False, "message": "ëŒ€ê¸°ì—´ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}
    result = await _flush_batch_api_queue()
    return {"success": "error" not in result, **result}


def _ensure_batch_poller():
    """ë°°ì¹˜ í´ëŸ¬ê°€ ëŒê³  ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì•ˆ ëŒë©´ ì‹œì‘í•©ë‹ˆë‹¤."""
    global _batch_poller_task
    if _batch_poller_task is None or _batch_poller_task.done():
        _batch_poller_task = asyncio.create_task(_batch_poller_loop())
        _log("[BATCH] ë°°ì¹˜ í´ëŸ¬ ì‹œì‘ë¨ (60ì´ˆ ê°„ê²©)")


async def _batch_poller_loop():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ 60ì´ˆë§ˆë‹¤ PENDING ë°°ì¹˜ + ë°°ì¹˜ ì²´ì¸ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    while True:
        try:
            await asyncio.sleep(60)

            has_work = False

            # â”€â”€ (A) ê¸°ì¡´ ë‹¨ë… ë°°ì¹˜ í™•ì¸ â”€â”€
            pending_batches = load_setting("pending_batches") or []
            active = [b for b in pending_batches if b.get("status") in ("pending", "processing")]

            if active:
                has_work = True
                for batch_info in active:
                    batch_id = batch_info["batch_id"]
                    provider = batch_info["provider"]

                    try:
                        status_result = await batch_check(batch_id, provider)
                        if "error" not in status_result:
                            batch_info["status"] = status_result["status"]
                            batch_info["progress"] = status_result.get("progress", {})

                            if status_result["status"] == "completed":
                                await _collect_batch_results(batch_info, pending_batches)
                            elif status_result["status"] in ("failed", "expired"):
                                batch_info["status"] = status_result["status"]
                                _log(f"[BATCH] ë°°ì¹˜ ì‹¤íŒ¨/ë§Œë£Œ: {batch_id}")
                    except Exception as e:
                        _log(f"[BATCH] ë°°ì¹˜ í™•ì¸ ì‹¤íŒ¨ ({batch_id}): {e}")

                save_setting("pending_batches", pending_batches)

            # â”€â”€ (B) ë°°ì¹˜ ì²´ì¸ í™•ì¸ + ìë™ ì§„í–‰ â”€â”€
            chains = load_setting("batch_chains") or []
            active_chains = [c for c in chains if c.get("status") in ("running", "pending")]

            if active_chains:
                has_work = True
                for chain in active_chains:
                    try:
                        await _advance_batch_chain(chain["chain_id"])
                    except Exception as e:
                        _log(f"[CHAIN] ì²´ì¸ ì§„í–‰ ì˜¤ë¥˜ ({chain['chain_id']}): {e}")

            if not has_work:
                _log("[BATCH] ì²˜ë¦¬ ì¤‘ì¸ ë°°ì¹˜/ì²´ì¸ ì—†ìŒ â€” í´ëŸ¬ ì¢…ë£Œ")
                break

        except asyncio.CancelledError:
            break
        except Exception as e:
            _log(f"[BATCH] í´ëŸ¬ ì˜¤ë¥˜: {e}")
            await asyncio.sleep(30)  # ì—ëŸ¬ ì‹œ 30ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â”€â”€ ë°°ì¹˜ ì²´ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° â”€â”€
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# CEOê°€ ğŸ“¦ ë°°ì¹˜ ëª¨ë“œë¡œ ëª…ë ¹ì„ ë³´ë‚´ë©´ ìœ„ì„ ì²´ì¸ ì „ì²´ê°€ Batch APIë¡œ ëŒì•„ê°:
#
#   [1ë‹¨ê³„] ë¹„ì„œì‹¤ì¥ ë¶„ë¥˜ â†’ Batch ì œì¶œ â†’ PENDING â†’ ê²°ê³¼: "CIOì—ê²Œ ìœ„ì„"
#   [2ë‹¨ê³„] ì „ë¬¸ê°€ Nëª… â†’ í”„ë¡œë°”ì´ë”ë³„ ë¬¶ì–´ì„œ Batch ì œì¶œ â†’ PENDING â†’ ì „ë¶€ ëŒ€ê¸°
#   [3ë‹¨ê³„] ì²˜ì¥ ì¢…í•©ë³´ê³ ì„œ â†’ Batch ì œì¶œ â†’ PENDING â†’ ê²°ê³¼: ì¢…í•© ë³´ê³ ì„œ
#   [4ë‹¨ê³„] CEOì—ê²Œ ì „ë‹¬ + ì•„ì¹´ì´ë¸Œ ì €ì¥
#
# ë§¤ ë‹¨ê³„ë§ˆë‹¤ Batch API ì‚¬ìš© â†’ ë¹„ìš© ~50% ì ˆê°
# í”„ë¡œë°”ì´ë”ë³„ ìë™ ê·¸ë£¹í™” (Claude + GPT + Gemini ì—ì´ì „íŠ¸ í˜¼í•© ê°€ëŠ¥)

# ë¶„ë¥˜ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë°°ì¹˜ ì²´ì¸ì—ì„œ ì‚¬ìš©)
_BATCH_CLASSIFY_PROMPT = """ë‹¹ì‹ ì€ ì—…ë¬´ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
CEOì˜ ëª…ë ¹ì„ ì½ê³  ì–´ëŠ ë¶€ì„œê°€ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

## ë¶€ì„œ ëª©ë¡
- cto_manager: ê¸°ìˆ ê°œë°œ (ì½”ë“œ, ì›¹ì‚¬ì´íŠ¸, API, ì„œë²„, ë°°í¬, í”„ë¡ íŠ¸ì—”ë“œ, ë°±ì—”ë“œ, ë²„ê·¸, UI, ë””ìì¸, ë°ì´í„°ë² ì´ìŠ¤)
- cso_manager: ì‚¬ì—…ê¸°íš (ì‹œì¥ì¡°ì‚¬, ì‚¬ì—…ê³„íš, ë§¤ì¶œ ì˜ˆì¸¡, ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸, ìˆ˜ìµ, ê²½ìŸì‚¬)
- clo_manager: ë²•ë¬´IP (ì €ì‘ê¶Œ, íŠ¹í—ˆ, ìƒí‘œ, ì•½ê´€, ê³„ì•½, ë²•ë¥ , ì†Œì†¡)
- cmo_manager: ë§ˆì¼€íŒ…ê³ ê° (ë§ˆì¼€íŒ…, ê´‘ê³ , SNS, ì¸ìŠ¤íƒ€ê·¸ë¨, ìœ íŠœë¸Œ, ì½˜í…ì¸ , ë¸Œëœë”©, ì„¤ë¬¸)
- cio_manager: íˆ¬ìë¶„ì„ (ì£¼ì‹, íˆ¬ì, ì¢…ëª©, ì‹œí™©, í¬íŠ¸í´ë¦¬ì˜¤, ì½”ìŠ¤í”¼, ë‚˜ìŠ¤ë‹¥, ì°¨íŠ¸, ê¸ˆë¦¬)
- cpo_manager: ì¶œíŒê¸°ë¡ (íšŒì‚¬ê¸°ë¡, ì—°ëŒ€ê¸°, ë¸”ë¡œê·¸, ì¶œíŒ, í¸ì§‘, íšŒê³ , ë¹Œë”©ë¡œê·¸)
- chief_of_staff: ì¼ë°˜ ì§ˆë¬¸, ìš”ì•½, ì¼ì • ê´€ë¦¬, ê¸°íƒ€ (ìœ„ ë¶€ì„œì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš°)

## ì¶œë ¥ í˜•ì‹
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì“°ì§€ ë§ˆì„¸ìš”.
{"agent_id": "ë¶€ì„œID", "reason": "í•œì¤„ ì´ìœ "}"""


def _save_chain(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ ìƒíƒœë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤."""
    chains = load_setting("batch_chains") or []
    # ê°™ì€ chain_idê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì¶”ê°€
    found = False
    for i, c in enumerate(chains):
        if c["chain_id"] == chain["chain_id"]:
            chains[i] = chain
            found = True
            break
    if not found:
        chains.append(chain)
    # ìµœê·¼ 50ê°œë§Œ ìœ ì§€ (ì˜¤ë˜ëœ ì™„ë£Œ/ì‹¤íŒ¨ ì²´ì¸ ì •ë¦¬)
    if len(chains) > 50:
        active = [c for c in chains if c.get("status") in ("running", "pending")]
        done = [c for c in chains if c.get("status") not in ("running", "pending")]
        chains = active + done[-20:]
    save_setting("batch_chains", chains)


def _load_chain(chain_id: str) -> dict | None:
    """DBì—ì„œ ë°°ì¹˜ ì²´ì¸ ìƒíƒœë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    chains = load_setting("batch_chains") or []
    for c in chains:
        if c["chain_id"] == chain_id:
            return c
    return None


async def _broadcast_chain_status(chain: dict, message: str):
    """ë°°ì¹˜ ì²´ì¸ ì§„í–‰ ìƒí™©ì„ WebSocketìœ¼ë¡œ CEOì—ê²Œ ì•Œë¦½ë‹ˆë‹¤."""
    step_labels = {
        "classify": "1ë‹¨ê³„: ë¶„ë¥˜",
        "specialists": "2ë‹¨ê³„: ì „ë¬¸ê°€ ë¶„ì„",
        "synthesis": "3ë‹¨ê³„: ì¢…í•© ë³´ê³ ì„œ",
        "completed": "ì™„ë£Œ",
        "failed": "ì‹¤íŒ¨",
        "direct": "ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬",
    }
    step_label = step_labels.get(chain.get("step", ""), chain.get("step", ""))
    for c in connected_clients[:]:
        try:
            await c.send_json({
                "event": "batch_chain_progress",
                "data": {
                    "chain_id": chain["chain_id"],
                    "step": chain.get("step", ""),
                    "step_label": step_label,
                    "status": chain.get("status", ""),
                    "message": message,
                    "mode": chain.get("mode", "single"),
                    "target_id": chain.get("target_id"),
                },
            })
        except Exception:
            pass


async def _start_batch_chain(text: str, task_id: str) -> dict:
    """ë°°ì¹˜ ì²´ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤.

    CEO ëª…ë ¹ì„ ë°›ì•„ì„œ ìœ„ì„ ì²´ì¸ ì „ì²´ë¥¼ Batch APIë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    í‚¤ì›Œë“œ ë§¤ì¹­ì´ ë˜ë©´ ë¶„ë¥˜ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ê³  ë°”ë¡œ ì „ë¬¸ê°€ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
    """
    chain_id = f"chain_{datetime.now(KST).strftime('%Y%m%d_%H%M%S')}_{task_id[:8]}"

    chain = {
        "chain_id": chain_id,
        "task_id": task_id,
        "text": text,
        "mode": "broadcast" if _is_broadcast_command(text) else "single",
        "step": "classify",
        "status": "running",
        "target_id": None,
        "batches": {"classify": None, "specialists": [], "synthesis": []},
        "results": {"classify": None, "specialists": {}, "synthesis": {}},
        "custom_id_map": {},  # custom_id â†’ {"agent_id", "step"} ì—­ë§¤í•‘
        "total_cost_usd": 0.0,
        "created_at": datetime.now(KST).isoformat(),
        "completed_at": None,
    }

    # ì˜ˆì‚° í™•ì¸
    limit = float(load_setting("daily_budget_usd") or 7.0)
    today = get_today_cost()
    if today >= limit:
        update_task(task_id, status="failed",
                    result_summary=f"ì¼ì¼ ì˜ˆì‚° ì´ˆê³¼ (${today:.2f}/${limit:.0f})",
                    success=0)
        return {"error": f"ì¼ì¼ ì˜ˆì‚°ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ (${today:.2f}/${limit:.0f})"}

    # â”€â”€ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ëª¨ë“œ â†’ ë¶„ë¥˜ ê±´ë„ˆë›°ê³  ë°”ë¡œ ì „ ë¶€ì„œ ì „ë¬¸ê°€ â”€â”€
    if chain["mode"] == "broadcast":
        chain["step"] = "specialists"
        chain["target_id"] = "broadcast"
        _save_chain(chain)

        await _broadcast_chain_status(chain, "ğŸ“¦ ë°°ì¹˜ ì²´ì¸ ì‹œì‘ (ë¸Œë¡œë“œìºìŠ¤íŠ¸: 6ê°œ ë¶€ì„œ)")
        await _chain_submit_specialists_broadcast(chain)
        return {"chain_id": chain_id, "status": "started", "mode": "broadcast"}

    # â”€â”€ í‚¤ì›Œë“œ ë¶„ë¥˜ ì‹œë„ (ë¬´ë£Œ, ì¦‰ì‹œ) â”€â”€
    keyword_match = _classify_by_keywords(text)
    if keyword_match:
        chain["target_id"] = keyword_match
        chain["results"]["classify"] = {
            "agent_id": keyword_match,
            "method": "í‚¤ì›Œë“œ",
            "cost_usd": 0,
        }

        if keyword_match == "chief_of_staff":
            # ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬ â†’ ë°”ë¡œ ì¢…í•©(=ì§ì ‘ ë‹µë³€) ë‹¨ê³„
            chain["step"] = "synthesis"
            _save_chain(chain)
            await _broadcast_chain_status(chain, "ğŸ“¦ í‚¤ì›Œë“œ ë¶„ë¥˜ â†’ ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬")
            await _chain_submit_synthesis(chain)
        else:
            # ì²˜ì¥ ë¶€ì„œë¡œ ìœ„ì„ â†’ ì „ë¬¸ê°€ í˜¸ì¶œ ë‹¨ê³„
            chain["step"] = "specialists"
            _save_chain(chain)
            target_name = _AGENT_NAMES.get(keyword_match, keyword_match)
            await _broadcast_chain_status(chain, f"ğŸ“¦ í‚¤ì›Œë“œ ë¶„ë¥˜ â†’ {target_name}ì—ê²Œ ìœ„ì„")
            await _chain_submit_specialists(chain)

        return {"chain_id": chain_id, "status": "started", "step": chain["step"]}

    # â”€â”€ AI ë¶„ë¥˜ê°€ í•„ìš” â†’ Batch APIë¡œ ë¶„ë¥˜ ìš”ì²­ ì œì¶œ â”€â”€
    # ê°€ì¥ ì €ë ´í•œ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ ì„ íƒ
    providers = get_available_providers()
    if providers.get("anthropic"):
        classify_model = "claude-haiku-4-5-20251001"
    elif providers.get("google"):
        classify_model = "gemini-2.5-flash"
    elif providers.get("openai"):
        classify_model = "gpt-5-mini"
    else:
        # AI ì—†ìŒ â†’ ë¹„ì„œì‹¤ì¥ ì§ì ‘
        chain["target_id"] = "chief_of_staff"
        chain["step"] = "synthesis"
        chain["results"]["classify"] = {"agent_id": "chief_of_staff", "method": "í´ë°±"}
        _save_chain(chain)
        await _chain_submit_synthesis(chain)
        return {"chain_id": chain_id, "status": "started", "step": "synthesis"}

    classify_custom_id = f"{chain_id}_classify"
    classify_req = {
        "custom_id": classify_custom_id,
        "message": text,
        "system_prompt": _BATCH_CLASSIFY_PROMPT,
        "model": classify_model,
    }

    result = await batch_submit([classify_req], model=classify_model)

    if "error" in result:
        # ë°°ì¹˜ ì‹¤íŒ¨ â†’ í´ë°±ìœ¼ë¡œ ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬
        _log(f"[CHAIN] ë¶„ë¥˜ ë°°ì¹˜ ì‹¤íŒ¨: {result['error']} â†’ ë¹„ì„œì‹¤ì¥ í´ë°±")
        chain["target_id"] = "chief_of_staff"
        chain["step"] = "synthesis"
        chain["results"]["classify"] = {"agent_id": "chief_of_staff", "method": "í´ë°±", "error": result["error"]}
        _save_chain(chain)
        await _chain_submit_synthesis(chain)
        return {"chain_id": chain_id, "status": "started", "step": "synthesis"}

    chain["batches"]["classify"] = {
        "batch_id": result["batch_id"],
        "provider": result["provider"],
        "status": "pending",
    }
    chain["status"] = "pending"
    chain["custom_id_map"][classify_custom_id] = {"agent_id": "classify", "step": "classify"}
    _save_chain(chain)

    _ensure_batch_poller()
    update_task(task_id, status="pending",
                result_summary="ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 1ë‹¨ê³„: ë¶„ë¥˜ ìš”ì²­ ì œì¶œë¨")
    await _broadcast_chain_status(chain, "ğŸ“¦ ë°°ì¹˜ ì²´ì¸ ì‹œì‘ â€” 1ë‹¨ê³„: ë¶„ë¥˜ ìš”ì²­ ì œì¶œë¨")

    _log(f"[CHAIN] ì‹œì‘: {chain_id} â€” ë¶„ë¥˜ ë°°ì¹˜ ì œì¶œ (batch_id: {result['batch_id']})")
    return {"chain_id": chain_id, "status": "pending", "step": "classify"}


async def _chain_submit_specialists(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ â€” ë‹¨ì¼ ë¶€ì„œì˜ ì „ë¬¸ê°€ë“¤ì—ê²Œ ë°°ì¹˜ ì œì¶œí•©ë‹ˆë‹¤."""
    target_id = chain["target_id"]
    text = chain["text"]
    specialists = _MANAGER_SPECIALISTS.get(target_id, [])

    if not specialists:
        # ì „ë¬¸ê°€ ì—†ìŒ â†’ ë°”ë¡œ ì¢…í•©(ì²˜ì¥ ì§ì ‘ ì²˜ë¦¬) ë‹¨ê³„
        chain["step"] = "synthesis"
        _save_chain(chain)
        await _chain_submit_synthesis(chain)
        return

    requests = []
    for spec_id in specialists:
        soul = _load_agent_prompt(spec_id)
        override = _get_model_override(spec_id)
        model = select_model(text, override=override)
        custom_id = f"{chain['chain_id']}_spec_{spec_id}"

        requests.append({
            "custom_id": custom_id,
            "message": text,
            "system_prompt": soul,
            "model": model,
        })
        chain["custom_id_map"][custom_id] = {"agent_id": spec_id, "step": "specialists"}

    # í”„ë¡œë°”ì´ë”ë³„ ê·¸ë£¹í™”í•˜ì—¬ ë°°ì¹˜ ì œì¶œ
    batch_results = await batch_submit_grouped(requests)

    chain["batches"]["specialists"] = []
    for br in batch_results:
        chain["batches"]["specialists"].append({
            "batch_id": br.get("batch_id", ""),
            "provider": br.get("provider", ""),
            "status": "pending" if "error" not in br else "failed",
            "custom_ids": br.get("custom_ids", []),
            "error": br.get("error"),
        })

    chain["status"] = "pending"
    _save_chain(chain)

    _ensure_batch_poller()
    spec_count = len(specialists)
    provider_count = len(batch_results)
    target_name = _AGENT_NAMES.get(target_id, target_id)
    update_task(chain["task_id"], status="pending",
                result_summary=f"ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 2ë‹¨ê³„: {target_name} ì „ë¬¸ê°€ {spec_count}ëª… ë°°ì¹˜ ì œì¶œ ({provider_count}ê°œ í”„ë¡œë°”ì´ë”)")
    await _broadcast_chain_status(chain, f"ğŸ“¦ 2ë‹¨ê³„: {target_name} ì „ë¬¸ê°€ {spec_count}ëª… â†’ {provider_count}ê°œ í”„ë¡œë°”ì´ë”ë³„ ë°°ì¹˜ ì œì¶œ")

    _log(f"[CHAIN] {chain['chain_id']} â€” ì „ë¬¸ê°€ {spec_count}ëª… ë°°ì¹˜ ì œì¶œ ({provider_count}ê°œ í”„ë¡œë°”ì´ë”)")


async def _chain_submit_specialists_broadcast(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ â€” ë¸Œë¡œë“œìºìŠ¤íŠ¸: 6ê°œ ë¶€ì„œ ì „ì²´ ì „ë¬¸ê°€ì—ê²Œ ë°°ì¹˜ ì œì¶œí•©ë‹ˆë‹¤."""
    text = chain["text"]
    all_managers = ["cto_manager", "cso_manager", "clo_manager", "cmo_manager", "cio_manager", "cpo_manager"]

    requests = []
    for mgr_id in all_managers:
        specialists = _MANAGER_SPECIALISTS.get(mgr_id, [])
        for spec_id in specialists:
            soul = _load_agent_prompt(spec_id)
            override = _get_model_override(spec_id)
            model = select_model(text, override=override)
            custom_id = f"{chain['chain_id']}_spec_{spec_id}"

            requests.append({
                "custom_id": custom_id,
                "message": text,
                "system_prompt": soul,
                "model": model,
            })
            chain["custom_id_map"][custom_id] = {"agent_id": spec_id, "step": "specialists"}

    if not requests:
        chain["step"] = "synthesis"
        _save_chain(chain)
        await _chain_submit_synthesis(chain)
        return

    # í”„ë¡œë°”ì´ë”ë³„ ê·¸ë£¹í™”í•˜ì—¬ ë°°ì¹˜ ì œì¶œ
    batch_results = await batch_submit_grouped(requests)

    chain["batches"]["specialists"] = []
    for br in batch_results:
        chain["batches"]["specialists"].append({
            "batch_id": br.get("batch_id", ""),
            "provider": br.get("provider", ""),
            "status": "pending" if "error" not in br else "failed",
            "custom_ids": br.get("custom_ids", []),
            "error": br.get("error"),
        })

    chain["status"] = "pending"
    _save_chain(chain)

    _ensure_batch_poller()
    spec_count = len(requests)
    provider_count = len(batch_results)
    update_task(chain["task_id"], status="pending",
                result_summary=f"ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 2ë‹¨ê³„: ì „ì²´ {spec_count}ëª… ì „ë¬¸ê°€ ë°°ì¹˜ ì œì¶œ ({provider_count}ê°œ í”„ë¡œë°”ì´ë”)")
    await _broadcast_chain_status(chain, f"ğŸ“¦ 2ë‹¨ê³„: 6ê°œ ë¶€ì„œ ì „ë¬¸ê°€ {spec_count}ëª… â†’ {provider_count}ê°œ í”„ë¡œë°”ì´ë”ë³„ ë°°ì¹˜ ì œì¶œ")

    _log(f"[CHAIN] {chain['chain_id']} â€” ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì „ë¬¸ê°€ {spec_count}ëª… ë°°ì¹˜ ì œì¶œ")


async def _chain_submit_synthesis(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ â€” ì²˜ì¥(ë“¤)ì´ ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ëŠ” ë°°ì¹˜ë¥¼ ì œì¶œí•©ë‹ˆë‹¤."""
    text = chain["text"]

    requests = []

    if chain["mode"] == "broadcast":
        # ë¸Œë¡œë“œìºìŠ¤íŠ¸: 6ê°œ ì²˜ì¥ì´ ê°ê° ìê¸° íŒ€ ê²°ê³¼ë¥¼ ì¢…í•©
        all_managers = ["cto_manager", "cso_manager", "clo_manager", "cmo_manager", "cio_manager", "cpo_manager"]
        for mgr_id in all_managers:
            specialists = _MANAGER_SPECIALISTS.get(mgr_id, [])
            spec_parts = []
            for s_id in specialists:
                s_res = chain["results"]["specialists"].get(s_id, {})
                name = _SPECIALIST_NAMES.get(s_id, s_id)
                content = s_res.get("content", "ì‘ë‹µ ì—†ìŒ")
                if s_res.get("error"):
                    content = f"ì˜¤ë¥˜: {s_res['error'][:100]}"
                spec_parts.append(f"[{name}]\n{content}")

            mgr_name = _AGENT_NAMES.get(mgr_id, mgr_id)
            synthesis_prompt = (
                f"ë‹¹ì‹ ì€ {mgr_name}ì…ë‹ˆë‹¤. ì†Œì† ì „ë¬¸ê°€ë“¤ì´ ì•„ë˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì œì¶œí–ˆìŠµë‹ˆë‹¤.\n"
                f"ì´ë¥¼ ê²€ìˆ˜í•˜ê³  ì¢…í•©í•˜ì—¬ CEOì—ê²Œ ë³´ê³ í•  ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
                f"ì „ë¬¸ê°€ ì˜ê²¬ ì¤‘ ë¶€ì¡±í•˜ê±°ë‚˜ ì˜ëª»ëœ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì§€ì í•˜ê³  ë³´ì™„í•˜ì„¸ìš”.\n\n"
                f"## CEO ì›ë³¸ ëª…ë ¹\n{text}\n\n"
                f"## ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼\n" + "\n\n".join(spec_parts)
            )

            soul = _load_agent_prompt(mgr_id)
            override = _get_model_override(mgr_id)
            model = select_model(synthesis_prompt, override=override)
            custom_id = f"{chain['chain_id']}_synth_{mgr_id}"

            requests.append({
                "custom_id": custom_id,
                "message": synthesis_prompt,
                "system_prompt": soul,
                "model": model,
            })
            chain["custom_id_map"][custom_id] = {"agent_id": mgr_id, "step": "synthesis"}

    elif chain["target_id"] == "chief_of_staff":
        # ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬ (ë¶„ë¥˜ ê²°ê³¼ê°€ chief_of_staffì¸ ê²½ìš°)
        soul = _load_agent_prompt("chief_of_staff")
        override = _get_model_override("chief_of_staff")
        model = select_model(text, override=override)
        custom_id = f"{chain['chain_id']}_synth_chief_of_staff"

        requests.append({
            "custom_id": custom_id,
            "message": text,
            "system_prompt": soul,
            "model": model,
        })
        chain["custom_id_map"][custom_id] = {"agent_id": "chief_of_staff", "step": "synthesis"}

    else:
        # ë‹¨ì¼ ë¶€ì„œ: ì²˜ì¥ì´ ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì¢…í•©
        target_id = chain["target_id"]
        specialists = _MANAGER_SPECIALISTS.get(target_id, [])

        if not specialists or not chain["results"]["specialists"]:
            # ì „ë¬¸ê°€ ê²°ê³¼ ì—†ìŒ â†’ ì²˜ì¥ì´ ì§ì ‘ ë‹µë³€
            soul = _load_agent_prompt(target_id)
            override = _get_model_override(target_id)
            model = select_model(text, override=override)
            custom_id = f"{chain['chain_id']}_synth_{target_id}"

            requests.append({
                "custom_id": custom_id,
                "message": text,
                "system_prompt": soul,
                "model": model,
            })
            chain["custom_id_map"][custom_id] = {"agent_id": target_id, "step": "synthesis"}
        else:
            # ì „ë¬¸ê°€ ê²°ê³¼ ì·¨í•© â†’ ì²˜ì¥ì—ê²Œ ì¢…í•© ìš”ì²­
            spec_parts = []
            for s_id in specialists:
                s_res = chain["results"]["specialists"].get(s_id, {})
                name = _SPECIALIST_NAMES.get(s_id, s_id)
                content = s_res.get("content", "ì‘ë‹µ ì—†ìŒ")
                if s_res.get("error"):
                    content = f"ì˜¤ë¥˜: {s_res['error'][:100]}"
                spec_parts.append(f"[{name}]\n{content}")

            mgr_name = _AGENT_NAMES.get(target_id, target_id)
            synthesis_prompt = (
                f"ë‹¹ì‹ ì€ {mgr_name}ì…ë‹ˆë‹¤. ì†Œì† ì „ë¬¸ê°€ë“¤ì´ ì•„ë˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì œì¶œí–ˆìŠµë‹ˆë‹¤.\n"
                f"ì´ë¥¼ ê²€ìˆ˜í•˜ê³  ì¢…í•©í•˜ì—¬ CEOì—ê²Œ ë³´ê³ í•  ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
                f"ì „ë¬¸ê°€ ì˜ê²¬ ì¤‘ ë¶€ì¡±í•˜ê±°ë‚˜ ì˜ëª»ëœ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì§€ì í•˜ê³  ë³´ì™„í•˜ì„¸ìš”.\n\n"
                f"## CEO ì›ë³¸ ëª…ë ¹\n{text}\n\n"
                f"## ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼\n" + "\n\n".join(spec_parts)
            )

            soul = _load_agent_prompt(target_id)
            override = _get_model_override(target_id)
            model = select_model(synthesis_prompt, override=override)
            custom_id = f"{chain['chain_id']}_synth_{target_id}"

            requests.append({
                "custom_id": custom_id,
                "message": synthesis_prompt,
                "system_prompt": soul,
                "model": model,
            })
            chain["custom_id_map"][custom_id] = {"agent_id": target_id, "step": "synthesis"}

    if not requests:
        # ìš”ì²­ ì—†ìŒ â†’ ë°”ë¡œ ì™„ë£Œ
        await _deliver_chain_result(chain)
        return

    # í”„ë¡œë°”ì´ë”ë³„ ê·¸ë£¹í™”í•˜ì—¬ ë°°ì¹˜ ì œì¶œ
    batch_results = await batch_submit_grouped(requests)

    chain["batches"]["synthesis"] = []
    for br in batch_results:
        chain["batches"]["synthesis"].append({
            "batch_id": br.get("batch_id", ""),
            "provider": br.get("provider", ""),
            "status": "pending" if "error" not in br else "failed",
            "custom_ids": br.get("custom_ids", []),
            "error": br.get("error"),
        })

    chain["step"] = "synthesis"
    chain["status"] = "pending"
    _save_chain(chain)

    _ensure_batch_poller()

    if chain["mode"] == "broadcast":
        update_task(chain["task_id"], status="pending",
                    result_summary="ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 3ë‹¨ê³„: 6ê°œ ì²˜ì¥ ì¢…í•©ë³´ê³ ì„œ ë°°ì¹˜ ì œì¶œ")
        await _broadcast_chain_status(chain, "ğŸ“¦ 3ë‹¨ê³„: 6ê°œ ì²˜ì¥ì´ ì¢…í•©ë³´ê³ ì„œ ì‘ì„± ì¤‘ (ë°°ì¹˜)")
    else:
        target_name = _AGENT_NAMES.get(chain["target_id"], chain["target_id"])
        update_task(chain["task_id"], status="pending",
                    result_summary=f"ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 3ë‹¨ê³„: {target_name} ì¢…í•©ë³´ê³ ì„œ ë°°ì¹˜ ì œì¶œ")
        await _broadcast_chain_status(chain, f"ğŸ“¦ 3ë‹¨ê³„: {target_name} ì¢…í•©ë³´ê³ ì„œ ì‘ì„± ì¤‘ (ë°°ì¹˜)")

    _log(f"[CHAIN] {chain['chain_id']} â€” ì¢…í•©ë³´ê³ ì„œ ë°°ì¹˜ ì œì¶œ ({len(requests)}ê±´)")


async def _deliver_chain_result(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ ìµœì¢… ê²°ê³¼ë¥¼ CEOì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤."""
    task_id = chain["task_id"]
    text = chain["text"]
    total_cost = chain.get("total_cost_usd", 0)

    if chain["mode"] == "broadcast":
        # ë¸Œë¡œë“œìºìŠ¤íŠ¸: 6ê°œ ì²˜ì¥ ì¢…í•© ê²°ê³¼ë¥¼ ëª¨ì•„ì„œ ì „ë‹¬
        all_managers = ["cto_manager", "cso_manager", "clo_manager", "cmo_manager", "cio_manager", "cpo_manager"]
        parts = []
        total_specialists = 0
        for mgr_id in all_managers:
            synth = chain["results"]["synthesis"].get(mgr_id, {})
            mgr_name = _AGENT_NAMES.get(mgr_id, mgr_id)
            content = synth.get("content", "ì‘ë‹µ ì—†ìŒ")
            specs = len(_MANAGER_SPECIALISTS.get(mgr_id, []))
            total_specialists += specs
            spec_label = f" (ì „ë¬¸ê°€ {specs}ëª… ë™ì›)" if specs else ""
            parts.append(f"### ğŸ“‹ {mgr_name}{spec_label}\n{content}")

        compiled = (
            f"ğŸ“¢ **ë°°ì¹˜ ì²´ì¸ ê²°ê³¼** (6ê°œ ë¶€ì„œ + ì „ë¬¸ê°€ {total_specialists}ëª… ë™ì›)\n"
            f"ğŸ’° ì´ ë¹„ìš©: ${total_cost:.4f} (ë°°ì¹˜ í• ì¸ ~50% ì ìš©)\n\n---\n\n"
            + "\n\n---\n\n".join(parts)
        )

        update_task(task_id, status="completed",
                    result_summary=compiled[:500],
                    result_data=compiled,
                    success=1, cost_usd=total_cost,
                    agent_id="chief_of_staff")

        # WebSocketìœ¼ë¡œ ìµœì¢… ê²°ê³¼ ì „ë‹¬
        for c in connected_clients[:]:
            try:
                await c.send_json({
                    "event": "result",
                    "data": {
                        "content": compiled,
                        "sender_id": "chief_of_staff",
                        "handled_by": "ë¹„ì„œì‹¤ì¥ â†’ 6ê°œ ì²˜ì¥",
                        "delegation": "ë¹„ì„œì‹¤ì¥ â†’ ì²˜ì¥ â†’ ì „ë¬¸ê°€ (ë°°ì¹˜)",
                        "time_seconds": 0,
                        "cost": total_cost,
                        "model": "multi-agent-batch",
                        "routing_method": "ë°°ì¹˜ ì²´ì¸ (ë¸Œë¡œë“œìºìŠ¤íŠ¸)",
                    }
                })
            except Exception:
                pass

    else:
        # ë‹¨ì¼ ë¶€ì„œ ê²°ê³¼
        target_id = chain.get("target_id", "chief_of_staff")
        synth = chain["results"]["synthesis"].get(
            target_id,
            chain["results"]["synthesis"].get("chief_of_staff", {})
        )
        content = synth.get("content", "")
        target_name = _AGENT_NAMES.get(target_id, target_id)

        # ìœ„ì„ ì •ë³´ êµ¬ì„±
        specs_count = len(_MANAGER_SPECIALISTS.get(target_id, []))
        if target_id == "chief_of_staff":
            delegation = ""
            handled_by = "ë¹„ì„œì‹¤ì¥"
            header = "ğŸ“‹ **ë¹„ì„œì‹¤ì¥** (ë°°ì¹˜ ì²˜ë¦¬)"
        else:
            delegation = f"ë¹„ì„œì‹¤ì¥ â†’ {target_name}"
            if specs_count:
                delegation += f" â†’ ì „ë¬¸ê°€ {specs_count}ëª…"
            handled_by = target_name
            header = f"ğŸ“‹ **{target_name}** ë³´ê³  (ë°°ì¹˜ ì²´ì¸)"
            if specs_count:
                header += f" (ì†Œì† ì „ë¬¸ê°€ {specs_count}ëª… ë™ì›)"

        final_content = f"{header}\nğŸ’° ë¹„ìš©: ${total_cost:.4f} (ë°°ì¹˜ í• ì¸ ~50% ì ìš©)\n\n---\n\n{content}"

        update_task(task_id, status="completed",
                    result_summary=final_content[:500],
                    result_data=final_content,
                    success=1, cost_usd=total_cost,
                    agent_id=target_id)

        # WebSocketìœ¼ë¡œ ìµœì¢… ê²°ê³¼ ì „ë‹¬
        for c in connected_clients[:]:
            try:
                await c.send_json({
                    "event": "result",
                    "data": {
                        "content": final_content,
                        "sender_id": target_id,
                        "handled_by": handled_by,
                        "delegation": delegation,
                        "time_seconds": 0,
                        "cost": total_cost,
                        "model": synth.get("model", "batch"),
                        "routing_method": "ë°°ì¹˜ ì²´ì¸",
                    }
                })
            except Exception:
                pass

    # ì•„ì¹´ì´ë¸Œì— ì €ì¥
    synth_content = ""
    if chain["mode"] == "broadcast":
        synth_content = compiled
    else:
        synth_content = content

    if synth_content and len(synth_content) > 20:
        division = _AGENT_DIVISION.get(chain.get("target_id", "chief_of_staff"), "secretary")
        now_str = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
        save_archive(
            division=division,
            filename=f"batch_chain_{now_str}.md",
            content=f"# [ë°°ì¹˜ ì²´ì¸] {text[:60]}\n\n{synth_content}",
            agent_id=chain.get("target_id", "chief_of_staff"),
        )

    chain["step"] = "completed"
    chain["status"] = "completed"
    chain["completed_at"] = datetime.now(KST).isoformat()
    _save_chain(chain)

    await _broadcast_chain_status(chain, "âœ… ë°°ì¹˜ ì²´ì¸ ì™„ë£Œ â€” ìµœì¢… ë³´ê³ ì„œ ì „ë‹¬ë¨")
    _log(f"[CHAIN] {chain['chain_id']} â€” ì™„ë£Œ! ë¹„ìš©: ${total_cost:.4f}")


async def _advance_batch_chain(chain_id: str):
    """ë°°ì¹˜ ì²´ì¸ì˜ í˜„ì¬ ë‹¨ê³„ë¥¼ í™•ì¸í•˜ê³ , ì™„ë£Œë˜ì—ˆìœ¼ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.

    ë°°ì¹˜ í´ëŸ¬(_batch_poller_loop)ì—ì„œ 60ì´ˆë§ˆë‹¤ í˜¸ì¶œë©ë‹ˆë‹¤.
    """
    chain = _load_chain(chain_id)
    if not chain or chain.get("status") not in ("running", "pending"):
        return

    step = chain.get("step", "")

    # â”€â”€ 1ë‹¨ê³„: ë¶„ë¥˜ â”€â”€
    if step == "classify":
        batch_info = chain["batches"].get("classify")
        if not batch_info:
            return

        status_result = await batch_check(batch_info["batch_id"], batch_info["provider"])
        if "error" in status_result:
            return

        batch_info["status"] = status_result["status"]

        if status_result["status"] == "completed":
            # ë¶„ë¥˜ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            result = await batch_retrieve(batch_info["batch_id"], batch_info["provider"])
            if "error" in result:
                chain["status"] = "failed"
                _save_chain(chain)
                return

            # JSON íŒŒì‹± â€” {"agent_id": "cio_manager", "reason": "..."}
            results_list = result.get("results", [])
            if results_list:
                raw_content = results_list[0].get("content", "").strip()
                cost = results_list[0].get("cost_usd", 0)
                chain["total_cost_usd"] += cost

                try:
                    if "```" in raw_content:
                        raw_content = raw_content.split("```")[1]
                        if raw_content.startswith("json"):
                            raw_content = raw_content[4:]
                    parsed = json.loads(raw_content)
                    target_id = parsed.get("agent_id", "chief_of_staff")
                    reason = parsed.get("reason", "")
                except (json.JSONDecodeError, IndexError):
                    _log(f"[CHAIN] ë¶„ë¥˜ JSON íŒŒì‹± ì‹¤íŒ¨: {raw_content[:100]}")
                    target_id = "chief_of_staff"
                    reason = "ë¶„ë¥˜ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"
            else:
                target_id = "chief_of_staff"
                reason = "ë¶„ë¥˜ ê²°ê³¼ ì—†ìŒ"

            chain["target_id"] = target_id
            chain["results"]["classify"] = {
                "agent_id": target_id,
                "reason": reason,
                "method": "AIë¶„ë¥˜ (ë°°ì¹˜)",
                "cost_usd": cost if results_list else 0,
            }

            target_name = _AGENT_NAMES.get(target_id, target_id)
            _log(f"[CHAIN] {chain['chain_id']} â€” ë¶„ë¥˜ ì™„ë£Œ: {target_name} ({reason})")

            if target_id == "chief_of_staff":
                # ë¹„ì„œì‹¤ì¥ ì§ì ‘ â†’ ì¢…í•© ë‹¨ê³„
                chain["step"] = "synthesis"
                _save_chain(chain)
                await _broadcast_chain_status(chain, f"ğŸ“¦ ë¶„ë¥˜ ì™„ë£Œ: ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬")
                await _chain_submit_synthesis(chain)
            else:
                # ì „ë¬¸ê°€ ë‹¨ê³„ë¡œ ì§„í–‰
                chain["step"] = "specialists"
                _save_chain(chain)
                await _broadcast_chain_status(chain, f"ğŸ“¦ ë¶„ë¥˜ ì™„ë£Œ: {target_name}ì—ê²Œ ìœ„ì„ â†’ ì „ë¬¸ê°€ í˜¸ì¶œ")
                await _chain_submit_specialists(chain)

        elif status_result["status"] in ("failed", "expired"):
            # ë¶„ë¥˜ ë°°ì¹˜ ì‹¤íŒ¨ â†’ ë¹„ì„œì‹¤ì¥ í´ë°±
            chain["target_id"] = "chief_of_staff"
            chain["step"] = "synthesis"
            chain["results"]["classify"] = {"agent_id": "chief_of_staff", "method": "í´ë°±"}
            _save_chain(chain)
            await _chain_submit_synthesis(chain)

    # â”€â”€ 2ë‹¨ê³„: ì „ë¬¸ê°€ â”€â”€
    elif step == "specialists":
        all_done = True
        for batch_info in chain["batches"].get("specialists", []):
            if batch_info.get("status") in ("pending", "processing"):
                try:
                    status_result = await batch_check(batch_info["batch_id"], batch_info["provider"])
                    if "error" not in status_result:
                        batch_info["status"] = status_result["status"]
                except Exception as e:
                    _log(f"[CHAIN] ì „ë¬¸ê°€ ë°°ì¹˜ í™•ì¸ ì˜¤ë¥˜: {e}")

            if batch_info.get("status") not in ("completed", "failed"):
                all_done = False

        _save_chain(chain)

        if all_done:
            # ëª¨ë“  ì „ë¬¸ê°€ ë°°ì¹˜ ì™„ë£Œ â†’ ê²°ê³¼ ìˆ˜ì§‘
            for batch_info in chain["batches"]["specialists"]:
                if batch_info.get("status") != "completed":
                    continue

                result = await batch_retrieve(batch_info["batch_id"], batch_info["provider"])
                if "error" in result:
                    continue

                for r in result.get("results", []):
                    custom_id = r.get("custom_id", "")
                    mapping = chain["custom_id_map"].get(custom_id, {})
                    agent_id = mapping.get("agent_id", custom_id)

                    chain["results"]["specialists"][agent_id] = {
                        "content": r.get("content", ""),
                        "model": r.get("model", ""),
                        "cost_usd": r.get("cost_usd", 0),
                        "error": r.get("error"),
                    }
                    chain["total_cost_usd"] += r.get("cost_usd", 0)

            spec_count = len(chain["results"]["specialists"])
            _log(f"[CHAIN] {chain['chain_id']} â€” ì „ë¬¸ê°€ {spec_count}ëª… ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ")

            # ì¢…í•© ë‹¨ê³„ë¡œ ì§„í–‰
            chain["step"] = "synthesis"
            _save_chain(chain)
            await _broadcast_chain_status(chain, f"ğŸ“¦ ì „ë¬¸ê°€ {spec_count}ëª… ì™„ë£Œ â†’ ì¢…í•©ë³´ê³ ì„œ ì‘ì„± ì‹œì‘")
            await _chain_submit_synthesis(chain)

    # â”€â”€ 3ë‹¨ê³„: ì¢…í•©ë³´ê³ ì„œ â”€â”€
    elif step == "synthesis":
        all_done = True
        for batch_info in chain["batches"].get("synthesis", []):
            if batch_info.get("status") in ("pending", "processing"):
                try:
                    status_result = await batch_check(batch_info["batch_id"], batch_info["provider"])
                    if "error" not in status_result:
                        batch_info["status"] = status_result["status"]
                except Exception as e:
                    _log(f"[CHAIN] ì¢…í•© ë°°ì¹˜ í™•ì¸ ì˜¤ë¥˜: {e}")

            if batch_info.get("status") not in ("completed", "failed"):
                all_done = False

        _save_chain(chain)

        if all_done:
            # ì¢…í•©ë³´ê³ ì„œ ê²°ê³¼ ìˆ˜ì§‘
            for batch_info in chain["batches"]["synthesis"]:
                if batch_info.get("status") != "completed":
                    continue

                result = await batch_retrieve(batch_info["batch_id"], batch_info["provider"])
                if "error" in result:
                    continue

                for r in result.get("results", []):
                    custom_id = r.get("custom_id", "")
                    mapping = chain["custom_id_map"].get(custom_id, {})
                    agent_id = mapping.get("agent_id", custom_id)

                    chain["results"]["synthesis"][agent_id] = {
                        "content": r.get("content", ""),
                        "model": r.get("model", ""),
                        "cost_usd": r.get("cost_usd", 0),
                        "error": r.get("error"),
                    }
                    chain["total_cost_usd"] += r.get("cost_usd", 0)

            _log(f"[CHAIN] {chain['chain_id']} â€” ì¢…í•©ë³´ê³ ì„œ ì™„ë£Œ")

            # ìµœì¢… ì „ë‹¬
            await _deliver_chain_result(chain)


@app.get("/api/batch/chains")
async def get_batch_chains():
    """ì§„í–‰ ì¤‘ì¸ ë°°ì¹˜ ì²´ì¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    chains = load_setting("batch_chains") or []
    active = [c for c in chains if c.get("status") in ("running", "pending")]
    recent_done = [c for c in chains if c.get("status") in ("completed", "failed")][-10:]
    return {"active": active, "recent": recent_done}


# â”€â”€ í¬ë¡  ì‹¤í–‰ ì—”ì§„ (asyncio ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬) â”€â”€

_cron_task = None  # í¬ë¡  ë£¨í”„ íƒœìŠ¤í¬


def _parse_cron_preset(preset: str) -> dict:
    """í¬ë¡  í”„ë¦¬ì…‹ì„ ì‹¤í–‰ ì¡°ê±´ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    presets = {
        "every_minute": {"interval_seconds": 60},
        "every_5min": {"interval_seconds": 300},
        "every_30min": {"interval_seconds": 1800},
        "hourly": {"interval_seconds": 3600},
        "daily_9am": {"hour": 9, "minute": 0},
        "daily_6pm": {"hour": 18, "minute": 0},
        "weekday_9am": {"hour": 9, "minute": 0, "weekday_only": True},
        "monday_9am": {"hour": 9, "minute": 0, "day_of_week": 0},
    }
    return presets.get(preset, {"interval_seconds": 3600})


def _should_run_schedule(schedule: dict, now: datetime) -> bool:
    """í˜„ì¬ ì‹œê°„ì— ì´ ì˜ˆì•½ì„ ì‹¤í–‰í•´ì•¼ í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    if not schedule.get("enabled", False):
        return False

    preset = schedule.get("cron_preset", "")
    cron_config = _parse_cron_preset(preset)

    # ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê°„ í™•ì¸
    last_run = schedule.get("last_run_ts", 0)
    elapsed = now.timestamp() - last_run

    if "interval_seconds" in cron_config:
        return elapsed >= cron_config["interval_seconds"]

    # ì‹œ/ë¶„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„
    if now.hour == cron_config.get("hour", -1) and now.minute == cron_config.get("minute", -1):
        if cron_config.get("weekday_only") and now.weekday() >= 5:
            return False
        if "day_of_week" in cron_config and now.weekday() != cron_config["day_of_week"]:
            return False
        # ê°™ì€ ì‹œê°ì— ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ (ìµœì†Œ 55ì´ˆ ê°„ê²©)
        return elapsed >= 55
    return False


async def _cron_loop():
    """1ë¶„ë§ˆë‹¤ ì˜ˆì•½ëœ ì‘ì—…ì„ í™•ì¸í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤."""
    logger = logging.getLogger("corthex.cron")
    logger.info("í¬ë¡  ì‹¤í–‰ ì—”ì§„ ì‹œì‘")

    while True:
        try:
            await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
            schedules = _load_data("schedules", [])
            now = datetime.now(KST)

            for schedule in schedules:
                if _should_run_schedule(schedule, now):
                    command = schedule.get("command", "")
                    if not command:
                        continue

                    logger.info("í¬ë¡  ì‹¤í–‰: %s â€” %s", schedule.get("name", ""), command)
                    save_activity_log("system", f"â° ì˜ˆì•½ ì‹¤í–‰: {schedule.get('name', '')} â€” {command[:50]}", "info")

                    # ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
                    schedule["last_run"] = now.strftime("%Y-%m-%d %H:%M")
                    schedule["last_run_ts"] = now.timestamp()
                    _save_data("schedules", schedules)

                    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëª…ë ¹ ì‹¤í–‰
                    asyncio.create_task(_run_scheduled_command(command, schedule.get("name", "")))

        except Exception as e:
            logger.error("í¬ë¡  ë£¨í”„ ì—ëŸ¬: %s", e)


async def _run_scheduled_command(command: str, schedule_name: str):
    """ì˜ˆì•½ëœ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    try:
        result = await _process_ai_command(command, source="cron")
        save_activity_log("system", f"âœ… ì˜ˆì•½ ì™„ë£Œ: {schedule_name}", "info")
    except Exception as e:
        save_activity_log("system", f"âŒ ì˜ˆì•½ ì‹¤íŒ¨: {schedule_name} â€” {str(e)[:100]}", "error")


@app.get("/api/replay/{correlation_id}")
async def get_replay(correlation_id: str):
    return {"steps": []}


@app.get("/api/replay/latest")
async def get_replay_latest():
    return {"steps": []}


# â”€â”€ ì˜ˆì•½ (ìŠ¤ì¼€ì¤„) ê´€ë¦¬ â”€â”€

@app.get("/api/schedules")
async def get_schedules():
    return _load_data("schedules", [])


@app.post("/api/schedules")
async def add_schedule(request: Request):
    """ìƒˆ ì˜ˆì•½ ì¶”ê°€."""
    body = await request.json()
    schedules = _load_data("schedules", [])
    schedule_id = f"sch_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{len(schedules)}"
    schedule = {
        "id": schedule_id,
        "name": body.get("name", ""),
        "command": body.get("command", ""),
        "cron": body.get("cron", ""),
        "cron_preset": body.get("cron_preset", ""),
        "description": body.get("description", ""),
        "enabled": True,
        "created_at": datetime.now(KST).isoformat(),
    }
    schedules.append(schedule)
    _save_data("schedules", schedules)
    return {"success": True, "schedule": schedule}


@app.post("/api/schedules/{schedule_id}/toggle")
async def toggle_schedule(schedule_id: str):
    """ì˜ˆì•½ í™œì„±í™”/ë¹„í™œì„±í™”."""
    schedules = _load_data("schedules", [])
    for s in schedules:
        if s.get("id") == schedule_id:
            s["enabled"] = not s.get("enabled", True)
            _save_data("schedules", schedules)
            return {"success": True, "enabled": s["enabled"]}
    return {"success": False, "error": "not found"}


@app.delete("/api/schedules/{schedule_id}")
async def delete_schedule(schedule_id: str):
    """ì˜ˆì•½ ì‚­ì œ."""
    schedules = _load_data("schedules", [])
    schedules = [s for s in schedules if s.get("id") != schedule_id]
    _save_data("schedules", schedules)
    return {"success": True}


# â”€â”€ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ â”€â”€

@app.get("/api/workflows")
async def get_workflows():
    return _load_data("workflows", [])


@app.post("/api/workflows")
async def create_workflow(request: Request):
    """ìƒˆ ì›Œí¬í”Œë¡œìš° ìƒì„±."""
    body = await request.json()
    workflows = _load_data("workflows", [])
    wf_id = f"wf_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{len(workflows)}"
    workflow = {
        "id": wf_id,
        "name": body.get("name", "ìƒˆ ì›Œí¬í”Œë¡œìš°"),
        "description": body.get("description", ""),
        "steps": body.get("steps", []),
        "created_at": datetime.now(KST).isoformat(),
    }
    workflows.append(workflow)
    _save_data("workflows", workflows)
    return {"success": True, "workflow": workflow}


@app.put("/api/workflows/{wf_id}")
async def save_workflow(wf_id: str, request: Request):
    """ì›Œí¬í”Œë¡œìš° ìˆ˜ì •."""
    body = await request.json()
    workflows = _load_data("workflows", [])
    for wf in workflows:
        if wf.get("id") == wf_id:
            wf["name"] = body.get("name", wf.get("name", ""))
            wf["description"] = body.get("description", wf.get("description", ""))
            wf["steps"] = body.get("steps", wf.get("steps", []))
            _save_data("workflows", workflows)
            return {"success": True, "workflow": wf}
    return {"success": False, "error": "not found"}


@app.delete("/api/workflows/{wf_id}")
async def delete_workflow(wf_id: str):
    """ì›Œí¬í”Œë¡œìš° ì‚­ì œ."""
    workflows = _load_data("workflows", [])
    workflows = [w for w in workflows if w.get("id") != wf_id]
    _save_data("workflows", workflows)
    return {"success": True}


@app.post("/api/workflows/{wf_id}/run")
async def run_workflow(wf_id: str):
    """ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤ â€” ìŠ¤í…ì„ ìˆœì„œëŒ€ë¡œ AIë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    workflows = _load_data("workflows", [])
    wf = None
    for w in workflows:
        if w.get("id") == wf_id:
            wf = w
            break
    if not wf:
        return {"success": False, "error": "ì›Œí¬í”Œë¡œìš°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    steps = wf.get("steps", [])
    if not steps:
        return {"success": False, "error": "ì›Œí¬í”Œë¡œìš°ì— ì‹¤í–‰í•  ë‹¨ê³„ê°€ ì—†ìŠµë‹ˆë‹¤"}

    if not is_ai_ready():
        return {"success": False, "error": "AIê°€ ì—°ê²°ë˜ì§€ ì•Šì•„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆœì°¨ ì‹¤í–‰
    asyncio.create_task(_run_workflow_steps(wf_id, wf.get("name", ""), steps))
    return {"success": True, "message": f"ì›Œí¬í”Œë¡œìš° '{wf.get('name', '')}' ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤ ({len(steps)}ë‹¨ê³„)"}


async def _run_workflow_steps(wf_id: str, wf_name: str, steps: list):
    """ì›Œí¬í”Œë¡œìš° ìŠ¤í…ì„ ìˆœì°¨ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    save_activity_log("system", f"ğŸ”„ ì›Œí¬í”Œë¡œìš° ì‹œì‘: {wf_name} ({len(steps)}ë‹¨ê³„)", "info")
    results = []
    prev_result = ""

    for i, step in enumerate(steps):
        step_name = step.get("name", f"ë‹¨ê³„ {i+1}")
        command = step.get("command", "")
        if not command:
            continue

        # ì´ì „ ë‹¨ê³„ ê²°ê³¼ë¥¼ ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡ ëª…ë ¹ì— ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if prev_result and i > 0:
            command = f"[ì´ì „ ë‹¨ê³„ ê²°ê³¼ ì°¸ê³ : {prev_result[:500]}]\n\n{command}"

        save_activity_log("system", f"â–¶ {wf_name} â€” {step_name} ì‹¤í–‰ ì¤‘", "info")

        try:
            result = await _process_ai_command(command, source="workflow")
            content = result.get("content", "") if isinstance(result, dict) else str(result)
            prev_result = content[:500]
            results.append({"step": step_name, "status": "completed", "result": content[:200]})
            save_activity_log("system", f"âœ… {wf_name} â€” {step_name} ì™„ë£Œ", "info")
        except Exception as e:
            results.append({"step": step_name, "status": "failed", "error": str(e)[:200]})
            save_activity_log("system", f"âŒ {wf_name} â€” {step_name} ì‹¤íŒ¨: {str(e)[:100]}", "error")
            break  # ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨

    save_activity_log("system", f"ğŸ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ: {wf_name} â€” {len(results)}/{len(steps)} ë‹¨ê³„ ì²˜ë¦¬", "info")


# â”€â”€ ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ (í‚¤ì›€ì¦ê¶Œ í”„ë ˆì„ì›Œí¬) â”€â”€

_trading_bot_active = False  # ìë™ë§¤ë§¤ ë´‡ ON/OFF
_trading_bot_task = None     # ìë™ë§¤ë§¤ ë´‡ asyncio Task


def _default_portfolio() -> dict:
    """ê¸°ë³¸ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°."""
    return {
        "cash": 50_000_000,    # ì´ˆê¸° í˜„ê¸ˆ (5ì²œë§Œì›)
        "initial_cash": 50_000_000,
        "holdings": [],        # [{ticker, name, qty, avg_price, current_price}]
        "updated_at": datetime.now(KST).isoformat(),
    }


def _default_trading_settings() -> dict:
    """ê¸°ë³¸ ìë™ë§¤ë§¤ ì„¤ì •."""
    return {
        "max_position_pct": 20,       # ì¢…ëª©ë‹¹ ìµœëŒ€ ë¹„ì¤‘ (%)
        "max_daily_trades": 10,       # ì¼ì¼ ìµœëŒ€ ê±°ë˜ íšŸìˆ˜
        "max_daily_loss_pct": 3,      # ì¼ì¼ ìµœëŒ€ ì†ì‹¤ (%)
        "default_stop_loss_pct": -5,  # ê¸°ë³¸ ì†ì ˆ (%)
        "default_take_profit_pct": 10, # ê¸°ë³¸ ìµì ˆ (%)
        "order_size": 1_000_000,      # ê¸°ë³¸ ì£¼ë¬¸ ê¸ˆì•¡ (ì›)
        "trading_hours_kr": {"start": "09:00", "end": "15:20"},   # í•œêµ­ ì¥ ì‹œê°„
        "trading_hours_us": {"start": "22:30", "end": "05:00"},   # ë¯¸êµ­ ì¥ ì‹œê°„ (KST ê¸°ì¤€, ì„œë¨¸íƒ€ì„ ì‹œ 23:30)
        "trading_hours": {"start": "09:00", "end": "15:20"},      # í•˜ìœ„í˜¸í™˜
        "auto_stop_loss": True,       # ìë™ ì†ì ˆ í™œì„±í™”
        "auto_take_profit": True,     # ìë™ ìµì ˆ í™œì„±í™”
        "auto_execute": False,        # CIO ì‹œê·¸ë„ ê¸°ë°˜ ìë™ ì£¼ë¬¸ ì‹¤í–‰ (ì•ˆì „ì¥ì¹˜: ê¸°ë³¸ OFF)
        "min_confidence": 70,         # ìë™ë§¤ë§¤ ìµœì†Œ ì‹ ë¢°ë„ (%)
        "kiwoom_connected": False,    # í‚¤ì›€ì¦ê¶Œ API ì—°ê²° ì—¬ë¶€
        "paper_trading": True,        # ëª¨ì˜íˆ¬ì ëª¨ë“œ (ì‹¤ê±°ë˜ ì „)
    }


@app.get("/api/trading/summary")
async def get_trading_summary():
    """íŠ¸ë ˆì´ë”© ëŒ€ì‹œë³´ë“œ ìš”ì•½ ë°ì´í„°."""
    portfolio = _load_data("trading_portfolio", _default_portfolio())
    strategies = _load_data("trading_strategies", [])
    watchlist = _load_data("trading_watchlist", [])
    history = _load_data("trading_history", [])
    signals = _load_data("trading_signals", [])
    settings = _load_data("trading_settings", _default_trading_settings())

    # í¬íŠ¸í´ë¦¬ì˜¤ í‰ê°€ ê³„ì‚°
    holdings = portfolio.get("holdings", [])
    total_eval = sum(h.get("current_price", 0) * h.get("qty", 0) for h in holdings)
    total_buy_cost = sum(h.get("avg_price", 0) * h.get("qty", 0) for h in holdings)
    cash = portfolio.get("cash", 0)
    total_asset = cash + total_eval
    total_pnl = total_eval - total_buy_cost
    pnl_pct = (total_pnl / total_buy_cost * 100) if total_buy_cost > 0 else 0

    # ì˜¤ëŠ˜ ê±°ë˜ ì§‘ê³„
    today_str = datetime.now(KST).strftime("%Y-%m-%d")
    today_trades = [t for t in history if t.get("date", "").startswith(today_str)]
    today_pnl = sum(t.get("pnl", 0) for t in today_trades)

    active_strategies = [s for s in strategies if s.get("active")]

    return {
        "portfolio": {
            "cash": cash,
            "total_eval": total_eval,
            "total_asset": total_asset,
            "total_pnl": total_pnl,
            "pnl_pct": round(pnl_pct, 2),
            "holdings_count": len(holdings),
            "initial_cash": portfolio.get("initial_cash", 50_000_000),
        },
        "strategies": {
            "total": len(strategies),
            "active": len(active_strategies),
        },
        "watchlist_count": len(watchlist),
        "today": {
            "trades": len(today_trades),
            "pnl": today_pnl,
        },
        "signals_count": len(signals),
        "settings": settings,
        "bot_active": _trading_bot_active,
    }


@app.get("/api/trading/portfolio")
async def get_trading_portfolio():
    """í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ë°ì´í„°."""
    portfolio = _load_data("trading_portfolio", _default_portfolio())
    return portfolio


@app.post("/api/trading/portfolio")
async def update_trading_portfolio(request: Request):
    """í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸ (ì´ˆê¸° ìê¸ˆ ì„¤ì • ë“±)."""
    body = await request.json()
    portfolio = _load_data("trading_portfolio", _default_portfolio())

    if "cash" in body:
        portfolio["cash"] = body["cash"]
    if "initial_cash" in body:
        portfolio["initial_cash"] = body["initial_cash"]
        portfolio["cash"] = body["initial_cash"]
        portfolio["holdings"] = []
    portfolio["updated_at"] = datetime.now(KST).isoformat()

    _save_data("trading_portfolio", portfolio)
    save_activity_log("system", f"ğŸ’° í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸: í˜„ê¸ˆ {portfolio['cash']:,.0f}ì›", "info")
    return {"success": True, "portfolio": portfolio}


@app.get("/api/trading/strategies")
async def get_trading_strategies():
    """ë§¤ë§¤ ì „ëµ ëª©ë¡."""
    return _load_data("trading_strategies", [])


@app.post("/api/trading/strategies")
async def save_trading_strategy(request: Request):
    """ë§¤ë§¤ ì „ëµ ì¶”ê°€/ìˆ˜ì •."""
    body = await request.json()
    strategies = _load_data("trading_strategies", [])

    strategy_id = body.get("id") or f"strat_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{len(strategies)}"

    existing = next((s for s in strategies if s.get("id") == strategy_id), None)
    if existing:
        existing.update({
            "name": body.get("name", existing.get("name", "")),
            "type": body.get("type", existing.get("type", "manual")),
            "indicator": body.get("indicator", existing.get("indicator", "")),
            "buy_condition": body.get("buy_condition", existing.get("buy_condition", "")),
            "sell_condition": body.get("sell_condition", existing.get("sell_condition", "")),
            "target_tickers": body.get("target_tickers", existing.get("target_tickers", [])),
            "stop_loss_pct": body.get("stop_loss_pct", existing.get("stop_loss_pct", -5)),
            "take_profit_pct": body.get("take_profit_pct", existing.get("take_profit_pct", 10)),
            "order_size": body.get("order_size", existing.get("order_size", 1_000_000)),
            "active": body.get("active", existing.get("active", True)),
            "updated_at": datetime.now(KST).isoformat(),
        })
    else:
        strategy = {
            "id": strategy_id,
            "name": body.get("name", "ìƒˆ ì „ëµ"),
            "type": body.get("type", "manual"),
            "indicator": body.get("indicator", ""),
            "buy_condition": body.get("buy_condition", ""),
            "sell_condition": body.get("sell_condition", ""),
            "target_tickers": body.get("target_tickers", []),
            "stop_loss_pct": body.get("stop_loss_pct", -5),
            "take_profit_pct": body.get("take_profit_pct", 10),
            "order_size": body.get("order_size", 1_000_000),
            "active": body.get("active", True),
            "created_at": datetime.now(KST).isoformat(),
            "updated_at": datetime.now(KST).isoformat(),
        }
        strategies.append(strategy)

    _save_data("trading_strategies", strategies)
    save_activity_log("system", f"ğŸ“Š ë§¤ë§¤ ì „ëµ ì €ì¥: {body.get('name', strategy_id)}", "info")
    return {"success": True, "strategies": strategies}


@app.delete("/api/trading/strategies/{strategy_id}")
async def delete_trading_strategy(strategy_id: str):
    """ë§¤ë§¤ ì „ëµ ì‚­ì œ."""
    strategies = _load_data("trading_strategies", [])
    strategies = [s for s in strategies if s.get("id") != strategy_id]
    _save_data("trading_strategies", strategies)
    return {"success": True}


@app.put("/api/trading/strategies/{strategy_id}/toggle")
async def toggle_trading_strategy(strategy_id: str):
    """ë§¤ë§¤ ì „ëµ í™œì„±/ë¹„í™œì„± í† ê¸€."""
    strategies = _load_data("trading_strategies", [])
    for s in strategies:
        if s.get("id") == strategy_id:
            s["active"] = not s.get("active", True)
            _save_data("trading_strategies", strategies)
            return {"success": True, "active": s["active"]}
    return {"success": False, "error": "ì „ëµì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}


@app.get("/api/trading/watchlist")
async def get_trading_watchlist():
    """ê´€ì‹¬ ì¢…ëª© ëª©ë¡."""
    return _load_data("trading_watchlist", [])


@app.post("/api/trading/watchlist")
async def add_trading_watchlist(request: Request):
    """ê´€ì‹¬ ì¢…ëª© ì¶”ê°€."""
    body = await request.json()
    watchlist = _load_data("trading_watchlist", [])

    ticker = body.get("ticker", "")
    if not ticker:
        return {"success": False, "error": "ì¢…ëª©ì½”ë“œ í•„ìˆ˜"}

    # ì¤‘ë³µ ì²´í¬
    if any(w.get("ticker") == ticker for w in watchlist):
        return {"success": False, "error": "ì´ë¯¸ ë“±ë¡ëœ ì¢…ëª©"}

    item = {
        "ticker": ticker,
        "name": body.get("name", ticker),
        "market": body.get("market", "KR"),
        "target_price": body.get("target_price", 0),
        "alert_type": body.get("alert_type", "above"),
        "notes": body.get("notes", ""),
        "added_at": datetime.now(KST).isoformat(),
    }
    watchlist.append(item)
    _save_data("trading_watchlist", watchlist)
    save_activity_log("system", f"ğŸ‘ï¸ ê´€ì‹¬ì¢…ëª© ì¶”ê°€: {item['name']} ({ticker})", "info")
    return {"success": True, "watchlist": watchlist}


@app.delete("/api/trading/watchlist/{ticker}")
async def remove_trading_watchlist(ticker: str):
    """ê´€ì‹¬ ì¢…ëª© ì‚­ì œ."""
    watchlist = _load_data("trading_watchlist", [])
    watchlist = [w for w in watchlist if w.get("ticker") != ticker]
    _save_data("trading_watchlist", watchlist)
    return {"success": True}


@app.get("/api/trading/watchlist/prices")
async def get_watchlist_prices():
    """ê´€ì‹¬ì¢…ëª©ì˜ ì‹¤ì‹œê°„ í˜„ì¬ê°€ë¥¼ ì¡°íšŒ.

    í•œêµ­ ì£¼ì‹: pykrx ë¼ì´ë¸ŒëŸ¬ë¦¬ (í•œêµ­ê±°ë˜ì†Œ ë¬´ë£Œ ë°ì´í„°)
    ë¯¸êµ­ ì£¼ì‹: yfinance ë¼ì´ë¸ŒëŸ¬ë¦¬ (Yahoo Finance ë¬´ë£Œ ë°ì´í„°)
    """
    watchlist = _load_data("trading_watchlist", [])
    if not watchlist:
        return {"prices": {}, "updated_at": datetime.now(KST).isoformat()}

    prices = {}

    # --- í•œêµ­ ì£¼ì‹ (pykrx) ---
    kr_tickers = [w for w in watchlist if w.get("market", "KR") == "KR"]
    if kr_tickers:
        try:
            from pykrx import stock as pykrx_stock
            today = datetime.now(KST).strftime("%Y%m%d")
            # ìµœê·¼ 5ì˜ì—…ì¼ ë²”ìœ„ë¡œ ì¡°íšŒ (ì£¼ë§/ê³µíœ´ì¼ ëŒ€ë¹„)
            start = (datetime.now(KST) - timedelta(days=7)).strftime("%Y%m%d")
            for w in kr_tickers:
                try:
                    df = await asyncio.to_thread(
                        pykrx_stock.get_market_ohlcv_by_date, start, today, w["ticker"]
                    )
                    if df is not None and not df.empty:
                        latest = df.iloc[-1]
                        prev = df.iloc[-2] if len(df) >= 2 else latest
                        close = int(latest["ì¢…ê°€"])
                        prev_close = int(prev["ì¢…ê°€"])
                        change = close - prev_close
                        change_pct = round((change / prev_close) * 100, 2) if prev_close else 0
                        prices[w["ticker"]] = {
                            "current_price": close,
                            "prev_close": prev_close,
                            "change": change,
                            "change_pct": change_pct,
                            "volume": int(latest.get("ê±°ë˜ëŸ‰", 0)),
                            "high": int(latest.get("ê³ ê°€", 0)),
                            "low": int(latest.get("ì €ê°€", 0)),
                            "currency": "KRW",
                        }
                except Exception as e:
                    logger.warning("í•œêµ­ ì£¼ê°€ ì¡°íšŒ ì‹¤íŒ¨ %s: %s", w["ticker"], e)
                    prices[w["ticker"]] = {"error": str(e)}
        except ImportError:
            for w in kr_tickers:
                prices[w["ticker"]] = {"error": "pykrx ë¯¸ì„¤ì¹˜"}

    # --- ë¯¸êµ­ ì£¼ì‹ (yfinance) ---
    us_tickers = [w for w in watchlist if w.get("market") == "US"]
    if us_tickers:
        try:
            import yfinance as yf
            for w in us_tickers:
                try:
                    ticker_obj = yf.Ticker(w["ticker"])
                    hist = await asyncio.to_thread(
                        lambda t=ticker_obj: t.history(period="5d")
                    )
                    if hist is not None and not hist.empty:
                        latest = hist.iloc[-1]
                        prev = hist.iloc[-2] if len(hist) >= 2 else latest
                        close = round(float(latest["Close"]), 2)
                        prev_close = round(float(prev["Close"]), 2)
                        change = round(close - prev_close, 2)
                        change_pct = round((change / prev_close) * 100, 2) if prev_close else 0
                        prices[w["ticker"]] = {
                            "current_price": close,
                            "prev_close": prev_close,
                            "change": change,
                            "change_pct": change_pct,
                            "volume": int(latest.get("Volume", 0)),
                            "high": round(float(latest.get("High", 0)), 2),
                            "low": round(float(latest.get("Low", 0)), 2),
                            "currency": "USD",
                        }
                except Exception as e:
                    logger.warning("ë¯¸êµ­ ì£¼ê°€ ì¡°íšŒ ì‹¤íŒ¨ %s: %s", w["ticker"], e)
                    prices[w["ticker"]] = {"error": str(e)}
        except ImportError:
            for w in us_tickers:
                prices[w["ticker"]] = {"error": "yfinance ë¯¸ì„¤ì¹˜"}

    return {"prices": prices, "updated_at": datetime.now(KST).isoformat()}


@app.get("/api/trading/watchlist/chart/{ticker}")
async def get_watchlist_chart(ticker: str, market: str = "KR", days: int = 30):
    """ê´€ì‹¬ì¢…ëª©ì˜ ì¼ë³„ ê°€ê²© ë°ì´í„° (ì°¨íŠ¸ìš©).

    ê°„ë‹¨í•œ ì¼ë³„ ì¢…ê°€ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì„  ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
    """
    chart_data = []

    if market == "KR":
        try:
            from pykrx import stock as pykrx_stock
            end = datetime.now(KST).strftime("%Y%m%d")
            start = (datetime.now(KST) - timedelta(days=days + 10)).strftime("%Y%m%d")
            df = await asyncio.to_thread(
                pykrx_stock.get_market_ohlcv_by_date, start, end, ticker
            )
            if df is not None and not df.empty:
                for date, row in df.tail(days).iterrows():
                    chart_data.append({
                        "date": date.strftime("%m/%d"),
                        "close": int(row["ì¢…ê°€"]),
                        "volume": int(row.get("ê±°ë˜ëŸ‰", 0)),
                    })
        except ImportError:
            return {"ticker": ticker, "chart": [], "error": "pykrx ë¯¸ì„¤ì¹˜"}
        except Exception as e:
            return {"ticker": ticker, "chart": [], "error": str(e)}
    else:
        try:
            import yfinance as yf
            ticker_obj = yf.Ticker(ticker)
            period = "1mo" if days <= 30 else "3mo"
            hist = await asyncio.to_thread(
                lambda t=ticker_obj, p=period: t.history(period=p)
            )
            if hist is not None and not hist.empty:
                for date, row in hist.tail(days).iterrows():
                    chart_data.append({
                        "date": date.strftime("%m/%d"),
                        "close": round(float(row["Close"]), 2),
                        "volume": int(row.get("Volume", 0)),
                    })
        except ImportError:
            return {"ticker": ticker, "chart": [], "error": "yfinance ë¯¸ì„¤ì¹˜"}
        except Exception as e:
            return {"ticker": ticker, "chart": [], "error": str(e)}

    return {"ticker": ticker, "chart": chart_data}


@app.post("/api/trading/order")
async def execute_trading_order(request: Request):
    """ëª¨ì˜ ì£¼ë¬¸ ì‹¤í–‰ (ë§¤ìˆ˜/ë§¤ë„).

    ì‹¤ì œ í‚¤ì›€ì¦ê¶Œ API ì—°ê²° ì „ê¹Œì§€ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    body = await request.json()
    action = body.get("action", "")  # "buy" or "sell"
    ticker = body.get("ticker", "")
    name = body.get("name", ticker)
    qty = int(body.get("qty", 0))
    price = int(body.get("price", 0))

    if not all([action in ("buy", "sell"), ticker, qty > 0, price > 0]):
        return {"success": False, "error": "ë§¤ìˆ˜/ë§¤ë„, ì¢…ëª©ì½”ë“œ, ìˆ˜ëŸ‰, ê°€ê²© í•„ìˆ˜"}

    portfolio = _load_data("trading_portfolio", _default_portfolio())
    total_amount = qty * price

    if action == "buy":
        if portfolio["cash"] < total_amount:
            return {"success": False, "error": f"í˜„ê¸ˆ ë¶€ì¡±: í•„ìš” {total_amount:,.0f}ì›, ë³´ìœ  {portfolio['cash']:,.0f}ì›"}

        # ê¸°ì¡´ ë³´ìœ  ì¢…ëª© í™•ì¸ (í‰ë‹¨ ê³„ì‚°)
        holding = next((h for h in portfolio["holdings"] if h["ticker"] == ticker), None)
        if holding:
            old_total = holding["avg_price"] * holding["qty"]
            new_total = old_total + total_amount
            holding["qty"] += qty
            holding["avg_price"] = int(new_total / holding["qty"])
            holding["current_price"] = price
        else:
            portfolio["holdings"].append({
                "ticker": ticker,
                "name": name,
                "qty": qty,
                "avg_price": price,
                "current_price": price,
            })

        portfolio["cash"] -= total_amount

    elif action == "sell":
        holding = next((h for h in portfolio["holdings"] if h["ticker"] == ticker), None)
        if not holding:
            return {"success": False, "error": f"{name} ë³´ìœ í•˜ì§€ ì•ŠìŒ"}
        if holding["qty"] < qty:
            return {"success": False, "error": f"ë³´ìœ  ìˆ˜ëŸ‰ ë¶€ì¡±: ë³´ìœ  {holding['qty']}ì£¼, ë§¤ë„ {qty}ì£¼"}

        pnl = (price - holding["avg_price"]) * qty
        holding["qty"] -= qty
        holding["current_price"] = price

        if holding["qty"] == 0:
            portfolio["holdings"] = [h for h in portfolio["holdings"] if h["ticker"] != ticker]

        portfolio["cash"] += total_amount

    portfolio["updated_at"] = datetime.now(KST).isoformat()
    _save_data("trading_portfolio", portfolio)

    # ê±°ë˜ ë‚´ì—­ ì €ì¥
    history = _load_data("trading_history", [])
    trade = {
        "id": f"trade_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{len(history)}",
        "date": datetime.now(KST).isoformat(),
        "ticker": ticker,
        "name": name,
        "action": action,
        "qty": qty,
        "price": price,
        "total": total_amount,
        "pnl": pnl if action == "sell" else 0,
        "strategy": body.get("strategy", "manual"),
        "status": "executed",
    }
    history.insert(0, trade)
    if len(history) > 500:
        history = history[:500]
    _save_data("trading_history", history)

    action_ko = "ë§¤ìˆ˜" if action == "buy" else "ë§¤ë„"
    pnl_str = f" (ì†ìµ: {pnl:+,.0f}ì›)" if action == "sell" else ""
    save_activity_log("system",
        f"{'ğŸ“ˆ' if action == 'buy' else 'ğŸ“‰'} {action_ko}: {name} {qty}ì£¼ Ã— {price:,.0f}ì› = {total_amount:,.0f}ì›{pnl_str}",
        "info")

    return {"success": True, "trade": trade, "portfolio": portfolio}


@app.get("/api/trading/history")
async def get_trading_history():
    """ê±°ë˜ ë‚´ì—­."""
    return _load_data("trading_history", [])


@app.get("/api/trading/signals")
async def get_trading_signals():
    """ë§¤ë§¤ ì‹œê·¸ë„ ëª©ë¡."""
    return _load_data("trading_signals", [])


@app.post("/api/trading/signals/generate")
async def generate_trading_signals():
    """CIO(íˆ¬ìë¶„ì„ì²˜ì¥) + 4ëª… ì „ë¬¸ê°€ê°€ ê´€ì‹¬ì¢…ëª©ì„ ë¶„ì„ â†’ ë§¤ë§¤ ì‹œê·¸ë„ ìƒì„±.

    íë¦„:
    1. ì‹œí™©ë¶„ì„ Specialist â†’ ê±°ì‹œê²½ì œ/ì‹œì¥ ë¶„ìœ„ê¸° ë¶„ì„
    2. ì¢…ëª©ë¶„ì„ Specialist â†’ ì¬ë¬´ì œí‘œ/ì‹¤ì /ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„
    3. ê¸°ìˆ ì ë¶„ì„ Specialist â†’ RSI/MACD/ë³¼ë¦°ì €ë°´ë“œ/ì´í‰ì„  ë¶„ì„
    4. ë¦¬ìŠ¤í¬ê´€ë¦¬ Specialist â†’ ì†ì ˆ/í¬ì§€ì…˜/ë¦¬ìŠ¤í¬ í‰ê°€
    5. CIOê°€ 4ëª… ê²°ê³¼ ì·¨í•© â†’ ì¢…ëª©ë³„ ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ íŒë‹¨
    """
    watchlist = _load_data("trading_watchlist", [])
    strategies = _load_data("trading_strategies", [])
    active_strategies = [s for s in strategies if s.get("active")]

    if not watchlist and not active_strategies:
        return {"success": False, "error": "ê´€ì‹¬ì¢…ëª©ì´ë‚˜ í™œì„± ì „ëµì´ ì—†ìŠµë‹ˆë‹¤"}

    # ì¢…ëª© ì •ë³´ ì •ë¦¬ (í•œêµ­/ë¯¸êµ­ êµ¬ë¶„)
    kr_tickers = [w for w in watchlist if w.get("market", "KR") == "KR"]
    us_tickers = [w for w in watchlist if w.get("market") == "US"]
    tickers_info = ", ".join([f"{w['name']}({w['ticker']})" for w in watchlist[:10]])
    strats_info = ", ".join([s["name"] for s in active_strategies[:5]])

    # CIOì—ê²Œ ë³´ë‚´ëŠ” ë¶„ì„ ëª…ë ¹
    prompt = f"""[ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ] ê´€ì‹¬ì¢…ëª© ì¢…í•© ë¶„ì„ì„ ìš”ì²­í•©ë‹ˆë‹¤.

## ê´€ì‹¬ì¢…ëª© ({len(watchlist)}ê°œ)
{tickers_info or 'ì—†ìŒ'}
{f'- í•œêµ­ ì£¼ì‹: {len(kr_tickers)}ê°œ' if kr_tickers else ''}
{f'- ë¯¸êµ­ ì£¼ì‹: {len(us_tickers)}ê°œ' if us_tickers else ''}

## í™œì„± ë§¤ë§¤ ì „ëµ
{strats_info or 'ê¸°ë³¸ ì „ëµ (RSI/MACD ê¸°ë°˜)'}

## ë¶„ì„ ìš”ì²­ì‚¬í•­
ê° ì „ë¬¸ê°€ì—ê²Œ ì•„ë˜ ë¶„ì„ì„ ì§€ì‹œí•˜ì„¸ìš”:
- **ì‹œí™©ë¶„ì„**: í˜„ì¬ ì‹œì¥ ë¶„ìœ„ê¸°, ê¸ˆë¦¬/í™˜ìœ¨ ë™í–¥, ì—…ì¢…ë³„ íë¦„
- **ì¢…ëª©ë¶„ì„**: ê° ê´€ì‹¬ì¢…ëª©ì˜ ì¬ë¬´ ê±´ì „ì„±, PER/PBR, ì‹¤ì  ì „ë§
- **ê¸°ìˆ ì ë¶„ì„**: ê° ê´€ì‹¬ì¢…ëª©ì˜ RSI, MACD, ì´ë™í‰ê· ì„ , ë³¼ë¦°ì €ë°´ë“œ ì§€í‘œ í™•ì¸
- **ë¦¬ìŠ¤í¬ê´€ë¦¬**: í¬ì§€ì…˜ í¬ê¸° ì ì •ì„±, ì†ì ˆê°€, ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬

## ìµœì¢… ì‚°ì¶œë¬¼ (ë°˜ë“œì‹œ ì´ í˜•ì‹ìœ¼ë¡œ)
ê° ì¢…ëª©ì— ëŒ€í•´ ë‹¤ìŒ í˜•ì‹ì˜ ê²°ë¡ ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
[ì‹œê·¸ë„] ì¢…ëª©ëª… (ì¢…ëª©ì½”ë“œ) | ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ | ì‹ ë¢°ë„ 0~100% | ê·¼ê±° í•œì¤„
[ì‹œê·¸ë„] ì¢…ëª©ëª… (ì¢…ëª©ì½”ë“œ) | ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ | ì‹ ë¢°ë„ 0~100% | ê·¼ê±° í•œì¤„"""

    if not is_ai_ready():
        # AI ë¯¸ì—°ê²° ì‹œ ë”ë¯¸ ì‹œê·¸ë„
        signals = _load_data("trading_signals", [])
        for w in watchlist[:5]:
            signal = {
                "id": f"sig_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{w['ticker']}",
                "date": datetime.now(KST).isoformat(),
                "ticker": w["ticker"],
                "name": w["name"],
                "market": w.get("market", "KR"),
                "action": "hold",
                "confidence": 50,
                "reason": "AI ë¯¸ì—°ê²° â€” ë¶„ì„ ë¶ˆê°€ (API í‚¤ ë“±ë¡ í•„ìš”)",
                "strategy": "auto",
                "analyzed_by": "system",
            }
            signals.insert(0, signal)
        if len(signals) > 200:
            signals = signals[:200]
        _save_data("trading_signals", signals)
        return {"success": True, "signals": signals[:20]}

    # CIO + 4ëª… ì „ë¬¸ê°€ì—ê²Œ ìœ„ì„ (ì‹¤ì œ ë„êµ¬ ì‚¬ìš© + ë³‘ë ¬ ë¶„ì„)
    save_activity_log("cio_manager", f"ğŸ“Š ìë™ë§¤ë§¤ ì‹œê·¸ë„ ìƒì„± â€” {len(watchlist)}ê°œ ì¢…ëª© ë¶„ì„ ì‹œì‘", "info")
    cio_result = await _manager_with_delegation("cio_manager", prompt)

    content = cio_result.get("content", "")
    cost = cio_result.get("cost_usd", 0)
    specialists_used = cio_result.get("specialists_used", 0)

    # CIO ë¶„ì„ ê²°ê³¼ì—ì„œ ì‹œê·¸ë„ íŒŒì‹±
    parsed_signals = _parse_cio_signals(content, watchlist)

    signals = _load_data("trading_signals", [])
    new_signal = {
        "id": f"sig_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}",
        "date": datetime.now(KST).isoformat(),
        "analysis": content,
        "tickers": [w["ticker"] for w in watchlist[:10]],
        "parsed_signals": parsed_signals,
        "strategy": "cio_analysis",
        "analyzed_by": f"CIO + ì „ë¬¸ê°€ {specialists_used}ëª…",
        "cost_usd": cost,
    }
    signals.insert(0, new_signal)
    if len(signals) > 200:
        signals = signals[:200]
    _save_data("trading_signals", signals)

    buy_count = len([s for s in parsed_signals if s.get("action") == "buy"])
    sell_count = len([s for s in parsed_signals if s.get("action") == "sell"])
    save_activity_log("cio_manager",
        f"ğŸ“Š CIO ì‹œê·¸ë„ ì™„ë£Œ: {len(watchlist)}ê°œ ì¢…ëª© (ë§¤ìˆ˜ {buy_count}, ë§¤ë„ {sell_count}, ë¹„ìš© ${cost:.4f})",
        "info")

    return {"success": True, "signal": new_signal, "parsed_signals": parsed_signals}


def _parse_cio_signals(content: str, watchlist: list) -> list:
    """CIO ë¶„ì„ ê²°ê³¼ì—ì„œ ì¢…ëª©ë³„ ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ ì‹œê·¸ë„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    import re
    parsed = []

    # [ì‹œê·¸ë„] íŒ¨í„´ ë§¤ì¹­
    pattern = r'\[ì‹œê·¸ë„\]\s*(.+?)\s*\((.+?)\)\s*\|\s*(ë§¤ìˆ˜|ë§¤ë„|ê´€ë§|buy|sell|hold)\s*\|\s*(\d+)%?\s*\|\s*(.+)'
    matches = re.findall(pattern, content, re.IGNORECASE)

    for name, ticker, action, confidence, reason in matches:
        action_map = {"ë§¤ìˆ˜": "buy", "ë§¤ë„": "sell", "ê´€ë§": "hold", "buy": "buy", "sell": "sell", "hold": "hold"}
        market = "US" if any(c.isalpha() and c.isupper() for c in ticker) and not ticker.isdigit() else "KR"
        parsed.append({
            "ticker": ticker.strip(),
            "name": name.strip(),
            "market": market,
            "action": action_map.get(action.lower(), "hold"),
            "confidence": int(confidence),
            "reason": reason.strip(),
        })

    # [ì‹œê·¸ë„] íŒ¨í„´ì´ ì—†ìœ¼ë©´ ê´€ì‹¬ì¢…ëª© ê¸°ë°˜ìœ¼ë¡œ í‚¤ì›Œë“œ íŒŒì‹±
    if not parsed:
        for w in watchlist:
            action = "hold"
            confidence = 50
            reason = ""
            name = w.get("name", w["ticker"])
            if name in content or w["ticker"] in content:
                lower_content = content.lower()
                if any(k in content for k in ["ë§¤ìˆ˜", "ì ê·¹ ë§¤ìˆ˜", "buy", "ì§„ì…"]):
                    action = "buy"
                    confidence = 65
                elif any(k in content for k in ["ë§¤ë„", "sell", "ì²­ì‚°", "ìµì ˆ"]):
                    action = "sell"
                    confidence = 65
                # ê·¼ê±° ì¶”ì¶œ (ì¢…ëª©ëª… ì£¼ë³€ ë¬¸ì¥)
                idx = content.find(name)
                if idx >= 0:
                    reason = content[idx:idx+100].split("\n")[0]
            parsed.append({
                "ticker": w["ticker"],
                "name": name,
                "market": w.get("market", "KR"),
                "action": action,
                "confidence": confidence,
                "reason": reason or "CIO ì¢…í•© ë¶„ì„ ì°¸ì¡°",
            })

    return parsed


@app.get("/api/trading/settings")
async def get_trading_settings():
    """ìë™ë§¤ë§¤ ì„¤ì •."""
    return _load_data("trading_settings", _default_trading_settings())


@app.post("/api/trading/settings")
async def save_trading_settings(request: Request):
    """ìë™ë§¤ë§¤ ì„¤ì • ì €ì¥."""
    body = await request.json()
    settings = _load_data("trading_settings", _default_trading_settings())
    settings.update(body)
    _save_data("trading_settings", settings)
    save_activity_log("system", "âš™ï¸ ìë™ë§¤ë§¤ ì„¤ì • ì—…ë°ì´íŠ¸", "info")
    return {"success": True, "settings": settings}


@app.post("/api/trading/bot/toggle")
async def toggle_trading_bot():
    """ìë™ë§¤ë§¤ ë´‡ ON/OFF í† ê¸€."""
    global _trading_bot_active, _trading_bot_task

    _trading_bot_active = not _trading_bot_active

    if _trading_bot_active:
        if _trading_bot_task is None or _trading_bot_task.done():
            _trading_bot_task = asyncio.create_task(_trading_bot_loop())
        save_activity_log("system", "ğŸ¤– ìë™ë§¤ë§¤ ë´‡ ê°€ë™ ì‹œì‘!", "info")
        _log("[TRADING] ìë™ë§¤ë§¤ ë´‡ ì‹œì‘ âœ…")
    else:
        save_activity_log("system", "â¹ï¸ ìë™ë§¤ë§¤ ë´‡ ì¤‘ì§€", "info")
        _log("[TRADING] ìë™ë§¤ë§¤ ë´‡ ì¤‘ì§€")

    return {"success": True, "bot_active": _trading_bot_active}


@app.get("/api/trading/bot/status")
async def get_trading_bot_status():
    """ìë™ë§¤ë§¤ ë´‡ ìƒíƒœ."""
    return {
        "active": _trading_bot_active,
        "task_running": _trading_bot_task is not None and not _trading_bot_task.done() if _trading_bot_task else False,
        "settings": _load_data("trading_settings", _default_trading_settings()),
    }


def _is_market_open(settings: dict) -> tuple[bool, str]:
    """í•œêµ­/ë¯¸êµ­ ì¥ ì‹œê°„ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤. (ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì—´ë ¤ìˆìœ¼ë©´ True)"""
    now = datetime.now(KST)
    now_min = now.hour * 60 + now.minute

    # í•œêµ­ ì¥ (09:00 ~ 15:20 KST)
    kr = settings.get("trading_hours_kr", settings.get("trading_hours", {}))
    kr_start = sum(int(x) * m for x, m in zip(kr.get("start", "09:00").split(":"), [60, 1]))
    kr_end = sum(int(x) * m for x, m in zip(kr.get("end", "15:20").split(":"), [60, 1]))
    if kr_start <= now_min < kr_end:
        return True, "KR"

    # ë¯¸êµ­ ì¥ (22:30 ~ 05:00 KST, ë‹¤ìŒë‚ ë¡œ ë„˜ì–´ê°)
    us = settings.get("trading_hours_us", {})
    us_start = sum(int(x) * m for x, m in zip(us.get("start", "22:30").split(":"), [60, 1]))
    us_end = sum(int(x) * m for x, m in zip(us.get("end", "05:00").split(":"), [60, 1]))
    if us_start <= now_min or now_min < us_end:  # ìì • ë„˜ê¹€ ì²˜ë¦¬
        return True, "US"

    return False, ""


async def _trading_bot_loop():
    """ìë™ë§¤ë§¤ ë´‡ ë£¨í”„ â€” CIO(íˆ¬ìë¶„ì„ì²˜ì¥) + 4ëª… ì „ë¬¸ê°€ê°€ ë¶„ì„ â†’ ìë™ ë§¤ë§¤.

    íë¦„:
    1. 5ë¶„ë§ˆë‹¤ ì¥ ì‹œê°„ ì²´í¬ (í•œêµ­ 09:00~15:20, ë¯¸êµ­ 22:30~05:00 KST)
    2. ê´€ì‹¬ì¢…ëª©ì´ ìˆìœ¼ë©´ CIO íŒ€ì—ê²Œ ë¶„ì„ ìœ„ì„
    3. CIOê°€ 4ëª… ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì·¨í•©í•˜ì—¬ ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ íŒë‹¨
    4. ì‹ ë¢°ë„ 70% ì´ìƒ ì‹œê·¸ë„ë§Œ ìë™ ì£¼ë¬¸ ì‹¤í–‰ (auto_execute=Trueì¼ ë•Œë§Œ)
    5. ëª¨ì˜íˆ¬ì ëª¨ë“œ(paper_trading=True)ì—ì„œëŠ” ê°€ìƒ í¬íŠ¸í´ë¦¬ì˜¤ë§Œ ì—…ë°ì´íŠ¸
    """
    logger = logging.getLogger("corthex.trading")
    logger.info("ìë™ë§¤ë§¤ ë´‡ ë£¨í”„ ì‹œì‘ (CIO ì—°ë™)")

    while _trading_bot_active:
        try:
            await asyncio.sleep(300)  # 5ë¶„ë§ˆë‹¤ ì²´í¬
            if not _trading_bot_active:
                break

            settings = _load_data("trading_settings", _default_trading_settings())
            is_open, market = _is_market_open(settings)

            if not is_open:
                continue

            # ê´€ì‹¬ì¢…ëª© í™•ì¸
            watchlist = _load_data("trading_watchlist", [])
            if not watchlist:
                continue

            # í•´ë‹¹ ì‹œì¥ì˜ ê´€ì‹¬ì¢…ëª©ë§Œ í•„í„° (í•œêµ­ ì¥ì´ë©´ í•œêµ­ ì¢…ëª©, ë¯¸êµ­ ì¥ì´ë©´ ë¯¸êµ­ ì¢…ëª©)
            market_watchlist = [w for w in watchlist if w.get("market", "KR") == market]
            if not market_watchlist:
                continue

            market_name = "í•œêµ­" if market == "KR" else "ë¯¸êµ­"
            logger.info("[TRADING BOT] %sì¥ ì˜¤í”ˆ â€” %dê°œ ì¢…ëª© CIO ë¶„ì„ ì‹œì‘", market_name, len(market_watchlist))
            save_activity_log("cio_manager",
                f"ğŸ¤– ìë™ë§¤ë§¤ ë´‡: {market_name}ì¥ {len(market_watchlist)}ê°œ ì¢…ëª© CIO ë¶„ì„ ì‹œì‘",
                "info")

            # CIO + ì „ë¬¸ê°€ íŒ€ì—ê²Œ ë¶„ì„ ìœ„ì„
            tickers_info = ", ".join([f"{w['name']}({w['ticker']})" for w in market_watchlist[:10]])
            strategies = _load_data("trading_strategies", [])
            active = [s for s in strategies if s.get("active")]
            strats_info = ", ".join([s["name"] for s in active[:5]]) or "ê¸°ë³¸ ì „ëµ"

            prompt = f"""[ìë™ë§¤ë§¤ ë´‡ â€” {market_name}ì¥ ì •ê¸° ë¶„ì„]

## ë¶„ì„ ëŒ€ìƒ ({len(market_watchlist)}ê°œ ì¢…ëª©)
{tickers_info}

## í™œì„± ì „ëµ: {strats_info}

## ë¶„ì„ ìš”ì²­
ê° ì „ë¬¸ê°€ì—ê²Œ ì•„ë˜ ë¶„ì„ì„ ì§€ì‹œí•˜ì„¸ìš”:
- **ì‹œí™©ë¶„ì„**: {'ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ ì§€ìˆ˜ íë¦„, ì™¸êµ­ì¸/ê¸°ê´€ ë™í–¥, ê¸ˆë¦¬/í™˜ìœ¨' if market == 'KR' else 'S&P500/ë‚˜ìŠ¤ë‹¥ ì§€ìˆ˜, ë¯¸êµ­ ê¸ˆë¦¬/ê³ ìš©ì§€í‘œ, ë‹¬ëŸ¬ ê°•ì„¸'}
- **ì¢…ëª©ë¶„ì„**: ê° ì¢…ëª© ì¬ë¬´ ê±´ì „ì„±, PER/PBR, ìµœê·¼ ì‹¤ì 
- **ê¸°ìˆ ì ë¶„ì„**: RSI, MACD, ì´ë™í‰ê· ì„ , ë³¼ë¦°ì €ë°´ë“œ
- **ë¦¬ìŠ¤í¬ê´€ë¦¬**: ì†ì ˆê°€, ì ì • í¬ì§€ì…˜ í¬ê¸°, ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬

## ìµœì¢… ì‚°ì¶œë¬¼ (ë°˜ë“œì‹œ ì´ í˜•ì‹ìœ¼ë¡œ)
[ì‹œê·¸ë„] ì¢…ëª©ëª… (ì¢…ëª©ì½”ë“œ) | ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ | ì‹ ë¢°ë„ 0~100% | ê·¼ê±° í•œì¤„"""

            cio_result = await _manager_with_delegation("cio_manager", prompt)
            content = cio_result.get("content", "")
            cost = cio_result.get("cost_usd", 0)

            # ì‹œê·¸ë„ íŒŒì‹±
            parsed_signals = _parse_cio_signals(content, market_watchlist)

            # ì‹œê·¸ë„ ì €ì¥
            signals = _load_data("trading_signals", [])
            new_signal = {
                "id": f"sig_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}",
                "date": datetime.now(KST).isoformat(),
                "market": market,
                "analysis": content,
                "tickers": [w["ticker"] for w in market_watchlist[:10]],
                "parsed_signals": parsed_signals,
                "strategy": "cio_bot_analysis",
                "analyzed_by": f"CIO + ì „ë¬¸ê°€ {cio_result.get('specialists_used', 0)}ëª…",
                "cost_usd": cost,
                "auto_bot": True,
            }
            signals.insert(0, new_signal)
            if len(signals) > 200:
                signals = signals[:200]
            _save_data("trading_signals", signals)

            # ìë™ ì£¼ë¬¸ ì‹¤í–‰ (auto_execute=True + ì‹ ë¢°ë„ ì¶©ì¡± ì‹œ)
            auto_execute = settings.get("auto_execute", False)
            min_confidence = settings.get("min_confidence", 70)
            order_size = settings.get("order_size", 1_000_000)

            if auto_execute:
                for sig in parsed_signals:
                    if sig["action"] in ("buy", "sell") and sig.get("confidence", 0) >= min_confidence:
                        # ì£¼ë¬¸ ê°€ê²©ì€ í˜„ì¬ê°€ ê¸°ì¤€ (ëª¨ì˜íˆ¬ìì´ë¯€ë¡œ ëª©í‘œê°€ ë˜ëŠ” ê¸°ë³¸ê°€ ì‚¬ìš©)
                        target_w = next((w for w in market_watchlist if w["ticker"] == sig["ticker"]), None)
                        price = target_w.get("target_price", 0) if target_w else 0
                        if price <= 0:
                            price = 50000  # ê°€ê²© ë¯¸ì„¤ì • ì‹œ ê¸°ë³¸ê°’

                        qty = max(1, int(order_size / price))

                        # ë‚´ë¶€ì ìœ¼ë¡œ ì£¼ë¬¸ ì‹¤í–‰ (ëª¨ì˜íˆ¬ì)
                        from starlette.testclient import TestClient  # noqa
                        try:
                            portfolio = _load_data("trading_portfolio", _default_portfolio())
                            if sig["action"] == "buy" and portfolio["cash"] >= price * qty:
                                # ë§¤ìˆ˜ ë¡œì§ (execute_trading_orderì™€ ë™ì¼)
                                holding = next((h for h in portfolio["holdings"] if h["ticker"] == sig["ticker"]), None)
                                total_amount = qty * price
                                if holding:
                                    old_total = holding["avg_price"] * holding["qty"]
                                    new_total = old_total + total_amount
                                    holding["qty"] += qty
                                    holding["avg_price"] = int(new_total / holding["qty"])
                                    holding["current_price"] = price
                                else:
                                    portfolio["holdings"].append({
                                        "ticker": sig["ticker"], "name": sig["name"],
                                        "qty": qty, "avg_price": price, "current_price": price,
                                        "market": sig.get("market", market),
                                    })
                                portfolio["cash"] -= total_amount
                                portfolio["updated_at"] = datetime.now(KST).isoformat()
                                _save_data("trading_portfolio", portfolio)

                                # ê±°ë˜ ë‚´ì—­ ì €ì¥
                                history = _load_data("trading_history", [])
                                history.insert(0, {
                                    "id": f"auto_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{sig['ticker']}",
                                    "date": datetime.now(KST).isoformat(),
                                    "ticker": sig["ticker"], "name": sig["name"],
                                    "action": "buy", "qty": qty, "price": price,
                                    "total": total_amount, "pnl": 0,
                                    "strategy": f"CIO ìë™ë§¤ë§¤ (ì‹ ë¢°ë„ {sig['confidence']}%)",
                                    "status": "executed", "market": sig.get("market", market),
                                })
                                _save_data("trading_history", history)

                                save_activity_log("cio_manager",
                                    f"ğŸ“ˆ ìë™ë§¤ìˆ˜: {sig['name']} {qty}ì£¼ Ã— {price:,.0f}ì› (ì‹ ë¢°ë„ {sig['confidence']}%)",
                                    "info")

                            elif sig["action"] == "sell":
                                holding = next((h for h in portfolio["holdings"] if h["ticker"] == sig["ticker"]), None)
                                if holding and holding["qty"] > 0:
                                    sell_qty = min(qty, holding["qty"])
                                    total_amount = sell_qty * price
                                    pnl = (price - holding["avg_price"]) * sell_qty
                                    holding["qty"] -= sell_qty
                                    if holding["qty"] == 0:
                                        portfolio["holdings"] = [h for h in portfolio["holdings"] if h["ticker"] != sig["ticker"]]
                                    portfolio["cash"] += total_amount
                                    portfolio["updated_at"] = datetime.now(KST).isoformat()
                                    _save_data("trading_portfolio", portfolio)

                                    history = _load_data("trading_history", [])
                                    history.insert(0, {
                                        "id": f"auto_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{sig['ticker']}",
                                        "date": datetime.now(KST).isoformat(),
                                        "ticker": sig["ticker"], "name": sig["name"],
                                        "action": "sell", "qty": sell_qty, "price": price,
                                        "total": total_amount, "pnl": pnl,
                                        "strategy": f"CIO ìë™ë§¤ë§¤ (ì‹ ë¢°ë„ {sig['confidence']}%)",
                                        "status": "executed", "market": sig.get("market", market),
                                    })
                                    _save_data("trading_history", history)

                                    pnl_str = f"{'+'if pnl>=0 else ''}{pnl:,.0f}ì›"
                                    save_activity_log("cio_manager",
                                        f"ğŸ“‰ ìë™ë§¤ë„: {sig['name']} {sell_qty}ì£¼ Ã— {price:,.0f}ì› (ì†ìµ {pnl_str})",
                                        "info")
                        except Exception as order_err:
                            logger.error("[TRADING BOT] ìë™ì£¼ë¬¸ ì˜¤ë¥˜: %s", order_err)

            buy_count = len([s for s in parsed_signals if s.get("action") == "buy"])
            sell_count = len([s for s in parsed_signals if s.get("action") == "sell"])
            logger.info("[TRADING BOT] CIO ë¶„ì„ ì™„ë£Œ: ë§¤ìˆ˜ %d, ë§¤ë„ %d (ë¹„ìš© $%.4f)", buy_count, sell_count, cost)

        except Exception as e:
            logger.error("[TRADING BOT] ì—ëŸ¬: %s", e)

    logger.info("ìë™ë§¤ë§¤ ë´‡ ë£¨í”„ ì¢…ë£Œ")


@app.post("/api/trading/portfolio/reset")
async def reset_trading_portfolio(request: Request):
    """í¬íŠ¸í´ë¦¬ì˜¤ ì´ˆê¸°í™” (ëª¨ì˜íˆ¬ì ë¦¬ì…‹)."""
    body = await request.json()
    initial_cash = body.get("initial_cash", 50_000_000)
    portfolio = {
        "cash": initial_cash,
        "initial_cash": initial_cash,
        "holdings": [],
        "updated_at": datetime.now(KST).isoformat(),
    }
    _save_data("trading_portfolio", portfolio)
    _save_data("trading_history", [])
    _save_data("trading_signals", [])
    save_activity_log("system", f"ğŸ”„ ëª¨ì˜íˆ¬ì ë¦¬ì…‹: ì´ˆê¸° ìê¸ˆ {initial_cash:,.0f}ì›", "info")
    return {"success": True, "portfolio": portfolio}


# â”€â”€ ì§€ì‹íŒŒì¼ ê´€ë¦¬ â”€â”€

@app.get("/api/knowledge")
async def get_knowledge():
    entries = []
    if KNOWLEDGE_DIR.exists():
        for folder in sorted(KNOWLEDGE_DIR.iterdir()):
            if folder.is_dir() and not folder.name.startswith("."):
                for f in sorted(folder.iterdir()):
                    if f.is_file() and f.suffix == ".md":
                        entries.append({
                            "folder": folder.name,
                            "filename": f.name,
                            "size": f.stat().st_size,
                            "modified": datetime.fromtimestamp(f.stat().st_mtime, KST).isoformat(),
                        })
    return {"entries": entries, "total": len(entries)}


@app.get("/api/knowledge/{folder}/{filename}")
async def get_knowledge_file(folder: str, filename: str):
    """ì§€ì‹ íŒŒì¼ ë‚´ìš© ì½ê¸°."""
    file_path = KNOWLEDGE_DIR / folder / filename
    if file_path.exists() and file_path.is_file():
        content = file_path.read_text(encoding="utf-8")
        return {"folder": folder, "filename": filename, "content": content}
    return {"error": "not found"}


@app.post("/api/knowledge")
async def save_knowledge(request: Request):
    """ì§€ì‹ íŒŒì¼ ì €ì¥/ì—…ë¡œë“œ."""
    body = await request.json()
    folder = body.get("folder", "shared")
    filename = body.get("filename", "untitled.md")
    content = body.get("content", "")
    folder_path = KNOWLEDGE_DIR / folder
    folder_path.mkdir(parents=True, exist_ok=True)
    file_path = folder_path / filename
    file_path.write_text(content, encoding="utf-8")
    return {"success": True, "folder": folder, "filename": filename}


@app.delete("/api/knowledge/{folder}/{filename}")
async def delete_knowledge(folder: str, filename: str):
    """ì§€ì‹ íŒŒì¼ ì‚­ì œ."""
    file_path = KNOWLEDGE_DIR / folder / filename
    if file_path.exists() and file_path.is_file():
        file_path.unlink()
        return {"success": True}
    return {"success": False, "error": "not found"}


# â”€â”€ ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ â”€â”€

@app.get("/api/memory/{agent_id}")
async def get_memory(agent_id: str):
    all_memories = _load_data("memories", {})
    return {"memories": all_memories.get(agent_id, [])}


@app.post("/api/memory/{agent_id}")
async def add_memory(agent_id: str, request: Request):
    """ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ì¶”ê°€."""
    body = await request.json()
    all_memories = _load_data("memories", {})
    if agent_id not in all_memories:
        all_memories[agent_id] = []
    memory_id = f"mem_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{len(all_memories[agent_id])}"
    memory = {
        "id": memory_id,
        "content": body.get("content", ""),
        "created_at": datetime.now(KST).isoformat(),
    }
    all_memories[agent_id].append(memory)
    _save_data("memories", all_memories)
    return {"success": True, "memory": memory}


@app.delete("/api/memory/{agent_id}/{memory_id}")
async def delete_memory(agent_id: str, memory_id: str):
    """ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ì‚­ì œ."""
    all_memories = _load_data("memories", {})
    if agent_id in all_memories:
        all_memories[agent_id] = [m for m in all_memories[agent_id] if m.get("id") != memory_id]
        _save_data("memories", all_memories)
    return {"success": True}


# â”€â”€ í”¼ë“œë°± â”€â”€

@app.get("/api/feedback")
async def get_feedback():
    return _load_data("feedback", {"good": 0, "bad": 0, "total": 0})


@app.post("/api/feedback")
async def send_feedback(request: Request):
    """í”¼ë“œë°± ì „ì†¡/ì·¨ì†Œ/ë³€ê²½.

    action íŒŒë¼ë¯¸í„°:
      - "send" (ê¸°ë³¸): ìƒˆ í”¼ë“œë°± ì¶”ê°€ (ì¹´ìš´íŠ¸ +1)
      - "cancel": ê¸°ì¡´ í”¼ë“œë°± ì·¨ì†Œ (ì¹´ìš´íŠ¸ -1)
      - "change": ê¸°ì¡´ í”¼ë“œë°± ë³€ê²½ (ì´ì „ ì¹´ìš´íŠ¸ -1 + ìƒˆ ì¹´ìš´íŠ¸ +1)
    """
    body = await request.json()
    feedback = _load_data("feedback", {"good": 0, "bad": 0, "total": 0})
    rating = body.get("rating", "")
    action = body.get("action", "send")  # "send", "cancel", "change"
    previous_rating = body.get("previous_rating")  # ë³€ê²½ ì‹œ ì´ì „ ê°’

    if not rating:
        return {"success": False, "error": "rating is required"}

    if action == "cancel":
        # í”¼ë“œë°± ì·¨ì†Œ: í•´ë‹¹ ì¹´ìš´íŠ¸ 1 ê°ì†Œ (0 ì´í•˜ë¡œ ë‚´ë ¤ê°€ì§€ ì•ŠìŒ)
        if rating == "good":
            feedback["good"] = max(0, feedback.get("good", 0) - 1)
        elif rating == "bad":
            feedback["bad"] = max(0, feedback.get("bad", 0) - 1)
    elif action == "change":
        # í”¼ë“œë°± ë³€ê²½: ì´ì „ í”¼ë“œë°± ì¹´ìš´íŠ¸ 1 ê°ì†Œ + ìƒˆ í”¼ë“œë°± ì¹´ìš´íŠ¸ 1 ì¦ê°€
        if previous_rating == "good":
            feedback["good"] = max(0, feedback.get("good", 0) - 1)
        elif previous_rating == "bad":
            feedback["bad"] = max(0, feedback.get("bad", 0) - 1)
        if rating == "good":
            feedback["good"] = feedback.get("good", 0) + 1
        elif rating == "bad":
            feedback["bad"] = feedback.get("bad", 0) + 1
    else:  # action == "send" (ê¸°ë³¸ê°’)
        if rating == "good":
            feedback["good"] = feedback.get("good", 0) + 1
        elif rating == "bad":
            feedback["bad"] = feedback.get("bad", 0) + 1

    feedback["total"] = feedback.get("good", 0) + feedback.get("bad", 0)
    _save_data("feedback", feedback)
    return {"success": True, **feedback}


# â”€â”€ ëŒ€í™” â”€â”€

@app.get("/api/conversation")
async def get_conversation():
    """ëŒ€í™” ê¸°ë¡ì„ DBì—ì„œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    messages = load_conversation_messages(limit=100)
    return messages


@app.post("/api/conversation/save")
async def save_conversation(data: dict = Body(...)):
    """ëŒ€í™” ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤.

    ìš”ì²­ ë³¸ë¬¸:
    - type: "user" ë˜ëŠ” "result"
    - user íƒ€ì…: text í•„ë“œ í•„ìˆ˜
    - result íƒ€ì…: content, sender_id ë“± í•„ë“œ ì „ë‹¬
    """
    try:
        message_type = data.get("type")
        if not message_type:
            return {"success": False, "error": "type í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤"}

        # type ì œì™¸í•œ ë‚˜ë¨¸ì§€ í•„ë“œë“¤ì„ kwargsë¡œ ì „ë‹¬
        kwargs = {k: v for k, v in data.items() if k != "type"}

        row_id = save_conversation_message(message_type, **kwargs)
        return {"success": True, "id": row_id}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.delete("/api/conversation")
async def delete_conversation():
    """ëŒ€í™” ê¸°ë¡ì„ ëª¨ë‘ ì‚­ì œí•©ë‹ˆë‹¤."""
    try:
        clear_conversation_messages()
        return {"success": True}
    except Exception as e:
        return {"success": False, "error": str(e)}


# â”€â”€ ì•„ì¹´ì´ë¸Œ (DB ê¸°ë°˜ â€” í•˜ë‹¨ activity-logs/archive API ì„¹ì…˜ì—ì„œ ì •ì˜ë¨) â”€â”€


# â”€â”€ SNS ì—°ë™ (í”Œë ˆì´ìŠ¤í™€ë” â€” ì‹¤ì œ ì—°ë™ì€ ì™¸ë¶€ API í‚¤ í•„ìš”) â”€â”€

_SNS_PLATFORMS = ["instagram", "x", "youtube", "threads", "tiktok", "facebook"]


@app.get("/api/sns/status")
async def get_sns_status():
    """SNS í”Œë«í¼ ì—°ê²° ìƒíƒœ."""
    return {p: {"connected": False, "username": ""} for p in _SNS_PLATFORMS}


@app.get("/api/sns/oauth/status")
async def get_sns_oauth_status():
    """SNS OAuth ì¸ì¦ ìƒíƒœ."""
    return {p: {"authenticated": False} for p in _SNS_PLATFORMS}


@app.get("/api/sns/auth/{platform}")
async def sns_auth(platform: str):
    """SNS í”Œë«í¼ ì¸ì¦ (ë¯¸êµ¬í˜„ â€” OAuth ì„¤ì • í•„ìš”)."""
    return {"success": False, "error": f"{platform} OAuth ì—°ë™ì´ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”."}


@app.post("/api/sns/instagram/photo")
async def post_instagram_photo(request: Request):
    return {"success": False, "error": "ì¸ìŠ¤íƒ€ê·¸ë¨ APIê°€ ì•„ì§ ì—°ë™ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}


@app.post("/api/sns/instagram/reel")
async def post_instagram_reel(request: Request):
    return {"success": False, "error": "ì¸ìŠ¤íƒ€ê·¸ë¨ APIê°€ ì•„ì§ ì—°ë™ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}


@app.post("/api/sns/youtube/upload")
async def post_youtube_video(request: Request):
    return {"success": False, "error": "ìœ íŠœë¸Œ APIê°€ ì•„ì§ ì—°ë™ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}


@app.get("/api/sns/queue")
async def get_sns_queue():
    """SNS ê²Œì‹œ ëŒ€ê¸°ì—´."""
    return _load_data("sns_queue", [])


@app.post("/api/sns/approve/{item_id}")
async def approve_sns(item_id: str):
    return {"success": False, "error": "SNS APIê°€ ì•„ì§ ì—°ë™ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}


@app.post("/api/sns/reject/{item_id}")
async def reject_sns(item_id: str):
    queue = _load_data("sns_queue", [])
    queue = [q for q in queue if q.get("id") != item_id]
    _save_data("sns_queue", queue)
    return {"success": True}


@app.get("/api/sns/events")
async def get_sns_events(limit: int = 50):
    """SNS ì´ë²¤íŠ¸ ë¡œê·¸."""
    return _load_data("sns_events", [])[:limit]


# â”€â”€ ì¸ì¦ (Phase 3: ë¹„ë°€ë²ˆí˜¸ ë¡œê·¸ì¸) â”€â”€

_sessions: dict[str, float] = {}  # token â†’ ë§Œë£Œ ì‹œê°„
_SESSION_TTL = 86400 * 7  # 7ì¼


def _check_auth(request: Request) -> bool:
    """ìš”ì²­ì˜ ì¸ì¦ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    token = request.headers.get("Authorization", "").replace("Bearer ", "")
    if not token:
        token = request.query_params.get("token", "")
    if token and token in _sessions:
        if _sessions[token] > time.time():
            return True
        del _sessions[token]
    return False


@app.post("/api/auth/login")
async def login(request: Request):
    """ë¹„ë°€ë²ˆí˜¸ ë¡œê·¸ì¸."""
    body = await request.json()
    pw = body.get("password", "")
    stored_pw = load_setting("admin_password") or "corthex2026"
    if pw != stored_pw:
        return JSONResponse({"success": False, "error": "ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦½ë‹ˆë‹¤"}, status_code=401)
    token = str(_uuid.uuid4())
    _sessions[token] = time.time() + _SESSION_TTL
    return {"success": True, "token": token, "user": {"role": "ceo", "name": "CEO"}}


@app.post("/api/auth/logout")
async def logout(request: Request):
    """ë¡œê·¸ì•„ì›ƒ."""
    token = request.headers.get("Authorization", "").replace("Bearer ", "")
    if token in _sessions:
        del _sessions[token]
    return {"success": True}


@app.get("/api/auth/check")
async def auth_check(request: Request):
    """í† í° ìœ íš¨ì„± í™•ì¸."""
    if _check_auth(request):
        return {"authenticated": True, "role": "ceo"}
    return JSONResponse({"authenticated": False}, status_code=401)


@app.post("/api/auth/change-password")
async def change_password(request: Request):
    """ë¹„ë°€ë²ˆí˜¸ ë³€ê²½."""
    if not _check_auth(request):
        return JSONResponse({"success": False, "error": "ì¸ì¦ í•„ìš”"}, status_code=401)
    body = await request.json()
    current = body.get("current", "")
    new_pw = body.get("new_password", "")
    stored_pw = load_setting("admin_password") or "corthex2026"
    if current != stored_pw:
        return JSONResponse({"success": False, "error": "í˜„ì¬ ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦½ë‹ˆë‹¤"}, status_code=401)
    if len(new_pw) < 4:
        return {"success": False, "error": "ë¹„ë°€ë²ˆí˜¸ëŠ” 4ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤"}
    save_setting("admin_password", new_pw)
    return {"success": True}


# â”€â”€ í—¬ìŠ¤ì²´í¬ â”€â”€

@app.get("/api/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸."""
    return {
        "status": "ok",
        "mode": "mini_server",
        "agents": len(AGENTS),
        "telegram": _telegram_available and _telegram_app is not None,
        "timestamp": datetime.now(KST).isoformat(),
    }


# í’ˆì§ˆê²€ìˆ˜ ê·œì¹™: DB ì˜¤ë²„ë¼ì´ë“œ ìš°ì„ , ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ
_QUALITY_RULES: dict = load_setting("config_quality_rules") or _load_config("quality_rules")

# ë¶€ì„œ ID â†’ í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
_DIVISION_LABELS: dict[str, str] = {
    "default": "ê¸°ë³¸ (ì „ì²´ ê³µí†µ)",
    "secretary": "ë¹„ì„œì‹¤",
    "leet_master.tech": "ê¸°ìˆ ê°œë°œíŒ€ (CTO)",
    "leet_master.strategy": "ì „ëµê¸°íšíŒ€ (CSO)",
    "leet_master.legal": "ë²•ë¬´íŒ€ (CLO)",
    "leet_master.marketing": "ë§ˆì¼€íŒ…íŒ€ (CMO)",
    "finance.investment": "ê¸ˆìœµë¶„ì„íŒ€ (CIO)",
    "publishing": "ì½˜í…ì¸ íŒ€ (CPO)",
}

# ë¶€ì„œ ëª©ë¡ (default ì œì™¸)
_KNOWN_DIVISIONS: list[str] = [
    "secretary",
    "leet_master.tech",
    "leet_master.strategy",
    "leet_master.legal",
    "leet_master.marketing",
    "finance.investment",
    "publishing",
]


@app.get("/api/quality-rules")
async def get_quality_rules():
    rules = _QUALITY_RULES.get("rules", {})
    rubrics = _QUALITY_RULES.get("rubrics", {})
    return {
        "rules": rules,
        "rubrics": rubrics,
        "known_divisions": _KNOWN_DIVISIONS,
        "division_labels": _DIVISION_LABELS,
    }


# â”€â”€ í’ˆì§ˆê²€ìˆ˜: ë£¨ë¸Œë¦­ ì €ì¥/ì‚­ì œ + ê·œì¹™ ì €ì¥ â”€â”€

@app.put("/api/quality-rules/rubric/{division}")
async def save_rubric(division: str, request: Request):
    """ë¶€ì„œë³„ ë£¨ë¸Œë¦­(ê²€ìˆ˜ ê¸°ì¤€) ì €ì¥."""
    body = await request.json()
    rubric = {
        "name": body.get("name", ""),
        "prompt": body.get("prompt", ""),
        "model": body.get("model", ""),
        "reasoning_effort": body.get("reasoning_effort", ""),
    }
    if "rubrics" not in _QUALITY_RULES:
        _QUALITY_RULES["rubrics"] = {}
    _QUALITY_RULES["rubrics"][division] = rubric
    _save_config_file("quality_rules", _QUALITY_RULES)
    return {"success": True, "division": division}


@app.delete("/api/quality-rules/rubric/{division}")
async def delete_rubric(division: str):
    """ë¶€ì„œë³„ ë£¨ë¸Œë¦­ ì‚­ì œ (defaultëŠ” ì‚­ì œ ë¶ˆê°€)."""
    if division == "default":
        return {"success": False, "error": "ê¸°ë³¸ ë£¨ë¸Œë¦­ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
    rubrics = _QUALITY_RULES.get("rubrics", {})
    if division in rubrics:
        del rubrics[division]
        _save_config_file("quality_rules", _QUALITY_RULES)
    return {"success": True}


@app.put("/api/quality-rules/model")
async def save_review_model(request: Request):
    """í’ˆì§ˆê²€ìˆ˜ì— ì‚¬ìš©í•  AI ëª¨ë¸ ë³€ê²½."""
    body = await request.json()
    if "rules" not in _QUALITY_RULES:
        _QUALITY_RULES["rules"] = {}
    _QUALITY_RULES["rules"]["review_model"] = body.get("model", "gpt-4o-mini")
    _save_config_file("quality_rules", _QUALITY_RULES)
    return {"success": True}


@app.put("/api/quality-rules/rules")
async def save_quality_rules(request: Request):
    """í’ˆì§ˆê²€ìˆ˜ ê·œì¹™ ì €ì¥ (ìµœì†Œ ê¸¸ì´, ì¬ì‹œë„ íšŸìˆ˜ ë“±)."""
    body = await request.json()
    if "rules" not in _QUALITY_RULES:
        _QUALITY_RULES["rules"] = {}
    for key in ("min_length", "max_retry", "check_hallucination", "check_relevance", "review_model"):
        if key in body:
            _QUALITY_RULES["rules"][key] = body[key]
    _save_config_file("quality_rules", _QUALITY_RULES)
    return {"success": True}


# â”€â”€ ì—ì´ì „íŠ¸ ì„¤ì •: ì†Œìš¸/ëª¨ë¸/ì¶”ë¡  ì €ì¥ â”€â”€

@app.put("/api/agents/bulk-model")
async def bulk_change_model(request: Request):
    """ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ëª¨ë¸ì„ í•œë²ˆì— ë³€ê²½."""
    body = await request.json()
    new_model = body.get("model_name", "")
    reasoning = body.get("reasoning_effort", "")
    if not new_model:
        return {"error": "model_name í•„ìˆ˜"}
    overrides = _load_data("agent_overrides", {})
    changed = 0
    for a in AGENTS:
        aid = a["agent_id"]
        a["model_name"] = new_model
        if aid in _AGENTS_DETAIL:
            _AGENTS_DETAIL[aid]["model_name"] = new_model
            _AGENTS_DETAIL[aid]["reasoning_effort"] = reasoning
        if aid not in overrides:
            overrides[aid] = {}
        overrides[aid]["model_name"] = new_model
        overrides[aid]["reasoning_effort"] = reasoning
        changed += 1
    _save_data("agent_overrides", overrides)
    return {"success": True, "changed": changed, "model_name": new_model, "reasoning_effort": reasoning}


@app.put("/api/agents/{agent_id}/soul")
async def save_agent_soul(agent_id: str, request: Request):
    """ì—ì´ì „íŠ¸ ì†Œìš¸(ì„±ê²©) ì €ì¥. DBì— ì˜êµ¬ ì €ì¥ë¨."""
    body = await request.json()
    soul_text = body.get("soul") or body.get("system_prompt", "")
    # DBì— ì €ì¥ (ì¬ë°°í¬í•´ë„ ìœ ì§€)
    save_setting(f"soul_{agent_id}", soul_text)
    return {"success": True, "agent_id": agent_id}


@app.put("/api/agents/{agent_id}/model")
async def save_agent_model(agent_id: str, request: Request):
    """ì—ì´ì „íŠ¸ì— ë°°ì •ëœ AI ëª¨ë¸ ë³€ê²½."""
    body = await request.json()
    new_model = body.get("model_name") or body.get("model", "")
    # ë©”ëª¨ë¦¬ ë‚´ AGENTS ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
    for a in AGENTS:
        if a["agent_id"] == agent_id:
            a["model_name"] = new_model
            break
    # agents.yaml ìƒì„¸ ì •ë³´ë„ ì—…ë°ì´íŠ¸
    if agent_id in _AGENTS_DETAIL:
        _AGENTS_DETAIL[agent_id]["model_name"] = new_model
    # ë°ì´í„° íŒŒì¼ì— ë³€ê²½ì‚¬í•­ ì €ì¥ (ì„œë²„ ì¬ì‹œì‘ ì‹œ ë³µì›ìš©)
    overrides = _load_data("agent_overrides", {})
    if agent_id not in overrides:
        overrides[agent_id] = {}
    overrides[agent_id]["model_name"] = new_model
    _save_data("agent_overrides", overrides)
    return {"success": True, "agent_id": agent_id, "model": new_model}


@app.put("/api/agents/{agent_id}/reasoning")
async def save_agent_reasoning(agent_id: str, request: Request):
    """ì—ì´ì „íŠ¸ ì¶”ë¡  ë°©ì‹(reasoning effort) ë³€ê²½."""
    body = await request.json()
    effort = body.get("reasoning_effort", "")
    if agent_id in _AGENTS_DETAIL:
        _AGENTS_DETAIL[agent_id]["reasoning_effort"] = effort
    overrides = _load_data("agent_overrides", {})
    if agent_id not in overrides:
        overrides[agent_id] = {}
    overrides[agent_id]["reasoning_effort"] = effort
    _save_data("agent_overrides", overrides)
    return {"success": True, "agent_id": agent_id, "reasoning_effort": effort}


# â”€â”€ ì˜ˆì‚° ì„¤ì • ì €ì¥ â”€â”€

@app.put("/api/budget")
async def save_budget(request: Request):
    """ì¼ì¼ ì˜ˆì‚° í•œë„ ë³€ê²½."""
    body = await request.json()
    if "daily_limit" in body:
        save_setting("daily_budget_usd", float(body["daily_limit"]))
    return {"success": True}


@app.get("/api/available-models")
async def get_available_models():
    return [
        # Anthropic (Claude) ëª¨ë¸ë“¤ - ì„ì›ê¸‰/ë§¤ë‹ˆì €ê¸‰
        {
            "name": "claude-opus-4-6",
            "provider": "anthropic",
            "tier": "executive",
            "cost_input": 15.0,
            "cost_output": 75.0,
            "reasoning_levels": ["low", "medium", "high"],
        },
        {
            "name": "claude-sonnet-4-5-20250929",
            "provider": "anthropic",
            "tier": "manager",
            "cost_input": 3.0,
            "cost_output": 15.0,
            "reasoning_levels": ["low", "medium", "high"],
        },
        {
            "name": "claude-haiku-4-5-20251001",
            "provider": "anthropic",
            "tier": "specialist",
            "cost_input": 0.25,
            "cost_output": 1.25,
            "reasoning_levels": [],
        },
        # OpenAI (GPT) ëª¨ë¸ë“¤ - ì„ì›ê¸‰/ë§¤ë‹ˆì €ê¸‰/ì „ë¬¸ê°€ê¸‰
        {
            "name": "gpt-5.2-pro",
            "provider": "openai",
            "tier": "executive",
            "cost_input": 18.0,
            "cost_output": 90.0,
            "reasoning_levels": ["medium", "high", "xhigh"],
        },
        {
            "name": "gpt-5.2",
            "provider": "openai",
            "tier": "manager",
            "cost_input": 5.0,
            "cost_output": 25.0,
            "reasoning_levels": ["none", "low", "medium", "high", "xhigh"],
        },
        {
            "name": "gpt-5.1",
            "provider": "openai",
            "tier": "manager",
            "cost_input": 4.0,
            "cost_output": 20.0,
            "reasoning_levels": ["none", "low", "medium", "high"],
        },
        {
            "name": "gpt-5",
            "provider": "openai",
            "tier": "specialist",
            "cost_input": 2.5,
            "cost_output": 10.0,
            "reasoning_levels": ["none", "low", "medium", "high"],
        },
        {
            "name": "gpt-5-mini",
            "provider": "openai",
            "tier": "specialist",
            "cost_input": 0.5,
            "cost_output": 2.0,
            "reasoning_levels": ["low", "medium", "high"],
        },
        # Google (Gemini) ëª¨ë¸ë“¤
        # Gemini 3: thinking_level íŒŒë¼ë¯¸í„° (low/highë§Œ ì§€ì›)
        {
            "name": "gemini-3-pro-preview",
            "provider": "google",
            "tier": "executive",
            "cost_input": 2.5,
            "cost_output": 15.0,
            "reasoning_levels": ["low", "high"],
        },
        # Gemini 2.5: thinking_budget íŒŒë¼ë¯¸í„° (í† í° ìˆ˜ ì¡°ì ˆ)
        # 2.5 Pro: ìµœì†Œ 128 í† í°, ëŒ ìˆ˜ ì—†ìŒ
        {
            "name": "gemini-2.5-pro",
            "provider": "google",
            "tier": "manager",
            "cost_input": 1.25,
            "cost_output": 10.0,
            "reasoning_levels": ["low", "medium", "high"],
        },
        # 2.5 Flash: 0~24576 í† í°, ëŒ ìˆ˜ ìˆìŒ (budget=0)
        {
            "name": "gemini-2.5-flash",
            "provider": "google",
            "tier": "specialist",
            "cost_input": 0.15,
            "cost_output": 0.60,
            "reasoning_levels": ["none", "low", "medium", "high"],
        },
    ]


# â”€â”€ í™œë™ ë¡œê·¸ API â”€â”€
@app.get("/api/activity-logs")
async def get_activity_logs(limit: int = 50, agent_id: str = None):
    logs = list_activity_logs(limit=limit, agent_id=agent_id)
    return logs


# â”€â”€ ì•„ì¹´ì´ë¸Œ API â”€â”€
@app.get("/api/archive")
async def get_archive_list(division: str = None, limit: int = 100):
    return list_archives(division=division, limit=limit)


@app.get("/api/archive/{division}/{filename}")
async def get_archive_file(division: str, filename: str):
    doc = db_get_archive(division, filename)
    if not doc:
        return {"error": "not found"}
    return doc


# â”€â”€ ì§„ë‹¨ API (í…”ë ˆê·¸ë¨ ë´‡ ë””ë²„ê¹…ìš©) â”€â”€
@app.get("/api/telegram-status")
async def telegram_status():
    """í…”ë ˆê·¸ë¨ ë´‡ ì§„ë‹¨ ì •ë³´ ë°˜í™˜."""
    return {
        **_diag,
        "tg_app_exists": _telegram_app is not None,
        "tg_available": _telegram_available,
        "env_token_set": bool(os.getenv("TELEGRAM_BOT_TOKEN", "")),
        "env_ceo_id": os.getenv("TELEGRAM_CEO_CHAT_ID", ""),
    }


# â”€â”€ í…”ë ˆê·¸ë¨ ë´‡ â”€â”€
# ì£¼ì˜: python-telegram-bot ë¯¸ì„¤ì¹˜ ì‹œì—ë„ ì„œë²„ê°€ ì •ìƒ ì‘ë™í•´ì•¼ í•¨
# ëª¨ë“  í…”ë ˆê·¸ë¨ ê´€ë ¨ ì½”ë“œëŠ” _telegram_available ì²´í¬ í›„ì—ë§Œ ì‹¤í–‰

_telegram_app = None  # telegram.ext.Application ì¸ìŠ¤í„´ìŠ¤


async def _start_telegram_bot() -> None:
    """í…”ë ˆê·¸ë¨ ë´‡ì„ ì‹œì‘í•©ë‹ˆë‹¤ (FastAPI ì´ë²¤íŠ¸ ë£¨í”„ ì•ˆì—ì„œ ì‹¤í–‰)."""
    global _telegram_app

    _log(f"[TG] ë´‡ ì‹œì‘ ì‹œë„ (_telegram_available={_telegram_available})")

    if not _telegram_available:
        _log("[TG] âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ â€” ê±´ë„ˆëœ€")
        return

    token = os.getenv("TELEGRAM_BOT_TOKEN", "")
    _log(f"[TG] í† í° ì¡´ì¬: {bool(token)} (ê¸¸ì´: {len(token)})")
    if not token:
        _log("[TG] âŒ í† í° ë¯¸ì„¤ì • â€” ê±´ë„ˆëœ€")
        _diag["tg_error"] = "TELEGRAM_BOT_TOKEN í™˜ê²½ë³€ìˆ˜ ì—†ìŒ"
        return

    try:
        _log("[TG] Application ë¹Œë“œ ì¤‘...")
        _telegram_app = Application.builder().token(token).build()

        # â”€â”€ í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë“¤ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ëœ ê²½ìš°ì—ë§Œ ì •ì˜) â”€â”€

        async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            chat_id = update.effective_chat.id
            ceo_id = os.getenv("TELEGRAM_CEO_CHAT_ID", "")
            if not ceo_id:
                logger.info("í…”ë ˆê·¸ë¨ chat_id ê°ì§€: %s", chat_id)
                await update.message.reply_text(
                    f"CORTHEX HQ í…”ë ˆê·¸ë¨ ë´‡ì…ë‹ˆë‹¤.\n\n"
                    f"ë‹¹ì‹ ì˜ chat_id: `{chat_id}`\n\n"
                    f"ì„œë²„ í™˜ê²½ë³€ìˆ˜ì— TELEGRAM_CEO_CHAT_ID={chat_id} ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.",
                    parse_mode="Markdown",
                )
                return
            if str(chat_id) != ceo_id:
                await update.message.reply_text("ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            await update.message.reply_text(
                "*CORTHEX HQ í…”ë ˆê·¸ë¨ ë´‡*\n\n"
                "CEO ì¸ì¦ ì™„ë£Œ.\n"
                "24ì‹œê°„ ì„œë²„ì—ì„œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.\n\n"
                "/help ë¡œ ì‚¬ìš©ë²•ì„ í™•ì¸í•˜ì„¸ìš”.",
                parse_mode="Markdown",
            )

        async def cmd_help(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            await update.message.reply_text(
                "*CORTHEX HQ ì‚¬ìš©ë²•*\n\n"
                "/agents â€” ì—ì´ì „íŠ¸ ëª©ë¡ (29ëª…)\n"
                "/health â€” ì„œë²„ ìƒíƒœ í™•ì¸\n"
                "/help â€” ì´ ì‚¬ìš©ë²•\n\n"
                "*ëª¨ë“œ ì „í™˜*\n"
                "/rt â€” ì‹¤ì‹œê°„ ëª¨ë“œ (AI ì¦‰ì‹œ ë‹µë³€)\n"
                "/batch â€” ë°°ì¹˜ ëª¨ë“œ (ì ‘ìˆ˜ë§Œ)\n\n"
                "ì¼ë°˜ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ë©´ AIê°€ ë‹µë³€í•©ë‹ˆë‹¤.",
                parse_mode="Markdown",
            )

        async def cmd_agents(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            divisions = {}
            for a in AGENTS:
                div = a.get("division", "ê¸°íƒ€")
                divisions.setdefault(div, []).append(a)
            lines = ["*CORTHEX HQ ì—ì´ì „íŠ¸ ëª©ë¡*\n"]
            div_labels = {
                "secretary": "ë¹„ì„œì‹¤",
                "leet_master.tech": "ê¸°ìˆ ê°œë°œì²˜ (CTO)",
                "leet_master.strategy": "ì‚¬ì—…ê¸°íšì²˜ (CSO)",
                "leet_master.legal": "ë²•ë¬´Â·IPì²˜ (CLO)",
                "leet_master.marketing": "ë§ˆì¼€íŒ…Â·ê³ ê°ì²˜ (CMO)",
                "finance.investment": "íˆ¬ìë¶„ì„ì²˜ (CIO)",
                "publishing": "ì¶œíŒÂ·ê¸°ë¡ì²˜ (CPO)",
            }
            for div, agents_list in divisions.items():
                label = div_labels.get(div, div)
                lines.append(f"\n*{label}* ({len(agents_list)}ëª…)")
                for a in agents_list:
                    icon = "ğŸ‘”" if a["role"] == "manager" else "ğŸ‘¤"
                    lines.append(f"  {icon} {a['name_ko']}")
            lines.append(f"\nì´ {len(AGENTS)}ëª…")
            await update.message.reply_text("\n".join(lines), parse_mode="Markdown")

        async def cmd_health(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            now = datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")
            await update.message.reply_text(
                f"*ì„œë²„ ìƒíƒœ*\n\n"
                f"ìƒíƒœ: ì •ìƒ ìš´ì˜ ì¤‘\n"
                f"ì„œë²„: Oracle Cloud (ì¶˜ì²œ)\n"
                f"ì—ì´ì „íŠ¸: {len(AGENTS)}ëª… ëŒ€ê¸° ì¤‘\n"
                f"ì‹œê°„: {now} KST",
                parse_mode="Markdown",
            )

        async def cmd_rt(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            """ì‹¤ì‹œê°„ ëª¨ë“œ ì „í™˜ (/rt)."""
            if not _is_tg_ceo(update):
                return
            save_setting("tg_mode", "realtime")
            await update.message.reply_text(
                "ğŸ”´ *ì‹¤ì‹œê°„ ëª¨ë“œ*ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.\n\n"
                "ì´ì œ ë³´ë‚´ì‹œëŠ” ë©”ì‹œì§€ì— AIê°€ ì¦‰ì‹œ ë‹µë³€í•©ë‹ˆë‹¤.",
                parse_mode="Markdown",
            )

        async def cmd_batch(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            """ë°°ì¹˜ ëª¨ë“œ ì „í™˜ (/batch)."""
            if not _is_tg_ceo(update):
                return
            save_setting("tg_mode", "batch")
            await update.message.reply_text(
                "ğŸ“¦ *ë°°ì¹˜ ëª¨ë“œ*ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.\n\n"
                "ë©”ì‹œì§€ë¥¼ ì ‘ìˆ˜ë§Œ í•˜ê³ , AI ì²˜ë¦¬ëŠ” í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                parse_mode="Markdown",
            )

        async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            text = update.message.text.strip()
            if not text:
                return

            # í•œêµ­ì–´ ëª…ë ¹ì–´ ì²˜ë¦¬ (í…”ë ˆê·¸ë¨ CommandHandlerëŠ” ì˜ì–´ë§Œ ì§€ì›í•˜ë¯€ë¡œ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬)
            if text in ("ì‹¤ì‹œê°„", "/ì‹¤ì‹œê°„"):
                save_setting("tg_mode", "realtime")
                await update.message.reply_text(
                    "ğŸ”´ *ì‹¤ì‹œê°„ ëª¨ë“œ*ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.\n\n"
                    "ì´ì œ ë³´ë‚´ì‹œëŠ” ë©”ì‹œì§€ì— AIê°€ ì¦‰ì‹œ ë‹µë³€í•©ë‹ˆë‹¤.",
                    parse_mode="Markdown",
                )
                return
            if text in ("ë°°ì¹˜", "/ë°°ì¹˜"):
                save_setting("tg_mode", "batch")
                await update.message.reply_text(
                    "ğŸ“¦ *ë°°ì¹˜ ëª¨ë“œ*ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.\n\n"
                    "ë©”ì‹œì§€ë¥¼ ì ‘ìˆ˜ë§Œ í•˜ê³ , AI ì²˜ë¦¬ëŠ” í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                    parse_mode="Markdown",
                )
                return

            chat_id = str(update.effective_chat.id)
            # DBì— ë©”ì‹œì§€ + ì‘ì—… ì €ì¥
            task = create_task(text, source="telegram")
            save_message(text, source="telegram", chat_id=chat_id,
                         task_id=task["task_id"])

            # ëª¨ë“œ í™•ì¸
            mode = load_setting("tg_mode") or "realtime"
            now = datetime.now(KST).strftime("%H:%M")
            result = {}  # ì›¹ì†Œì¼“ ë¸Œë¡œë“œìºìŠ¤íŠ¸ìš©

            if mode == "realtime" and is_ai_ready():
                # ì‹¤ì‹œê°„ ëª¨ë“œ: AIê°€ ë‹µë³€
                update_task(task["task_id"], status="running")
                await update.message.reply_text(f"â³ ì²˜ë¦¬ ì¤‘... (#{task['task_id']})")

                result = await _process_ai_command(text, task["task_id"])

                if "error" in result:
                    await update.message.reply_text(f"âŒ {result['error']}")
                else:
                    content = result.get("content", "")
                    cost = result.get("cost_usd", 0)
                    model = result.get("model", "")
                    # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (4096ì)
                    if len(content) > 3900:
                        content = content[:3900] + "\n\n... (ê²°ê³¼ê°€ ì˜ë ¸ìŠµë‹ˆë‹¤. ì›¹ì—ì„œ ì „ì²´ í™•ì¸)"
                    delegation = result.get("delegation", "")
                    model_short = model.split("-")[1] if "-" in model else model
                    # ë¹„ì„œì‹¤ì¥ ìœ„ì„ í‘œì‹œ: "ë¹„ì„œì‹¤ì¥ â†’ CTO" ë˜ëŠ” "ë¹„ì„œì‹¤ì¥"
                    footer_who = delegation if delegation else "ë¹„ì„œì‹¤ì¥"
                    await update.message.reply_text(
                        f"{content}\n\n"
                        f"â”€â”€â”€â”€â”€\n"
                        f"ğŸ‘¤ {footer_who} | ğŸ’° ${cost:.4f} | ğŸ¤– {model_short}",
                        parse_mode=None,
                    )
            else:
                # ë°°ì¹˜ ëª¨ë“œ ë˜ëŠ” AI ë¯¸ì¤€ë¹„
                update_task(task["task_id"], status="completed",
                            result_summary="ë°°ì¹˜ ëª¨ë“œ â€” ì ‘ìˆ˜ë§Œ ì™„ë£Œ" if mode == "batch" else "AI ë¯¸ì—°ê²° â€” ì ‘ìˆ˜ë§Œ ì™„ë£Œ",
                            success=1, time_seconds=0.1)
                reason = "ë°°ì¹˜ ëª¨ë“œ" if mode == "batch" else "AI ë¯¸ì—°ê²°"
                await update.message.reply_text(
                    f"ğŸ“‹ ì ‘ìˆ˜í–ˆìŠµë‹ˆë‹¤. ({now})\n"
                    f"ì‘ì—… ID: `{task['task_id']}`\n"
                    f"ìƒíƒœ: {reason}",
                    parse_mode="Markdown",
                )

            # í™œë™ ë¡œê·¸ ì €ì¥ + ì›¹ì†Œì¼“ ë¸Œë¡œë“œìºìŠ¤íŠ¸ (ì›¹ ì±„íŒ…ì—ë„ ëŒ€í™” í‘œì‹œ)
            log_entry = save_activity_log(
                "chief_of_staff",
                f"[í…”ë ˆê·¸ë¨] CEO ì§€ì‹œ: {text[:50]}{'...' if len(text) > 50 else ''} (#{task['task_id']})",
            )
            for ws in connected_clients[:]:
                try:
                    await ws.send_json({"event": "task_accepted", "data": task})
                    await ws.send_json({"event": "activity_log", "data": log_entry})
                    # í…”ë ˆê·¸ë¨ ëŒ€í™”ë¥¼ ì›¹ ì±„íŒ…ì—ë„ í‘œì‹œ
                    await ws.send_json({
                        "event": "telegram_message",
                        "data": {"type": "user", "text": text, "source": "telegram"}
                    })
                    if "error" not in result:
                        await ws.send_json({
                            "event": "result",
                            "data": {
                                "content": result.get("content", ""),
                                "sender_id": result.get("agent_id", "chief_of_staff"),
                                "handled_by": result.get("handled_by", "ë¹„ì„œì‹¤ì¥"),
                                "delegation": result.get("delegation", ""),
                                "time_seconds": result.get("time_seconds", 0),
                                "cost": result.get("total_cost_usd", result.get("cost_usd", 0)),
                                "model": result.get("model", ""),
                                "routing_method": result.get("routing_method", ""),
                                "source": "telegram",
                            }
                        })
                    else:
                        await ws.send_json({
                            "event": "result",
                            "data": {
                                "content": f"âŒ {result['error']}",
                                "sender_id": "chief_of_staff",
                                "handled_by": "ë¹„ì„œì‹¤ì¥",
                                "time_seconds": 0, "cost": 0,
                                "source": "telegram",
                            }
                        })
                except Exception:
                    pass

        def _is_tg_ceo(update: Update) -> bool:
            if not update.effective_chat or not update.message:
                return False
            ceo_id = os.getenv("TELEGRAM_CEO_CHAT_ID", "")
            if not ceo_id:
                return False
            if str(update.effective_chat.id) != ceo_id:
                asyncio.create_task(update.message.reply_text("ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤."))
                return False
            return True

        # í•¸ë“¤ëŸ¬ ë“±ë¡
        _telegram_app.add_handler(CommandHandler("start", cmd_start))
        _telegram_app.add_handler(CommandHandler("help", cmd_help))
        _telegram_app.add_handler(CommandHandler("agents", cmd_agents))
        _telegram_app.add_handler(CommandHandler("health", cmd_health))
        _telegram_app.add_handler(CommandHandler("rt", cmd_rt))
        _telegram_app.add_handler(CommandHandler("batch", cmd_batch))
        _telegram_app.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message)
        )

        # ë´‡ ëª…ë ¹ì–´ ë©”ë‰´ ì„¤ì •
        await _telegram_app.bot.set_my_commands([
            BotCommand("start", "ë´‡ ì‹œì‘"),
            BotCommand("help", "ì‚¬ìš©ë²•"),
            BotCommand("agents", "ì—ì´ì „íŠ¸ ëª©ë¡"),
            BotCommand("health", "ì„œë²„ ìƒíƒœ"),
            BotCommand("rt", "ì‹¤ì‹œê°„ ëª¨ë“œ (AI ì¦‰ì‹œ ë‹µë³€)"),
            BotCommand("batch", "ë°°ì¹˜ ëª¨ë“œ (ì ‘ìˆ˜ë§Œ)"),
        ])

        _log("[TG] í•¸ë“¤ëŸ¬ ë“±ë¡ ì™„ë£Œ, initialize()...")
        await _telegram_app.initialize()
        _log("[TG] start()...")
        await _telegram_app.start()
        _log("[TG] polling ì‹œì‘...")
        await _telegram_app.updater.start_polling(drop_pending_updates=True)

        ceo_id = os.getenv("TELEGRAM_CEO_CHAT_ID", "")
        _diag["tg_started"] = True
        _log(f"[TG] âœ… ë´‡ ì‹œì‘ ì™„ë£Œ! (CEO: {ceo_id or 'ë¯¸ì„¤ì •'})")
    except Exception as e:
        _diag["tg_error"] = str(e)
        _log(f"[TG] âŒ ë´‡ ì‹œì‘ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        _telegram_app = None


async def _stop_telegram_bot() -> None:
    """í…”ë ˆê·¸ë¨ ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."""
    global _telegram_app
    if _telegram_app:
        try:
            await _telegram_app.updater.stop()
            await _telegram_app.stop()
            await _telegram_app.shutdown()
            logger.info("í…”ë ˆê·¸ë¨ ë´‡ ì¢…ë£Œ ì™„ë£Œ")
        except Exception as e:
            logger.warning("í…”ë ˆê·¸ë¨ ë´‡ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: %s", e)
        _telegram_app = None


# â”€â”€ AI ì—ì´ì „íŠ¸ ìœ„ì„ ì‹œìŠ¤í…œ (Phase 5) â”€â”€

# ë¶€ì„œë³„ í‚¤ì›Œë“œ ë¼ìš°íŒ… í…Œì´ë¸”
_ROUTING_KEYWORDS: dict[str, list[str]] = {
    "cto_manager": [
        "ì½”ë“œ", "ë²„ê·¸", "í”„ë¡ íŠ¸", "ë°±ì—”ë“œ", "API", "ì„œë²„", "ë°°í¬",
        "ì›¹ì‚¬ì´íŠ¸", "í™ˆí˜ì´ì§€", "ë””ìì¸", "UI", "UX", "ë°ì´í„°ë² ì´ìŠ¤",
        "ê°œë°œ", "í”„ë¡œê·¸ë˜ë°", "ê¹ƒí—ˆë¸Œ", "github", "ë¦¬íŒ©í† ë§",
    ],
    "cso_manager": [
        "ì‹œì¥", "ê²½ìŸì‚¬", "ì‚¬ì—…ê³„íš", "ë§¤ì¶œ", "ì˜ˆì¸¡", "ì „ëµ",
        "ë¹„ì¦ˆë‹ˆìŠ¤", "BM", "ìˆ˜ìµ", "ì‚¬ì—…", "ê¸°íš", "ì„±ì¥",
    ],
    "clo_manager": [
        "ì €ì‘ê¶Œ", "íŠ¹í—ˆ", "ìƒí‘œ", "ì•½ê´€", "ê³„ì•½", "ë²•ë¥ ", "ì†Œì†¡", "IP",
        "ê·œì œ", "ë¼ì´ì„ ìŠ¤", "ë²•ì ", "ë²•ë¬´",
    ],
    "cmo_manager": [
        "ë§ˆì¼€íŒ…", "ê´‘ê³ ", "SNS", "ì¸ìŠ¤íƒ€", "ìœ íŠœë¸Œ", "ê³ ê°",
        "ì„¤ë¬¸", "ë¸Œëœë”©", "ì½˜í…ì¸ ", "í™ë³´", "í”„ë¡œëª¨ì…˜", "ìº í˜ì¸",
    ],
    "cio_manager": [
        "ì‚¼ì„±", "ì• í”Œ", "ì£¼ì‹", "íˆ¬ì", "ì¢…ëª©", "ì°¨íŠ¸", "ì‹œí™©",
        "ì½”ìŠ¤í”¼", "ë‚˜ìŠ¤ë‹¥", "í¬íŠ¸í´ë¦¬ì˜¤", "ê¸ˆë¦¬", "í™˜ìœ¨", "ì±„ê¶Œ",
        "ETF", "í€ë“œ", "ë°°ë‹¹", "í…ŒìŠ¬ë¼", "ì—”ë¹„ë””ì•„",
        "ë§¤ìˆ˜", "ë§¤ë„", "ìë™ë§¤ë§¤", "í‚¤ì›€", "ë°±í…ŒìŠ¤íŠ¸", "ì „ëµ",
        "ì†ì ˆ", "ìµì ˆ", "ì‹œê°€ì´ì•¡", "PER", "RSI", "MACD",
    ],
    "cpo_manager": [
        "ê¸°ë¡", "ë¹Œë”©ë¡œê·¸", "ì—°ëŒ€ê¸°", "ë¸”ë¡œê·¸", "ì¶œíŒ", "í¸ì§‘", "íšŒê³ ",
        "ì•„ì¹´ì´ë¸Œ", "ë¬¸ì„œí™”", "íšŒì˜ë¡",
    ],
}

# ì—ì´ì „íŠ¸ ID â†’ í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
_AGENT_NAMES: dict[str, str] = {
    "chief_of_staff": "ë¹„ì„œì‹¤ì¥",
    "cto_manager": "CTO (ê¸°ìˆ ê°œë°œì²˜ì¥)",
    "cso_manager": "CSO (ì‚¬ì—…ê¸°íšì²˜ì¥)",
    "clo_manager": "CLO (ë²•ë¬´IPì²˜ì¥)",
    "cmo_manager": "CMO (ë§ˆì¼€íŒ…ê³ ê°ì²˜ì¥)",
    "cio_manager": "CIO (íˆ¬ìë¶„ì„ì²˜ì¥)",
    "cpo_manager": "CPO (ì¶œíŒê¸°ë¡ì²˜ì¥)",
}

# â”€â”€ ë…¸ì…˜ API ì—°ë™ (ì—ì´ì „íŠ¸ ì‚°ì¶œë¬¼ ìë™ ì €ì¥) â”€â”€

_NOTION_API_KEY = os.getenv("NOTION_API_KEY", "")
_NOTION_DB_ID = os.getenv("NOTION_DEFAULT_DB_ID", "ee0527e4-697b-4cb6-8df0-6dca3f59ad4e")

# ì—ì´ì „íŠ¸ ID â†’ ë¶€ì„œëª… ë§¤í•‘
_AGENT_DIVISION: dict[str, str] = {}
for _a in AGENTS:
    if _a.get("division"):
        _AGENT_DIVISION[_a["agent_id"]] = _a["division"]


async def _save_to_notion(agent_id: str, title: str, content: str,
                          report_type: str = "ë³´ê³ ì„œ") -> str | None:
    """ì—ì´ì „íŠ¸ ì‚°ì¶œë¬¼ì„ ë…¸ì…˜ DBì— ì €ì¥í•©ë‹ˆë‹¤.

    Python ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬(urllib)ë§Œ ì‚¬ìš© â€” ì¶”ê°€ íŒ¨í‚¤ì§€ ë¶ˆí•„ìš”.
    ì‹¤íŒ¨í•´ë„ ì—ëŸ¬ë§Œ ë¡œê¹…í•˜ê³  None ë°˜í™˜ (ì„œë²„ ë™ì‘ì— ì˜í–¥ ì—†ìŒ).
    """
    if not _NOTION_API_KEY:
        return None

    division = _AGENT_DIVISION.get(agent_id, "")
    agent_name = _AGENT_NAMES.get(agent_id, _SPECIALIST_NAMES.get(agent_id, agent_id))
    now_str = datetime.now(KST).strftime("%Y-%m-%d")

    # ë…¸ì…˜ í˜ì´ì§€ í”„ë¡œí¼í‹° êµ¬ì„±
    properties: dict = {
        "Name": {"title": [{"text": {"content": title[:100]}}]},
    }
    # ì„ íƒ ì†ì„±ë“¤ (DBì— í•´ë‹¹ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë…¸ì…˜ì´ ë¬´ì‹œí•¨)
    if agent_name:
        properties["Agent"] = {"rich_text": [{"text": {"content": agent_name}}]}
    if division:
        properties["Division"] = {"rich_text": [{"text": {"content": division}}]}
    if report_type:
        properties["Type"] = {"rich_text": [{"text": {"content": report_type}}]}
    properties["Status"] = {"rich_text": [{"text": {"content": "ì™„ë£Œ"}}]}

    # ë³¸ë¬¸ â†’ ë…¸ì…˜ ë¸”ë¡ (ìµœëŒ€ 2000ì, ë…¸ì…˜ ë¸”ë¡ í¬ê¸° ì œí•œ)
    children = []
    text_chunks = [content[i:i+1900] for i in range(0, min(len(content), 8000), 1900)]
    for chunk in text_chunks:
        children.append({
            "object": "block",
            "type": "paragraph",
            "paragraph": {"rich_text": [{"text": {"content": chunk}}]},
        })

    body = json.dumps({
        "parent": {"database_id": _NOTION_DB_ID},
        "properties": properties,
        "children": children,
    }).encode("utf-8")

    headers = {
        "Authorization": f"Bearer {_NOTION_API_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28",
    }

    def _do_request():
        req = urllib.request.Request(
            "https://api.notion.com/v1/pages",
            data=body, headers=headers, method="POST",
        )
        try:
            with urllib.request.urlopen(req, timeout=10) as resp:
                return json.loads(resp.read().decode("utf-8"))
        except urllib.error.HTTPError as e:
            err_body = e.read().decode("utf-8", errors="replace")[:200]
            _log(f"[Notion] HTTP {e.code} ì˜¤ë¥˜: {err_body}")
            return None
        except Exception as e:
            _log(f"[Notion] ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None

    try:
        result = await asyncio.to_thread(_do_request)
        if result and result.get("url"):
            _log(f"[Notion] ì €ì¥ ì™„ë£Œ: {title[:50]} â†’ {result['url']}")
            return result["url"]
    except Exception as e:
        _log(f"[Notion] ë¹„ë™ê¸° ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    return None


# ë¸Œë¡œë“œìºìŠ¤íŠ¸ í‚¤ì›Œë“œ (ëª¨ë“  ë¶€ì„œì— ë™ì‹œ ì „ë‹¬í•˜ëŠ” ëª…ë ¹)
_BROADCAST_KEYWORDS = [
    "ì „ì²´", "ëª¨ë“  ë¶€ì„œ", "ì¶œì„", "íšŒì˜", "í˜„í™© ë³´ê³ ",
    "ì´ê´„", "ì „ì›", "ê° ë¶€ì„œ", "ì¶œì„ì²´í¬", "ë¸Œë¦¬í•‘",
]

# ì²˜ì¥ â†’ ì†Œì† ì „ë¬¸ê°€ ë§¤í•‘
_MANAGER_SPECIALISTS: dict[str, list[str]] = {
    "cto_manager": ["frontend_specialist", "backend_specialist", "infra_specialist", "ai_model_specialist"],
    "cso_manager": ["market_research_specialist", "business_plan_specialist", "financial_model_specialist"],
    "clo_manager": ["copyright_specialist", "patent_specialist"],
    "cmo_manager": ["survey_specialist", "content_specialist", "community_specialist"],
    "cio_manager": ["market_condition_specialist", "stock_analysis_specialist", "technical_analysis_specialist", "risk_management_specialist"],
    "cpo_manager": ["chronicle_specialist", "editor_specialist", "archive_specialist"],
}

# ì „ë¬¸ê°€ ID â†’ í•œêµ­ì–´ ì´ë¦„ (AGENTS ë¦¬ìŠ¤íŠ¸ì—ì„œ ìë™ êµ¬ì¶•)
_SPECIALIST_NAMES: dict[str, str] = {}
for _a in AGENTS:
    if _a["role"] == "specialist":
        _SPECIALIST_NAMES[_a["agent_id"]] = _a["name_ko"]


def _is_broadcast_command(text: str) -> bool:
    """ë¸Œë¡œë“œìºìŠ¤íŠ¸ ëª…ë ¹ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return any(kw in text for kw in _BROADCAST_KEYWORDS)


async def _broadcast_status(agent_id: str, status: str, progress: float, detail: str = ""):
    """ì—ì´ì „íŠ¸ ìƒíƒœë¥¼ ëª¨ë“  WebSocket í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡í•©ë‹ˆë‹¤.

    í”„ë¡ íŠ¸ì—”ë“œì˜ ìƒíƒœ í‘œì‹œë“±(ì´ˆë¡ë¶ˆ ê¹œë¹¡ì„)ì„ ì œì–´í•©ë‹ˆë‹¤.
    status: 'working' | 'done' | 'idle'
    """
    for c in connected_clients[:]:
        try:
            await c.send_json({
                "event": "agent_status",
                "data": {
                    "agent_id": agent_id,
                    "status": status,
                    "progress": progress,
                    "detail": detail,
                }
            })
        except Exception:
            pass


async def _call_agent(agent_id: str, text: str) -> dict:
    """ë‹¨ì¼ ì—ì´ì „íŠ¸ì—ê²Œ AI í˜¸ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ìƒíƒœ ì´ë²¤íŠ¸ + í™œë™ ë¡œê·¸ + ë„êµ¬ ìë™í˜¸ì¶œ í¬í•¨)."""
    agent_name = _AGENT_NAMES.get(agent_id, _SPECIALIST_NAMES.get(agent_id, agent_id))
    await _broadcast_status(agent_id, "working", 0.2, f"{agent_name} ë¶„ì„ ì¤‘...")

    # í™œë™ ë¡œê·¸ â€” ëˆ„ê°€ ì¼í•˜ëŠ”ì§€ ê¸°ë¡
    log_entry = save_activity_log(agent_id, f"[{agent_name}] ì‘ì—… ì‹œì‘: {text[:40]}...")
    for c in connected_clients[:]:
        try:
            await c.send_json({"event": "activity_log", "data": log_entry})
        except Exception:
            pass

    soul = _load_agent_prompt(agent_id)
    override = _get_model_override(agent_id)
    model = select_model(text, override=override)

    # â”€â”€ ë„êµ¬ ìë™í˜¸ì¶œ (Function Calling) â”€â”€
    # ì—ì´ì „íŠ¸ë³„ í—ˆìš© ë„êµ¬ ëª©ë¡ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆë¥¼ ë¡œë“œí•˜ê³ , ë„êµ¬ ì‹¤í–‰ í•¨ìˆ˜ë¥¼ ì „ë‹¬
    tool_schemas = None
    tool_executor_fn = None
    detail = _AGENTS_DETAIL.get(agent_id, {})
    allowed = detail.get("allowed_tools", [])
    if allowed:
        schemas = _load_tool_schemas(allowed_tools=allowed)
        if schemas.get("anthropic"):
            tool_schemas = schemas["anthropic"]  # ask_ai ë‚´ë¶€ì—ì„œ í”„ë¡œë°”ì´ë”ë³„ ë³€í™˜

            async def _tool_executor(tool_name: str, tool_input: dict):
                """ToolPoolì„ í†µí•´ ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
                pool = _init_tool_pool()
                if pool and hasattr(pool, '_tools') and tool_name in pool._tools:
                    await _broadcast_status(agent_id, "working", 0.5, f"ğŸ”§ {tool_name} ë„êµ¬ ì‹¤í–‰ ì¤‘...")
                    tool_obj = pool._tools[tool_name]
                    # ë„êµ¬ì˜ execute ë©”ì„œë“œ í˜¸ì¶œ
                    if asyncio.iscoroutinefunction(getattr(tool_obj, 'execute', None)):
                        return await tool_obj.execute(**tool_input)
                    elif hasattr(tool_obj, 'execute'):
                        return await asyncio.to_thread(tool_obj.execute, **tool_input)
                # ToolPoolì— ì—†ìœ¼ë©´ ë‹¨ìˆœ ì„¤ëª… ë°˜í™˜
                return f"ë„êµ¬ '{tool_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            tool_executor_fn = _tool_executor

    result = await ask_ai(text, system_prompt=soul, model=model,
                          tools=tool_schemas, tool_executor=tool_executor_fn)

    if "error" in result:
        await _broadcast_status(agent_id, "done", 1.0, "ì˜¤ë¥˜ ë°œìƒ")
        return {"agent_id": agent_id, "name": agent_name, "error": result["error"], "cost_usd": 0}

    await _broadcast_status(agent_id, "done", 1.0, "ì™„ë£Œ")

    # ì™„ë£Œ ë¡œê·¸
    cost = result.get("cost_usd", 0)
    content = result.get("content", "")
    log_done = save_activity_log(agent_id, f"[{agent_name}] ì‘ì—… ì™„ë£Œ (${cost:.4f})")
    for c in connected_clients[:]:
        try:
            await c.send_json({"event": "activity_log", "data": log_done})
        except Exception:
            pass

    # ì‚°ì¶œë¬¼ ì €ì¥ (ë…¸ì…˜ + ì•„ì¹´ì´ë¸Œ DB)
    if content and len(content) > 20:
        # ë…¸ì…˜ì— ì €ì¥ (ë¹„ë™ê¸°, ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ)
        asyncio.create_task(_save_to_notion(
            agent_id=agent_id,
            title=f"[{agent_name}] {text[:50]}",
            content=content,
        ))
        # ì•„ì¹´ì´ë¸Œ DBì— ì €ì¥ (ì˜êµ¬ ë³´ê´€)
        division = _AGENT_DIVISION.get(agent_id, "secretary")
        now_str = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
        archive_content = f"# [{agent_name}] {text[:60]}\n\n{content}"
        save_archive(
            division=division,
            filename=f"{agent_id}_{now_str}.md",
            content=archive_content,
            agent_id=agent_id,
        )

    return {
        "agent_id": agent_id,
        "name": agent_name,
        "content": content,
        "cost_usd": cost,
        "model": result.get("model", ""),
        "time_seconds": result.get("time_seconds", 0),
        "input_tokens": result.get("input_tokens", 0),
        "output_tokens": result.get("output_tokens", 0),
    }


async def _delegate_to_specialists(manager_id: str, text: str) -> list[dict]:
    """ì²˜ì¥ì´ ì†Œì† ì „ë¬¸ê°€ë“¤ì—ê²Œ ë³‘ë ¬ë¡œ ìœ„ì„í•©ë‹ˆë‹¤.

    asyncio.gatherë¡œ ì „ë¬¸ê°€ë“¤ì„ ë™ì‹œì— í˜¸ì¶œ â†’ ìƒíƒœ í‘œì‹œë“± ì „ë¶€ ê¹œë¹¡ì„.
    """
    specialists = _MANAGER_SPECIALISTS.get(manager_id, [])
    if not specialists:
        return []

    tasks = [_call_agent(spec_id, text) for spec_id in specialists]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    processed = []
    for i, r in enumerate(results):
        spec_id = specialists[i]
        if isinstance(r, Exception):
            processed.append({"agent_id": spec_id, "name": _SPECIALIST_NAMES.get(spec_id, spec_id), "error": str(r)[:100], "cost_usd": 0})
        else:
            processed.append(r)
    return processed


async def _manager_with_delegation(manager_id: str, text: str) -> dict:
    """ì²˜ì¥ì´ ì „ë¬¸ê°€ì—ê²Œ ìœ„ì„ â†’ ê²°ê³¼ ì¢…í•©(ê²€ìˆ˜) â†’ ë³´ê³ ì„œ ì‘ì„±.

    íë¦„: ì²˜ì¥ ë¶„ì„ ì‹œì‘ â†’ ì „ë¬¸ê°€ ë³‘ë ¬ í˜¸ì¶œ â†’ ì²˜ì¥ì´ ê²°ê³¼ ì¢…í•© + ê²€ìˆ˜ â†’ ë³´ê³ ì„œ ë°˜í™˜
    ê²€ìˆ˜: ì²˜ì¥ì´ ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì½ê³  ì¢…í•©í•˜ëŠ” ê³¼ì • ìì²´ê°€ í’ˆì§ˆ ê²€ìˆ˜ ì—­í• ì„ í•©ë‹ˆë‹¤.
    """
    mgr_name = _AGENT_NAMES.get(manager_id, manager_id)
    specialists = _MANAGER_SPECIALISTS.get(manager_id, [])
    spec_names = [_SPECIALIST_NAMES.get(s, s) for s in specialists]

    # ì²˜ì¥ ìƒíƒœ: ëª…ë ¹ ë¶„ì„ ì¤‘
    await _broadcast_status(manager_id, "working", 0.1, "ëª…ë ¹ ë¶„ì„ â†’ ì „ë¬¸ê°€ ìœ„ì„ ì¤‘...")

    # ì²˜ì¥ í™œë™ ë¡œê·¸ â€” ì „ë¬¸ê°€ì—ê²Œ ìœ„ì„
    if specialists:
        log_mgr = save_activity_log(manager_id, f"[{mgr_name}] ì „ë¬¸ê°€ {len(specialists)}ëª…ì—ê²Œ ìœ„ì„: {', '.join(spec_names)}")
        for c in connected_clients[:]:
            try:
                await c.send_json({"event": "activity_log", "data": log_mgr})
            except Exception:
                pass

    # ì „ë¬¸ê°€ë“¤ì—ê²Œ ë³‘ë ¬ ìœ„ì„
    spec_results = await _delegate_to_specialists(manager_id, text)

    if not spec_results:
        # ì „ë¬¸ê°€ê°€ ì—†ìœ¼ë©´ ì²˜ì¥ì´ ì§ì ‘ ì²˜ë¦¬
        return await _call_agent(manager_id, text)

    # ì „ë¬¸ê°€ ê²°ê³¼ ì·¨í•©
    spec_parts = []
    spec_cost = 0.0
    spec_time = 0.0
    for r in spec_results:
        name = r.get("name", r.get("agent_id", "?"))
        if "error" in r:
            spec_parts.append(f"[{name}] ì˜¤ë¥˜: {r['error'][:80]}")
        else:
            spec_parts.append(f"[{name}]\n{r.get('content', 'ì‘ë‹µ ì—†ìŒ')}")
            spec_cost += r.get("cost_usd", 0)
            spec_time = max(spec_time, r.get("time_seconds", 0))

    # ì²˜ì¥ì´ ì¢…í•© + ê²€ìˆ˜ (ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì½ê³  CEOì—ê²Œ ë³´ê³ ì„œ ì‘ì„±)
    synthesis_prompt = (
        f"ë‹¹ì‹ ì€ {mgr_name}ì…ë‹ˆë‹¤. ì†Œì† ì „ë¬¸ê°€ë“¤ì´ ì•„ë˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì œì¶œí–ˆìŠµë‹ˆë‹¤.\n"
        f"ì´ë¥¼ ê²€ìˆ˜í•˜ê³  ì¢…í•©í•˜ì—¬ CEOì—ê²Œ ë³´ê³ í•  ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
        f"ì „ë¬¸ê°€ ì˜ê²¬ ì¤‘ ë¶€ì¡±í•˜ê±°ë‚˜ ì˜ëª»ëœ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì§€ì í•˜ê³  ë³´ì™„í•˜ì„¸ìš”.\n\n"
        f"## CEO ì›ë³¸ ëª…ë ¹\n{text}\n\n"
        f"## ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼\n" + "\n\n".join(spec_parts)
    )

    soul = _load_agent_prompt(manager_id)
    override = _get_model_override(manager_id)
    model = select_model(synthesis_prompt, override=override)

    await _broadcast_status(manager_id, "working", 0.7, "ì „ë¬¸ê°€ ê²°ê³¼ ê²€ìˆ˜ + ì¢…í•© ì¤‘...")
    synthesis = await ask_ai(synthesis_prompt, system_prompt=soul, model=model)

    await _broadcast_status(manager_id, "done", 1.0, "ë³´ê³  ì™„ë£Œ")

    if "error" in synthesis:
        # ì¢…í•© ì‹¤íŒ¨ ì‹œ ì „ë¬¸ê°€ ê²°ê³¼ë§Œ ë°˜í™˜
        content = f"**{mgr_name} ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼**\n\n" + "\n\n---\n\n".join(spec_parts)
        return {"agent_id": manager_id, "name": mgr_name, "content": content, "cost_usd": spec_cost}

    total_cost = spec_cost + synthesis.get("cost_usd", 0)
    specialists_used = len([r for r in spec_results if "error" not in r])
    synth_content = synthesis.get("content", "")

    # ì¢…í•© ë³´ê³ ì„œ ì €ì¥ (ë…¸ì…˜ + ì•„ì¹´ì´ë¸Œ DB)
    if synth_content and len(synth_content) > 20:
        asyncio.create_task(_save_to_notion(
            agent_id=manager_id,
            title=f"[{mgr_name}] ì¢…í•©ë³´ê³ : {text[:40]}",
            content=synth_content,
            report_type="ì¢…í•©ë³´ê³ ì„œ",
        ))
        # ì•„ì¹´ì´ë¸Œ DBì— ì €ì¥
        division = _AGENT_DIVISION.get(manager_id, "secretary")
        now_str = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
        archive_content = f"# [{mgr_name}] ì¢…í•©ë³´ê³ : {text[:50]}\n\n{synth_content}"
        save_archive(
            division=division,
            filename=f"{manager_id}_synthesis_{now_str}.md",
            content=archive_content,
            agent_id=manager_id,
        )

    return {
        "agent_id": manager_id,
        "name": mgr_name,
        "content": synth_content,
        "cost_usd": total_cost,
        "model": synthesis.get("model", ""),
        "time_seconds": round(spec_time + synthesis.get("time_seconds", 0), 2),
        "specialists_used": specialists_used,
    }


async def _broadcast_to_managers(text: str, task_id: str) -> dict:
    """ì „ì²´ ë¶€ì„œ ë¸Œë¡œë“œìºìŠ¤íŠ¸.

    ë¹„ì„œì‹¤ì¥ â†’ 6ê°œ ì²˜ì¥ì—ê²Œ ëª…ë ¹ ì „ë‹¬.
    ê° ì²˜ì¥ì€ ìê¸° ì†Œì† ì „ë¬¸ê°€ë“¤ì—ê²Œ ìœ„ì„ â†’ ê²°ê³¼ ê²€ìˆ˜ â†’ ì¢…í•© ë³´ê³ ì„œ ì‘ì„±.
    ë¹„ì„œì‹¤ì¥ì€ ì²˜ì¥ë§Œ í˜¸ì¶œí•˜ê³ , ì „ë¬¸ê°€ëŠ” ì²˜ì¥ì´ ì•Œì•„ì„œ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    managers = ["cto_manager", "cso_manager", "clo_manager", "cmo_manager", "cio_manager", "cpo_manager"]

    # ë¹„ì„œì‹¤ì¥ ìƒíƒœ: ì „ë‹¬ ì¤‘
    await _broadcast_status("chief_of_staff", "working", 0.1, "6ê°œ ë¶€ì„œ ì²˜ì¥ì—ê²Œ ëª…ë ¹ í•˜ë‹¬ ì¤‘...")

    # í™œë™ ë¡œê·¸ â€” ë¹„ì„œì‹¤ì¥ì´ ì²˜ì¥ë“¤ì—ê²Œ ì „ë‹¬
    log_entry = save_activity_log("chief_of_staff", f"[ë¹„ì„œì‹¤ì¥] 6ê°œ ì²˜ì¥ì—ê²Œ ëª…ë ¹ ì „ë‹¬: {text[:40]}...")
    for c in connected_clients[:]:
        try:
            await c.send_json({"event": "activity_log", "data": log_entry})
        except Exception:
            pass

    # 6ê°œ ì²˜ì¥ ë™ì‹œ í˜¸ì¶œ (ê° ì²˜ì¥ì´ ìê¸° ì „ë¬¸ê°€ë¥¼ ì•Œì•„ì„œ í˜¸ì¶œ + ê²€ìˆ˜)
    tasks = [_manager_with_delegation(mgr_id, text) for mgr_id in managers]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # ê²°ê³¼ ì¢…í•©
    compiled_parts = []
    total_cost = 0.0
    total_time = 0.0
    success_count = 0
    total_specialists = 0

    for i, result in enumerate(results):
        mgr_id = managers[i]
        mgr_name = _AGENT_NAMES.get(mgr_id, mgr_id)

        if isinstance(result, Exception):
            compiled_parts.append(f"### âŒ {mgr_name}\nì˜¤ë¥˜: {str(result)[:100]}")
        elif "error" in result:
            compiled_parts.append(f"### âŒ {mgr_name}\n{result['error'][:200]}")
        else:
            specs = result.get("specialists_used", 0)
            total_specialists += specs
            spec_label = f" (ì „ë¬¸ê°€ {specs}ëª… ë™ì›)" if specs else ""
            compiled_parts.append(f"### ğŸ“‹ {mgr_name}{spec_label}\n{result.get('content', 'ì‘ë‹µ ì—†ìŒ')}")
            total_cost += result.get("cost_usd", 0)
            total_time = max(total_time, result.get("time_seconds", 0))
            success_count += 1

    # ë¹„ì„œì‹¤ì¥ ì™„ë£Œ
    await _broadcast_status("chief_of_staff", "done", 1.0, "ì¢…í•© ì™„ë£Œ")

    compiled_content = (
        f"ğŸ“¢ **ì „ì²´ ë¶€ì„œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê²°ê³¼** (6ê°œ ì²˜ì¥ + ì „ë¬¸ê°€ {total_specialists}ëª… ë™ì›)\n\n"
        f"ë¹„ì„œì‹¤ì¥ â†’ 6ê°œ ì²˜ì¥ì—ê²Œ ëª…ë ¹ ì „ë‹¬ â†’ ê° ì²˜ì¥ì´ ì†Œì† ì „ë¬¸ê°€ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ì¢…í•©í–ˆìŠµë‹ˆë‹¤.\n\n---\n\n"
        + "\n\n---\n\n".join(compiled_parts)
    )

    # DB ì—…ë°ì´íŠ¸
    update_task(task_id, status="completed",
                result_summary=f"ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì™„ë£Œ ({success_count}/6 ë¶€ì„œ ë³´ê³ , ì „ë¬¸ê°€ {total_specialists}ëª…)",
                result_data=compiled_content,
                success=1,
                cost_usd=total_cost,
                time_seconds=round(total_time, 2),
                agent_id="chief_of_staff")

    return {
        "content": compiled_content,
        "agent_id": "chief_of_staff",
        "handled_by": "ë¹„ì„œì‹¤ì¥ â†’ 6ê°œ ì²˜ì¥",
        "delegation": "ë¹„ì„œì‹¤ì¥ â†’ ì²˜ì¥ â†’ ì „ë¬¸ê°€",
        "total_cost_usd": round(total_cost, 6),
        "time_seconds": round(total_time, 2),
        "model": "multi-agent",
        "routing_method": "ë¸Œë¡œë“œìºìŠ¤íŠ¸",
    }


def _classify_by_keywords(text: str) -> str | None:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ë¥˜. ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜."""
    for agent_id, keywords in _ROUTING_KEYWORDS.items():
        if any(kw in text for kw in keywords):
            return agent_id
    return None


async def _route_task(text: str) -> dict:
    """CEO ëª…ë ¹ì„ ì í•©í•œ ì—ì´ì „íŠ¸ì—ê²Œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.

    1ë‹¨ê³„: í‚¤ì›Œë“œ ë§¤ì¹­ (ë¬´ë£Œ, ì¦‰ì‹œ)
    2ë‹¨ê³„: AI ë¶„ë¥˜ (Haiku, ~$0.001)
    3ë‹¨ê³„: í´ë°± â†’ ë¹„ì„œì‹¤ì¥
    """
    # 1ë‹¨ê³„: í‚¤ì›Œë“œ ë¶„ë¥˜
    agent_id = _classify_by_keywords(text)
    if agent_id:
        return {
            "agent_id": agent_id,
            "method": "í‚¤ì›Œë“œ",
            "cost_usd": 0.0,
            "reason": "í‚¤ì›Œë“œ ë§¤ì¹­",
        }

    # 2ë‹¨ê³„: AI ë¶„ë¥˜ (í‚¤ì›Œë“œ ì‹¤íŒ¨ ì‹œ)
    result = await classify_task(text)
    if result.get("agent_id") and result["agent_id"] != "chief_of_staff":
        return {
            "agent_id": result["agent_id"],
            "method": "AIë¶„ë¥˜",
            "cost_usd": result.get("cost_usd", 0),
            "reason": result.get("reason", "AI ë¶„ë¥˜"),
        }

    # 3ë‹¨ê³„: í´ë°± â€” ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬
    return {
        "agent_id": "chief_of_staff",
        "method": "ì§ì ‘",
        "cost_usd": result.get("cost_usd", 0),
        "reason": result.get("reason", "ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬"),
    }


def _get_tool_descriptions(agent_id: str) -> str:
    """ì—ì´ì „íŠ¸ì— í• ë‹¹ëœ ë„êµ¬ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    detail = _AGENTS_DETAIL.get(agent_id, {})
    allowed = detail.get("allowed_tools", [])
    if not allowed:
        return ""

    # ë„êµ¬ ID â†’ ì„¤ëª… ë§¤í•‘
    tool_map = {t.get("tool_id"): t for t in _TOOLS_LIST}
    descs = []
    for tid in allowed:
        t = tool_map.get(tid)
        if t:
            name = t.get("name_ko") or t.get("name", tid)
            desc = t.get("description", "")[:150]
            descs.append(f"- **{name}**: {desc}")

    if not descs:
        return ""

    return (
        "\n\n## ì‚¬ìš© ê°€ëŠ¥í•œ ì „ë¬¸ ë„êµ¬\n"
        "ì•„ë˜ ë„êµ¬ì˜ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ë” ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n"
        + "\n".join(descs)
    )


def _load_agent_prompt(agent_id: str) -> str:
    """ì—ì´ì „íŠ¸ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(ì†Œìš¸) + ë„êµ¬ ì •ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

    ìš°ì„ ìˆœìœ„: DB ì˜¤ë²„ë¼ì´ë“œ > souls/*.md íŒŒì¼ > agents.yaml system_prompt > ê¸°ë³¸ê°’
    ë§ˆì§€ë§‰ì— í• ë‹¹ëœ ë„êµ¬ ì„¤ëª…ì„ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    prompt = ""

    # 1ìˆœìœ„: DB ì˜¤ë²„ë¼ì´ë“œ
    soul = load_setting(f"soul_{agent_id}")
    if soul:
        prompt = soul
    else:
        # 2ìˆœìœ„: souls íŒŒì¼
        soul_path = Path(BASE_DIR).parent / "souls" / "agents" / f"{agent_id}.md"
        if soul_path.exists():
            try:
                prompt = soul_path.read_text(encoding="utf-8")
            except Exception:
                pass

    if not prompt:
        # 3ìˆœìœ„: agents.yamlì˜ system_prompt
        detail = _AGENTS_DETAIL.get(agent_id, {})
        if detail.get("system_prompt"):
            prompt = detail["system_prompt"]

    if not prompt:
        # 4ìˆœìœ„: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        name = _AGENT_NAMES.get(agent_id, _SPECIALIST_NAMES.get(agent_id, agent_id))
        prompt = (
            f"ë‹¹ì‹ ì€ CORTHEX HQì˜ {name}ì…ë‹ˆë‹¤. "
            "CEOì˜ ì—…ë¬´ ì§€ì‹œë¥¼ ë°›ì•„ ì²˜ë¦¬í•˜ê³ , ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤. "
            "í•­ìƒ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤."
        )

    # ë„êµ¬ ì„¤ëª… ì¶”ê°€ (ì—ì´ì „íŠ¸ê°€ ìì‹ ì˜ ë„êµ¬ë¥¼ ì¸ì§€í•˜ê³  í™œìš©í•  ìˆ˜ ìˆê²Œ)
    tools_desc = _get_tool_descriptions(agent_id)
    if tools_desc:
        prompt += tools_desc

    return prompt


_chief_prompt: str = ""


def _load_chief_prompt() -> None:
    """ë¹„ì„œì‹¤ì¥ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤ (ì„œë²„ ì‹œì‘ ì‹œ ìºì‹œ)."""
    global _chief_prompt
    _chief_prompt = _load_agent_prompt("chief_of_staff")
    _log("[AI] ë¹„ì„œì‹¤ì¥ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ")


def _get_model_override(agent_id: str) -> str | None:
    """ëª¨ë¸ ëª¨ë“œì— ë”°ë¼ ì—ì´ì „íŠ¸ì˜ ëª¨ë¸ì„ ê²°ì •í•©ë‹ˆë‹¤.

    - ìë™ ëª¨ë“œ: None ë°˜í™˜ â†’ select_model()ì´ ì§ˆë¬¸ ë‚´ìš©ì— ë”°ë¼ ìë™ ì„ íƒ
    - ìˆ˜ë™ ëª¨ë“œ: í•´ë‹¹ ì—ì´ì „íŠ¸ì— ê°œë³„ ì§€ì •ëœ ëª¨ë¸ì„ ë°˜í™˜
      (ì—ì´ì „íŠ¸ ìƒì„¸ì—ì„œ CEOê°€ ì§ì ‘ ì„¤ì •í•œ ëª¨ë¸)
    """
    mode = load_setting("model_mode") or "auto"
    if mode != "manual":
        return None
    # ìˆ˜ë™ ëª¨ë“œ â†’ ì—ì´ì „íŠ¸ë³„ ê°œë³„ ì§€ì • ëª¨ë¸ ì‚¬ìš©
    detail = _AGENTS_DETAIL.get(agent_id, {})
    agent_model = detail.get("model_name")
    if agent_model:
        return agent_model
    # AGENTS ë¦¬ìŠ¤íŠ¸ì—ì„œë„ í™•ì¸
    for a in AGENTS:
        if a["agent_id"] == agent_id and a.get("model_name"):
            return a["model_name"]
    return None


async def _process_ai_command(text: str, task_id: str) -> dict:
    """CEO ëª…ë ¹ì„ ì í•©í•œ ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„í•˜ê³  AI ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    íë¦„:
      ì˜ˆì‚° í™•ì¸ â†’ ë¸Œë¡œë“œìºìŠ¤íŠ¸ í™•ì¸ â†’ ë¼ìš°íŒ…(ë¶„ë¥˜) â†’ ìƒíƒœ ì „ì†¡
      â†’ ì²˜ì¥+ì „ë¬¸ê°€ í’€ ì²´ì¸ ìœ„ì„ â†’ ê²€ìˆ˜ â†’ DB ì €ì¥

    ë¸Œë¡œë“œìºìŠ¤íŠ¸ ëª¨ë“œ: "ì „ì²´", "ì¶œì„ì²´í¬" ë“± â†’ 29ëª… ë™ì‹œ ê°€ë™
    ë‹¨ì¼ ìœ„ì„ ëª¨ë“œ: í‚¤ì›Œë“œ/AI ë¶„ë¥˜ â†’ ì²˜ì¥+ì „ë¬¸ê°€ ì²´ì¸ í˜¸ì¶œ
    ì§ì ‘ ì²˜ë¦¬: ë¹„ì„œì‹¤ì¥ì´ ì§ì ‘ ë‹µë³€ (ë‹¨ìˆœ ì§ˆë¬¸)
    """
    # 1) ì˜ˆì‚° í™•ì¸
    limit = float(load_setting("daily_budget_usd") or 7.0)
    today = get_today_cost()
    if today >= limit:
        update_task(task_id, status="failed",
                    result_summary=f"ì¼ì¼ ì˜ˆì‚° ì´ˆê³¼ (${today:.2f}/${limit:.0f})",
                    success=0)
        return {"error": f"ì¼ì¼ ì˜ˆì‚°ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ (${today:.2f}/${limit:.0f})"}

    # 1.5) ë°°ì¹˜ íŠ¹ìˆ˜ ëª…ë ¹ ì²˜ë¦¬
    text_lower = text.strip().lower()
    if text_lower in ("/ë°°ì¹˜ì‹¤í–‰", "/batch_flush", "ë°°ì¹˜ì‹¤í–‰", "ë°°ì¹˜ ì‹¤í–‰"):
        result = await _flush_batch_api_queue()
        content = f"ğŸ“¦ **ë°°ì¹˜ ì‹¤í–‰ ê²°ê³¼**\n\n"
        if "error" in result:
            content += f"âŒ ì‹¤íŒ¨: {result['error']}"
        elif result.get("batch_id"):
            content += f"âœ… Batch API ì œì¶œ ì™„ë£Œ\n- batch_id: `{result['batch_id']}`\n- ê±´ìˆ˜: {result.get('count', 0)}ê±´\n- í”„ë¡œë°”ì´ë”: {result.get('provider', '?')}"
        else:
            content += result.get("message", "ì²˜ë¦¬ ì™„ë£Œ")
        update_task(task_id, status="completed", result_summary=content[:500], success=1)
        return {"content": content, "handled_by": "ë¹„ì„œì‹¤ì¥", "agent_id": "chief_of_staff"}

    if text_lower in ("/ë°°ì¹˜ìƒíƒœ", "/batch_status", "ë°°ì¹˜ìƒíƒœ", "ë°°ì¹˜ ìƒíƒœ"):
        pending_batches = load_setting("pending_batches") or []
        active = [b for b in pending_batches if b.get("status") in ("pending", "processing")]
        queue_count = len(_batch_api_queue)
        content = f"ğŸ“¦ **ë°°ì¹˜ ìƒíƒœ**\n\n"
        content += f"- ëŒ€ê¸°ì—´: {queue_count}ê±´\n"
        content += f"- ì²˜ë¦¬ ì¤‘ì¸ ë°°ì¹˜: {len(active)}ê±´\n"
        for b in active:
            prog = b.get("progress", {})
            content += f"  - `{b['batch_id'][:20]}...` ({b['provider']}) â€” {prog.get('completed', '?')}/{prog.get('total', '?')} ì™„ë£Œ\n"
        update_task(task_id, status="completed", result_summary=content[:500], success=1)
        return {"content": content, "handled_by": "ë¹„ì„œì‹¤ì¥", "agent_id": "chief_of_staff"}

    # 2) ë¸Œë¡œë“œìºìŠ¤íŠ¸ ëª…ë ¹ í™•ì¸ â†’ 29ëª… ë™ì‹œ ê°€ë™
    if _is_broadcast_command(text):
        return await _broadcast_to_managers(text, task_id)

    # 3) ë¼ìš°íŒ… â€” ì í•©í•œ ì—ì´ì „íŠ¸ ê²°ì •
    routing = await _route_task(text)
    target_id = routing["agent_id"]
    routing_cost = routing.get("cost_usd", 0)

    # 4) ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬ (ì¼ë°˜ ì§ˆë¬¸, ì¸ì‚¬ ë“±)
    if target_id == "chief_of_staff":
        await _broadcast_status("chief_of_staff", "working", 0.2, "ì§ì ‘ ì²˜ë¦¬ ì¤‘...")
        soul = _chief_prompt if _chief_prompt else _load_agent_prompt("chief_of_staff")
        override = _get_model_override("chief_of_staff")
        model = select_model(text, override=override)
        result = await ask_ai(text, system_prompt=soul, model=model)

        await _broadcast_status("chief_of_staff", "done", 1.0, "ì™„ë£Œ")

        if "error" in result:
            update_task(task_id, status="failed",
                        result_summary=f"AI ì˜¤ë¥˜: {result['error'][:100]}",
                        success=0, agent_id="chief_of_staff")
            result["handled_by"] = "ë¹„ì„œì‹¤ì¥"
            return result

        total_cost = routing_cost + result.get("cost_usd", 0)
        update_task(task_id, status="completed",
                    result_summary=result["content"][:500],
                    result_data=result["content"],
                    success=1, cost_usd=total_cost,
                    tokens_used=result.get("input_tokens", 0) + result.get("output_tokens", 0),
                    time_seconds=result.get("time_seconds", 0),
                    agent_id="chief_of_staff")
        result["handled_by"] = "ë¹„ì„œì‹¤ì¥"
        result["delegation"] = ""
        result["agent_id"] = "chief_of_staff"
        result["routing_method"] = routing["method"]
        result["total_cost_usd"] = total_cost
        return result

    # 5) ë¶€ì„œ ìœ„ì„ â€” ë¹„ì„œì‹¤ì¥ â†’ ì²˜ì¥ â†’ ì „ë¬¸ê°€
    target_name = _AGENT_NAMES.get(target_id, target_id)
    await _broadcast_status("chief_of_staff", "working", 0.1, f"{target_name}ì—ê²Œ ìœ„ì„ ì¤‘...")

    # ì²˜ì¥ì´ ìê¸° ì „ë¬¸ê°€ë¥¼ í˜¸ì¶œ â†’ ê²°ê³¼ ê²€ìˆ˜ â†’ ì¢…í•© ë³´ê³ ì„œ
    delegation_result = await _manager_with_delegation(target_id, text)

    await _broadcast_status("chief_of_staff", "done", 1.0, "ìœ„ì„ ì™„ë£Œ")

    if "error" in delegation_result:
        update_task(task_id, status="failed",
                    result_summary=f"ìœ„ì„ ì˜¤ë¥˜: {delegation_result['error'][:100]}",
                    success=0, agent_id=target_id)
        delegation_result["handled_by"] = target_name
        return delegation_result

    # 6) ê²°ê³¼ ì •ë¦¬
    total_cost = routing_cost + delegation_result.get("cost_usd", 0)
    specs_used = delegation_result.get("specialists_used", 0)
    delegation_label = f"ë¹„ì„œì‹¤ì¥ â†’ {target_name}"
    if specs_used:
        delegation_label += f" â†’ ì „ë¬¸ê°€ {specs_used}ëª…"

    content = delegation_result.get("content", "")
    header = f"ğŸ“‹ **{target_name}** ë³´ê³ "
    if specs_used:
        header += f" (ì†Œì† ì „ë¬¸ê°€ {specs_used}ëª… ë™ì›)"
    content = f"{header}\n\n---\n\n{content}"

    update_task(task_id, status="completed",
                result_summary=content[:500],
                result_data=content,
                success=1, cost_usd=total_cost,
                time_seconds=delegation_result.get("time_seconds", 0),
                agent_id=target_id)

    return {
        "content": content,
        "agent_id": target_id,
        "handled_by": target_name,
        "delegation": delegation_label,
        "total_cost_usd": round(total_cost, 6),
        "time_seconds": delegation_result.get("time_seconds", 0),
        "model": delegation_result.get("model", ""),
        "routing_method": routing["method"],
    }


# â”€â”€ ë„êµ¬ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸ â”€â”€

def _init_tool_pool():
    """ToolPool ì´ˆê¸°í™” â€” src/tools/ ëª¨ë“ˆì„ ë™ì ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.

    ask_ai()ë¥¼ ModelRouter ì¸í„°í˜ì´ìŠ¤ë¡œ ê°ì‹¸ëŠ” ì–´ëŒ‘í„°ë¥¼ ë§Œë“¤ì–´,
    ê¸°ì¡´ ë„êµ¬ ì½”ë“œë¥¼ ìˆ˜ì • ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
    """
    global _tool_pool
    if _tool_pool is not None:
        return _tool_pool if _tool_pool else None

    try:
        from src.tools.pool import ToolPool
        from src.llm.base import LLMResponse

        class _MiniModelRouter:
            """ask_ai()ë¥¼ ModelRouter.complete() ì¸í„°í˜ì´ìŠ¤ë¡œ ê°ì‹¸ëŠ” ì–´ëŒ‘í„°."""

            class cost_tracker:
                """ë”ë¯¸ ë¹„ìš© ì¶”ì ê¸° (mini_serverëŠ” ìì²´ ë¹„ìš© ì¶”ì  ì‚¬ìš©)."""
                @staticmethod
                def record(*args, **kwargs):
                    pass

            async def complete(self, model_name="", messages=None,
                             temperature=0.3, max_tokens=4096,
                             agent_id="", reasoning_effort=None,
                             use_batch=False):
                messages = messages or []
                system_prompt = ""
                user_message = ""
                for msg in messages:
                    if msg.get("role") == "system":
                        system_prompt = msg["content"]
                    elif msg.get("role") == "user":
                        user_message = msg["content"]

                result = await ask_ai(user_message, system_prompt, model_name)

                if "error" in result:
                    return LLMResponse(
                        content=f"[ë„êµ¬ LLM ì˜¤ë¥˜] {result['error']}",
                        model=model_name,
                        input_tokens=0, output_tokens=0,
                        cost_usd=0.0, provider="unknown",
                    )
                return LLMResponse(
                    content=result["content"],
                    model=result.get("model", model_name),
                    input_tokens=result.get("input_tokens", 0),
                    output_tokens=result.get("output_tokens", 0),
                    cost_usd=result.get("cost_usd", 0.0),
                    provider=result.get("provider", "unknown"),
                )

            async def close(self):
                pass

        router = _MiniModelRouter()
        pool = ToolPool(router)

        tools_config = _load_config("tools")
        pool.build_from_config(tools_config)

        loaded = len(pool._tools)
        _tool_pool = pool
        _log(f"[TOOLS] ToolPool ì´ˆê¸°í™” ì™„ë£Œ: {loaded}ê°œ ë„êµ¬ ë¡œë“œ âœ…")
        return pool

    except Exception as e:
        _log(f"[TOOLS] ToolPool ì´ˆê¸°í™” ì‹¤íŒ¨ (ë„êµ¬ ëª©ë¡ë§Œ í‘œì‹œ): {e}")
        _tool_pool = False
        return None


@app.post("/api/tools/{tool_id}/execute")
async def execute_tool(tool_id: str, request: Request):
    """ë„êµ¬ë¥¼ ì§ì ‘ ì‹¤í–‰í•©ë‹ˆë‹¤.

    ìš”ì²­ body: {"action": "...", "query": "...", ...} (ë„êµ¬ë³„ ìƒì´)
    ì‘ë‹µ: {"result": "...", "tool_id": "...", "cost_usd": 0.0}
    """
    pool = _init_tool_pool()
    if not pool:
        return JSONResponse(
            {"error": "ë„êµ¬ ì‹¤í–‰ ì—”ì§„ ë¯¸ì´ˆê¸°í™” (ToolPool ë¡œë“œ ì‹¤íŒ¨)"},
            status_code=503,
        )

    try:
        body = await request.json()
    except Exception:
        body = {}

    try:
        result = await pool.invoke(tool_id, caller_id="ceo_direct", **body)
        return {"result": result, "tool_id": tool_id, "status": "ok"}
    except Exception as e:
        return JSONResponse(
            {"error": f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)[:300]}", "tool_id": tool_id},
            status_code=400,
        )


@app.get("/api/tools/status")
async def get_tools_status():
    """ë¡œë“œëœ ë„êµ¬ ëª©ë¡ê³¼ ToolPool ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    pool = _init_tool_pool()
    if not pool:
        return {
            "pool_status": "unavailable",
            "loaded_tools": [],
            "total_defined": len(_TOOLS_LIST),
        }

    loaded = list(pool._tools.keys())
    return {
        "pool_status": "ready",
        "loaded_tools": loaded,
        "loaded_count": len(loaded),
        "total_defined": len(_TOOLS_LIST),
    }


@app.on_event("startup")
async def on_startup():
    """ì„œë²„ ì‹œì‘ ì‹œ DB ì´ˆê¸°í™” + AI í´ë¼ì´ì–¸íŠ¸ + í…”ë ˆê·¸ë¨ ë´‡ + í¬ë¡  ì—”ì§„ + ë„êµ¬ í’€ ì‹œì‘."""
    init_db()
    _load_chief_prompt()
    ai_ok = init_ai_client()
    _log(f"[AI] í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”: {'ì„±ê³µ âœ…' if ai_ok else 'ì‹¤íŒ¨ âŒ (ANTHROPIC_API_KEY ë¯¸ì„¤ì •?)'}")
    await _start_telegram_bot()
    # í¬ë¡  ì‹¤í–‰ ì—”ì§„ ì‹œì‘
    global _cron_task
    _cron_task = asyncio.create_task(_cron_loop())
    _log("[CRON] í¬ë¡  ì‹¤í–‰ ì—”ì§„ ì‹œì‘ âœ…")
    # ë„êµ¬ ì‹¤í–‰ ì—”ì§„ ì´ˆê¸°í™” (ë¹„ë™ê¸° ì•„ë‹Œ ë™ê¸° â€” ì²« ìš”ì²­ ì‹œ lazy ë¡œë“œë„ ì§€ì›)
    _init_tool_pool()
    # PENDING ë°°ì¹˜ ë˜ëŠ” ì§„í–‰ ì¤‘ì¸ ì²´ì¸ì´ ìˆìœ¼ë©´ í´ëŸ¬ ì‹œì‘
    pending_batches = load_setting("pending_batches") or []
    active_batches = [b for b in pending_batches if b.get("status") in ("pending", "processing")]
    chains = load_setting("batch_chains") or []
    active_chains = [c for c in chains if c.get("status") in ("running", "pending")]
    if active_batches or active_chains:
        _ensure_batch_poller()
        _log(f"[BATCH] ë¯¸ì™„ë£Œ ë°°ì¹˜ {len(active_batches)}ê°œ + ì²´ì¸ {len(active_chains)}ê°œ ê°ì§€ â€” í´ëŸ¬ ìë™ ì‹œì‘")


@app.on_event("shutdown")
async def on_shutdown():
    """ì„œë²„ ì¢…ë£Œ ì‹œ í…”ë ˆê·¸ë¨ ë´‡ë„ í•¨ê»˜ ì¢…ë£Œ."""
    await _stop_telegram_bot()


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
