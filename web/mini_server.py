"""
CORTHEX HQ - ARM Server

Oracle Cloud ARM ì„œë²„ (4ì½”ì–´ 24GB)ì—ì„œ ëŒ€ì‹œë³´ë“œë¥¼ ì„œë¹„ìŠ¤í•©ë‹ˆë‹¤.
ì „ì²´ ë°±ì—”ë“œì˜ í•µì‹¬ APIë§Œ ì œê³µí•˜ì—¬ ëŒ€ì‹œë³´ë“œ UIê°€ ì •ìƒ ì‘ë™í•˜ë„ë¡ í•¨.
í…”ë ˆê·¸ë¨ ë´‡ë„ ì—¬ê¸°ì„œ 24ì‹œê°„ êµ¬ë™ë©ë‹ˆë‹¤.
"""
import asyncio
import json
import logging
import os
import sys
import time
import uuid as _uuid
import urllib.request
import urllib.error
from datetime import datetime, timezone, timedelta
from pathlib import Path

# DB ëª¨ë“ˆì„ ê°™ì€ í´ë”ì—ì„œ ì„í¬íŠ¸
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from db import (
    init_db, save_message, create_task, get_task as db_get_task,
    update_task, list_tasks, toggle_bookmark as db_toggle_bookmark,
    get_dashboard_stats, save_activity_log, list_activity_logs,
    save_archive, list_archives, get_archive as db_get_archive, delete_archive as db_delete_archive,
    save_setting, load_setting, get_today_cost,
    save_conversation_message, load_conversation_messages, clear_conversation_messages,
    delete_task as db_delete_task, bulk_delete_tasks, bulk_archive_tasks,
    set_task_tags, mark_task_read, bulk_mark_read,
)
try:
    from ai_handler import (
        init_ai_client, is_ai_ready, ask_ai, select_model,
        classify_task, get_available_providers,
        _load_tool_schemas,  # ë„êµ¬ ìŠ¤í‚¤ë§ˆ ë¡œë”© (function callingìš©)
        batch_submit, batch_check, batch_retrieve,  # Batch API
        batch_submit_grouped,  # í”„ë¡œë°”ì´ë”ë³„ ê·¸ë£¹ ë°°ì¹˜ ì œì¶œ (ë°°ì¹˜ ì²´ì¸ìš©)
    )
except ImportError:
    def init_ai_client(): return False
    def is_ai_ready(): return False
    async def ask_ai(*a, **kw): return {"error": "ai_handler ë¯¸ì„¤ì¹˜"}
    def select_model(t, override=None): return override or "claude-sonnet-4-6"
    async def classify_task(t): return {"agent_id": "chief_of_staff", "reason": "ai_handler ë¯¸ì„¤ì¹˜", "cost_usd": 0}
    def get_available_providers(): return {"anthropic": False, "google": False, "openai": False}
    def _load_tool_schemas(allowed_tools=None): return {}
    async def batch_submit(*a, **kw): return {"error": "ai_handler ë¯¸ì„¤ì¹˜"}
    async def batch_check(*a, **kw): return {"error": "ai_handler ë¯¸ì„¤ì¹˜"}
    async def batch_retrieve(*a, **kw): return {"error": "ai_handler ë¯¸ì„¤ì¹˜"}
    async def batch_submit_grouped(*a, **kw): return [{"error": "ai_handler ë¯¸ì„¤ì¹˜"}]

# Python ì¶œë ¥ ë²„í¼ë§ ë¹„í™œì„±í™” (systemdì—ì„œ ë¡œê·¸ê°€ ë°”ë¡œ ë³´ì´ë„ë¡)
os.environ["PYTHONUNBUFFERED"] = "1"

# ì§„ë‹¨ ì •ë³´ ìˆ˜ì§‘ìš©
_diag: dict = {"env_loaded": False, "env_file": "", "env_count": 0,
               "tg_import": False, "tg_import_error": "",
               "tg_token_found": False, "tg_started": False, "tg_error": ""}


def _log(msg: str) -> None:
    """ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥ (stdout + stderr ì–‘ìª½ì— flush)."""
    print(msg, flush=True)
    sys.stderr.write(msg + "\n")
    sys.stderr.flush()


def _load_env_file() -> None:
    """í™˜ê²½ë³€ìˆ˜ íŒŒì¼ì„ ì§ì ‘ ì½ì–´ì„œ os.environì— ì„¤ì •."""
    env_paths = [
        Path("/home/ubuntu/corthex.env"),        # ì„œë²„ ë°°í¬ í™˜ê²½
        Path(__file__).parent.parent / ".env.local",  # ë¡œì»¬ ê°œë°œ í™˜ê²½
        Path(__file__).parent.parent / ".env",        # ë¡œì»¬ í´ë°±
    ]
    for env_path in env_paths:
        _log(f"[ENV] í™•ì¸: {env_path} (ì¡´ì¬: {env_path.exists()})")
        if env_path.exists():
            try:
                loaded = 0
                for line in env_path.read_text(encoding="utf-8").splitlines():
                    line = line.strip()
                    if not line or line.startswith("#"):
                        continue
                    if "=" in line:
                        key, _, value = line.partition("=")
                        key = key.strip()
                        value = value.strip()
                        if key:
                            os.environ[key] = value
                            loaded += 1
                _diag["env_loaded"] = True
                _diag["env_file"] = str(env_path)
                _diag["env_count"] = loaded
                tg = os.getenv("TELEGRAM_BOT_TOKEN", "")
                _diag["tg_token_found"] = bool(tg)
                _log(f"[ENV] âœ… {loaded}ê°œ ë¡œë“œ: {env_path}")
                _log(f"[ENV] TG_TOKEN: {bool(tg)} (ê¸¸ì´:{len(tg)})")
            except Exception as e:
                _log(f"[ENV] âŒ ì‹¤íŒ¨: {e}")
            break


_load_env_file()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€ (src/ ëª¨ë“ˆ ì„í¬íŠ¸ìš©)
_PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if _PROJECT_ROOT not in sys.path:
    sys.path.insert(0, _PROJECT_ROOT)

try:
    import yaml
except ImportError:
    yaml = None  # PyYAML ë¯¸ì„¤ì¹˜ ì‹œ graceful fallback

# â”€â”€ ToolPool ì§€ì—° ë¡œë”© â”€â”€
_tool_pool = None  # None=ë¯¸ì´ˆê¸°í™”, False=ì‹¤íŒ¨, ToolPoolì¸ìŠ¤í„´ìŠ¤=ì„±ê³µ

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Body, Request
from fastapi.responses import HTMLResponse, FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import Optional

logger = logging.getLogger("corthex.mini_server")

# â”€â”€ í…”ë ˆê·¸ë¨ ë´‡ (ì„ íƒì  ë¡œë“œ) â”€â”€
_telegram_available = False
try:
    from telegram import Update, BotCommand, InlineKeyboardButton, InlineKeyboardMarkup
    from telegram.ext import (
        Application,
        CommandHandler,
        MessageHandler,
        CallbackQueryHandler,
        ContextTypes,
        filters,
    )
    _telegram_available = True
    _diag["tg_import"] = True
    _log("[TG] python-telegram-bot ì„í¬íŠ¸ ì„±ê³µ âœ…")
except ImportError as e:
    _diag["tg_import_error"] = str(e)
    _log(f"[TG] python-telegram-bot ì„í¬íŠ¸ ì‹¤íŒ¨ âŒ: {e}")

KST = timezone(timedelta(hours=9))

app = FastAPI(title="CORTHEX HQ")

# â”€â”€ HTML ì„œë¹™ â”€â”€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
TEMPLATE_DIR = os.path.join(BASE_DIR, "templates")

def get_build_number() -> str:
    """ë¹Œë“œ ë²ˆí˜¸ ë°˜í™˜.
    ì‹¤ì œ ë¹Œë“œ ë²ˆí˜¸ëŠ” GitHub Actions ë°°í¬ ì‹œ deploy.ymlì´ HTMLì— ì§ì ‘ ì£¼ì…í•¨.
    ì´ í•¨ìˆ˜ëŠ” ë¡œì»¬ ê°œë°œ í™˜ê²½(ë°°í¬ ì „)ì—ì„œë§Œ ì‚¬ìš©ë˜ëŠ” í´ë°± ê°’ì„ ë°˜í™˜."""
    return "dev"

# â”€â”€ ì„¤ì • íŒŒì¼ì—ì„œ ì—ì´ì „íŠ¸/ë„êµ¬ ì •ë³´ ë¡œë“œ â”€â”€
CONFIG_DIR = Path(BASE_DIR).parent / "config"

def _load_config(name: str) -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ. JSONì„ ë¨¼ì € ì‹œë„í•˜ê³ , ì—†ìœ¼ë©´ YAMLë¡œ ì‹œë„."""
    # 1ìˆœìœ„: JSON íŒŒì¼ (deploy.ymlì´ ë°°í¬ ì‹œ YAML â†’ JSONìœ¼ë¡œ ë³€í™˜í•´ë‘ )
    json_path = CONFIG_DIR / f"{name}.json"
    if json_path.exists():
        try:
            raw = json.loads(json_path.read_text(encoding="utf-8"))
            logger.info("%s.json ë¡œë“œ ì„±ê³µ", name)
            return raw
        except Exception as e:
            logger.warning("%s.json ë¡œë“œ ì‹¤íŒ¨: %s", name, e)

    # 2ìˆœìœ„: YAML íŒŒì¼ (PyYAML í•„ìš”)
    yaml_path = CONFIG_DIR / f"{name}.yaml"
    if yaml is not None and yaml_path.exists():
        try:
            raw = yaml.safe_load(yaml_path.read_text(encoding="utf-8"))
            logger.info("%s.yaml ë¡œë“œ ì„±ê³µ", name)
            # ë³´í—˜: YAML ì½ì€ í›„ JSONë„ ìë™ ìƒì„± (ë‹¤ìŒ ê¸°ë™ ì‹œ 1ìˆœìœ„ë¡œ ë°”ë¡œ ë¡œë“œ)
            try:
                json_path.write_text(
                    json.dumps(raw, ensure_ascii=False, indent=2), encoding="utf-8"
                )
                logger.info("%s.yaml â†’ %s.json ìë™ ë³€í™˜ ì™„ë£Œ", name, name)
            except Exception:
                pass  # JSON ìƒì„± ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ (YAML ì½ê¸°ëŠ” ì„±ê³µí–ˆìœ¼ë¯€ë¡œ)
            return raw
        except Exception as e:
            logger.warning("%s.yaml ë¡œë“œ ì‹¤íŒ¨: %s", name, e)

    logger.warning("%s ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ (ë¹ˆ ì„¤ì • ì‚¬ìš©)", name)
    return {}


def _load_agents() -> dict:
    """ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ì •ë³´(allowed_tools, capabilities ë“±)ë¥¼ ë¡œë“œ."""
    raw = _load_config("agents")
    lookup: dict[str, dict] = {}
    for a in raw.get("agents", []):
        lookup[a["agent_id"]] = a
    return lookup


def _load_tools() -> list[dict]:
    """ë„êµ¬ ëª©ë¡ì„ ë¡œë“œ."""
    raw = _load_config("tools")
    return raw.get("tools", [])

# ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½: í•„ìš”í•œ ì •ë³´ë§Œ ìºì‹œ)
_AGENTS_DETAIL: dict[str, dict] = _load_agents()
_TOOLS_LIST: list[dict] = _load_tools()

# â”€â”€ ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬ (ëŸ°íƒ€ì„ ë°ì´í„°) â”€â”€
DATA_DIR = Path(BASE_DIR).parent / "data"
DATA_DIR.mkdir(exist_ok=True)
KNOWLEDGE_DIR = Path(BASE_DIR).parent / "knowledge"
ARCHIVE_DIR = Path(BASE_DIR).parent / "archive"


def _load_data(name: str, default=None):
    """DBì—ì„œ ì„¤ì • ë°ì´í„° ë¡œë“œ. DBì— ì—†ìœ¼ë©´ ê¸°ì¡´ JSON íŒŒì¼ í™•ì¸ í›„ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜."""
    # 1ìˆœìœ„: SQLite DB
    db_val = load_setting(name)
    if db_val is not None:
        return db_val
    # 2ìˆœìœ„: ê¸°ì¡´ JSON íŒŒì¼ (ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜)
    path = DATA_DIR / f"{name}.json"
    if path.exists():
        try:
            val = json.loads(path.read_text(encoding="utf-8"))
            save_setting(name, val)  # DBë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
            return val
        except Exception:
            pass
    return default if default is not None else {}


def _save_data(name: str, data) -> None:
    """DBì— ì„¤ì • ë°ì´í„° ì €ì¥."""
    save_setting(name, data)


def _save_config_file(name: str, data: dict) -> None:
    """ì„¤ì • ë³€ê²½ì„ DBì— ì €ì¥. (ì¬ë°°í¬í•´ë„ ìœ ì§€ë¨)"""
    save_setting(f"config_{name}", data)


@app.get("/", response_class=HTMLResponse)
async def index():
    html_path = os.path.join(TEMPLATE_DIR, "index.html")
    with open(html_path, "r", encoding="utf-8") as f:
        html_content = f.read()

    # BUILD_NUMBER_PLACEHOLDERë¥¼ ì‹¤ì œ ë¹Œë“œ ë²ˆí˜¸ë¡œ ì¹˜í™˜
    build_number = get_build_number()
    html_content = html_content.replace("BUILD_NUMBER_PLACEHOLDER", build_number)

    return HTMLResponse(content=html_content)


@app.get("/deploy-status.json")
async def deploy_status():
    """ë°°í¬ ìƒíƒœ JSON (deploy.ymlì´ /var/www/html/ì— ìƒì„±í•œ íŒŒì¼ ì½ê¸°)."""
    import json as _json
    for path in ["/var/www/html/deploy-status.json", os.path.join(BASE_DIR, "deploy-status.json")]:
        if os.path.exists(path):
            try:
                with open(path, "r") as f:
                    return _json.load(f)
            except Exception:
                pass
    return {"build": get_build_number(), "time": datetime.now(KST).isoformat(), "status": "success", "commit": ""}


# â”€â”€ ì—ì´ì „íŠ¸ ëª©ë¡ â”€â”€
AGENTS = [
    {"agent_id": "chief_of_staff", "name_ko": "ë¹„ì„œì‹¤ì¥", "role": "manager", "division": "secretary", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "report_specialist", "name_ko": "ê¸°ë¡ ë³´ì¢Œê´€", "role": "specialist", "division": "secretary", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "schedule_specialist", "name_ko": "ì¼ì • ë³´ì¢Œê´€", "role": "specialist", "division": "secretary", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "relay_specialist", "name_ko": "ì†Œí†µ ë³´ì¢Œê´€", "role": "specialist", "division": "secretary", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "cto_manager", "name_ko": "ê¸°ìˆ ê°œë°œì²˜ì¥ (CTO)", "role": "manager", "division": "leet_master.tech", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "frontend_specialist", "name_ko": "í”„ë¡ íŠ¸ì—”ë“œ Specialist", "role": "specialist", "division": "leet_master.tech", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "backend_specialist", "name_ko": "ë°±ì—”ë“œ/API Specialist", "role": "specialist", "division": "leet_master.tech", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "infra_specialist", "name_ko": "DB/ì¸í”„ë¼ Specialist", "role": "specialist", "division": "leet_master.tech", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "ai_model_specialist", "name_ko": "AI ëª¨ë¸ Specialist", "role": "specialist", "division": "leet_master.tech", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "cso_manager", "name_ko": "ì‚¬ì—…ê¸°íšì²˜ì¥ (CSO)", "role": "manager", "division": "leet_master.strategy", "status": "idle", "model_name": "claude-opus-4-6"},
    {"agent_id": "market_research_specialist", "name_ko": "ì‹œì¥ì¡°ì‚¬ Specialist", "role": "specialist", "division": "leet_master.strategy", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "business_plan_specialist", "name_ko": "ì‚¬ì—…ê³„íšì„œ Specialist", "role": "specialist", "division": "leet_master.strategy", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "financial_model_specialist", "name_ko": "ì¬ë¬´ëª¨ë¸ë§ Specialist", "role": "specialist", "division": "leet_master.strategy", "status": "idle", "model_name": "gpt-5.2"},
    {"agent_id": "clo_manager", "name_ko": "ë²•ë¬´Â·IPì²˜ì¥ (CLO)", "role": "manager", "division": "leet_master.legal", "status": "idle", "model_name": "claude-opus-4-6"},
    {"agent_id": "copyright_specialist", "name_ko": "ì €ì‘ê¶Œ Specialist", "role": "specialist", "division": "leet_master.legal", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "patent_specialist", "name_ko": "íŠ¹í—ˆ/ì•½ê´€ Specialist", "role": "specialist", "division": "leet_master.legal", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "cmo_manager", "name_ko": "ë§ˆì¼€íŒ…Â·ê³ ê°ì²˜ì¥ (CMO)", "role": "manager", "division": "leet_master.marketing", "status": "idle", "model_name": "gemini-3-pro-preview"},
    {"agent_id": "survey_specialist", "name_ko": "ì„¤ë¬¸/ë¦¬ì„œì¹˜ Specialist", "role": "specialist", "division": "leet_master.marketing", "status": "idle", "model_name": "gemini-3-pro-preview"},
    {"agent_id": "content_specialist", "name_ko": "ì½˜í…ì¸  Specialist", "role": "specialist", "division": "leet_master.marketing", "status": "idle", "model_name": "gemini-3-pro-preview"},
    {"agent_id": "community_specialist", "name_ko": "ì»¤ë®¤ë‹ˆí‹° Specialist", "role": "specialist", "division": "leet_master.marketing", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "cio_manager", "name_ko": "íˆ¬ìë¶„ì„ì²˜ì¥ (CIO)", "role": "manager", "division": "finance.investment", "status": "idle", "model_name": "gpt-5.2-pro"},
    {"agent_id": "market_condition_specialist", "name_ko": "ì‹œí™©ë¶„ì„ Specialist", "role": "specialist", "division": "finance.investment", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "stock_analysis_specialist", "name_ko": "ì¢…ëª©ë¶„ì„ Specialist", "role": "specialist", "division": "finance.investment", "status": "idle", "model_name": "gpt-5.2"},
    {"agent_id": "technical_analysis_specialist", "name_ko": "ê¸°ìˆ ì ë¶„ì„ Specialist", "role": "specialist", "division": "finance.investment", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "risk_management_specialist", "name_ko": "ë¦¬ìŠ¤í¬ê´€ë¦¬ Specialist", "role": "specialist", "division": "finance.investment", "status": "idle", "model_name": "gpt-5.2"},
    {"agent_id": "cpo_manager", "name_ko": "ì¶œíŒÂ·ê¸°ë¡ì²˜ì¥ (CPO)", "role": "manager", "division": "publishing", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "chronicle_specialist", "name_ko": "íšŒì‚¬ì—°ëŒ€ê¸° Specialist", "role": "specialist", "division": "publishing", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "editor_specialist", "name_ko": "ì½˜í…ì¸ í¸ì§‘ Specialist", "role": "specialist", "division": "publishing", "status": "idle", "model_name": "claude-sonnet-4-6"},
    {"agent_id": "archive_specialist", "name_ko": "ì•„ì¹´ì´ë¸Œ Specialist", "role": "specialist", "division": "publishing", "status": "idle", "model_name": "claude-sonnet-4-6"},
]

# â”€â”€ WebSocket ê´€ë¦¬ â”€â”€
connected_clients: list[WebSocket] = []


@app.websocket("/ws")
async def websocket_endpoint(ws: WebSocket):
    await ws.accept()
    connected_clients.append(ws)
    try:
        # ì—°ê²° ì‹œ ì´ˆê¸° ìƒíƒœ ì „ì†¡ (activity_logê°€ ì•„ë‹Œ system_info ì´ë²¤íŠ¸ ì‚¬ìš© â€” í†µì‹ ë¡œê·¸ì— ì•ˆ ëœ¨ê²Œ)
        now = datetime.now(KST).strftime("%H:%M:%S")
        await ws.send_json({
            "event": "system_info",
            "data": {
                "message": "ì‹œìŠ¤í…œ ì—°ê²° ì™„ë£Œ. ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.",
                "time": now,
            }
        })
        # ì—°ê²° ì§í›„ ì˜¤ëŠ˜ ë¹„ìš©ì„ ì „ì†¡ â†’ ìš°ì¸¡ ìƒë‹¨ $0.0000 ë¬¸ì œ í•´ê²°
        try:
            today_cost = get_today_cost()
            await ws.send_json({
                "event": "cost_update",
                "data": {"total_cost": today_cost, "total_tokens": 0},
            })
        except Exception:
            pass
        while True:
            data = await ws.receive_text()
            msg = json.loads(data)
            # ë©”ì‹œì§€ë¥¼ ë°›ìœ¼ë©´ DBì— ì €ì¥ + ì‘ë‹µ
            if msg.get("type") == "command":
                cmd_text = (msg.get("content") or msg.get("text", "")).strip()
                use_batch = msg.get("batch", False)
                ws_target_agent_id = msg.get("target_agent_id", None)
                if cmd_text:
                    # DBì— ë©”ì‹œì§€ + ì‘ì—… ì €ì¥
                    task = create_task(cmd_text, source="websocket_batch" if use_batch else "websocket")
                    save_message(cmd_text, source="websocket",
                                 task_id=task["task_id"])
                    # ì‘ì—… ì ‘ìˆ˜ ì´ë²¤íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                    mode_label = "ğŸ“¦ ë°°ì¹˜" if use_batch else "âš¡ ì‹¤ì‹œê°„"
                    log_entry = save_activity_log(
                        "chief_of_staff",
                        f"[ì›¹] {mode_label} ëª…ë ¹ ì ‘ìˆ˜: {cmd_text[:50]}{'...' if len(cmd_text) > 50 else ''} (#{task['task_id']})",
                    )
                    for c in connected_clients[:]:
                        try:
                            await c.send_json({"event": "task_accepted", "data": task})
                            await c.send_json({"event": "activity_log", "data": log_entry})
                        except Exception:
                            pass

                    # ë°°ì¹˜ ëª¨ë“œ: ìœ„ì„ ì²´ì¸ ì „ì²´ë¥¼ Batch APIë¡œ ì‹¤í–‰
                    if use_batch and is_ai_ready():
                        update_task(task["task_id"], status="pending",
                                    result_summary="ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] ì‹œì‘ ì¤‘...")
                        # ì¦‰ì‹œ ì ‘ìˆ˜ ì‘ë‹µ â†’ ëŒ€í™”ì°½ ë°”ë¡œ í’€ë¦¼ (ë°°ì¹˜ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
                        await ws.send_json({
                            "event": "result",
                            "data": {
                                "content": (
                                    f"ğŸ“¦ **ë°°ì¹˜ ì ‘ìˆ˜ ì™„ë£Œ** (#{task['task_id']})\n\n"
                                    f"ë°°ì¹˜ ì²´ì¸ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n"
                                    f"ê° ë‹¨ê³„ ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ì§„í–‰ë˜ë©°, "
                                    f"ìµœì¢… ë³´ê³ ì„œê°€ ì™„ì„±ë˜ë©´ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n"
                                    f"ğŸ’¡ ëŒ€í™”ë¥¼ ê³„ì†í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                                ),
                                "sender_id": "chief_of_staff",
                                "handled_by": "ë¹„ì„œì‹¤ì¥",
                                "time_seconds": 0,
                                "cost": 0,
                            }
                        })

                        # ë°°ì¹˜ ì²´ì¸ì„ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰ (ëŒ€í™” ì°¨ë‹¨ ì—†ìŒ)
                        async def _run_batch_chain(text, task_id, ws_ref):
                            try:
                                chain_result = await _start_batch_chain(text, task_id)
                                if "error" in chain_result:
                                    for c in connected_clients[:]:
                                        try:
                                            await c.send_json({
                                                "event": "batch_chain_progress",
                                                "data": {"message": f"âŒ ë°°ì¹˜ ì‹œì‘ ì‹¤íŒ¨: {chain_result['error']}"}
                                            })
                                        except Exception:
                                            pass
                            except Exception as e:
                                _log(f"[CHAIN] ë°±ê·¸ë¼ìš´ë“œ ë°°ì¹˜ ì²´ì¸ ì˜¤ë¥˜: {e}")

                        asyncio.create_task(_run_batch_chain(cmd_text, task["task_id"], ws))
                        continue

                    # í† ë¡  ëª…ë ¹: ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (ì±„íŒ… ì°¨ë‹¨ ì—†ìŒ)
                    _stripped = cmd_text.strip()
                    is_debate_cmd = _stripped.startswith("/í† ë¡ ") or _stripped.startswith("/ì‹¬ì¸µí† ë¡ ")
                    if is_ai_ready() and is_debate_cmd:
                        debate_rounds = 3 if _stripped.startswith("/ì‹¬ì¸µí† ë¡ ") else 2
                        await ws.send_json({
                            "event": "result",
                            "data": {
                                "content": (
                                    f"ğŸ—£ï¸ **ì„ì› í† ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤** ({debate_rounds}ë¼ìš´ë“œ)\n\n"
                                    f"ì²˜ì¥ 6ëª…ì´ í† ë¡  ì¤‘ì…ë‹ˆë‹¤. 2~5ë¶„ ì†Œìš”ë©ë‹ˆë‹¤.\n"
                                    f"**í† ë¡ ì´ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì „ë‹¬í•´ë“œë¦½ë‹ˆë‹¤.**\n"
                                    f"ğŸ’¡ í† ë¡ ì´ ì§„í–‰ë˜ëŠ” ë™ì•ˆ ì±„íŒ…ì„ ê³„ì† ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                                ),
                                "sender_id": "chief_of_staff",
                                "handled_by": f"ì„ì› í† ë¡  ì‹œì‘ ({debate_rounds}ë¼ìš´ë“œ)",
                                "time_seconds": 0,
                                "cost": 0,
                            }
                        })

                        async def _run_debate_bg(text, task_id):
                            try:
                                update_task(task_id, status="running")
                                debate_result = await _process_ai_command(text, task_id)
                                for c in connected_clients[:]:
                                    try:
                                        if "error" in debate_result:
                                            await c.send_json({
                                                "event": "result",
                                                "data": {
                                                    "content": f"âŒ í† ë¡  ì‹¤íŒ¨: {debate_result['error']}",
                                                    "sender_id": "chief_of_staff",
                                                    "time_seconds": 0,
                                                    "cost": 0,
                                                }
                                            })
                                        else:
                                            await c.send_json({
                                                "event": "result",
                                                "data": {
                                                    "content": debate_result.get("content", ""),
                                                    "sender_id": debate_result.get("agent_id", "chief_of_staff"),
                                                    "handled_by": debate_result.get("handled_by", "ì„ì› í† ë¡ "),
                                                    "time_seconds": debate_result.get("time_seconds", 0),
                                                    "cost": debate_result.get("total_cost_usd", debate_result.get("cost_usd", 0)),
                                                }
                                            })
                                    except Exception:
                                        pass
                            except Exception as e:
                                _log(f"[DEBATE] ë°±ê·¸ë¼ìš´ë“œ í† ë¡  ì˜¤ë¥˜: {e}")

                        asyncio.create_task(_run_debate_bg(cmd_text, task["task_id"]))
                        continue

                    # ì‹¤ì‹œê°„ ëª¨ë“œ: AI ì¦‰ì‹œ ì²˜ë¦¬
                    if is_ai_ready():
                        update_task(task["task_id"], status="running")
                        result = await _process_ai_command(cmd_text, task["task_id"], target_agent_id=ws_target_agent_id)
                        if "error" in result:
                            await ws.send_json({
                                "event": "result",
                                "data": {"content": f"âŒ {result['error']}", "sender_id": result.get("agent_id", "chief_of_staff"), "handled_by": result.get("handled_by", "ë¹„ì„œì‹¤ì¥"), "time_seconds": 0, "cost": 0}
                            })
                        else:
                            await ws.send_json({
                                "event": "result",
                                "data": {
                                    "content": result.get("content", ""),
                                    "sender_id": result.get("agent_id", "chief_of_staff"),
                                    "handled_by": result.get("handled_by", "ë¹„ì„œì‹¤ì¥"),
                                    "delegation": result.get("delegation", ""),
                                    "time_seconds": result.get("time_seconds", 0),
                                    "cost": result.get("total_cost_usd", result.get("cost_usd", 0)),
                                    "model": result.get("model", ""),
                                    "routing_method": result.get("routing_method", ""),
                                }
                            })
                    else:
                        update_task(task["task_id"], status="completed",
                                    result_summary="AI ë¯¸ì—°ê²° â€” ì ‘ìˆ˜ë§Œ ì™„ë£Œ",
                                    success=1, time_seconds=0.1)
                        await ws.send_json({
                            "event": "result",
                            "data": {
                                "content": "AIê°€ ì•„ì§ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ANTHROPIC_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.",
                                "sender_id": "chief_of_staff",
                                "time_seconds": 0.1,
                                "cost": 0,
                            }
                        })
    except WebSocketDisconnect:
        connected_clients.remove(ws)
    except Exception:
        if ws in connected_clients:
            connected_clients.remove(ws)


# â”€â”€ API ì—”ë“œí¬ì¸íŠ¸ â”€â”€

@app.get("/api/auth/status")
async def auth_status(request: Request):
    if _check_auth(request):
        return {"bootstrap_mode": False, "role": "ceo", "authenticated": True}
    # ë¹„ë°€ë²ˆí˜¸ê°€ ê¸°ë³¸ê°’ì´ê³  ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ë¶€íŠ¸ìŠ¤íŠ¸ë© ëª¨ë“œ
    stored_pw = load_setting("admin_password")
    if (not stored_pw or stored_pw == "corthex2026") and not _sessions:
        return {"bootstrap_mode": True, "role": "ceo", "authenticated": True}
    return {"bootstrap_mode": False, "role": "viewer", "authenticated": False}


@app.get("/api/agents")
async def get_agents():
    """ì—ì´ì „íŠ¸ ëª©ë¡ ë°˜í™˜ (ì˜¤ë²„ë¼ì´ë“œëœ model_name, reasoning_effort í¬í•¨)."""
    result = []
    overrides = _load_data("agent_overrides", {})
    for a in AGENTS:
        agent = dict(a)
        aid = agent["agent_id"]
        detail = _AGENTS_DETAIL.get(aid, {})
        # ì˜¤ë²„ë¼ì´ë“œëœ ëª¨ë¸ëª… ë°˜ì˜
        if aid in overrides and "model_name" in overrides[aid]:
            agent["model_name"] = overrides[aid]["model_name"]
        elif detail.get("model_name"):
            agent["model_name"] = detail["model_name"]
        # ì¶”ë¡  ë ˆë²¨ ë°˜ì˜
        agent["reasoning_effort"] = ""
        if aid in overrides and "reasoning_effort" in overrides[aid]:
            agent["reasoning_effort"] = overrides[aid]["reasoning_effort"]
        elif detail.get("reasoning_effort"):
            agent["reasoning_effort"] = detail["reasoning_effort"]
        result.append(agent)
    return result


@app.get("/api/agents/{agent_id}")
async def get_agent(agent_id: str):
    for a in AGENTS:
        if a["agent_id"] == agent_id:
            # agents.yamlì—ì„œ ìƒì„¸ ì •ë³´ ë³´ì¶© (allowed_tools, capabilities ë“±)
            detail = _AGENTS_DETAIL.get(agent_id, {})
            # ì†Œìš¸ ë¡œë“œ ìš°ì„ ìˆœìœ„: 1) DB ì˜¤ë²„ë¼ì´ë“œ â†’ 2) souls/*.md íŒŒì¼ â†’ 3) agents.yaml
            soul_override = load_setting(f"soul_{agent_id}")
            if soul_override is not None:
                system_prompt = soul_override
            else:
                # souls/agents/{agent_id}.md íŒŒì¼ì—ì„œ ì†Œìš¸ ë¡œë“œ
                soul_md = Path(BASE_DIR).parent / "souls" / "agents" / f"{agent_id}.md"
                if soul_md.exists():
                    try:
                        system_prompt = soul_md.read_text(encoding="utf-8")
                    except Exception:
                        system_prompt = detail.get("system_prompt", "")
                else:
                    system_prompt = detail.get("system_prompt", "")
            return {
                **a,
                "system_prompt": system_prompt,
                "capabilities": detail.get("capabilities", []),
                "allowed_tools": detail.get("allowed_tools", []),
                "subordinate_ids": detail.get("subordinate_ids", []),
                "superior_id": detail.get("superior_id", ""),
                "temperature": detail.get("temperature", 0.3),
                "reasoning_effort": detail.get("reasoning_effort", ""),
            }
    return {"error": "not found"}


@app.get("/api/tools")
async def get_tools():
    return _TOOLS_LIST


@app.get("/api/dashboard")
async def get_dashboard():
    now = datetime.now(KST).isoformat()
    stats = get_dashboard_stats()
    today_cost = get_today_cost()
    daily_limit = float(load_setting("daily_budget_usd") or 7.0)

    # â”€â”€ í”„ë¡œë°”ì´ë”ë³„ ì˜¤ëŠ˜ AI í˜¸ì¶œ íšŸìˆ˜ â”€â”€
    provider_calls = {"anthropic": 0, "openai": 0, "google": 0}
    try:
        conn = __import__("db").get_connection()
        today_start = datetime.now(KST).strftime("%Y-%m-%dT00:00:00")
        rows = conn.execute(
            "SELECT provider, COUNT(*) FROM agent_calls "
            "WHERE created_at >= ? GROUP BY provider", (today_start,)
        ).fetchall()
        for row in rows:
            p = (row[0] or "").lower()
            if p in provider_calls:
                provider_calls[p] = row[1]
        conn.close()
    except Exception:
        pass
    total_ai_calls = sum(provider_calls.values())

    # â”€â”€ ë°°ì¹˜ í˜„í™© â”€â”€
    chains = load_setting("batch_chains") or []
    batch_active = len([c for c in chains if c.get("status") in ("running", "pending")])
    batch_done = len([c for c in chains if c.get("status") == "completed"])

    # â”€â”€ ë„êµ¬ ìˆ˜ â”€â”€
    tool_count = 0
    try:
        pool = _init_tool_pool()
        if pool:
            tool_count = len(pool.registry)
    except Exception:
        pass
    if tool_count == 0:
        tool_count = len(_load_tool_schemas().get("anthropic", []))

    # â”€â”€ API í‚¤ ìƒíƒœ â”€â”€
    api_keys = {
        "anthropic": get_available_providers().get("anthropic", False),
        "google": get_available_providers().get("google", False),
        "openai": get_available_providers().get("openai", False),
        "notion": bool(os.getenv("NOTION_API_KEY", "")),
        "telegram": bool(os.getenv("TELEGRAM_BOT_TOKEN", "")),
    }
    api_connected = sum(1 for v in api_keys.values() if v)
    api_total = len(api_keys)

    # â”€â”€ ì‹œìŠ¤í…œ ìƒíƒœ íŒë‹¨ (ìµœê·¼ 1ì‹œê°„ ì‹¤íŒ¨ 3ê±´ ì´ìƒ â†’ ì´ìƒ) â”€â”€
    recent_failed = 0
    try:
        one_hour_ago = (datetime.now(KST) - timedelta(hours=1)).isoformat()
        _conn_tmp = __import__("db").get_connection()
        recent_failed = _conn_tmp.execute(
            "SELECT COUNT(*) FROM tasks WHERE created_at >= ? AND status = 'failed'",
            (one_hour_ago,),
        ).fetchone()[0]
        _conn_tmp.close()
    except Exception:
        pass
    if recent_failed >= 3:
        sys_status = "error"
    elif stats["running_count"] > 0:
        sys_status = "busy"
    else:
        sys_status = "ok"

    return {
        "total_agents": len(AGENTS),
        "active_agents": stats["running_count"],
        "idle_agents": len(AGENTS) - stats["running_count"],
        "total_tasks_today": stats["today_task_count"],
        "today_completed": stats["today_completed"],
        "today_failed": stats["today_failed"],
        "total_cost": stats["total_cost"],
        "today_cost": today_cost,
        "total_tokens": stats["total_tokens"],
        "notion_connected": bool(_NOTION_API_KEY),
        "system_status": sys_status,
        "uptime": now,
        "agents": AGENTS,
        "recent_completed": stats["recent_completed"],
        "api_keys": api_keys,
        # â”€â”€ Cì•ˆ: ëŒ€ì‹œë³´ë“œ í™•ì¥ ë°ì´í„° â”€â”€
        "provider_calls": provider_calls,
        "total_ai_calls": total_ai_calls,
        "daily_limit": daily_limit,
        "batch_active": batch_active,
        "batch_done": batch_done,
        "tool_count": tool_count,
        "api_connected": api_connected,
        "api_total": api_total,
    }


@app.get("/api/budget")
async def get_budget():
    limit = float(load_setting("daily_budget_usd") or 7.0)
    today = get_today_cost()
    # ì›”ê°„ ë¹„ìš©: db.pyì˜ get_monthly_cost() ì‚¬ìš© (ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë¹„ìš©ìœ¼ë¡œ í´ë°±)
    try:
        from db import get_monthly_cost
        monthly = get_monthly_cost()
    except (ImportError, Exception):
        monthly = today
    monthly_limit = float(load_setting("monthly_budget_usd") or 300.0)
    return {
        "daily_limit": limit, "daily_used": today,
        "today_spent": today, "today_cost": today,
        "remaining": round(limit - today, 6),
        "exceeded": today >= limit,
        "monthly_limit": monthly_limit, "monthly_used": monthly,
    }


@app.get("/api/model-mode")
async def get_model_mode():
    """í˜„ì¬ ëª¨ë¸ ëª¨ë“œ ì¡°íšŒ (auto/manual)."""
    mode = load_setting("model_mode") or "auto"
    override = load_setting("model_override") or "claude-sonnet-4-6"
    return {"mode": mode, "override": override}


@app.put("/api/model-mode")
async def set_model_mode(request: Request):
    """ëª¨ë¸ ëª¨ë“œ ë³€ê²½."""
    body = await request.json()
    mode = body.get("mode", "auto")
    save_setting("model_mode", mode)
    if mode == "manual" and "override" in body:
        save_setting("model_override", body["override"])
    return {"success": True, "mode": mode}


@app.get("/api/quality")
async def get_quality():
    return {"average_score": 0, "total_evaluated": 0, "rules": []}


# â”€â”€ í”„ë¦¬ì…‹ ê´€ë¦¬ â”€â”€

@app.get("/api/presets")
async def get_presets():
    return _load_data("presets", [])


@app.post("/api/presets")
async def save_preset(request: Request):
    """í”„ë¦¬ì…‹ ì €ì¥."""
    body = await request.json()
    presets = _load_data("presets", [])
    name = body.get("name", "")
    # ê°™ì€ ì´ë¦„ì´ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
    presets = [p for p in presets if p.get("name") != name]
    presets.append(body)
    _save_data("presets", presets)
    return {"success": True}


@app.delete("/api/presets/{name}")
async def delete_preset(name: str):
    """í”„ë¦¬ì…‹ ì‚­ì œ."""
    presets = _load_data("presets", [])
    presets = [p for p in presets if p.get("name") != name]
    _save_data("presets", presets)
    return {"success": True}


# â”€â”€ ì„±ëŠ¥/ì‘ì—… (ì½ê¸° ì „ìš© â€” ì‹¤ì œ ë°ì´í„°ëŠ” í’€ ì„œë²„ì—ì„œ ìƒì„±) â”€â”€

@app.get("/api/performance")
async def get_performance():
    """ì—ì´ì „íŠ¸ë³„ ì‹¤ì œ ì„±ëŠ¥ í†µê³„ë¥¼ DBì—ì„œ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from db import get_connection
    conn = get_connection()
    try:
        # DBì—ì„œ ì—ì´ì „íŠ¸ë³„ ì‘ì—… í†µê³„ ì§‘ê³„
        rows = conn.execute("""
            SELECT agent_id,
                   COUNT(*) as total_tasks,
                   SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as completed,
                   SUM(CASE WHEN success = 0 THEN 1 ELSE 0 END) as failed,
                   COALESCE(SUM(cost_usd), 0) as total_cost,
                   COALESCE(AVG(time_seconds), 0) as avg_time,
                   COALESCE(SUM(tokens_used), 0) as total_tokens
            FROM tasks
            WHERE agent_id IS NOT NULL AND agent_id != ''
            GROUP BY agent_id
            ORDER BY total_tasks DESC
        """).fetchall()

        # ì—ì´ì „íŠ¸ ì´ë¦„/ì—­í•  ë§µ êµ¬ì¶•
        agent_map = {a["agent_id"]: a for a in AGENTS}

        agents_perf = []
        total_llm_calls = 0
        total_cost = 0.0

        for row in rows:
            aid = row["agent_id"]
            info = agent_map.get(aid, {})
            total = row["total_tasks"]
            completed = row["completed"] or 0
            rate = round(completed / total * 100, 1) if total > 0 else 0

            agents_perf.append({
                "agent_id": aid,
                "name_ko": info.get("name_ko", aid),
                "role": info.get("role", "unknown"),
                "division": info.get("division", ""),
                "llm_calls": total,
                "tasks_completed": completed,
                "tasks_failed": row["failed"] or 0,
                "success_rate": rate,
                "cost_usd": round(row["total_cost"], 6),
                "avg_execution_seconds": round(row["avg_time"], 2),
                "total_tokens": row["total_tokens"] or 0,
            })
            total_llm_calls += total
            total_cost += row["total_cost"]

        # DBì— ì‘ì—…ì´ ì•„ì§ ì—†ìœ¼ë©´ ì—ì´ì „íŠ¸ ëª©ë¡ë§Œ ë¹ˆ ê°’ìœ¼ë¡œ ë°˜í™˜
        if not agents_perf:
            for a in AGENTS:
                agents_perf.append({
                    "agent_id": a["agent_id"],
                    "name_ko": a["name_ko"],
                    "role": a["role"],
                    "division": a.get("division", ""),
                    "llm_calls": 0,
                    "tasks_completed": 0,
                    "tasks_failed": 0,
                    "success_rate": 0,
                    "cost_usd": 0,
                    "avg_execution_seconds": 0,
                    "total_tokens": 0,
                })

        # agent_calls í…Œì´ë¸” ë°ì´í„°ë¥¼ agents_perfì— ë³‘í•©
        # (ìŠ¤í˜ì…œë¦¬ìŠ¤íŠ¸ ë“± tasksì— ì—†ëŠ” ì—ì´ì „íŠ¸ë„ í¬í•¨ì‹œí‚¤ê¸° ìœ„í•¨)
        try:
            from db import get_agent_performance
            agent_perf = get_agent_performance()
        except Exception:
            agent_perf = []

        perf_map = {ap["agent_id"]: ap for ap in agents_perf}
        for ap in agent_perf:
            aid = ap["agent_id"]
            if aid in perf_map:
                # tasksì— ì´ë¯¸ ìˆëŠ” ì—ì´ì „íŠ¸ â†’ agent_calls ìˆ˜ì¹˜ í•©ì‚°
                existing = perf_map[aid]
                existing["llm_calls"] += ap.get("call_count", 0)
                existing["cost_usd"] = round(
                    existing["cost_usd"] + ap.get("total_cost", 0), 6
                )
                existing["total_tokens"] += (
                    ap.get("total_input_tokens", 0) + ap.get("total_output_tokens", 0)
                )
                total_llm_calls += ap.get("call_count", 0)
                total_cost += ap.get("total_cost", 0)
            else:
                # tasksì— ì—†ëŠ” ì—ì´ì „íŠ¸ (ìŠ¤í˜ì…œë¦¬ìŠ¤íŠ¸ ë“±) â†’ ìƒˆë¡œ ì¶”ê°€
                info = agent_map.get(aid, {})
                call_count = ap.get("call_count", 0)
                cost = ap.get("total_cost", 0)
                new_entry = {
                    "agent_id": aid,
                    "name_ko": info.get("name_ko", aid),
                    "role": info.get("role", "unknown"),
                    "division": info.get("division", ""),
                    "llm_calls": call_count,
                    "tasks_completed": 0,
                    "tasks_failed": 0,
                    "success_rate": ap.get("success_rate", 0),
                    "cost_usd": round(cost, 6),
                    "avg_execution_seconds": ap.get("avg_time", 0),
                    "total_tokens": (
                        ap.get("total_input_tokens", 0)
                        + ap.get("total_output_tokens", 0)
                    ),
                }
                agents_perf.append(new_entry)
                perf_map[aid] = new_entry
                total_llm_calls += call_count
                total_cost += cost

        return {
            "agents": agents_perf,
            "total_llm_calls": total_llm_calls,
            "total_cost_usd": round(total_cost, 6),
        }
    except Exception as e:
        logger.error("ì„±ëŠ¥ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: %s", e)
        # ì—ëŸ¬ ì‹œì—ë„ ì—ì´ì „íŠ¸ ëª©ë¡ì€ ë³´ì—¬ì£¼ê¸°
        return {
            "agents": [{"agent_id": a["agent_id"], "name_ko": a["name_ko"],
                        "role": a["role"], "llm_calls": 0, "tasks_completed": 0,
                        "success_rate": 0, "cost_usd": 0, "avg_execution_seconds": 0}
                       for a in AGENTS],
            "total_llm_calls": 0,
            "total_cost_usd": 0,
            "agent_calls": [],
        }
    finally:
        conn.close()


@app.get("/api/tasks")
async def get_tasks(keyword: str = "", status: str = "", bookmarked: bool = False,
                    limit: int = 50, archived: bool = False, tag: str = ""):
    tasks = list_tasks(keyword=keyword, status=status,
                       bookmarked=bookmarked, limit=limit,
                       archived=archived, tag=tag)
    return tasks


@app.get("/api/tasks/{task_id}")
async def get_task(task_id: str):
    task = db_get_task(task_id)
    if not task:
        return {"error": "not found"}
    return task


@app.post("/api/tasks/{task_id}/bookmark")
async def bookmark_task(task_id: str):
    new_state = db_toggle_bookmark(task_id)
    return {"bookmarked": new_state}


@app.delete("/api/tasks/{task_id}")
async def delete_task_api(task_id: str):
    """ì‘ì—… ì‚­ì œ."""
    db_delete_task(task_id)
    return {"success": True}


@app.put("/api/tasks/{task_id}/tags")
async def update_task_tags(task_id: str, request: Request):
    """ì‘ì—… íƒœê·¸ ì—…ë°ì´íŠ¸."""
    body = await request.json()
    tags = body.get("tags", [])
    set_task_tags(task_id, tags)
    return {"success": True, "tags": tags}


@app.put("/api/tasks/{task_id}/read")
async def mark_task_read_api(task_id: str, request: Request):
    """ì‘ì—… ì½ìŒ/ì•ˆì½ìŒ í‘œì‹œ."""
    body = await request.json()
    is_read = body.get("is_read", True)
    mark_task_read(task_id, is_read)
    return {"success": True, "is_read": is_read}


@app.post("/api/tasks/bulk")
async def bulk_task_action(request: Request):
    """ì‘ì—… ì¼ê´„ ì²˜ë¦¬ (ì‚­ì œ/ì•„ì¹´ì´ë¸Œ/ì½ìŒ/ë¶ë§ˆí¬/íƒœê·¸ ë“±)."""
    body = await request.json()
    action = body.get("action", "")
    task_ids = body.get("task_ids", [])
    if not task_ids:
        return {"success": False, "error": "task_idsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    if action == "delete":
        count = bulk_delete_tasks(task_ids)
        return {"success": True, "action": "delete", "affected": count}
    elif action == "archive":
        count = bulk_archive_tasks(task_ids, archive=True)
        return {"success": True, "action": "archive", "affected": count}
    elif action == "unarchive":
        count = bulk_archive_tasks(task_ids, archive=False)
        return {"success": True, "action": "unarchive", "affected": count}
    elif action == "read":
        count = bulk_mark_read(task_ids, is_read=True)
        return {"success": True, "action": "read", "affected": count}
    elif action == "unread":
        count = bulk_mark_read(task_ids, is_read=False)
        return {"success": True, "action": "unread", "affected": count}
    elif action == "bookmark":
        for tid in task_ids:
            db_toggle_bookmark(tid)
        return {"success": True, "action": "bookmark", "affected": len(task_ids)}
    elif action == "tag":
        tag = body.get("tag", "")
        if not tag:
            return {"success": False, "error": "íƒœê·¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”"}
        for tid in task_ids:
            task = db_get_task(tid)
            if task:
                existing_tags = task.get("tags", [])
                if tag not in existing_tags:
                    existing_tags.append(tag)
                    set_task_tags(tid, existing_tags)
        return {"success": True, "action": "tag", "affected": len(task_ids)}
    else:
        return {"success": False, "error": f"ì•Œ ìˆ˜ ì—†ëŠ” ì•¡ì…˜: {action}"}


# â”€â”€ ë°°ì¹˜ ëª…ë ¹ (ì—¬ëŸ¬ ëª…ë ¹ í•œë²ˆì— ì‹¤í–‰) â”€â”€

_batch_queue: list[dict] = []  # ë°°ì¹˜ ëŒ€ê¸°ì—´ (ë¡œì»¬ ìˆœì°¨/ë³‘ë ¬ ì‹¤í–‰ìš©)
_batch_running = False
_batch_api_queue: list[dict] = []  # Batch API ëŒ€ê¸°ì—´ (í”„ë¡œë°”ì´ë” ë°°ì¹˜ ì œì¶œìš©)


@app.get("/api/batch/queue")
async def get_batch_queue():
    """ë°°ì¹˜ ëŒ€ê¸°ì—´ ì¡°íšŒ."""
    return {"queue": _batch_queue, "running": _batch_running}


@app.post("/api/batch")
async def submit_batch(request: Request):
    """ë°°ì¹˜ ëª…ë ¹ ì œì¶œ â€” ì—¬ëŸ¬ ëª…ë ¹ì„ í•œë²ˆì— ì ‘ìˆ˜í•©ë‹ˆë‹¤."""
    body = await request.json()
    commands = body.get("commands", [])
    mode = body.get("mode", "sequential")  # sequential ë˜ëŠ” parallel

    if not commands:
        return {"success": False, "error": "ëª…ë ¹ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    batch_id = f"batch_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}"
    batch_items = []
    for i, cmd in enumerate(commands):
        item = {
            "batch_id": batch_id,
            "index": i,
            "command": cmd if isinstance(cmd, str) else cmd.get("command", ""),
            "status": "pending",
            "result": None,
            "task_id": None,
        }
        batch_items.append(item)
        _batch_queue.append(item)

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë°°ì¹˜ ì‹¤í–‰
    asyncio.create_task(_run_batch(batch_id, batch_items, mode))

    return {"success": True, "batch_id": batch_id, "count": len(commands), "mode": mode}


async def _run_batch(batch_id: str, items: list, mode: str):
    """ë°°ì¹˜ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    global _batch_running
    _batch_running = True

    try:
        if mode == "parallel":
            # ë³‘ë ¬ ì‹¤í–‰
            tasks = []
            for item in items:
                tasks.append(_run_batch_item(item))
            await asyncio.gather(*tasks)
        else:
            # ìˆœì°¨ ì‹¤í–‰
            for item in items:
                await _run_batch_item(item)
    finally:
        _batch_running = False
        # ì™„ë£Œëœ ë°°ì¹˜ í•­ëª©ì€ 10ë¶„ í›„ ì •ë¦¬
        await asyncio.sleep(600)
        for item in items:
            if item in _batch_queue:
                _batch_queue.remove(item)


async def _run_batch_item(item: dict):
    """ë°°ì¹˜ ë‚´ ê°œë³„ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    item["status"] = "running"
    try:
        task = create_task(item["command"], source="batch")
        item["task_id"] = task["task_id"]

        # AI ì²˜ë¦¬
        result = await _process_ai_command(item["command"], task["task_id"])

        item["status"] = "completed"
        item["result"] = result.get("content", "")[:200] if isinstance(result, dict) else str(result)[:200]
    except Exception as e:
        item["status"] = "failed"
        item["result"] = str(e)[:200]


@app.delete("/api/batch/queue")
async def clear_batch_queue():
    """ë°°ì¹˜ ëŒ€ê¸°ì—´ì„ ë¹„ì›ë‹ˆë‹¤."""
    global _batch_queue
    _batch_queue = [item for item in _batch_queue if item.get("status") == "running"]
    return {"success": True}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â”€â”€ AI Batch API ì‹œìŠ¤í…œ (PENDING ì¶”ì  + ìë™ ê²°ê³¼ ìˆ˜ì§‘) â”€â”€
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# CEOê°€ ì—¬ëŸ¬ ëª…ë ¹ì„ AI Batch APIë¡œ ë³´ë‚´ë©´:
#   1) ê° ëª…ë ¹ì´ PENDING ìƒíƒœë¡œ DBì— ì €ì¥ë¨
#   2) í”„ë¡œë°”ì´ë”ì˜ Batch APIì— í•œêº¼ë²ˆì— ì œì¶œ (ì‹¤ì‹œê°„ë³´ë‹¤ ~50% ì €ë ´)
#   3) ë°±ê·¸ë¼ìš´ë“œ í´ëŸ¬ê°€ 60ì´ˆë§ˆë‹¤ ìƒíƒœë¥¼ í™•ì¸
#   4) ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„í•˜ì—¬ ë³´ê³ ì„œ ì‘ì„±
#   5) WebSocketìœ¼ë¡œ CEOì—ê²Œ ì‹¤ì‹œê°„ ì•Œë¦¼

_batch_poller_task = None  # ë°°ì¹˜ í´ëŸ¬ ë£¨í”„ íƒœìŠ¤í¬


@app.post("/api/batch/ai")
async def submit_ai_batch(request: Request):
    """AI Batch APIë¡œ ì—¬ëŸ¬ ìš”ì²­ì„ í•œêº¼ë²ˆì— ì œì¶œí•©ë‹ˆë‹¤.

    ìš”ì²­ body:
    {
        "requests": [
            {"message": "ì‚¼ì„±ì „ì ë¶„ì„í•´ì¤˜", "system_prompt": "...", "agent_id": "cio_manager"},
            {"message": "íŠ¹í—ˆ ê²€ìƒ‰í•´ì¤˜", "system_prompt": "...", "agent_id": "clo_manager"},
        ],
        "model": "claude-sonnet-4-6",  // ê¸°ë³¸ ëª¨ë¸ (ì„ íƒ)
        "auto_delegate": true  // ê²°ê³¼ë¥¼ ì—ì´ì „íŠ¸ì—ê²Œ ìë™ ìœ„ì„í• ì§€ (ê¸°ë³¸: true)
    }

    ì‘ë‹µ: {"batch_id": "...", "count": N, "status": "submitted"}
    """
    body = await request.json()
    requests_list = body.get("requests", [])
    model = body.get("model")
    auto_delegate = body.get("auto_delegate", True)

    if not requests_list:
        return {"success": False, "error": "ìš”ì²­ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    # ê° ìš”ì²­ì— custom_id ìë™ ë¶€ì—¬
    now_str = datetime.now(KST).strftime('%Y%m%d_%H%M%S')
    for i, req in enumerate(requests_list):
        if "custom_id" not in req:
            req["custom_id"] = f"batch_{now_str}_{i}"
        # ì—ì´ì „íŠ¸ ì†Œìš¸(ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)ì„ ìë™ìœ¼ë¡œ ë¡œë“œ
        agent_id = req.get("agent_id")
        if agent_id and not req.get("system_prompt"):
            req["system_prompt"] = _load_agent_prompt(agent_id)

    # Batch API ì œì¶œ
    result = await batch_submit(requests_list, model=model)

    if "error" in result:
        return {"success": False, "error": result["error"]}

    batch_id = result["batch_id"]
    provider = result["provider"]

    # DBì— PENDING ìƒíƒœë¡œ ì €ì¥
    pending_data = {
        "batch_id": batch_id,
        "provider": provider,
        "model": model,
        "status": "pending",
        "auto_delegate": auto_delegate,
        "submitted_at": datetime.now(KST).isoformat(),
        "requests": [
            {
                "custom_id": r.get("custom_id"),
                "message": r.get("message", "")[:200],
                "agent_id": r.get("agent_id", ""),
            }
            for r in requests_list
        ],
        "results": [],
    }

    # ê¸°ì¡´ pending_batches ëª©ë¡ì— ì¶”ê°€
    pending_batches = load_setting("pending_batches") or []
    pending_batches.append(pending_data)
    save_setting("pending_batches", pending_batches)

    # ê° ìš”ì²­ì„ taskë¡œë„ ìƒì„± (PENDING ìƒíƒœ)
    for req in requests_list:
        task = create_task(
            req.get("message", "ë°°ì¹˜ ìš”ì²­"),
            source="batch_api",
            agent_id=req.get("agent_id", "chief_of_staff"),
        )
        update_task(task["task_id"], status="pending",
                    result_summary=f"[PENDING] ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ (batch_id: {batch_id[:20]}...)")

    # WebSocket ì•Œë¦¼
    for c in connected_clients[:]:
        try:
            await c.send_json({
                "event": "batch_submitted",
                "data": {
                    "batch_id": batch_id,
                    "provider": provider,
                    "count": len(requests_list),
                },
            })
        except Exception:
            pass

    _log(f"[BATCH] AI ë°°ì¹˜ ì œì¶œ ì™„ë£Œ: {batch_id} ({len(requests_list)}ê°œ ìš”ì²­, {provider})")

    # í´ëŸ¬ê°€ ì•ˆ ëŒê³  ìˆìœ¼ë©´ ì‹œì‘
    _ensure_batch_poller()

    return {
        "success": True,
        "batch_id": batch_id,
        "provider": provider,
        "count": len(requests_list),
        "status": "submitted",
    }


@app.get("/api/batch/pending")
async def get_pending_batches():
    """PENDING ìƒíƒœì¸ ë°°ì¹˜ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    pending_batches = load_setting("pending_batches") or []
    # pendingê³¼ processingë§Œ ë°˜í™˜
    active = [b for b in pending_batches if b.get("status") in ("pending", "processing")]
    return {"pending": active, "total": len(pending_batches)}


@app.post("/api/batch/check/{batch_id}")
async def check_batch_status(batch_id: str):
    """íŠ¹ì • ë°°ì¹˜ì˜ ìƒíƒœë¥¼ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤."""
    pending_batches = load_setting("pending_batches") or []
    batch_info = next((b for b in pending_batches if b["batch_id"] == batch_id), None)

    if not batch_info:
        return {"error": f"ë°°ì¹˜ '{batch_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    provider = batch_info["provider"]
    status_result = await batch_check(batch_id, provider)

    if "error" in status_result:
        return status_result

    # ìƒíƒœ ì—…ë°ì´íŠ¸
    batch_info["status"] = status_result["status"]
    batch_info["progress"] = status_result.get("progress", {})
    save_setting("pending_batches", pending_batches)

    # ì™„ë£Œë˜ì—ˆìœ¼ë©´ ê²°ê³¼ ìˆ˜ì§‘
    if status_result["status"] == "completed":
        await _collect_batch_results(batch_info, pending_batches)

    return status_result


@app.post("/api/batch/resume")
async def resume_all_pending():
    """ëª¨ë“  PENDING ë°°ì¹˜ì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê³ , ì™„ë£Œëœ ê²ƒì€ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    pending_batches = load_setting("pending_batches") or []
    active = [b for b in pending_batches if b.get("status") in ("pending", "processing")]

    if not active:
        return {"message": "ì²˜ë¦¬ ì¤‘ì¸ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤", "checked": 0}

    checked = 0
    collected = 0
    for batch_info in active:
        batch_id = batch_info["batch_id"]
        provider = batch_info["provider"]

        status_result = await batch_check(batch_id, provider)
        if "error" not in status_result:
            batch_info["status"] = status_result["status"]
            batch_info["progress"] = status_result.get("progress", {})
            checked += 1

            if status_result["status"] == "completed":
                await _collect_batch_results(batch_info, pending_batches)
                collected += 1

    save_setting("pending_batches", pending_batches)
    return {"checked": checked, "collected": collected, "remaining": len(active) - collected}


@app.get("/api/batch/history")
async def get_batch_history():
    """ëª¨ë“  ë°°ì¹˜ì˜ íˆìŠ¤í† ë¦¬ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (ì™„ë£Œëœ ê²ƒ í¬í•¨)."""
    all_batches = load_setting("pending_batches") or []
    return {"batches": all_batches[-50:], "total": len(all_batches)}  # ìµœê·¼ 50ê°œë§Œ


async def _collect_batch_results(batch_info: dict, all_batches: list):
    """ì™„ë£Œëœ ë°°ì¹˜ì˜ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ê³ , í•„ìš”ì‹œ ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„í•©ë‹ˆë‹¤."""
    batch_id = batch_info["batch_id"]
    provider = batch_info["provider"]

    _log(f"[BATCH] ê²°ê³¼ ìˆ˜ì§‘ ì‹œì‘: {batch_id}")

    # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    result = await batch_retrieve(batch_id, provider)
    if "error" in result:
        _log(f"[BATCH] ê²°ê³¼ ìˆ˜ì§‘ ì‹¤íŒ¨: {result['error']}")
        return

    results = result.get("results", [])
    batch_info["results"] = results
    batch_info["status"] = "completed"
    batch_info["completed_at"] = datetime.now(KST).isoformat()

    # ì´ ë¹„ìš© ê³„ì‚°
    total_cost = sum(r.get("cost_usd", 0) for r in results if r.get("cost_usd"))
    batch_info["total_cost_usd"] = round(total_cost, 6)

    save_setting("pending_batches", all_batches)

    # ì—ì´ì „íŠ¸ì—ê²Œ ìë™ ìœ„ì„ (auto_delegate=trueì¸ ê²½ìš°)
    if batch_info.get("auto_delegate"):
        req_map = {r["custom_id"]: r for r in batch_info.get("requests", [])}
        for res in results:
            if res.get("error"):
                continue
            custom_id = res.get("custom_id", "")
            req_info = req_map.get(custom_id, {})
            agent_id = req_info.get("agent_id")
            message = req_info.get("message", "")

            if agent_id and res.get("content"):
                # ê²°ê³¼ë¥¼ í™œë™ ë¡œê·¸ì— ê¸°ë¡
                agent_name = _AGENT_NAMES.get(agent_id, agent_id)
                log_entry = save_activity_log(
                    agent_id,
                    f"[ë°°ì¹˜ ì™„ë£Œ] {agent_name}: {message[:40]}... â†’ {res['content'][:60]}..."
                )
                for c in connected_clients[:]:
                    try:
                        await c.send_json({"event": "activity_log", "data": log_entry})
                    except Exception:
                        pass

                # ì•„ì¹´ì´ë¸Œì— ì €ì¥
                division = _AGENT_DIVISION.get(agent_id, "secretary")
                now_str = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
                archive_content = f"# [ë°°ì¹˜] [{agent_name}] {message[:60]}\n\n{res['content']}"
                save_archive(
                    division=division,
                    filename=f"batch_{agent_id}_{now_str}.md",
                    content=archive_content,
                    agent_id=agent_id,
                )

    # WebSocketìœ¼ë¡œ ì™„ë£Œ ì•Œë¦¼
    for c in connected_clients[:]:
        try:
            await c.send_json({
                "event": "batch_completed",
                "data": {
                    "batch_id": batch_id,
                    "provider": provider,
                    "count": len(results),
                    "total_cost_usd": total_cost,
                    "succeeded": sum(1 for r in results if not r.get("error")),
                    "failed": sum(1 for r in results if r.get("error")),
                },
            })
        except Exception:
            pass

    _log(f"[BATCH] ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ: {batch_id} ({len(results)}ê°œ, ${total_cost:.4f})")


async def _flush_batch_api_queue():
    """ë°°ì¹˜ ëŒ€ê¸°ì—´ì— ìŒ“ì¸ ìš”ì²­ì„ Batch APIì— ì œì¶œí•©ë‹ˆë‹¤."""
    global _batch_api_queue
    if not _batch_api_queue:
        return {"message": "ëŒ€ê¸°ì—´ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    queue_copy = list(_batch_api_queue)
    _batch_api_queue = []

    _log(f"[BATCH] ëŒ€ê¸°ì—´ {len(queue_copy)}ê±´ â†’ Batch API ì œì¶œ ì¤‘...")

    # ê° ìš”ì²­ì— ì—ì´ì „íŠ¸ ë¼ìš°íŒ… (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê²°ì •)
    for req in queue_copy:
        if not req.get("system_prompt"):
            routing = await _route_task(req.get("message", ""))
            agent_id = routing.get("agent_id", "chief_of_staff")
            req["agent_id"] = agent_id
            req["system_prompt"] = _load_agent_prompt(agent_id)

    # Batch API ì œì¶œ â€” í”„ë¡œë°”ì´ë”ë³„ë¡œ ìë™ ê·¸ë£¹í™” (Claude/GPT/Gemini ìš”ì²­ì´ ì„ì—¬ë„ ê°ê° ì˜¬ë°”ë¥¸ APIë¡œ ì „ì†¡)
    batch_results = await batch_submit_grouped(queue_copy)

    # ì „ë¶€ ì‹¤íŒ¨í•œ ê²½ìš° ëŒ€ê¸°ì—´ì— ë³µêµ¬
    all_failed = all("error" in br for br in batch_results)
    if all_failed:
        first_error = batch_results[0].get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜") if batch_results else "ê²°ê³¼ ì—†ìŒ"
        _log(f"[BATCH] ì œì¶œ ì‹¤íŒ¨ (ì „ì²´): {first_error}")
        _batch_api_queue.extend(queue_copy)
        return {"error": first_error}

    # ì„±ê³µí•œ ë°°ì¹˜ë“¤ì„ DBì— PENDING ìƒíƒœë¡œ ì €ì¥
    pending_batches = load_setting("pending_batches") or []
    submitted_ids = []
    for result in batch_results:
        if "error" in result:
            _log(f"[BATCH] í”„ë¡œë°”ì´ë” {result.get('provider','?')} ì œì¶œ ì‹¤íŒ¨: {result['error']}")
            continue

        batch_id = result["batch_id"]
        provider = result["provider"]
        custom_ids_in_batch = result.get("custom_ids", [])

        # ì´ ë°°ì¹˜ì— í¬í•¨ëœ ìš”ì²­ë§Œ í•„í„°ë§
        reqs_in_batch = [r for r in queue_copy if r.get("custom_id", r.get("task_id", "")) in custom_ids_in_batch]

        pending_data = {
            "batch_id": batch_id,
            "provider": provider,
            "status": "pending",
            "auto_delegate": True,
            "submitted_at": datetime.now(KST).isoformat(),
            "requests": [
                {
                    "custom_id": r.get("custom_id", r.get("task_id", "")),
                    "message": r.get("message", "")[:200],
                    "agent_id": r.get("agent_id", ""),
                    "task_id": r.get("task_id", ""),
                }
                for r in reqs_in_batch
            ],
            "results": [],
        }
        pending_batches.append(pending_data)
        submitted_ids.append(batch_id)

        # ê° taskë¥¼ PENDING ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
        for req in reqs_in_batch:
            task_id = req.get("task_id")
            if task_id:
                update_task(task_id, status="pending",
                            result_summary=f"[PENDING] Batch API ì œì¶œë¨ ({batch_id[:20]}...)")

        # WebSocket ì•Œë¦¼
        for c in connected_clients[:]:
            try:
                await c.send_json({
                    "event": "batch_submitted",
                    "data": {"batch_id": batch_id, "provider": provider, "count": len(reqs_in_batch)},
                })
            except Exception:
                pass

        _log(f"[BATCH] Batch API ì œì¶œ ì™„ë£Œ: {batch_id} ({len(reqs_in_batch)}ê±´, {provider})")

    save_setting("pending_batches", pending_batches)
    _ensure_batch_poller()

    # ì²« ë²ˆì§¸ ì„±ê³µ ê²°ê³¼ë¥¼ ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
    first_success = next((r for r in batch_results if "error" not in r), batch_results[0] if batch_results else {})
    return first_success


@app.post("/api/batch/flush")
async def flush_batch_queue():
    """ë°°ì¹˜ ëŒ€ê¸°ì—´ì— ìŒ“ì¸ ìš”ì²­ì„ ì¦‰ì‹œ Batch APIì— ì œì¶œí•©ë‹ˆë‹¤."""
    if not _batch_api_queue:
        return {"success": False, "message": "ëŒ€ê¸°ì—´ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}
    result = await _flush_batch_api_queue()
    return {"success": "error" not in result, **result}


def _ensure_batch_poller():
    """ë°°ì¹˜ í´ëŸ¬ê°€ ëŒê³  ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì•ˆ ëŒë©´ ì‹œì‘í•©ë‹ˆë‹¤."""
    global _batch_poller_task
    if _batch_poller_task is None or _batch_poller_task.done():
        _batch_poller_task = asyncio.create_task(_batch_poller_loop())
        _log("[BATCH] ë°°ì¹˜ í´ëŸ¬ ì‹œì‘ë¨ (60ì´ˆ ê°„ê²©)")


async def _batch_poller_loop():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ 60ì´ˆë§ˆë‹¤ PENDING ë°°ì¹˜ + ë°°ì¹˜ ì²´ì¸ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    while True:
        try:
            await asyncio.sleep(60)

            has_work = False

            # â”€â”€ (A) ê¸°ì¡´ ë‹¨ë… ë°°ì¹˜ í™•ì¸ â”€â”€
            pending_batches = load_setting("pending_batches") or []
            active = [b for b in pending_batches if b.get("status") in ("pending", "processing")]

            if active:
                has_work = True
                for batch_info in active:
                    batch_id = batch_info["batch_id"]
                    provider = batch_info["provider"]

                    try:
                        status_result = await batch_check(batch_id, provider)
                        if "error" not in status_result:
                            batch_info["status"] = status_result["status"]
                            batch_info["progress"] = status_result.get("progress", {})

                            if status_result["status"] == "completed":
                                await _collect_batch_results(batch_info, pending_batches)
                            elif status_result["status"] in ("failed", "expired"):
                                batch_info["status"] = status_result["status"]
                                _log(f"[BATCH] ë°°ì¹˜ ì‹¤íŒ¨/ë§Œë£Œ: {batch_id}")
                    except Exception as e:
                        _log(f"[BATCH] ë°°ì¹˜ í™•ì¸ ì‹¤íŒ¨ ({batch_id}): {e}")

                save_setting("pending_batches", pending_batches)

            # â”€â”€ (B) ë°°ì¹˜ ì²´ì¸ í™•ì¸ + ìë™ ì§„í–‰ â”€â”€
            chains = load_setting("batch_chains") or []
            active_chains = [c for c in chains if c.get("status") in ("running", "pending")]

            if active_chains:
                has_work = True
                for chain in active_chains:
                    try:
                        await _advance_batch_chain(chain["chain_id"])
                    except Exception as e:
                        _log(f"[CHAIN] ì²´ì¸ ì§„í–‰ ì˜¤ë¥˜ ({chain['chain_id']}): {e}")

            if not has_work:
                _log("[BATCH] ì²˜ë¦¬ ì¤‘ì¸ ë°°ì¹˜/ì²´ì¸ ì—†ìŒ â€” í´ëŸ¬ ì¢…ë£Œ")
                break

        except asyncio.CancelledError:
            break
        except Exception as e:
            _log(f"[BATCH] í´ëŸ¬ ì˜¤ë¥˜: {e}")
            await asyncio.sleep(30)  # ì—ëŸ¬ ì‹œ 30ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â”€â”€ ë°°ì¹˜ ì²´ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° â”€â”€
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# CEOê°€ ğŸ“¦ ë°°ì¹˜ ëª¨ë“œë¡œ ëª…ë ¹ì„ ë³´ë‚´ë©´ ìœ„ì„ ì²´ì¸ ì „ì²´ê°€ Batch APIë¡œ ëŒì•„ê°:
#
#   [1ë‹¨ê³„] ë¹„ì„œì‹¤ì¥ ë¶„ë¥˜ â†’ Batch ì œì¶œ â†’ PENDING â†’ ê²°ê³¼: "CIOì—ê²Œ ìœ„ì„"
#   [2ë‹¨ê³„] ì „ë¬¸ê°€ Nëª… â†’ í”„ë¡œë°”ì´ë”ë³„ ë¬¶ì–´ì„œ Batch ì œì¶œ â†’ PENDING â†’ ì „ë¶€ ëŒ€ê¸°
#   [3ë‹¨ê³„] ì²˜ì¥ ì¢…í•©ë³´ê³ ì„œ â†’ Batch ì œì¶œ â†’ PENDING â†’ ê²°ê³¼: ì¢…í•© ë³´ê³ ì„œ
#   [4ë‹¨ê³„] CEOì—ê²Œ ì „ë‹¬ + ì•„ì¹´ì´ë¸Œ ì €ì¥
#
# ë§¤ ë‹¨ê³„ë§ˆë‹¤ Batch API ì‚¬ìš© â†’ ë¹„ìš© ~50% ì ˆê°
# í”„ë¡œë°”ì´ë”ë³„ ìë™ ê·¸ë£¹í™” (Claude + GPT + Gemini ì—ì´ì „íŠ¸ í˜¼í•© ê°€ëŠ¥)

# ë¶„ë¥˜ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë°°ì¹˜ ì²´ì¸ì—ì„œ ì‚¬ìš©)
_BATCH_CLASSIFY_PROMPT = """ë‹¹ì‹ ì€ ì—…ë¬´ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
CEOì˜ ëª…ë ¹ì„ ì½ê³  ì–´ëŠ ë¶€ì„œê°€ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

## ë¶€ì„œ ëª©ë¡
- cto_manager: ê¸°ìˆ ê°œë°œ (ì½”ë“œ, ì›¹ì‚¬ì´íŠ¸, API, ì„œë²„, ë°°í¬, í”„ë¡ íŠ¸ì—”ë“œ, ë°±ì—”ë“œ, ë²„ê·¸, UI, ë””ìì¸, ë°ì´í„°ë² ì´ìŠ¤)
- cso_manager: ì‚¬ì—…ê¸°íš (ì‹œì¥ì¡°ì‚¬, ì‚¬ì—…ê³„íš, ë§¤ì¶œ ì˜ˆì¸¡, ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸, ìˆ˜ìµ, ê²½ìŸì‚¬)
- clo_manager: ë²•ë¬´IP (ì €ì‘ê¶Œ, íŠ¹í—ˆ, ìƒí‘œ, ì•½ê´€, ê³„ì•½, ë²•ë¥ , ì†Œì†¡)
- cmo_manager: ë§ˆì¼€íŒ…ê³ ê° (ë§ˆì¼€íŒ…, ê´‘ê³ , SNS, ì¸ìŠ¤íƒ€ê·¸ë¨, ìœ íŠœë¸Œ, ì½˜í…ì¸ , ë¸Œëœë”©, ì„¤ë¬¸)
- cio_manager: íˆ¬ìë¶„ì„ (ì£¼ì‹, íˆ¬ì, ì¢…ëª©, ì‹œí™©, í¬íŠ¸í´ë¦¬ì˜¤, ì½”ìŠ¤í”¼, ë‚˜ìŠ¤ë‹¥, ì°¨íŠ¸, ê¸ˆë¦¬)
- cpo_manager: ì¶œíŒê¸°ë¡ (íšŒì‚¬ê¸°ë¡, ì—°ëŒ€ê¸°, ë¸”ë¡œê·¸, ì¶œíŒ, í¸ì§‘, íšŒê³ , ë¹Œë”©ë¡œê·¸)
- chief_of_staff: ì¼ë°˜ ì§ˆë¬¸, ìš”ì•½, ì¼ì • ê´€ë¦¬, ê¸°íƒ€ (ìœ„ ë¶€ì„œì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš°)

## ì¶œë ¥ í˜•ì‹
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì“°ì§€ ë§ˆì„¸ìš”.
{"agent_id": "ë¶€ì„œID", "reason": "í•œì¤„ ì´ìœ "}"""


def _save_chain(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ ìƒíƒœë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤."""
    chains = load_setting("batch_chains") or []
    # ê°™ì€ chain_idê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì¶”ê°€
    found = False
    for i, c in enumerate(chains):
        if c["chain_id"] == chain["chain_id"]:
            chains[i] = chain
            found = True
            break
    if not found:
        chains.append(chain)
    # ìµœê·¼ 50ê°œë§Œ ìœ ì§€ (ì˜¤ë˜ëœ ì™„ë£Œ/ì‹¤íŒ¨ ì²´ì¸ ì •ë¦¬)
    if len(chains) > 50:
        active = [c for c in chains if c.get("status") in ("running", "pending")]
        done = [c for c in chains if c.get("status") not in ("running", "pending")]
        chains = active + done[-20:]
    save_setting("batch_chains", chains)


def _load_chain(chain_id: str) -> dict | None:
    """DBì—ì„œ ë°°ì¹˜ ì²´ì¸ ìƒíƒœë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    chains = load_setting("batch_chains") or []
    for c in chains:
        if c["chain_id"] == chain_id:
            return c
    return None


async def _broadcast_chain_status(chain: dict, message: str):
    """ë°°ì¹˜ ì²´ì¸ ì§„í–‰ ìƒí™©ì„ WebSocketìœ¼ë¡œ CEOì—ê²Œ ì•Œë¦½ë‹ˆë‹¤."""
    step_labels = {
        "classify": "1ë‹¨ê³„: ë¶„ë¥˜",
        "delegation": "2ë‹¨ê³„: ì²˜ì¥ ì§€ì‹œì„œ",
        "specialists": "3ë‹¨ê³„: ì „ë¬¸ê°€ ë¶„ì„",
        "synthesis": "4ë‹¨ê³„: ì¢…í•© ë³´ê³ ì„œ",
        "completed": "ì™„ë£Œ",
        "failed": "ì‹¤íŒ¨",
        "direct": "ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬",
    }
    step_label = step_labels.get(chain.get("step", ""), chain.get("step", ""))
    for c in connected_clients[:]:
        try:
            await c.send_json({
                "event": "batch_chain_progress",
                "data": {
                    "chain_id": chain["chain_id"],
                    "step": chain.get("step", ""),
                    "step_label": step_label,
                    "status": chain.get("status", ""),
                    "message": message,
                    "mode": chain.get("mode", "single"),
                    "target_id": chain.get("target_id"),
                },
            })
        except Exception:
            pass

    # í…”ë ˆê·¸ë¨ìœ¼ë¡œë„ ì§„í–‰ ìƒíƒœ ì „ë‹¬
    if _telegram_app:
        ceo_id = os.getenv("TELEGRAM_CEO_CHAT_ID", "")
        if ceo_id:
            try:
                await _telegram_app.bot.send_message(
                    chat_id=int(ceo_id),
                    text=f"ğŸ“¦ {message}",
                )
            except Exception:
                pass


async def _start_batch_chain(text: str, task_id: str) -> dict:
    """ë°°ì¹˜ ì²´ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤.

    CEO ëª…ë ¹ì„ ë°›ì•„ì„œ ìœ„ì„ ì²´ì¸ ì „ì²´ë¥¼ Batch APIë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    í‚¤ì›Œë“œ ë§¤ì¹­ì´ ë˜ë©´ ë¶„ë¥˜ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ê³  ë°”ë¡œ ì „ë¬¸ê°€ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
    """
    chain_id = f"chain_{datetime.now(KST).strftime('%Y%m%d_%H%M%S')}_{task_id[:8]}"

    correlation_id = f"batch_{chain_id}"

    chain = {
        "chain_id": chain_id,
        "task_id": task_id,
        "correlation_id": correlation_id,
        "text": text,
        "mode": "broadcast" if _is_broadcast_command(text) else "single",
        "step": "classify",
        "status": "running",
        "target_id": None,
        "batches": {"classify": None, "specialists": [], "synthesis": []},
        "results": {"classify": None, "specialists": {}, "synthesis": {}},
        "custom_id_map": {},  # custom_id â†’ {"agent_id", "step"} ì—­ë§¤í•‘
        "delegation_instructions": {},  # ì²˜ì¥ ì§€ì‹œì„œ (ë‹¨ì¼ ë¶€ì„œ)
        "broadcast_delegations": {},  # ì²˜ì¥ ì§€ì‹œì„œ (ë¸Œë¡œë“œìºìŠ¤íŠ¸)
        "total_cost_usd": 0.0,
        "created_at": datetime.now(KST).isoformat(),
        "completed_at": None,
    }

    # taskì— correlation_id ì—°ê²°
    update_task(task_id, correlation_id=correlation_id)

    # ì˜ˆì‚° í™•ì¸
    limit = float(load_setting("daily_budget_usd") or 7.0)
    today = get_today_cost()
    if today >= limit:
        update_task(task_id, status="failed",
                    result_summary=f"ì¼ì¼ ì˜ˆì‚° ì´ˆê³¼ (${today:.2f}/${limit:.0f})",
                    success=0)
        return {"error": f"ì¼ì¼ ì˜ˆì‚°ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ (${today:.2f}/${limit:.0f})"}

    # â”€â”€ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ëª¨ë“œ â†’ ë¶„ë¥˜ ê±´ë„ˆë›°ê³  ì²˜ì¥ ì§€ì‹œì„œ â†’ ì „ ë¶€ì„œ ì „ë¬¸ê°€ â”€â”€
    if chain["mode"] == "broadcast":
        chain["step"] = "delegation"
        chain["target_id"] = "broadcast"
        _save_chain(chain)

        await _broadcast_chain_status(chain, "ğŸ“¦ ë°°ì¹˜ ì²´ì¸ ì‹œì‘ (ë¸Œë¡œë“œìºìŠ¤íŠ¸: 6ê°œ ë¶€ì„œ â†’ ì²˜ì¥ ì§€ì‹œì„œ ìƒì„± ì¤‘)")
        await _chain_create_delegation_broadcast(chain)
        return {"chain_id": chain_id, "status": "started", "mode": "broadcast", "step": chain["step"]}

    # â”€â”€ í‚¤ì›Œë“œ ë¶„ë¥˜ ì‹œë„ (ë¬´ë£Œ, ì¦‰ì‹œ) â”€â”€
    keyword_match = _classify_by_keywords(text)
    if keyword_match:
        chain["target_id"] = keyword_match
        chain["results"]["classify"] = {
            "agent_id": keyword_match,
            "method": "í‚¤ì›Œë“œ",
            "cost_usd": 0,
        }

        if keyword_match == "chief_of_staff":
            # ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬ â†’ ë°”ë¡œ ì¢…í•©(=ì§ì ‘ ë‹µë³€) ë‹¨ê³„
            chain["step"] = "synthesis"
            _save_chain(chain)
            await _broadcast_chain_status(chain, "ğŸ“¦ í‚¤ì›Œë“œ ë¶„ë¥˜ â†’ ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬")
            await _chain_submit_synthesis(chain)
        else:
            # ì²˜ì¥ ë¶€ì„œë¡œ ìœ„ì„ â†’ ì²˜ì¥ ì§€ì‹œì„œ â†’ ì „ë¬¸ê°€ í˜¸ì¶œ ë‹¨ê³„
            chain["step"] = "delegation"
            _save_chain(chain)
            target_name = _AGENT_NAMES.get(keyword_match, keyword_match)
            await _broadcast_chain_status(chain, f"ğŸ“¦ í‚¤ì›Œë“œ ë¶„ë¥˜ â†’ {target_name} ì§€ì‹œì„œ ìƒì„± ì¤‘")
            await _chain_create_delegation(chain)

        return {"chain_id": chain_id, "status": "started", "step": chain["step"]}

    # â”€â”€ AI ë¶„ë¥˜ê°€ í•„ìš” â†’ Batch APIë¡œ ë¶„ë¥˜ ìš”ì²­ ì œì¶œ â”€â”€
    # ê°€ì¥ ì €ë ´í•œ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸ ì„ íƒ
    providers = get_available_providers()
    if providers.get("anthropic"):
        classify_model = "claude-sonnet-4-6"
    elif providers.get("google"):
        classify_model = "gemini-2.5-flash"
    elif providers.get("openai"):
        classify_model = "gpt-5-mini"
    else:
        # AI ì—†ìŒ â†’ ë¹„ì„œì‹¤ì¥ ì§ì ‘
        chain["target_id"] = "chief_of_staff"
        chain["step"] = "synthesis"
        chain["results"]["classify"] = {"agent_id": "chief_of_staff", "method": "í´ë°±"}
        _save_chain(chain)
        await _chain_submit_synthesis(chain)
        return {"chain_id": chain_id, "status": "started", "step": "synthesis"}

    classify_custom_id = f"{chain_id}_classify"
    classify_req = {
        "custom_id": classify_custom_id,
        "message": text,
        "system_prompt": _BATCH_CLASSIFY_PROMPT,
        "model": classify_model,
        "max_tokens": 1024,
    }

    result = await batch_submit([classify_req], model=classify_model)

    if "error" in result:
        # ë°°ì¹˜ ì‹¤íŒ¨ â†’ í´ë°±ìœ¼ë¡œ ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬
        _log(f"[CHAIN] ë¶„ë¥˜ ë°°ì¹˜ ì‹¤íŒ¨: {result['error']} â†’ ë¹„ì„œì‹¤ì¥ í´ë°±")
        chain["target_id"] = "chief_of_staff"
        chain["step"] = "synthesis"
        chain["results"]["classify"] = {"agent_id": "chief_of_staff", "method": "í´ë°±", "error": result["error"]}
        _save_chain(chain)
        await _chain_submit_synthesis(chain)
        return {"chain_id": chain_id, "status": "started", "step": "synthesis"}

    chain["batches"]["classify"] = {
        "batch_id": result["batch_id"],
        "provider": result["provider"],
        "status": "pending",
    }
    chain["status"] = "pending"
    chain["custom_id_map"][classify_custom_id] = {"agent_id": "classify", "step": "classify"}
    _save_chain(chain)

    _ensure_batch_poller()
    update_task(task_id, status="pending",
                result_summary="ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 1ë‹¨ê³„: ë¶„ë¥˜ ìš”ì²­ ì œì¶œë¨")
    await _broadcast_chain_status(chain, "ğŸ“¦ ë°°ì¹˜ ì²´ì¸ ì‹œì‘ â€” 1ë‹¨ê³„: ë¶„ë¥˜ ìš”ì²­ ì œì¶œë¨")

    _log(f"[CHAIN] ì‹œì‘: {chain_id} â€” ë¶„ë¥˜ ë°°ì¹˜ ì œì¶œ (batch_id: {result['batch_id']})")
    return {"chain_id": chain_id, "status": "pending", "step": "classify"}


# â”€â”€ ì²˜ì¥ ì§€ì‹œì„œ ìƒì„± í”„ë¡¬í”„íŠ¸ â”€â”€
_DELEGATION_PROMPT = """ë‹¹ì‹ ì€ {mgr_name}ì…ë‹ˆë‹¤. CEOë¡œë¶€í„° ì•„ë˜ ì—…ë¬´ ì§€ì‹œë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.

ì†Œì† ì „ë¬¸ê°€ë“¤ì—ê²Œ ê°ê° êµ¬ì²´ì ì¸ ì‘ì—… ì§€ì‹œë¥¼ ë‚´ë ¤ì•¼ í•©ë‹ˆë‹¤.
ê° ì „ë¬¸ê°€ì˜ ì „ë¬¸ ë¶„ì•¼ì— ë§ê²Œ CEO ëª…ë ¹ì„ ì„¸ë¶€ ì—…ë¬´ë¡œ ë¶„í•´í•˜ì„¸ìš”.

## ì†Œì† ì „ë¬¸ê°€
{spec_list}

## CEO ëª…ë ¹
{text}

## ì¶œë ¥ í˜•ì‹
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì“°ì§€ ë§ˆì„¸ìš”.
ê° ì „ë¬¸ê°€ IDë¥¼ í‚¤ë¡œ, êµ¬ì²´ì ì¸ ì‘ì—… ì§€ì‹œ(2~4ë¬¸ì¥)ë¥¼ ê°’ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

{json_example}"""


async def _chain_create_delegation(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ â€” ì²˜ì¥ì´ ì „ë¬¸ê°€ë³„ ì§€ì‹œì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤ (ì‹¤ì‹œê°„ API 1íšŒ í˜¸ì¶œ).

    ë¶„ë¥˜ ì™„ë£Œ í›„, ì „ë¬¸ê°€ ë°°ì¹˜ ì œì¶œ ì „ì— í˜¸ì¶œë©ë‹ˆë‹¤.
    ì²˜ì¥ì—ê²Œ CEO ëª…ë ¹ì„ ì „ë‹¬í•˜ê³ , ê° ì „ë¬¸ê°€ì—ê²Œ ë‚´ë¦´ êµ¬ì²´ì  ì§€ì‹œì„œë¥¼ ë°›ìŠµë‹ˆë‹¤.
    """
    target_id = chain["target_id"]
    text = chain["text"]
    specialists = _MANAGER_SPECIALISTS.get(target_id, [])

    if not specialists:
        # ì „ë¬¸ê°€ ì—†ìŒ â†’ ì§€ì‹œì„œ ìƒì„± ë¶ˆí•„ìš”
        await _chain_submit_specialists(chain)
        return

    mgr_name = _AGENT_NAMES.get(target_id, target_id)

    # ì „ë¬¸ê°€ ëª©ë¡ í…ìŠ¤íŠ¸ ìƒì„±
    spec_list_parts = []
    json_example_parts = []
    for s_id in specialists:
        s_name = _SPECIALIST_NAMES.get(s_id, s_id)
        spec_list_parts.append(f"- {s_id}: {s_name}")
        json_example_parts.append(f'  "{s_id}": "êµ¬ì²´ì ì¸ ì‘ì—… ì§€ì‹œ ë‚´ìš©"')

    spec_list = "\n".join(spec_list_parts)
    json_example = "{\n" + ",\n".join(json_example_parts) + "\n}"

    delegation_prompt = _DELEGATION_PROMPT.format(
        mgr_name=mgr_name,
        spec_list=spec_list,
        text=text,
        json_example=json_example,
    )

    # ê°€ì¥ ì €ë ´í•œ ëª¨ë¸ë¡œ ì‹¤ì‹œê°„ API í˜¸ì¶œ (ë°°ì¹˜ ëŒ€ê¸° ì—†ì´ ì¦‰ì‹œ ì‘ë‹µ)
    providers = get_available_providers()
    if providers.get("anthropic"):
        deleg_model = "claude-sonnet-4-6"
    elif providers.get("google"):
        deleg_model = "gemini-2.5-flash"
    elif providers.get("openai"):
        deleg_model = "gpt-5-mini"
    else:
        deleg_model = None

    if deleg_model:
        # ì²˜ì¥ ì´ˆë¡ë¶ˆ ì¼œê¸°
        await _broadcast_status(target_id, "working", 0.2, f"{mgr_name} ì§€ì‹œì„œ ì‘ì„± ì¤‘...")
        try:
            result = await ask_ai(
                user_message=delegation_prompt,
                model=deleg_model,
                max_tokens=2048,
            )
            response_text = result.get("content", "") or result.get("text", "")

            # JSON íŒŒì‹± ì‹œë„
            import json as _json
            # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` ë˜ëŠ” { ... })
            json_text = response_text.strip()
            if "```" in json_text:
                # ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ
                start = json_text.find("{")
                end = json_text.rfind("}") + 1
                if start >= 0 and end > start:
                    json_text = json_text[start:end]
            elif json_text.startswith("{"):
                pass  # ì´ë¯¸ JSON
            else:
                # { ì°¾ê¸°
                start = json_text.find("{")
                end = json_text.rfind("}") + 1
                if start >= 0 and end > start:
                    json_text = json_text[start:end]

            instructions = _json.loads(json_text)
            if isinstance(instructions, dict):
                chain["delegation_instructions"] = instructions
                chain["results"]["delegation"] = {
                    "agent_id": target_id,
                    "instructions": instructions,
                    "model": deleg_model,
                    "cost_usd": result.get("cost_usd", 0),
                }
                chain["total_cost_usd"] += result.get("cost_usd", 0)
                _log(f"[CHAIN] {chain['chain_id']} â€” {mgr_name} ì§€ì‹œì„œ ìƒì„± ì™„ë£Œ ({len(instructions)}ëª…)")
            else:
                _log(f"[CHAIN] {chain['chain_id']} â€” ì§€ì‹œì„œ íŒŒì‹± ì‹¤íŒ¨ (dict ì•„ë‹˜)")
        except Exception as e:
            _log(f"[CHAIN] {chain['chain_id']} â€” ì§€ì‹œì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•´ë„ ì§„í–‰ (ì§€ì‹œì„œ ì—†ì´ ì›ë³¸ ëª…ë ¹ìœ¼ë¡œ)

    # ì§€ì‹œì„œ ìƒíƒœ ì—…ë°ì´íŠ¸ + ì²˜ì¥ ì´ˆë¡ë¶ˆ ë„ê¸°
    has_instructions = bool(chain.get("delegation_instructions"))
    deleg_status = f"âœ… {mgr_name} ì§€ì‹œì„œ ìƒì„± ì™„ë£Œ" if has_instructions else f"âš ï¸ ì§€ì‹œì„œ ì—†ì´ ì§„í–‰"
    await _broadcast_status(target_id, "done", 0.5, deleg_status)
    update_task(chain["task_id"], status="pending",
                result_summary=f"ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 2ë‹¨ê³„: {deleg_status}")
    await _broadcast_chain_status(chain, f"ğŸ“¦ 2ë‹¨ê³„: {deleg_status}")

    _save_chain(chain)

    # ì „ë¬¸ê°€ ë°°ì¹˜ ì œì¶œë¡œ ì§„í–‰
    await _chain_submit_specialists(chain)


async def _chain_create_delegation_broadcast(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ â€” ë¸Œë¡œë“œìºìŠ¤íŠ¸: 6ê°œ ì²˜ì¥ì´ ê°ê° ì§€ì‹œì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."""
    text = chain["text"]
    all_managers = ["cto_manager", "cso_manager", "clo_manager", "cmo_manager", "cio_manager", "cpo_manager"]

    # ê°€ì¥ ì €ë ´í•œ ëª¨ë¸ ì„ íƒ
    providers = get_available_providers()
    if providers.get("anthropic"):
        deleg_model = "claude-sonnet-4-6"
    elif providers.get("google"):
        deleg_model = "gemini-2.5-flash"
    elif providers.get("openai"):
        deleg_model = "gpt-5-mini"
    else:
        deleg_model = None

    broadcast_delegations = {}

    if deleg_model:
        import asyncio as _asyncio

        async def _get_delegation(mgr_id: str) -> tuple[str, dict]:
            specialists = _MANAGER_SPECIALISTS.get(mgr_id, [])
            if not specialists:
                return mgr_id, {}
            mgr_name = _AGENT_NAMES.get(mgr_id, mgr_id)
            spec_list_parts = []
            json_example_parts = []
            for s_id in specialists:
                s_name = _SPECIALIST_NAMES.get(s_id, s_id)
                spec_list_parts.append(f"- {s_id}: {s_name}")
                json_example_parts.append(f'  "{s_id}": "êµ¬ì²´ì ì¸ ì‘ì—… ì§€ì‹œ ë‚´ìš©"')

            prompt = _DELEGATION_PROMPT.format(
                mgr_name=mgr_name,
                spec_list="\n".join(spec_list_parts),
                text=text,
                json_example="{\n" + ",\n".join(json_example_parts) + "\n}",
            )
            try:
                result = await ask_ai(user_message=prompt, model=deleg_model)
                response_text = result.get("content", "") or result.get("text", "")
                import json as _json
                json_text = response_text.strip()
                start = json_text.find("{")
                end = json_text.rfind("}") + 1
                if start >= 0 and end > start:
                    json_text = json_text[start:end]
                instructions = _json.loads(json_text)
                chain["total_cost_usd"] += result.get("cost_usd", 0)
                return mgr_id, instructions if isinstance(instructions, dict) else {}
            except Exception as e:
                _log(f"[CHAIN] ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì§€ì‹œì„œ ì‹¤íŒ¨ ({mgr_id}): {e}")
                return mgr_id, {}

        # 6ê°œ ì²˜ì¥ì—ê²Œ ë™ì‹œì— ì§€ì‹œì„œ ìš”ì²­
        tasks = [_get_delegation(m) for m in all_managers]
        results = await _asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, tuple):
                mgr_id, instructions = r
                if instructions:
                    broadcast_delegations[mgr_id] = instructions

    chain["broadcast_delegations"] = broadcast_delegations
    chain["results"]["delegation"] = {
        "mode": "broadcast",
        "delegations": broadcast_delegations,
    }

    deleg_count = sum(1 for d in broadcast_delegations.values() if d)
    _log(f"[CHAIN] {chain['chain_id']} â€” ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì§€ì‹œì„œ {deleg_count}/6 ì™„ë£Œ")
    update_task(chain["task_id"], status="pending",
                result_summary=f"ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 2ë‹¨ê³„: ì²˜ì¥ ì§€ì‹œì„œ {deleg_count}/6 ì™„ë£Œ")
    await _broadcast_chain_status(chain, f"ğŸ“¦ 2ë‹¨ê³„: ì²˜ì¥ ì§€ì‹œì„œ {deleg_count}/6 ì™„ë£Œ")
    _save_chain(chain)

    # ì „ë¬¸ê°€ ë°°ì¹˜ ì œì¶œë¡œ ì§„í–‰
    await _chain_submit_specialists_broadcast(chain)


async def _chain_submit_specialists(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ â€” ë‹¨ì¼ ë¶€ì„œì˜ ì „ë¬¸ê°€ë“¤ì—ê²Œ ë°°ì¹˜ ì œì¶œí•©ë‹ˆë‹¤."""
    target_id = chain["target_id"]
    text = chain["text"]
    specialists = _MANAGER_SPECIALISTS.get(target_id, [])

    if not specialists:
        # ì „ë¬¸ê°€ ì—†ìŒ â†’ ë°”ë¡œ ì¢…í•©(ì²˜ì¥ ì§ì ‘ ì²˜ë¦¬) ë‹¨ê³„
        chain["step"] = "synthesis"
        _save_chain(chain)
        await _chain_submit_synthesis(chain)
        return

    # ì²˜ì¥ ì§€ì‹œì„œê°€ ìˆìœ¼ë©´ ì „ë¬¸ê°€ì—ê²Œ í•¨ê»˜ ì „ë‹¬
    delegation = chain.get("delegation_instructions", {})

    requests = []
    for spec_id in specialists:
        # ì „ë¬¸ê°€ ì´ˆë¡ë¶ˆ ì¼œê¸°
        spec_name = _SPECIALIST_NAMES.get(spec_id, spec_id)
        await _broadcast_status(spec_id, "working", 0.3, f"{spec_name} ë°°ì¹˜ ì²˜ë¦¬ ì¤‘...")

        soul = _load_agent_prompt(spec_id, include_tools=False) + _BATCH_MODE_SUFFIX
        override = _get_model_override(spec_id)
        model = select_model(text, override=override)
        custom_id = f"{chain['chain_id']}_spec_{spec_id}"

        # ì²˜ì¥ ì§€ì‹œì„œê°€ ìˆìœ¼ë©´ ì „ë¬¸ê°€ì—ê²Œ í•¨ê»˜ ì „ë‹¬
        spec_instruction = delegation.get(spec_id, "")
        if spec_instruction:
            message = (
                f"## ì²˜ì¥ ì§€ì‹œ\n{spec_instruction}\n\n"
                f"## CEO ì›ë³¸ ëª…ë ¹\n{text}"
            )
        else:
            message = text

        requests.append({
            "custom_id": custom_id,
            "message": message,
            "system_prompt": soul,
            "model": model,
            "max_tokens": 8192,
        })
        chain["custom_id_map"][custom_id] = {"agent_id": spec_id, "step": "specialists"}

    # í”„ë¡œë°”ì´ë”ë³„ ê·¸ë£¹í™”í•˜ì—¬ ë°°ì¹˜ ì œì¶œ
    batch_results = await batch_submit_grouped(requests)

    chain["batches"]["specialists"] = []
    for br in batch_results:
        chain["batches"]["specialists"].append({
            "batch_id": br.get("batch_id", ""),
            "provider": br.get("provider", ""),
            "status": "pending" if "error" not in br else "failed",
            "custom_ids": br.get("custom_ids", []),
            "error": br.get("error"),
        })

    chain["step"] = "specialists"
    chain["status"] = "pending"
    _save_chain(chain)

    _ensure_batch_poller()
    spec_count = len(specialists)
    provider_count = len(batch_results)
    target_name = _AGENT_NAMES.get(target_id, target_id)
    update_task(chain["task_id"], status="pending",
                result_summary=f"ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 3ë‹¨ê³„: {target_name} ì „ë¬¸ê°€ {spec_count}ëª… ë°°ì¹˜ ì œì¶œ ({provider_count}ê°œ í”„ë¡œë°”ì´ë”)")
    await _broadcast_chain_status(chain, f"ğŸ“¦ 3ë‹¨ê³„: {target_name} ì „ë¬¸ê°€ {spec_count}ëª… â†’ {provider_count}ê°œ í”„ë¡œë°”ì´ë”ë³„ ë°°ì¹˜ ì œì¶œ")

    _log(f"[CHAIN] {chain['chain_id']} â€” ì „ë¬¸ê°€ {spec_count}ëª… ë°°ì¹˜ ì œì¶œ ({provider_count}ê°œ í”„ë¡œë°”ì´ë”)")


async def _chain_submit_specialists_broadcast(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ â€” ë¸Œë¡œë“œìºìŠ¤íŠ¸: 6ê°œ ë¶€ì„œ ì „ì²´ ì „ë¬¸ê°€ì—ê²Œ ë°°ì¹˜ ì œì¶œí•©ë‹ˆë‹¤."""
    text = chain["text"]
    all_managers = ["cto_manager", "cso_manager", "clo_manager", "cmo_manager", "cio_manager", "cpo_manager"]

    # ë¸Œë¡œë“œìºìŠ¤íŠ¸ ëª¨ë“œì˜ ì²˜ì¥ë³„ ì§€ì‹œì„œ
    broadcast_delegations = chain.get("broadcast_delegations", {})

    requests = []
    for mgr_id in all_managers:
        specialists = _MANAGER_SPECIALISTS.get(mgr_id, [])
        mgr_delegation = broadcast_delegations.get(mgr_id, {})
        for spec_id in specialists:
            soul = _load_agent_prompt(spec_id, include_tools=False) + _BATCH_MODE_SUFFIX
            override = _get_model_override(spec_id)
            model = select_model(text, override=override)
            custom_id = f"{chain['chain_id']}_spec_{spec_id}"

            # ì²˜ì¥ ì§€ì‹œì„œê°€ ìˆìœ¼ë©´ ì „ë¬¸ê°€ì—ê²Œ í•¨ê»˜ ì „ë‹¬
            spec_instruction = mgr_delegation.get(spec_id, "")
            if spec_instruction:
                message = (
                    f"## ì²˜ì¥ ì§€ì‹œ\n{spec_instruction}\n\n"
                    f"## CEO ì›ë³¸ ëª…ë ¹\n{text}"
                )
            else:
                message = text

            requests.append({
                "custom_id": custom_id,
                "message": message,
                "system_prompt": soul,
                "model": model,
                "max_tokens": 8192,
            })
            chain["custom_id_map"][custom_id] = {"agent_id": spec_id, "step": "specialists"}

    if not requests:
        chain["step"] = "synthesis"
        _save_chain(chain)
        await _chain_submit_synthesis(chain)
        return

    # í”„ë¡œë°”ì´ë”ë³„ ê·¸ë£¹í™”í•˜ì—¬ ë°°ì¹˜ ì œì¶œ
    batch_results = await batch_submit_grouped(requests)

    chain["batches"]["specialists"] = []
    for br in batch_results:
        chain["batches"]["specialists"].append({
            "batch_id": br.get("batch_id", ""),
            "provider": br.get("provider", ""),
            "status": "pending" if "error" not in br else "failed",
            "custom_ids": br.get("custom_ids", []),
            "error": br.get("error"),
        })

    chain["step"] = "specialists"
    chain["status"] = "pending"
    _save_chain(chain)

    _ensure_batch_poller()
    spec_count = len(requests)
    provider_count = len(batch_results)
    update_task(chain["task_id"], status="pending",
                result_summary=f"ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 2ë‹¨ê³„: ì „ì²´ {spec_count}ëª… ì „ë¬¸ê°€ ë°°ì¹˜ ì œì¶œ ({provider_count}ê°œ í”„ë¡œë°”ì´ë”)")
    await _broadcast_chain_status(chain, f"ğŸ“¦ 2ë‹¨ê³„: 6ê°œ ë¶€ì„œ ì „ë¬¸ê°€ {spec_count}ëª… â†’ {provider_count}ê°œ í”„ë¡œë°”ì´ë”ë³„ ë°°ì¹˜ ì œì¶œ")

    _log(f"[CHAIN] {chain['chain_id']} â€” ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì „ë¬¸ê°€ {spec_count}ëª… ë°°ì¹˜ ì œì¶œ")


async def _chain_submit_synthesis(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ â€” ì²˜ì¥(ë“¤)ì´ ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ëŠ” ë°°ì¹˜ë¥¼ ì œì¶œí•©ë‹ˆë‹¤."""
    text = chain["text"]

    requests = []

    if chain["mode"] == "broadcast":
        # ë¸Œë¡œë“œìºìŠ¤íŠ¸: 6ê°œ ì²˜ì¥ì´ ê°ê° ìê¸° íŒ€ ê²°ê³¼ë¥¼ ì¢…í•©
        all_managers = ["cto_manager", "cso_manager", "clo_manager", "cmo_manager", "cio_manager", "cpo_manager"]
        for mgr_id in all_managers:
            specialists = _MANAGER_SPECIALISTS.get(mgr_id, [])
            spec_parts = []
            for s_id in specialists:
                s_res = chain["results"]["specialists"].get(s_id, {})
                name = _SPECIALIST_NAMES.get(s_id, s_id)
                content = s_res.get("content", "ì‘ë‹µ ì—†ìŒ")
                if s_res.get("error"):
                    content = f"ì˜¤ë¥˜: {s_res['error'][:100]}"
                spec_parts.append(f"[{name}]\n{content}")

            mgr_name = _AGENT_NAMES.get(mgr_id, mgr_id)
            synthesis_prompt = (
                f"ë‹¹ì‹ ì€ {mgr_name}ì…ë‹ˆë‹¤. ì†Œì† ì „ë¬¸ê°€ë“¤ì´ ì•„ë˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì œì¶œí–ˆìŠµë‹ˆë‹¤.\n"
                f"ì´ë¥¼ ê²€ìˆ˜í•˜ê³  ì¢…í•©í•˜ì—¬ CEOì—ê²Œ ë³´ê³ í•  ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
                f"ì „ë¬¸ê°€ ì˜ê²¬ ì¤‘ ë¶€ì¡±í•˜ê±°ë‚˜ ì˜ëª»ëœ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì§€ì í•˜ê³  ë³´ì™„í•˜ì„¸ìš”.\n\n"
                f"## CEO ì›ë³¸ ëª…ë ¹\n{text}\n\n"
                f"## ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼\n" + "\n\n".join(spec_parts)
            )

            soul = _load_agent_prompt(mgr_id, include_tools=False) + _BATCH_MODE_SUFFIX
            override = _get_model_override(mgr_id)
            model = select_model(synthesis_prompt, override=override)
            custom_id = f"{chain['chain_id']}_synth_{mgr_id}"

            requests.append({
                "custom_id": custom_id,
                "message": synthesis_prompt,
                "system_prompt": soul,
                "model": model,
                "max_tokens": 8192,
            })
            chain["custom_id_map"][custom_id] = {"agent_id": mgr_id, "step": "synthesis"}

    elif chain["target_id"] == "chief_of_staff":
        # ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬ (ë¶„ë¥˜ ê²°ê³¼ê°€ chief_of_staffì¸ ê²½ìš°)
        soul = _load_agent_prompt("chief_of_staff", include_tools=False) + _BATCH_MODE_SUFFIX
        override = _get_model_override("chief_of_staff")
        model = select_model(text, override=override)
        custom_id = f"{chain['chain_id']}_synth_chief_of_staff"

        requests.append({
            "custom_id": custom_id,
            "message": text,
            "system_prompt": soul,
            "model": model,
            "max_tokens": 8192,
        })
        chain["custom_id_map"][custom_id] = {"agent_id": "chief_of_staff", "step": "synthesis"}

    else:
        # ë‹¨ì¼ ë¶€ì„œ: ì²˜ì¥ì´ ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì¢…í•©
        target_id = chain["target_id"]
        specialists = _MANAGER_SPECIALISTS.get(target_id, [])

        if not specialists or not chain["results"]["specialists"]:
            # ì „ë¬¸ê°€ ê²°ê³¼ ì—†ìŒ â†’ ì²˜ì¥ì´ ì§ì ‘ ë‹µë³€
            soul = _load_agent_prompt(target_id, include_tools=False) + _BATCH_MODE_SUFFIX
            override = _get_model_override(target_id)
            model = select_model(text, override=override)
            custom_id = f"{chain['chain_id']}_synth_{target_id}"

            requests.append({
                "custom_id": custom_id,
                "message": text,
                "system_prompt": soul,
                "model": model,
                "max_tokens": 8192,
            })
            chain["custom_id_map"][custom_id] = {"agent_id": target_id, "step": "synthesis"}
        else:
            # ì „ë¬¸ê°€ ê²°ê³¼ ì·¨í•© â†’ ì²˜ì¥ì—ê²Œ ì¢…í•© ìš”ì²­
            spec_parts = []
            for s_id in specialists:
                s_res = chain["results"]["specialists"].get(s_id, {})
                name = _SPECIALIST_NAMES.get(s_id, s_id)
                content = s_res.get("content", "ì‘ë‹µ ì—†ìŒ")
                if s_res.get("error"):
                    content = f"ì˜¤ë¥˜: {s_res['error'][:100]}"
                spec_parts.append(f"[{name}]\n{content}")

            mgr_name = _AGENT_NAMES.get(target_id, target_id)
            synthesis_prompt = (
                f"ë‹¹ì‹ ì€ {mgr_name}ì…ë‹ˆë‹¤. ì†Œì† ì „ë¬¸ê°€ë“¤ì´ ì•„ë˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì œì¶œí–ˆìŠµë‹ˆë‹¤.\n"
                f"ì´ë¥¼ ê²€ìˆ˜í•˜ê³  ì¢…í•©í•˜ì—¬ CEOì—ê²Œ ë³´ê³ í•  ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
                f"ì „ë¬¸ê°€ ì˜ê²¬ ì¤‘ ë¶€ì¡±í•˜ê±°ë‚˜ ì˜ëª»ëœ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì§€ì í•˜ê³  ë³´ì™„í•˜ì„¸ìš”.\n\n"
                f"## CEO ì›ë³¸ ëª…ë ¹\n{text}\n\n"
                f"## ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼\n" + "\n\n".join(spec_parts)
            )

            soul = _load_agent_prompt(target_id, include_tools=False) + _BATCH_MODE_SUFFIX
            override = _get_model_override(target_id)
            model = select_model(synthesis_prompt, override=override)
            custom_id = f"{chain['chain_id']}_synth_{target_id}"

            requests.append({
                "custom_id": custom_id,
                "message": synthesis_prompt,
                "system_prompt": soul,
                "model": model,
                "max_tokens": 8192,
            })
            chain["custom_id_map"][custom_id] = {"agent_id": target_id, "step": "synthesis"}

    if not requests:
        # ìš”ì²­ ì—†ìŒ â†’ ë°”ë¡œ ì™„ë£Œ
        await _deliver_chain_result(chain)
        return

    # í”„ë¡œë°”ì´ë”ë³„ ê·¸ë£¹í™”í•˜ì—¬ ë°°ì¹˜ ì œì¶œ
    batch_results = await batch_submit_grouped(requests)

    chain["batches"]["synthesis"] = []
    for br in batch_results:
        chain["batches"]["synthesis"].append({
            "batch_id": br.get("batch_id", ""),
            "provider": br.get("provider", ""),
            "status": "pending" if "error" not in br else "failed",
            "custom_ids": br.get("custom_ids", []),
            "error": br.get("error"),
        })

    chain["step"] = "synthesis"
    chain["status"] = "pending"
    _save_chain(chain)

    _ensure_batch_poller()

    if chain["mode"] == "broadcast":
        update_task(chain["task_id"], status="pending",
                    result_summary="ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 4ë‹¨ê³„: 6ê°œ ì²˜ì¥ ì¢…í•©ë³´ê³ ì„œ ë°°ì¹˜ ì œì¶œ")
        await _broadcast_chain_status(chain, "ğŸ“¦ 4ë‹¨ê³„: 6ê°œ ì²˜ì¥ì´ ì¢…í•©ë³´ê³ ì„œ ì‘ì„± ì¤‘ (ë°°ì¹˜)")
    else:
        target_name = _AGENT_NAMES.get(chain["target_id"], chain["target_id"])
        update_task(chain["task_id"], status="pending",
                    result_summary=f"ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] 4ë‹¨ê³„: {target_name} ì¢…í•©ë³´ê³ ì„œ ë°°ì¹˜ ì œì¶œ")
        await _broadcast_chain_status(chain, f"ğŸ“¦ 4ë‹¨ê³„: {target_name} ì¢…í•©ë³´ê³ ì„œ ì‘ì„± ì¤‘ (ë°°ì¹˜)")

    _log(f"[CHAIN] {chain['chain_id']} â€” ì¢…í•©ë³´ê³ ì„œ ë°°ì¹˜ ì œì¶œ ({len(requests)}ê±´)")


async def _send_batch_result_to_telegram(content: str, cost: float):
    """ë°°ì¹˜ ì²´ì¸ ê²°ê³¼ë¥¼ í…”ë ˆê·¸ë¨ CEOì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤."""
    if not _telegram_app:
        return
    ceo_id = os.getenv("TELEGRAM_CEO_CHAT_ID", "")
    if not ceo_id:
        return
    try:
        # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (4096ì)
        if len(content) > 3800:
            content = content[:3800] + "\n\n... (ì „ì²´ ê²°ê³¼ëŠ” ì›¹ì—ì„œ í™•ì¸)"
        await _telegram_app.bot.send_message(
            chat_id=int(ceo_id),
            text=f"ğŸ“¦ ë°°ì¹˜ ì²´ì¸ ì™„ë£Œ\n\n{content}\n\nâ”€â”€â”€â”€â”€\nğŸ’° ${cost:.4f}",
        )
    except Exception as e:
        _log(f"[TG] ë°°ì¹˜ ê²°ê³¼ ì „ì†¡ ì‹¤íŒ¨: {e}")


async def _synthesis_realtime_fallback(chain: dict):
    """ì¢…í•© ë°°ì¹˜ ì‹¤íŒ¨ ì‹œ ì‹¤ì‹œê°„ ask_ai()ë¡œ ì¢…í•©ë³´ê³ ì„œë¥¼ ëŒ€ì‹  ìƒì„±í•©ë‹ˆë‹¤."""
    text = chain["text"]
    _log(f"[CHAIN] {chain['chain_id']} â€” ì‹¤ì‹œê°„ í´ë°± ì‹œì‘")

    if chain["mode"] == "broadcast":
        all_managers = ["cto_manager", "cso_manager", "clo_manager", "cmo_manager", "cio_manager", "cpo_manager"]
        for mgr_id in all_managers:
            if mgr_id in chain["results"]["synthesis"]:
                continue  # ì´ë¯¸ ìˆìœ¼ë©´ skip
            specialists = _MANAGER_SPECIALISTS.get(mgr_id, [])
            spec_parts = []
            for s_id in specialists:
                s_res = chain["results"]["specialists"].get(s_id, {})
                name = _SPECIALIST_NAMES.get(s_id, s_id)
                content = s_res.get("content", "ì‘ë‹µ ì—†ìŒ")
                spec_parts.append(f"[{name}]\n{content}")

            mgr_name = _AGENT_NAMES.get(mgr_id, mgr_id)
            if spec_parts:
                synthesis_prompt = (
                    f"ë‹¹ì‹ ì€ {mgr_name}ì…ë‹ˆë‹¤. ì†Œì† ì „ë¬¸ê°€ë“¤ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ CEOì—ê²Œ ë³´ê³ í•˜ì„¸ìš”.\n\n"
                    f"## CEO ì›ë³¸ ëª…ë ¹\n{text}\n\n"
                    f"## ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼\n" + "\n\n".join(spec_parts)
                )
            else:
                synthesis_prompt = text
            soul = _load_agent_prompt(mgr_id, include_tools=False)
            try:
                result = await ask_ai(user_message=synthesis_prompt, system_prompt=soul)
                chain["results"]["synthesis"][mgr_id] = {
                    "content": result.get("content", ""),
                    "model": result.get("model", ""),
                    "cost_usd": result.get("cost_usd", 0),
                    "error": result.get("error"),
                }
                chain["total_cost_usd"] += result.get("cost_usd", 0)
            except Exception as e:
                _log(f"[CHAIN] ì‹¤ì‹œê°„ í´ë°± ì‹¤íŒ¨ ({mgr_id}): {e}")
                chain["results"]["synthesis"][mgr_id] = {"content": "", "error": str(e)[:100]}
    else:
        target_id = chain.get("target_id", "chief_of_staff")
        if target_id not in chain["results"]["synthesis"]:
            soul = _load_agent_prompt(target_id, include_tools=False)
            try:
                result = await ask_ai(user_message=text, system_prompt=soul)
                chain["results"]["synthesis"][target_id] = {
                    "content": result.get("content", ""),
                    "model": result.get("model", ""),
                    "cost_usd": result.get("cost_usd", 0),
                    "error": result.get("error"),
                }
                chain["total_cost_usd"] += result.get("cost_usd", 0)
            except Exception as e:
                _log(f"[CHAIN] ì‹¤ì‹œê°„ í´ë°± ì‹¤íŒ¨ ({target_id}): {e}")
                chain["results"]["synthesis"][target_id] = {"content": "", "error": str(e)[:100]}

    target_id = chain.get("target_id", "chief_of_staff")
    await _broadcast_status(target_id, "done", 1.0, "ë³´ê³  ì™„ë£Œ")
    _save_chain(chain)
    await _deliver_chain_result(chain)


async def _deliver_chain_result(chain: dict):
    """ë°°ì¹˜ ì²´ì¸ ìµœì¢… ê²°ê³¼ë¥¼ CEOì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤."""
    # â”€â”€ ì¤‘ë³µ ì „ë‹¬ ë°©ì§€ â”€â”€
    if chain.get("delivered"):
        _log(f"[CHAIN] {chain.get('chain_id', '?')} â€” ì´ë¯¸ ì „ë‹¬ë¨, ì¤‘ë³µ ë°©ì§€")
        return
    chain["delivered"] = True
    # ì¦‰ì‹œ completed ìƒíƒœë¡œ ë³€ê²½ â†’ í´ëŸ¬ê°€ ì¬ì§„ì… ëª»í•˜ê²Œ ë°©ì§€
    chain["step"] = "completed"
    chain["status"] = "completed"
    chain["completed_at"] = datetime.now(KST).isoformat()
    _save_chain(chain)

    task_id = chain["task_id"]
    text = chain["text"]
    total_cost = chain.get("total_cost_usd", 0)

    if chain["mode"] == "broadcast":
        # ë¸Œë¡œë“œìºìŠ¤íŠ¸: 6ê°œ ì²˜ì¥ ì¢…í•© ê²°ê³¼ë¥¼ ëª¨ì•„ì„œ ì „ë‹¬
        all_managers = ["cto_manager", "cso_manager", "clo_manager", "cmo_manager", "cio_manager", "cpo_manager"]
        parts = []
        total_specialists = 0
        for mgr_id in all_managers:
            synth = chain["results"]["synthesis"].get(mgr_id, {})
            mgr_name = _AGENT_NAMES.get(mgr_id, mgr_id)
            content = synth.get("content", "")
            # ì¢…í•©ë³´ê³ ì„œê°€ ë¹„ì—ˆìœ¼ë©´ ì „ë¬¸ê°€ ì›ë³¸ ê²°ê³¼ë¥¼ í´ë°±ìœ¼ë¡œ ì‚¬ìš©
            if not content or content == "ì‘ë‹µ ì—†ìŒ":
                specialists = _MANAGER_SPECIALISTS.get(mgr_id, [])
                fallback_parts = []
                for s_id in specialists:
                    s_res = chain["results"].get("specialists", {}).get(s_id, {})
                    s_content = s_res.get("content", "")
                    if s_content:
                        s_name = _SPECIALIST_NAMES.get(s_id, s_id)
                        fallback_parts.append(f"**{s_name}**: {s_content[:300]}")
                if fallback_parts:
                    content = "(ì¢…í•© ë°°ì¹˜ ì‹¤íŒ¨ â€” ì „ë¬¸ê°€ ì›ë³¸ ê²°ê³¼)\n" + "\n".join(fallback_parts)
                else:
                    content = "ì‘ë‹µ ì—†ìŒ (ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ)"
            specs = len(_MANAGER_SPECIALISTS.get(mgr_id, []))
            total_specialists += specs
            spec_label = f" (ì „ë¬¸ê°€ {specs}ëª… ë™ì›)" if specs else ""
            parts.append(f"### ğŸ“‹ {mgr_name}{spec_label}\n{content}")

        compiled = (
            f"ğŸ“¢ **ë°°ì¹˜ ì²´ì¸ ê²°ê³¼** (6ê°œ ë¶€ì„œ + ì „ë¬¸ê°€ {total_specialists}ëª… ë™ì›)\n"
            f"ğŸ’° ì´ ë¹„ìš©: ${total_cost:.4f} (ë°°ì¹˜ í• ì¸ ~50% ì ìš©)\n\n---\n\n"
            + "\n\n---\n\n".join(parts)
        )

        update_task(task_id, status="completed",
                    result_summary=compiled[:500],
                    result_data=compiled,
                    success=1, cost_usd=total_cost,
                    agent_id="chief_of_staff")

        # WebSocketìœ¼ë¡œ ìµœì¢… ê²°ê³¼ ì „ë‹¬
        for c in connected_clients[:]:
            try:
                await c.send_json({
                    "event": "result",
                    "data": {
                        "content": compiled,
                        "sender_id": "chief_of_staff",
                        "handled_by": "ë¹„ì„œì‹¤ì¥ â†’ 6ê°œ ì²˜ì¥",
                        "delegation": "ë¹„ì„œì‹¤ì¥ â†’ ì²˜ì¥ â†’ ì „ë¬¸ê°€ (ë°°ì¹˜)",
                        "time_seconds": 0,
                        "cost": total_cost,
                        "model": "multi-agent-batch",
                        "routing_method": "ë°°ì¹˜ ì²´ì¸ (ë¸Œë¡œë“œìºìŠ¤íŠ¸)",
                    }
                })
            except Exception:
                pass

    else:
        # ë‹¨ì¼ ë¶€ì„œ ê²°ê³¼
        target_id = chain.get("target_id", "chief_of_staff")
        synth = chain["results"]["synthesis"].get(
            target_id,
            chain["results"]["synthesis"].get("chief_of_staff", {})
        )
        content = synth.get("content", "")
        target_name = _AGENT_NAMES.get(target_id, target_id)

        # ìœ„ì„ ì •ë³´ êµ¬ì„±
        specs_count = len(_MANAGER_SPECIALISTS.get(target_id, []))
        if target_id == "chief_of_staff":
            delegation = ""
            handled_by = "ë¹„ì„œì‹¤ì¥"
            header = "ğŸ“‹ **ë¹„ì„œì‹¤ì¥** (ë°°ì¹˜ ì²˜ë¦¬)"
        else:
            delegation = f"ë¹„ì„œì‹¤ì¥ â†’ {target_name}"
            if specs_count:
                delegation += f" â†’ ì „ë¬¸ê°€ {specs_count}ëª…"
            handled_by = target_name
            header = f"ğŸ“‹ **{target_name}** ë³´ê³  (ë°°ì¹˜ ì²´ì¸)"
            if specs_count:
                header += f" (ì†Œì† ì „ë¬¸ê°€ {specs_count}ëª… ë™ì›)"

        final_content = f"{header}\nğŸ’° ë¹„ìš©: ${total_cost:.4f} (ë°°ì¹˜ í• ì¸ ~50% ì ìš©)\n\n---\n\n{content}"

        update_task(task_id, status="completed",
                    result_summary=final_content[:500],
                    result_data=final_content,
                    success=1, cost_usd=total_cost,
                    agent_id=target_id)

        # WebSocketìœ¼ë¡œ ìµœì¢… ê²°ê³¼ ì „ë‹¬
        for c in connected_clients[:]:
            try:
                await c.send_json({
                    "event": "result",
                    "data": {
                        "content": final_content,
                        "sender_id": target_id,
                        "handled_by": handled_by,
                        "delegation": delegation,
                        "time_seconds": 0,
                        "cost": total_cost,
                        "model": synth.get("model", "batch"),
                        "routing_method": "ë°°ì¹˜ ì²´ì¸",
                    }
                })
            except Exception:
                pass

    # í…”ë ˆê·¸ë¨ìœ¼ë¡œë„ ê²°ê³¼ ì „ë‹¬
    tg_content = compiled if chain["mode"] == "broadcast" else final_content
    await _send_batch_result_to_telegram(tg_content, total_cost)

    # ì•„ì¹´ì´ë¸Œì— ì €ì¥
    synth_content = ""
    if chain["mode"] == "broadcast":
        synth_content = compiled
    else:
        synth_content = content

    if synth_content and len(synth_content) > 20:
        division = _AGENT_DIVISION.get(chain.get("target_id", "chief_of_staff"), "secretary")
        now_str = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
        save_archive(
            division=division,
            filename=f"batch_chain_{now_str}.md",
            content=f"# [ë°°ì¹˜ ì²´ì¸] {text[:60]}\n\n{synth_content}",
            agent_id=chain.get("target_id", "chief_of_staff"),
        )

    _save_chain(chain)

    await _broadcast_chain_status(chain, "âœ… ë°°ì¹˜ ì²´ì¸ ì™„ë£Œ â€” ìµœì¢… ë³´ê³ ì„œ ì „ë‹¬ë¨")
    _log(f"[CHAIN] {chain['chain_id']} â€” ì™„ë£Œ! ë¹„ìš©: ${total_cost:.4f}")


async def _advance_batch_chain(chain_id: str):
    """ë°°ì¹˜ ì²´ì¸ì˜ í˜„ì¬ ë‹¨ê³„ë¥¼ í™•ì¸í•˜ê³ , ì™„ë£Œë˜ì—ˆìœ¼ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.

    ë°°ì¹˜ í´ëŸ¬(_batch_poller_loop)ì—ì„œ 60ì´ˆë§ˆë‹¤ í˜¸ì¶œë©ë‹ˆë‹¤.
    """
    chain = _load_chain(chain_id)
    if not chain or chain.get("status") not in ("running", "pending"):
        return

    step = chain.get("step", "")

    # â”€â”€ 1ë‹¨ê³„: ë¶„ë¥˜ â”€â”€
    if step == "classify":
        batch_info = chain["batches"].get("classify")
        if not batch_info:
            return

        status_result = await batch_check(batch_info["batch_id"], batch_info["provider"])
        if "error" in status_result:
            return

        batch_info["status"] = status_result["status"]

        if status_result["status"] == "completed":
            # ë¶„ë¥˜ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            result = await batch_retrieve(batch_info["batch_id"], batch_info["provider"])
            if "error" in result:
                chain["status"] = "failed"
                _save_chain(chain)
                return

            # JSON íŒŒì‹± â€” {"agent_id": "cio_manager", "reason": "..."}
            results_list = result.get("results", [])
            if results_list:
                raw_content = results_list[0].get("content", "").strip()
                cost = results_list[0].get("cost_usd", 0)
                chain["total_cost_usd"] += cost

                try:
                    if "```" in raw_content:
                        raw_content = raw_content.split("```")[1]
                        if raw_content.startswith("json"):
                            raw_content = raw_content[4:]
                    parsed = json.loads(raw_content)
                    target_id = parsed.get("agent_id", "chief_of_staff")
                    reason = parsed.get("reason", "")
                except (json.JSONDecodeError, IndexError):
                    _log(f"[CHAIN] ë¶„ë¥˜ JSON íŒŒì‹± ì‹¤íŒ¨: {raw_content[:100]}")
                    target_id = "chief_of_staff"
                    reason = "ë¶„ë¥˜ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"
            else:
                target_id = "chief_of_staff"
                reason = "ë¶„ë¥˜ ê²°ê³¼ ì—†ìŒ"

            chain["target_id"] = target_id
            chain["results"]["classify"] = {
                "agent_id": target_id,
                "reason": reason,
                "method": "AIë¶„ë¥˜ (ë°°ì¹˜)",
                "cost_usd": cost if results_list else 0,
            }

            target_name = _AGENT_NAMES.get(target_id, target_id)
            _log(f"[CHAIN] {chain['chain_id']} â€” ë¶„ë¥˜ ì™„ë£Œ: {target_name} ({reason})")

            if target_id == "chief_of_staff":
                # ë¹„ì„œì‹¤ì¥ ì§ì ‘ â†’ ì¢…í•© ë‹¨ê³„
                chain["step"] = "synthesis"
                _save_chain(chain)
                await _broadcast_chain_status(chain, f"ğŸ“¦ ë¶„ë¥˜ ì™„ë£Œ: ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬")
                await _chain_submit_synthesis(chain)
            else:
                # ì²˜ì¥ ì§€ì‹œì„œ â†’ ì „ë¬¸ê°€ ë‹¨ê³„ë¡œ ì§„í–‰
                chain["step"] = "delegation"
                _save_chain(chain)
                await _broadcast_chain_status(chain, f"ğŸ“¦ ë¶„ë¥˜ ì™„ë£Œ: {target_name} ì§€ì‹œì„œ ìƒì„± ì¤‘")
                await _chain_create_delegation(chain)

        elif status_result["status"] in ("failed", "expired"):
            # ë¶„ë¥˜ ë°°ì¹˜ ì‹¤íŒ¨ â†’ ë¹„ì„œì‹¤ì¥ í´ë°±
            chain["target_id"] = "chief_of_staff"
            chain["step"] = "synthesis"
            chain["results"]["classify"] = {"agent_id": "chief_of_staff", "method": "í´ë°±"}
            _save_chain(chain)
            await _chain_submit_synthesis(chain)

    # â”€â”€ delegation ì•ˆì „ë§ â”€â”€
    # delegationì€ ì‹¤ì‹œê°„ APIë¡œ ì¦‰ì‹œ ì²˜ë¦¬ë˜ë¯€ë¡œ í´ëŸ¬ê°€ ê´€ì—¬í•  ì¼ì´ ì—†ìŒ.
    # í•˜ì§€ë§Œ _chain_create_delegation() ì¤‘ ì—ëŸ¬ë¡œ stepì´ "delegation"ì— ë©ˆì¶°ìˆìœ¼ë©´
    # ì—¬ê¸°ì„œ ë³µêµ¬í•˜ì—¬ ì „ë¬¸ê°€ ë‹¨ê³„ë¥¼ ì¬ì‹œë„í•©ë‹ˆë‹¤.
    elif step == "delegation":
        # ì´ë¯¸ ì „ë¬¸ê°€ ë°°ì¹˜ê°€ ì œì¶œëœ ìƒíƒœë©´ â†’ specialistsë¡œ ì „í™˜
        if chain["batches"].get("specialists"):
            chain["step"] = "specialists"
            _save_chain(chain)
            _log(f"[CHAIN] {chain_id} â€” delegation ì•ˆì „ë§: specialistsë¡œ ì „í™˜")
        else:
            # ì „ë¬¸ê°€ ë°°ì¹˜ê°€ ì•„ì§ ì œì¶œ ì•ˆ ë¨ â†’ ì§€ì‹œì„œ ìƒì„±ë¶€í„° ì¬ì‹œë„
            _log(f"[CHAIN] {chain_id} â€” delegation ì•ˆì „ë§: ì§€ì‹œì„œ ìƒì„± ì¬ì‹œë„")
            try:
                await _chain_create_delegation(chain)
            except Exception as e:
                _log(f"[CHAIN] {chain_id} â€” delegation ì¬ì‹œë„ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨ ì‹œ ì§€ì‹œì„œ ì—†ì´ ì „ë¬¸ê°€ì—ê²Œ ì§ì ‘ ì „ë‹¬
                chain["step"] = "specialists"
                _save_chain(chain)
                await _chain_submit_specialists(chain)
        return

    # â”€â”€ 3ë‹¨ê³„: ì „ë¬¸ê°€ â”€â”€
    elif step == "specialists":
        all_done = True
        batch_errors = []  # ì˜¤ë¥˜ ì¶”ì 
        for batch_info in chain["batches"].get("specialists", []):
            if batch_info.get("status") in ("pending", "processing"):
                try:
                    status_result = await batch_check(batch_info["batch_id"], batch_info["provider"])
                    if "error" not in status_result:
                        batch_info["status"] = status_result["status"]
                    else:
                        err = status_result.get("error", "ë°°ì¹˜ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨")
                        _log(f"[CHAIN] ì „ë¬¸ê°€ ë°°ì¹˜ í™•ì¸ ì˜¤ë¥˜ ({batch_info['provider']}): {err}")
                        batch_errors.append(f"{batch_info['provider']}: {err[:80]}")
                except Exception as e:
                    _log(f"[CHAIN] ì „ë¬¸ê°€ ë°°ì¹˜ í™•ì¸ ì˜ˆì™¸ ({batch_info.get('provider','?')}): {e}")
                    batch_errors.append(f"{batch_info.get('provider','?')}: {str(e)[:80]}")

            if batch_info.get("status") not in ("completed", "failed"):
                all_done = False

        _save_chain(chain)

        if not all_done:
            # â”€â”€ ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ â†’ ì´ˆë¡ë¶ˆ ìœ ì§€ (ë§¥ë°• íš¨ê³¼) â”€â”€
            # Anthropic/OpenAI/Google í”„ë¡œë°”ì´ë” ë¬´ê´€, ê²°ê³¼ ì—†ëŠ” ì „ë¬¸ê°€ì—ê²Œ ì´ˆë¡ë¶ˆ
            target_id = chain.get("target_id", "")
            specialists = _MANAGER_SPECIALISTS.get(target_id, [])
            for spec_id in specialists:
                spec_res = chain["results"].get("specialists", {}).get(spec_id)
                if spec_res is None:
                    spec_name = _SPECIALIST_NAMES.get(spec_id, spec_id)
                    await _broadcast_status(spec_id, "working", 0.5, f"{spec_name} ë°°ì¹˜ ì²˜ë¦¬ ì¤‘...")
            return

        if all_done:
            # ëª¨ë“  ì „ë¬¸ê°€ ë°°ì¹˜ ì™„ë£Œ â†’ ê²°ê³¼ ìˆ˜ì§‘
            retrieve_errors = []
            for batch_info in chain["batches"]["specialists"]:
                if batch_info.get("status") != "completed":
                    if batch_info.get("status") == "failed":
                        err_detail = batch_info.get("error", "ë°°ì¹˜ ì‹¤íŒ¨")
                        retrieve_errors.append(f"{batch_info['provider']}: {err_detail[:80]}")
                    continue

                result = await batch_retrieve(batch_info["batch_id"], batch_info["provider"])
                if "error" in result:
                    retrieve_errors.append(f"{batch_info['provider']}: {result['error'][:80]}")
                    _log(f"[CHAIN] ì „ë¬¸ê°€ ê²°ê³¼ ìˆ˜ì§‘ ì‹¤íŒ¨ ({batch_info['provider']}): {result['error']}")
                    continue

                for r in result.get("results", []):
                    custom_id = r.get("custom_id", "")
                    mapping = chain["custom_id_map"].get(custom_id, {})
                    agent_id = mapping.get("agent_id", custom_id)

                    chain["results"]["specialists"][agent_id] = {
                        "content": r.get("content", ""),
                        "model": r.get("model", ""),
                        "cost_usd": r.get("cost_usd", 0),
                        "error": r.get("error"),
                    }
                    chain["total_cost_usd"] += r.get("cost_usd", 0)
                    # ì „ë¬¸ê°€ ì´ˆë¡ë¶ˆ ë„ê¸°
                    await _broadcast_status(agent_id, "done", 1.0, "ì™„ë£Œ")

            spec_count = len(chain["results"]["specialists"])
            _log(f"[CHAIN] {chain['chain_id']} â€” ì „ë¬¸ê°€ {spec_count}ëª… ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ")

            # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ì›ì¸ì„ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì „ë‹¬
            if spec_count == 0:
                all_errors = batch_errors + retrieve_errors
                if all_errors:
                    error_summary = " | ".join(all_errors[:3])
                    await _broadcast_chain_status(chain, f"âš ï¸ ì „ë¬¸ê°€ ë°°ì¹˜ ì‹¤íŒ¨ â€” ì›ì¸: {error_summary}")
                else:
                    await _broadcast_chain_status(chain, "âš ï¸ ì „ë¬¸ê°€ ë°°ì¹˜ ê²°ê³¼ ì—†ìŒ â€” ì²˜ì¥ ì§ì ‘ ì²˜ë¦¬ë¡œ ì „í™˜")

            # ì¢…í•© ë‹¨ê³„ë¡œ ì§„í–‰ â€” ì²˜ì¥ ì´ˆë¡ë¶ˆ ì¼œê¸°
            target_id = chain.get("target_id", "chief_of_staff")
            target_name = _AGENT_NAMES.get(target_id, target_id)
            await _broadcast_status(target_id, "working", 0.7, f"{target_name} ì¢…í•©ë³´ê³ ì„œ ì‘ì„± ì¤‘...")

            chain["step"] = "synthesis"
            _save_chain(chain)
            await _broadcast_chain_status(chain, f"ğŸ“¦ ì „ë¬¸ê°€ {spec_count}ëª… ì™„ë£Œ â†’ ì¢…í•©ë³´ê³ ì„œ ì‘ì„± ì‹œì‘")
            await _chain_submit_synthesis(chain)

    # â”€â”€ 4ë‹¨ê³„: ì¢…í•©ë³´ê³ ì„œ â”€â”€
    elif step == "synthesis":
        all_done = True
        synth_errors = []  # ì˜¤ë¥˜ ì¶”ì 
        for batch_info in chain["batches"].get("synthesis", []):
            if batch_info.get("status") in ("pending", "processing"):
                try:
                    status_result = await batch_check(batch_info["batch_id"], batch_info["provider"])
                    if "error" not in status_result:
                        batch_info["status"] = status_result["status"]
                    else:
                        err = status_result.get("error", "ë°°ì¹˜ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨")
                        _log(f"[CHAIN] ì¢…í•© ë°°ì¹˜ í™•ì¸ ì˜¤ë¥˜ ({batch_info['provider']}): {err}")
                        synth_errors.append(f"{batch_info['provider']}: {err[:80]}")
                except Exception as e:
                    _log(f"[CHAIN] ì¢…í•© ë°°ì¹˜ í™•ì¸ ì˜ˆì™¸ ({batch_info.get('provider','?')}): {e}")
                    synth_errors.append(f"{batch_info.get('provider','?')}: {str(e)[:80]}")

            if batch_info.get("status") not in ("completed", "failed"):
                all_done = False

        _save_chain(chain)

        if not all_done:
            # â”€â”€ ì¢…í•©ë³´ê³ ì„œ ë°°ì¹˜ ëŒ€ê¸° ì¤‘ â†’ ì²˜ì¥ ì´ˆë¡ë¶ˆ ìœ ì§€ â”€â”€
            target_id = chain.get("target_id", "chief_of_staff")
            target_name = _AGENT_NAMES.get(target_id, target_id)
            await _broadcast_status(target_id, "working", 0.8, f"{target_name} ì¢…í•©ë³´ê³ ì„œ ì‘ì„± ì¤‘...")
            return

        if all_done:
            # ì¢…í•©ë³´ê³ ì„œ ê²°ê³¼ ìˆ˜ì§‘
            retrieve_errors = []
            for batch_info in chain["batches"]["synthesis"]:
                if batch_info.get("status") != "completed":
                    if batch_info.get("status") == "failed":
                        err_detail = batch_info.get("error", "ë°°ì¹˜ ì‹¤íŒ¨")
                        retrieve_errors.append(f"{batch_info['provider']}: {err_detail[:80]}")
                    continue

                result = await batch_retrieve(batch_info["batch_id"], batch_info["provider"])
                if "error" in result:
                    retrieve_errors.append(f"{batch_info['provider']}: {result['error'][:80]}")
                    _log(f"[CHAIN] ì¢…í•© ê²°ê³¼ ìˆ˜ì§‘ ì‹¤íŒ¨ ({batch_info['provider']}): {result['error']}")
                    continue

                for r in result.get("results", []):
                    custom_id = r.get("custom_id", "")
                    mapping = chain["custom_id_map"].get(custom_id, {})
                    agent_id = mapping.get("agent_id", custom_id)

                    chain["results"]["synthesis"][agent_id] = {
                        "content": r.get("content", ""),
                        "model": r.get("model", ""),
                        "cost_usd": r.get("cost_usd", 0),
                        "error": r.get("error"),
                    }
                    chain["total_cost_usd"] += r.get("cost_usd", 0)

            synth_count = len(chain["results"]["synthesis"])
            _log(f"[CHAIN] {chain['chain_id']} â€” ì¢…í•©ë³´ê³ ì„œ {synth_count}ê°œ ì™„ë£Œ")

            # ì¢…í•© ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ì›ì¸ ì•Œë¦¼ + ì‹¤ì‹œê°„ í´ë°±
            if synth_count == 0:
                all_errors = synth_errors + retrieve_errors
                if all_errors:
                    error_summary = " | ".join(all_errors[:3])
                    await _broadcast_chain_status(chain, f"âš ï¸ ì¢…í•© ë°°ì¹˜ ì‹¤íŒ¨ â€” ì‹¤ì‹œê°„ìœ¼ë¡œ ì¬ì²˜ë¦¬: {error_summary}")
                else:
                    await _broadcast_chain_status(chain, "âš ï¸ ì¢…í•© ë°°ì¹˜ ê²°ê³¼ ì—†ìŒ â€” ì‹¤ì‹œê°„ìœ¼ë¡œ ì¬ì²˜ë¦¬")

                # ì‹¤ì‹œê°„ í´ë°±: ask_ai()ë¡œ ì§ì ‘ ì¢…í•©ë³´ê³ ì„œ ìƒì„±
                await _synthesis_realtime_fallback(chain)
                return

            # ì²˜ì¥ ì´ˆë¡ë¶ˆ ë„ê¸°
            target_id = chain.get("target_id", "chief_of_staff")
            await _broadcast_status(target_id, "done", 1.0, "ë³´ê³  ì™„ë£Œ")

            # ìµœì¢… ì „ë‹¬
            await _deliver_chain_result(chain)


@app.get("/api/batch/chains")
async def get_batch_chains():
    """ì§„í–‰ ì¤‘ì¸ ë°°ì¹˜ ì²´ì¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    chains = load_setting("batch_chains") or []
    active = [c for c in chains if c.get("status") in ("running", "pending")]
    recent_done = [c for c in chains if c.get("status") in ("completed", "failed")][-10:]
    return {"active": active, "recent": recent_done}


# â”€â”€ í¬ë¡  ì‹¤í–‰ ì—”ì§„ (asyncio ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬) â”€â”€

_cron_task = None  # í¬ë¡  ë£¨í”„ íƒœìŠ¤í¬


def _parse_cron_preset(preset: str) -> dict:
    """í¬ë¡  í”„ë¦¬ì…‹ì„ ì‹¤í–‰ ì¡°ê±´ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    presets = {
        "every_minute": {"interval_seconds": 60},
        "every_5min": {"interval_seconds": 300},
        "every_30min": {"interval_seconds": 1800},
        "hourly": {"interval_seconds": 3600},
        "daily_9am": {"hour": 9, "minute": 0},
        "daily_6pm": {"hour": 18, "minute": 0},
        "weekday_9am": {"hour": 9, "minute": 0, "weekday_only": True},
        "monday_9am": {"hour": 9, "minute": 0, "day_of_week": 0},
    }
    return presets.get(preset, {"interval_seconds": 3600})


def _should_run_schedule(schedule: dict, now: datetime) -> bool:
    """í˜„ì¬ ì‹œê°„ì— ì´ ì˜ˆì•½ì„ ì‹¤í–‰í•´ì•¼ í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    if not schedule.get("enabled", False):
        return False

    preset = schedule.get("cron_preset", "")
    cron_config = _parse_cron_preset(preset)

    # ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê°„ í™•ì¸
    last_run = schedule.get("last_run_ts", 0)
    elapsed = now.timestamp() - last_run

    if "interval_seconds" in cron_config:
        return elapsed >= cron_config["interval_seconds"]

    # ì‹œ/ë¶„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„
    if now.hour == cron_config.get("hour", -1) and now.minute == cron_config.get("minute", -1):
        if cron_config.get("weekday_only") and now.weekday() >= 5:
            return False
        if "day_of_week" in cron_config and now.weekday() != cron_config["day_of_week"]:
            return False
        # ê°™ì€ ì‹œê°ì— ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ (ìµœì†Œ 55ì´ˆ ê°„ê²©)
        return elapsed >= 55
    return False


async def _cron_loop():
    """1ë¶„ë§ˆë‹¤ ì˜ˆì•½ëœ ì‘ì—…ì„ í™•ì¸í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤."""
    logger = logging.getLogger("corthex.cron")
    logger.info("í¬ë¡  ì‹¤í–‰ ì—”ì§„ ì‹œì‘")

    while True:
        try:
            await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
            schedules = _load_data("schedules", [])
            now = datetime.now(KST)

            for schedule in schedules:
                if _should_run_schedule(schedule, now):
                    command = schedule.get("command", "")
                    if not command:
                        continue

                    logger.info("í¬ë¡  ì‹¤í–‰: %s â€” %s", schedule.get("name", ""), command)
                    save_activity_log("system", f"â° ì˜ˆì•½ ì‹¤í–‰: {schedule.get('name', '')} â€” {command[:50]}", "info")

                    # ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
                    schedule["last_run"] = now.strftime("%Y-%m-%d %H:%M")
                    schedule["last_run_ts"] = now.timestamp()
                    _save_data("schedules", schedules)

                    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëª…ë ¹ ì‹¤í–‰
                    asyncio.create_task(_run_scheduled_command(command, schedule.get("name", "")))

        except Exception as e:
            logger.error("í¬ë¡  ë£¨í”„ ì—ëŸ¬: %s", e)


async def _run_scheduled_command(command: str, schedule_name: str):
    """ì˜ˆì•½ëœ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    try:
        task = create_task(command, source="cron")
        result = await _process_ai_command(command, task["task_id"])
        save_activity_log("system", f"âœ… ì˜ˆì•½ ì™„ë£Œ: {schedule_name}", "info")
    except Exception as e:
        save_activity_log("system", f"âŒ ì˜ˆì•½ ì‹¤íŒ¨: {schedule_name} â€” {str(e)[:100]}", "error")


@app.get("/api/replay/{correlation_id}")
async def get_replay(correlation_id: str):
    """ë°°ì¹˜ ì²´ì¸ì˜ ë‹¨ê³„ë³„ ê²°ê³¼ë¥¼ íŠ¸ë¦¬ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    chains = load_setting("batch_chains") or []

    # correlation_id ë˜ëŠ” chain_idë¡œ ê²€ìƒ‰
    chain = None
    for c in chains:
        if c.get("correlation_id") == correlation_id:
            chain = c
            break
        if c.get("chain_id") == correlation_id.replace("batch_", ""):
            chain = c
            break

    if not chain:
        return {"steps": [], "error": "ì²´ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    steps = []

    # 1ë‹¨ê³„: ë¶„ë¥˜
    classify = chain.get("results", {}).get("classify")
    if classify:
        agent_name = _AGENT_NAMES.get(classify.get("agent_id", ""), classify.get("agent_id", ""))
        steps.append({
            "step": "classify",
            "step_label": "1ë‹¨ê³„: ë¶„ë¥˜",
            "agent": classify.get("method", "AI ë¶„ë¥˜"),
            "agent_name": agent_name,
            "result": classify.get("reason", f"â†’ {agent_name}"),
            "cost_usd": classify.get("cost_usd", 0),
        })

    # 2ë‹¨ê³„: ì²˜ì¥ ì§€ì‹œì„œ
    delegation = chain.get("results", {}).get("delegation")
    if delegation:
        if delegation.get("mode") == "broadcast":
            for mgr_id, instructions in delegation.get("delegations", {}).items():
                mgr_name = _AGENT_NAMES.get(mgr_id, mgr_id)
                spec_instructions = []
                for s_id, instruction in instructions.items():
                    s_name = _SPECIALIST_NAMES.get(s_id, s_id)
                    spec_instructions.append(f"**{s_name}**: {instruction}")
                steps.append({
                    "step": "delegation",
                    "step_label": "2ë‹¨ê³„: ì²˜ì¥ ì§€ì‹œì„œ",
                    "agent": mgr_id,
                    "agent_name": mgr_name,
                    "result": "\n".join(spec_instructions) if spec_instructions else "ì§€ì‹œì„œ ì—†ìŒ",
                })
        else:
            deleg_agent = delegation.get("agent_id", "")
            deleg_name = _AGENT_NAMES.get(deleg_agent, deleg_agent)
            instructions = delegation.get("instructions", {})
            spec_instructions = []
            for s_id, instruction in instructions.items():
                s_name = _SPECIALIST_NAMES.get(s_id, s_id)
                spec_instructions.append(f"**{s_name}**: {instruction}")
            steps.append({
                "step": "delegation",
                "step_label": "2ë‹¨ê³„: ì²˜ì¥ ì§€ì‹œì„œ",
                "agent": deleg_agent,
                "agent_name": deleg_name,
                "result": "\n".join(spec_instructions) if spec_instructions else "ì§€ì‹œì„œ ì—†ìŒ",
                "cost_usd": delegation.get("cost_usd", 0),
            })

    # 3ë‹¨ê³„: ì „ë¬¸ê°€ ê²°ê³¼
    specialists = chain.get("results", {}).get("specialists", {})
    for s_id, s_res in specialists.items():
        s_name = _SPECIALIST_NAMES.get(s_id, s_id)
        steps.append({
            "step": "specialist",
            "step_label": "3ë‹¨ê³„: ì „ë¬¸ê°€ ë¶„ì„",
            "agent": s_id,
            "agent_name": s_name,
            "result": s_res.get("content", "")[:2000],
            "model": s_res.get("model", ""),
            "cost_usd": s_res.get("cost_usd", 0),
            "error": s_res.get("error"),
        })

    # 4ë‹¨ê³„: ì¢…í•©ë³´ê³ ì„œ
    synthesis = chain.get("results", {}).get("synthesis", {})
    for mgr_id, synth_res in synthesis.items():
        mgr_name = _AGENT_NAMES.get(mgr_id, mgr_id)
        steps.append({
            "step": "synthesis",
            "step_label": "4ë‹¨ê³„: ì¢…í•©ë³´ê³ ì„œ",
            "agent": mgr_id,
            "agent_name": mgr_name,
            "result": synth_res.get("content", "")[:2000],
            "model": synth_res.get("model", ""),
            "cost_usd": synth_res.get("cost_usd", 0),
        })

    return {
        "steps": steps,
        "chain_id": chain.get("chain_id", ""),
        "mode": chain.get("mode", ""),
        "status": chain.get("status", ""),
        "total_cost_usd": chain.get("total_cost_usd", 0),
    }


@app.get("/api/replay/latest")
async def get_replay_latest():
    """ê°€ì¥ ìµœê·¼ ì™„ë£Œëœ ë°°ì¹˜ ì²´ì¸ì˜ replayë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    chains = load_setting("batch_chains") or []
    completed = [c for c in chains if c.get("status") == "completed"]
    if not completed:
        return {"steps": []}
    latest = max(completed, key=lambda c: c.get("completed_at", ""))
    corr_id = latest.get("correlation_id", "")
    if corr_id:
        return await get_replay(corr_id)
    return {"steps": []}


# â”€â”€ ì˜ˆì•½ (ìŠ¤ì¼€ì¤„) ê´€ë¦¬ â”€â”€

@app.get("/api/schedules")
async def get_schedules():
    return _load_data("schedules", [])


@app.post("/api/schedules")
async def add_schedule(request: Request):
    """ìƒˆ ì˜ˆì•½ ì¶”ê°€."""
    body = await request.json()
    schedules = _load_data("schedules", [])
    schedule_id = f"sch_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{len(schedules)}"
    schedule = {
        "id": schedule_id,
        "name": body.get("name", ""),
        "command": body.get("command", ""),
        "cron": body.get("cron", ""),
        "cron_preset": body.get("cron_preset", ""),
        "description": body.get("description", ""),
        "enabled": True,
        "created_at": datetime.now(KST).isoformat(),
    }
    schedules.append(schedule)
    _save_data("schedules", schedules)
    return {"success": True, "schedule": schedule}


@app.post("/api/schedules/{schedule_id}/toggle")
async def toggle_schedule(schedule_id: str):
    """ì˜ˆì•½ í™œì„±í™”/ë¹„í™œì„±í™”."""
    schedules = _load_data("schedules", [])
    for s in schedules:
        if s.get("id") == schedule_id:
            s["enabled"] = not s.get("enabled", True)
            _save_data("schedules", schedules)
            return {"success": True, "enabled": s["enabled"]}
    return {"success": False, "error": "not found"}


@app.delete("/api/schedules/{schedule_id}")
async def delete_schedule(schedule_id: str):
    """ì˜ˆì•½ ì‚­ì œ."""
    schedules = _load_data("schedules", [])
    schedules = [s for s in schedules if s.get("id") != schedule_id]
    _save_data("schedules", schedules)
    return {"success": True}


# â”€â”€ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ â”€â”€

@app.get("/api/workflows")
async def get_workflows():
    return _load_data("workflows", [])


@app.post("/api/workflows")
async def create_workflow(request: Request):
    """ìƒˆ ì›Œí¬í”Œë¡œìš° ìƒì„±."""
    body = await request.json()
    workflows = _load_data("workflows", [])
    wf_id = f"wf_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{len(workflows)}"
    workflow = {
        "id": wf_id,
        "name": body.get("name", "ìƒˆ ì›Œí¬í”Œë¡œìš°"),
        "description": body.get("description", ""),
        "steps": body.get("steps", []),
        "created_at": datetime.now(KST).isoformat(),
    }
    workflows.append(workflow)
    _save_data("workflows", workflows)
    return {"success": True, "workflow": workflow}


@app.put("/api/workflows/{wf_id}")
async def save_workflow(wf_id: str, request: Request):
    """ì›Œí¬í”Œë¡œìš° ìˆ˜ì •."""
    body = await request.json()
    workflows = _load_data("workflows", [])
    for wf in workflows:
        if wf.get("id") == wf_id:
            wf["name"] = body.get("name", wf.get("name", ""))
            wf["description"] = body.get("description", wf.get("description", ""))
            wf["steps"] = body.get("steps", wf.get("steps", []))
            _save_data("workflows", workflows)
            return {"success": True, "workflow": wf}
    return {"success": False, "error": "not found"}


@app.delete("/api/workflows/{wf_id}")
async def delete_workflow(wf_id: str):
    """ì›Œí¬í”Œë¡œìš° ì‚­ì œ."""
    workflows = _load_data("workflows", [])
    workflows = [w for w in workflows if w.get("id") != wf_id]
    _save_data("workflows", workflows)
    return {"success": True}


@app.post("/api/workflows/{wf_id}/run")
async def run_workflow(wf_id: str):
    """ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤ â€” ìŠ¤í…ì„ ìˆœì„œëŒ€ë¡œ AIë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    workflows = _load_data("workflows", [])
    wf = None
    for w in workflows:
        if w.get("id") == wf_id:
            wf = w
            break
    if not wf:
        return {"success": False, "error": "ì›Œí¬í”Œë¡œìš°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    steps = wf.get("steps", [])
    if not steps:
        return {"success": False, "error": "ì›Œí¬í”Œë¡œìš°ì— ì‹¤í–‰í•  ë‹¨ê³„ê°€ ì—†ìŠµë‹ˆë‹¤"}

    if not is_ai_ready():
        return {"success": False, "error": "AIê°€ ì—°ê²°ë˜ì§€ ì•Šì•„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆœì°¨ ì‹¤í–‰
    asyncio.create_task(_run_workflow_steps(wf_id, wf.get("name", ""), steps))
    return {"success": True, "message": f"ì›Œí¬í”Œë¡œìš° '{wf.get('name', '')}' ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤ ({len(steps)}ë‹¨ê³„)"}


async def _run_workflow_steps(wf_id: str, wf_name: str, steps: list):
    """ì›Œí¬í”Œë¡œìš° ìŠ¤í…ì„ ìˆœì°¨ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    save_activity_log("system", f"ğŸ”„ ì›Œí¬í”Œë¡œìš° ì‹œì‘: {wf_name} ({len(steps)}ë‹¨ê³„)", "info")
    results = []
    prev_result = ""

    for i, step in enumerate(steps):
        step_name = step.get("name", f"ë‹¨ê³„ {i+1}")
        command = step.get("command", "")
        if not command:
            continue

        # ì´ì „ ë‹¨ê³„ ê²°ê³¼ë¥¼ ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡ ëª…ë ¹ì— ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if prev_result and i > 0:
            command = f"[ì´ì „ ë‹¨ê³„ ê²°ê³¼ ì°¸ê³ : {prev_result[:500]}]\n\n{command}"

        save_activity_log("system", f"â–¶ {wf_name} â€” {step_name} ì‹¤í–‰ ì¤‘", "info")
        # ì›¹ì†Œì¼“ìœ¼ë¡œ ë‹¨ê³„ ì‹œì‘ ì•Œë¦¼
        await _broadcast_workflow_progress(i, len(steps), "running", step_name, "", workflow_id=wf_id)

        try:
            task = create_task(command, source="workflow")
            result = await _process_ai_command(command, task["task_id"])
            content = result.get("content", "") if isinstance(result, dict) else str(result)
            prev_result = content[:500]
            results.append({"step": step_name, "status": "completed", "result": content[:200]})
            save_activity_log("system", f"âœ… {wf_name} â€” {step_name} ì™„ë£Œ", "info")
            # ì›¹ì†Œì¼“ìœ¼ë¡œ ë‹¨ê³„ ì™„ë£Œ ì•Œë¦¼
            await _broadcast_workflow_progress(i, len(steps), "completed", step_name, content[:300], workflow_id=wf_id)
        except Exception as e:
            results.append({"step": step_name, "status": "failed", "error": str(e)[:200]})
            save_activity_log("system", f"âŒ {wf_name} â€” {step_name} ì‹¤íŒ¨: {str(e)[:100]}", "error")
            await _broadcast_workflow_progress(i, len(steps), "failed", step_name, str(e)[:200], workflow_id=wf_id)
            break  # ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨

    # ì „ì²´ ì™„ë£Œ ì•Œë¦¼
    final_result = "\n\n".join([f"**{r['step']}**: {r.get('result', r.get('error', ''))}" for r in results])
    await _broadcast_workflow_progress(-1, len(steps), "done", "", final_result, workflow_done=True, workflow_id=wf_id)
    save_activity_log("system", f"ğŸ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ: {wf_name} â€” {len(results)}/{len(steps)} ë‹¨ê³„ ì²˜ë¦¬", "info")


async def _broadcast_workflow_progress(step_index: int, total_steps: int, status: str,
                                        step_name: str, result: str, workflow_done: bool = False,
                                        workflow_id: str = ""):
    """ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒíƒœë¥¼ ì›¹ì†Œì¼“ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤."""
    msg = {
        "event": "workflow_progress",
        "data": {
            "workflow_id": workflow_id,
            "step_index": step_index,
            "total_steps": total_steps,
            "status": status,
            "step_name": step_name,
            "result": result,
            "workflow_done": workflow_done,
            "final_result": result if workflow_done else "",
        },
    }
    for ws in list(connected_clients):
        try:
            await ws.send_json(msg)
        except Exception:
            pass


# â”€â”€ ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ (í‚¤ì›€ì¦ê¶Œ í”„ë ˆì„ì›Œí¬) â”€â”€

_trading_bot_active = False  # ìë™ë§¤ë§¤ ë´‡ ON/OFF
_trading_bot_task = None     # ìë™ë§¤ë§¤ ë´‡ asyncio Task


def _default_portfolio() -> dict:
    """ê¸°ë³¸ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°."""
    return {
        "cash": 50_000_000,    # ì´ˆê¸° í˜„ê¸ˆ (5ì²œë§Œì›)
        "initial_cash": 50_000_000,
        "holdings": [],        # [{ticker, name, qty, avg_price, current_price}]
        "updated_at": datetime.now(KST).isoformat(),
    }


def _default_trading_settings() -> dict:
    """ê¸°ë³¸ ìë™ë§¤ë§¤ ì„¤ì •."""
    return {
        "max_position_pct": 20,       # ì¢…ëª©ë‹¹ ìµœëŒ€ ë¹„ì¤‘ (%)
        "max_daily_trades": 10,       # ì¼ì¼ ìµœëŒ€ ê±°ë˜ íšŸìˆ˜
        "max_daily_loss_pct": 3,      # ì¼ì¼ ìµœëŒ€ ì†ì‹¤ (%)
        "default_stop_loss_pct": -5,  # ê¸°ë³¸ ì†ì ˆ (%)
        "default_take_profit_pct": 10, # ê¸°ë³¸ ìµì ˆ (%)
        "order_size": 1_000_000,      # ê¸°ë³¸ ì£¼ë¬¸ ê¸ˆì•¡ (ì›)
        "trading_hours_kr": {"start": "09:00", "end": "15:20"},   # í•œêµ­ ì¥ ì‹œê°„
        "trading_hours_us": {"start": "22:30", "end": "05:00"},   # ë¯¸êµ­ ì¥ ì‹œê°„ (KST ê¸°ì¤€, ì„œë¨¸íƒ€ì„ ì‹œ 23:30)
        "trading_hours": {"start": "09:00", "end": "15:20"},      # í•˜ìœ„í˜¸í™˜
        "auto_stop_loss": True,       # ìë™ ì†ì ˆ í™œì„±í™”
        "auto_take_profit": True,     # ìë™ ìµì ˆ í™œì„±í™”
        "auto_execute": False,        # CIO ì‹œê·¸ë„ ê¸°ë°˜ ìë™ ì£¼ë¬¸ ì‹¤í–‰ (ì•ˆì „ì¥ì¹˜: ê¸°ë³¸ OFF)
        "min_confidence": 70,         # ìë™ë§¤ë§¤ ìµœì†Œ ì‹ ë¢°ë„ (%)
        "kiwoom_connected": False,    # í‚¤ì›€ì¦ê¶Œ API ì—°ê²° ì—¬ë¶€
        "paper_trading": True,        # ëª¨ì˜íˆ¬ì ëª¨ë“œ (ì‹¤ê±°ë˜ ì „)
    }


@app.get("/api/trading/summary")
async def get_trading_summary():
    """íŠ¸ë ˆì´ë”© ëŒ€ì‹œë³´ë“œ ìš”ì•½ ë°ì´í„°."""
    portfolio = _load_data("trading_portfolio", _default_portfolio())
    strategies = _load_data("trading_strategies", [])
    watchlist = _load_data("trading_watchlist", [])
    history = _load_data("trading_history", [])
    signals = _load_data("trading_signals", [])
    settings = _load_data("trading_settings", _default_trading_settings())

    # í¬íŠ¸í´ë¦¬ì˜¤ í‰ê°€ ê³„ì‚°
    holdings = portfolio.get("holdings", [])
    total_eval = sum(h.get("current_price", 0) * h.get("qty", 0) for h in holdings)
    total_buy_cost = sum(h.get("avg_price", 0) * h.get("qty", 0) for h in holdings)
    cash = portfolio.get("cash", 0)
    total_asset = cash + total_eval
    total_pnl = total_eval - total_buy_cost
    pnl_pct = (total_pnl / total_buy_cost * 100) if total_buy_cost > 0 else 0

    # ì˜¤ëŠ˜ ê±°ë˜ ì§‘ê³„
    today_str = datetime.now(KST).strftime("%Y-%m-%d")
    today_trades = [t for t in history if t.get("date", "").startswith(today_str)]
    today_pnl = sum(t.get("pnl", 0) for t in today_trades)

    active_strategies = [s for s in strategies if s.get("active")]

    return {
        "portfolio": {
            "cash": cash,
            "total_eval": total_eval,
            "total_asset": total_asset,
            "total_pnl": total_pnl,
            "pnl_pct": round(pnl_pct, 2),
            "holdings_count": len(holdings),
            "initial_cash": portfolio.get("initial_cash", 50_000_000),
        },
        "strategies": {
            "total": len(strategies),
            "active": len(active_strategies),
        },
        "watchlist_count": len(watchlist),
        "today": {
            "trades": len(today_trades),
            "pnl": today_pnl,
        },
        "signals_count": len(signals),
        "settings": settings,
        "bot_active": _trading_bot_active,
    }


@app.get("/api/trading/portfolio")
async def get_trading_portfolio():
    """í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ë°ì´í„°."""
    portfolio = _load_data("trading_portfolio", _default_portfolio())
    return portfolio


@app.post("/api/trading/portfolio")
async def update_trading_portfolio(request: Request):
    """í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸ (ì´ˆê¸° ìê¸ˆ ì„¤ì • ë“±)."""
    body = await request.json()
    portfolio = _load_data("trading_portfolio", _default_portfolio())

    if "cash" in body:
        portfolio["cash"] = body["cash"]
    if "initial_cash" in body:
        portfolio["initial_cash"] = body["initial_cash"]
        portfolio["cash"] = body["initial_cash"]
        portfolio["holdings"] = []
    portfolio["updated_at"] = datetime.now(KST).isoformat()

    _save_data("trading_portfolio", portfolio)
    save_activity_log("system", f"ğŸ’° í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸: í˜„ê¸ˆ {portfolio['cash']:,.0f}ì›", "info")
    return {"success": True, "portfolio": portfolio}


@app.get("/api/trading/strategies")
async def get_trading_strategies():
    """ë§¤ë§¤ ì „ëµ ëª©ë¡."""
    return _load_data("trading_strategies", [])


@app.post("/api/trading/strategies")
async def save_trading_strategy(request: Request):
    """ë§¤ë§¤ ì „ëµ ì¶”ê°€/ìˆ˜ì •."""
    body = await request.json()
    strategies = _load_data("trading_strategies", [])

    strategy_id = body.get("id") or f"strat_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{len(strategies)}"

    existing = next((s for s in strategies if s.get("id") == strategy_id), None)
    if existing:
        existing.update({
            "name": body.get("name", existing.get("name", "")),
            "type": body.get("type", existing.get("type", "manual")),
            "indicator": body.get("indicator", existing.get("indicator", "")),
            "buy_condition": body.get("buy_condition", existing.get("buy_condition", "")),
            "sell_condition": body.get("sell_condition", existing.get("sell_condition", "")),
            "target_tickers": body.get("target_tickers", existing.get("target_tickers", [])),
            "stop_loss_pct": body.get("stop_loss_pct", existing.get("stop_loss_pct", -5)),
            "take_profit_pct": body.get("take_profit_pct", existing.get("take_profit_pct", 10)),
            "order_size": body.get("order_size", existing.get("order_size", 1_000_000)),
            "active": body.get("active", existing.get("active", True)),
            "updated_at": datetime.now(KST).isoformat(),
        })
    else:
        strategy = {
            "id": strategy_id,
            "name": body.get("name", "ìƒˆ ì „ëµ"),
            "type": body.get("type", "manual"),
            "indicator": body.get("indicator", ""),
            "buy_condition": body.get("buy_condition", ""),
            "sell_condition": body.get("sell_condition", ""),
            "target_tickers": body.get("target_tickers", []),
            "stop_loss_pct": body.get("stop_loss_pct", -5),
            "take_profit_pct": body.get("take_profit_pct", 10),
            "order_size": body.get("order_size", 1_000_000),
            "active": body.get("active", True),
            "created_at": datetime.now(KST).isoformat(),
            "updated_at": datetime.now(KST).isoformat(),
        }
        strategies.append(strategy)

    _save_data("trading_strategies", strategies)
    save_activity_log("system", f"ğŸ“Š ë§¤ë§¤ ì „ëµ ì €ì¥: {body.get('name', strategy_id)}", "info")
    return {"success": True, "strategies": strategies}


@app.delete("/api/trading/strategies/{strategy_id}")
async def delete_trading_strategy(strategy_id: str):
    """ë§¤ë§¤ ì „ëµ ì‚­ì œ."""
    strategies = _load_data("trading_strategies", [])
    strategies = [s for s in strategies if s.get("id") != strategy_id]
    _save_data("trading_strategies", strategies)
    return {"success": True}


@app.put("/api/trading/strategies/{strategy_id}/toggle")
async def toggle_trading_strategy(strategy_id: str):
    """ë§¤ë§¤ ì „ëµ í™œì„±/ë¹„í™œì„± í† ê¸€."""
    strategies = _load_data("trading_strategies", [])
    for s in strategies:
        if s.get("id") == strategy_id:
            s["active"] = not s.get("active", True)
            _save_data("trading_strategies", strategies)
            return {"success": True, "active": s["active"]}
    return {"success": False, "error": "ì „ëµì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}


@app.get("/api/trading/watchlist")
async def get_trading_watchlist():
    """ê´€ì‹¬ ì¢…ëª© ëª©ë¡."""
    return _load_data("trading_watchlist", [])


@app.post("/api/trading/watchlist")
async def add_trading_watchlist(request: Request):
    """ê´€ì‹¬ ì¢…ëª© ì¶”ê°€."""
    body = await request.json()
    watchlist = _load_data("trading_watchlist", [])

    ticker = body.get("ticker", "")
    if not ticker:
        return {"success": False, "error": "ì¢…ëª©ì½”ë“œ í•„ìˆ˜"}

    # ì¤‘ë³µ ì²´í¬
    if any(w.get("ticker") == ticker for w in watchlist):
        return {"success": False, "error": "ì´ë¯¸ ë“±ë¡ëœ ì¢…ëª©"}

    item = {
        "ticker": ticker,
        "name": body.get("name", ticker),
        "market": body.get("market", "KR"),
        "target_price": body.get("target_price", 0),
        "alert_type": body.get("alert_type", "above"),
        "notes": body.get("notes", ""),
        "added_at": datetime.now(KST).isoformat(),
    }
    watchlist.append(item)
    _save_data("trading_watchlist", watchlist)
    save_activity_log("system", f"ğŸ‘ï¸ ê´€ì‹¬ì¢…ëª© ì¶”ê°€: {item['name']} ({ticker})", "info")
    return {"success": True, "watchlist": watchlist}


@app.delete("/api/trading/watchlist/{ticker}")
async def remove_trading_watchlist(ticker: str):
    """ê´€ì‹¬ ì¢…ëª© ì‚­ì œ."""
    watchlist = _load_data("trading_watchlist", [])
    watchlist = [w for w in watchlist if w.get("ticker") != ticker]
    _save_data("trading_watchlist", watchlist)
    return {"success": True}


@app.get("/api/trading/watchlist/prices")
async def get_watchlist_prices():
    """ê´€ì‹¬ì¢…ëª©ì˜ ì‹¤ì‹œê°„ í˜„ì¬ê°€ë¥¼ ì¡°íšŒ.

    í•œêµ­ ì£¼ì‹: pykrx ë¼ì´ë¸ŒëŸ¬ë¦¬ (í•œêµ­ê±°ë˜ì†Œ ë¬´ë£Œ ë°ì´í„°)
    ë¯¸êµ­ ì£¼ì‹: yfinance ë¼ì´ë¸ŒëŸ¬ë¦¬ (Yahoo Finance ë¬´ë£Œ ë°ì´í„°)
    """
    watchlist = _load_data("trading_watchlist", [])
    if not watchlist:
        return {"prices": {}, "updated_at": datetime.now(KST).isoformat()}

    prices = {}

    # --- í•œêµ­ ì£¼ì‹ (pykrx) ---
    kr_tickers = [w for w in watchlist if w.get("market", "KR") == "KR"]
    if kr_tickers:
        try:
            from pykrx import stock as pykrx_stock
            today = datetime.now(KST).strftime("%Y%m%d")
            # ìµœê·¼ 5ì˜ì—…ì¼ ë²”ìœ„ë¡œ ì¡°íšŒ (ì£¼ë§/ê³µíœ´ì¼ ëŒ€ë¹„)
            start = (datetime.now(KST) - timedelta(days=7)).strftime("%Y%m%d")
            for w in kr_tickers:
                try:
                    df = await asyncio.to_thread(
                        pykrx_stock.get_market_ohlcv_by_date, start, today, w["ticker"]
                    )
                    if df is not None and not df.empty:
                        latest = df.iloc[-1]
                        prev = df.iloc[-2] if len(df) >= 2 else latest
                        close = int(latest["ì¢…ê°€"])
                        prev_close = int(prev["ì¢…ê°€"])
                        change = close - prev_close
                        change_pct = round((change / prev_close) * 100, 2) if prev_close else 0
                        prices[w["ticker"]] = {
                            "current_price": close,
                            "prev_close": prev_close,
                            "change": change,
                            "change_pct": change_pct,
                            "volume": int(latest.get("ê±°ë˜ëŸ‰", 0)),
                            "high": int(latest.get("ê³ ê°€", 0)),
                            "low": int(latest.get("ì €ê°€", 0)),
                            "currency": "KRW",
                        }
                except Exception as e:
                    logger.warning("í•œêµ­ ì£¼ê°€ ì¡°íšŒ ì‹¤íŒ¨ %s: %s", w["ticker"], e)
                    prices[w["ticker"]] = {"error": str(e)}
        except ImportError:
            for w in kr_tickers:
                prices[w["ticker"]] = {"error": "pykrx ë¯¸ì„¤ì¹˜"}

    # --- ë¯¸êµ­ ì£¼ì‹ (yfinance) ---
    us_tickers = [w for w in watchlist if w.get("market") == "US"]
    if us_tickers:
        try:
            import yfinance as yf
            for w in us_tickers:
                try:
                    ticker_obj = yf.Ticker(w["ticker"])
                    hist = await asyncio.to_thread(
                        lambda t=ticker_obj: t.history(period="5d")
                    )
                    if hist is not None and not hist.empty:
                        latest = hist.iloc[-1]
                        prev = hist.iloc[-2] if len(hist) >= 2 else latest
                        close = round(float(latest["Close"]), 2)
                        prev_close = round(float(prev["Close"]), 2)
                        change = round(close - prev_close, 2)
                        change_pct = round((change / prev_close) * 100, 2) if prev_close else 0
                        prices[w["ticker"]] = {
                            "current_price": close,
                            "prev_close": prev_close,
                            "change": change,
                            "change_pct": change_pct,
                            "volume": int(latest.get("Volume", 0)),
                            "high": round(float(latest.get("High", 0)), 2),
                            "low": round(float(latest.get("Low", 0)), 2),
                            "currency": "USD",
                        }
                except Exception as e:
                    logger.warning("ë¯¸êµ­ ì£¼ê°€ ì¡°íšŒ ì‹¤íŒ¨ %s: %s", w["ticker"], e)
                    prices[w["ticker"]] = {"error": str(e)}
        except ImportError:
            for w in us_tickers:
                prices[w["ticker"]] = {"error": "yfinance ë¯¸ì„¤ì¹˜"}

    return {"prices": prices, "updated_at": datetime.now(KST).isoformat()}


@app.get("/api/trading/watchlist/chart/{ticker}")
async def get_watchlist_chart(ticker: str, market: str = "KR", days: int = 30):
    """ê´€ì‹¬ì¢…ëª©ì˜ ì¼ë³„ ê°€ê²© ë°ì´í„° (ì°¨íŠ¸ìš©).

    ê°„ë‹¨í•œ ì¼ë³„ ì¢…ê°€ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì„  ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
    """
    chart_data = []

    if market == "KR":
        try:
            from pykrx import stock as pykrx_stock
            end = datetime.now(KST).strftime("%Y%m%d")
            start = (datetime.now(KST) - timedelta(days=days + 10)).strftime("%Y%m%d")
            df = await asyncio.to_thread(
                pykrx_stock.get_market_ohlcv_by_date, start, end, ticker
            )
            if df is not None and not df.empty:
                for date, row in df.tail(days).iterrows():
                    chart_data.append({
                        "date": date.strftime("%m/%d"),
                        "close": int(row["ì¢…ê°€"]),
                        "volume": int(row.get("ê±°ë˜ëŸ‰", 0)),
                    })
        except ImportError:
            return {"ticker": ticker, "chart": [], "error": "pykrx ë¯¸ì„¤ì¹˜"}
        except Exception as e:
            return {"ticker": ticker, "chart": [], "error": str(e)}
    else:
        try:
            import yfinance as yf
            ticker_obj = yf.Ticker(ticker)
            period = "1mo" if days <= 30 else "3mo"
            hist = await asyncio.to_thread(
                lambda t=ticker_obj, p=period: t.history(period=p)
            )
            if hist is not None and not hist.empty:
                for date, row in hist.tail(days).iterrows():
                    chart_data.append({
                        "date": date.strftime("%m/%d"),
                        "close": round(float(row["Close"]), 2),
                        "volume": int(row.get("Volume", 0)),
                    })
        except ImportError:
            return {"ticker": ticker, "chart": [], "error": "yfinance ë¯¸ì„¤ì¹˜"}
        except Exception as e:
            return {"ticker": ticker, "chart": [], "error": str(e)}

    return {"ticker": ticker, "chart": chart_data}


@app.post("/api/trading/order")
async def execute_trading_order(request: Request):
    """ëª¨ì˜ ì£¼ë¬¸ ì‹¤í–‰ (ë§¤ìˆ˜/ë§¤ë„).

    ì‹¤ì œ í‚¤ì›€ì¦ê¶Œ API ì—°ê²° ì „ê¹Œì§€ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    body = await request.json()
    action = body.get("action", "")  # "buy" or "sell"
    ticker = body.get("ticker", "")
    name = body.get("name", ticker)
    qty = int(body.get("qty", 0))
    price = int(body.get("price", 0))

    if not all([action in ("buy", "sell"), ticker, qty > 0, price > 0]):
        return {"success": False, "error": "ë§¤ìˆ˜/ë§¤ë„, ì¢…ëª©ì½”ë“œ, ìˆ˜ëŸ‰, ê°€ê²© í•„ìˆ˜"}

    portfolio = _load_data("trading_portfolio", _default_portfolio())
    total_amount = qty * price

    if action == "buy":
        if portfolio["cash"] < total_amount:
            return {"success": False, "error": f"í˜„ê¸ˆ ë¶€ì¡±: í•„ìš” {total_amount:,.0f}ì›, ë³´ìœ  {portfolio['cash']:,.0f}ì›"}

        # ê¸°ì¡´ ë³´ìœ  ì¢…ëª© í™•ì¸ (í‰ë‹¨ ê³„ì‚°)
        holding = next((h for h in portfolio["holdings"] if h["ticker"] == ticker), None)
        if holding:
            old_total = holding["avg_price"] * holding["qty"]
            new_total = old_total + total_amount
            holding["qty"] += qty
            holding["avg_price"] = int(new_total / holding["qty"])
            holding["current_price"] = price
        else:
            portfolio["holdings"].append({
                "ticker": ticker,
                "name": name,
                "qty": qty,
                "avg_price": price,
                "current_price": price,
            })

        portfolio["cash"] -= total_amount

    elif action == "sell":
        holding = next((h for h in portfolio["holdings"] if h["ticker"] == ticker), None)
        if not holding:
            return {"success": False, "error": f"{name} ë³´ìœ í•˜ì§€ ì•ŠìŒ"}
        if holding["qty"] < qty:
            return {"success": False, "error": f"ë³´ìœ  ìˆ˜ëŸ‰ ë¶€ì¡±: ë³´ìœ  {holding['qty']}ì£¼, ë§¤ë„ {qty}ì£¼"}

        pnl = (price - holding["avg_price"]) * qty
        holding["qty"] -= qty
        holding["current_price"] = price

        if holding["qty"] == 0:
            portfolio["holdings"] = [h for h in portfolio["holdings"] if h["ticker"] != ticker]

        portfolio["cash"] += total_amount

    portfolio["updated_at"] = datetime.now(KST).isoformat()
    _save_data("trading_portfolio", portfolio)

    # ê±°ë˜ ë‚´ì—­ ì €ì¥
    history = _load_data("trading_history", [])
    trade = {
        "id": f"trade_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{len(history)}",
        "date": datetime.now(KST).isoformat(),
        "ticker": ticker,
        "name": name,
        "action": action,
        "qty": qty,
        "price": price,
        "total": total_amount,
        "pnl": pnl if action == "sell" else 0,
        "strategy": body.get("strategy", "manual"),
        "status": "executed",
    }
    history.insert(0, trade)
    if len(history) > 500:
        history = history[:500]
    _save_data("trading_history", history)

    action_ko = "ë§¤ìˆ˜" if action == "buy" else "ë§¤ë„"
    pnl_str = f" (ì†ìµ: {pnl:+,.0f}ì›)" if action == "sell" else ""
    save_activity_log("system",
        f"{'ğŸ“ˆ' if action == 'buy' else 'ğŸ“‰'} {action_ko}: {name} {qty}ì£¼ Ã— {price:,.0f}ì› = {total_amount:,.0f}ì›{pnl_str}",
        "info")

    return {"success": True, "trade": trade, "portfolio": portfolio}


@app.get("/api/trading/history")
async def get_trading_history():
    """ê±°ë˜ ë‚´ì—­."""
    return _load_data("trading_history", [])


@app.get("/api/trading/signals")
async def get_trading_signals():
    """ë§¤ë§¤ ì‹œê·¸ë„ ëª©ë¡."""
    return _load_data("trading_signals", [])


@app.delete("/api/trading/signals/{signal_id}")
async def delete_trading_signal(signal_id: str):
    """ê°œë³„ ë§¤ë§¤ ì‹œê·¸ë„ ì‚­ì œ."""
    signals = _load_data("trading_signals", [])
    new_signals = [s for s in signals if s.get("id") != signal_id]
    if len(new_signals) == len(signals):
        return {"success": False, "error": "ì‹œê·¸ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
    _save_data("trading_signals", new_signals)
    return {"success": True}


@app.post("/api/trading/signals/generate")
async def generate_trading_signals():
    """CIO(íˆ¬ìë¶„ì„ì²˜ì¥) + 4ëª… ì „ë¬¸ê°€ê°€ ê´€ì‹¬ì¢…ëª©ì„ ë¶„ì„ â†’ ë§¤ë§¤ ì‹œê·¸ë„ ìƒì„±.

    íë¦„:
    1. ì‹œí™©ë¶„ì„ Specialist â†’ ê±°ì‹œê²½ì œ/ì‹œì¥ ë¶„ìœ„ê¸° ë¶„ì„
    2. ì¢…ëª©ë¶„ì„ Specialist â†’ ì¬ë¬´ì œí‘œ/ì‹¤ì /ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„
    3. ê¸°ìˆ ì ë¶„ì„ Specialist â†’ RSI/MACD/ë³¼ë¦°ì €ë°´ë“œ/ì´í‰ì„  ë¶„ì„
    4. ë¦¬ìŠ¤í¬ê´€ë¦¬ Specialist â†’ ì†ì ˆ/í¬ì§€ì…˜/ë¦¬ìŠ¤í¬ í‰ê°€
    5. CIOê°€ 4ëª… ê²°ê³¼ ì·¨í•© â†’ ì¢…ëª©ë³„ ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ íŒë‹¨
    """
    watchlist = _load_data("trading_watchlist", [])
    strategies = _load_data("trading_strategies", [])
    active_strategies = [s for s in strategies if s.get("active")]

    if not watchlist and not active_strategies:
        return {"success": False, "error": "ê´€ì‹¬ì¢…ëª©ì´ë‚˜ í™œì„± ì „ëµì´ ì—†ìŠµë‹ˆë‹¤"}

    # ì¢…ëª© ì •ë³´ ì •ë¦¬ (í•œêµ­/ë¯¸êµ­ êµ¬ë¶„)
    kr_tickers = [w for w in watchlist if w.get("market", "KR") == "KR"]
    us_tickers = [w for w in watchlist if w.get("market") == "US"]
    tickers_info = ", ".join([f"{w['name']}({w['ticker']})" for w in watchlist[:10]])
    strats_info = ", ".join([s["name"] for s in active_strategies[:5]])

    # CIOì—ê²Œ ë³´ë‚´ëŠ” ë¶„ì„ ëª…ë ¹
    prompt = f"""[ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ] ê´€ì‹¬ì¢…ëª© ì¢…í•© ë¶„ì„ì„ ìš”ì²­í•©ë‹ˆë‹¤.

## ê´€ì‹¬ì¢…ëª© ({len(watchlist)}ê°œ)
{tickers_info or 'ì—†ìŒ'}
{f'- í•œêµ­ ì£¼ì‹: {len(kr_tickers)}ê°œ' if kr_tickers else ''}
{f'- ë¯¸êµ­ ì£¼ì‹: {len(us_tickers)}ê°œ' if us_tickers else ''}

## í™œì„± ë§¤ë§¤ ì „ëµ
{strats_info or 'ê¸°ë³¸ ì „ëµ (RSI/MACD ê¸°ë°˜)'}

## ë¶„ì„ ìš”ì²­ì‚¬í•­
ê° ì „ë¬¸ê°€ì—ê²Œ ì•„ë˜ ë¶„ì„ì„ ì§€ì‹œí•˜ì„¸ìš”:
- **ì‹œí™©ë¶„ì„**: í˜„ì¬ ì‹œì¥ ë¶„ìœ„ê¸°, ê¸ˆë¦¬/í™˜ìœ¨ ë™í–¥, ì—…ì¢…ë³„ íë¦„
- **ì¢…ëª©ë¶„ì„**: ê° ê´€ì‹¬ì¢…ëª©ì˜ ì¬ë¬´ ê±´ì „ì„±, PER/PBR, ì‹¤ì  ì „ë§
- **ê¸°ìˆ ì ë¶„ì„**: ê° ê´€ì‹¬ì¢…ëª©ì˜ RSI, MACD, ì´ë™í‰ê· ì„ , ë³¼ë¦°ì €ë°´ë“œ ì§€í‘œ í™•ì¸
- **ë¦¬ìŠ¤í¬ê´€ë¦¬**: í¬ì§€ì…˜ í¬ê¸° ì ì •ì„±, ì†ì ˆê°€, ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬

## ìµœì¢… ì‚°ì¶œë¬¼ (ë°˜ë“œì‹œ ì´ í˜•ì‹ìœ¼ë¡œ)
ê° ì¢…ëª©ì— ëŒ€í•´ ë‹¤ìŒ í˜•ì‹ì˜ ê²°ë¡ ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
[ì‹œê·¸ë„] ì¢…ëª©ëª… (ì¢…ëª©ì½”ë“œ) | ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ | ì‹ ë¢°ë„ 0~100% | ê·¼ê±° í•œì¤„
[ì‹œê·¸ë„] ì¢…ëª©ëª… (ì¢…ëª©ì½”ë“œ) | ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ | ì‹ ë¢°ë„ 0~100% | ê·¼ê±° í•œì¤„"""

    if not is_ai_ready():
        # AI ë¯¸ì—°ê²° ì‹œ ë”ë¯¸ ì‹œê·¸ë„
        signals = _load_data("trading_signals", [])
        for w in watchlist[:5]:
            signal = {
                "id": f"sig_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{w['ticker']}",
                "date": datetime.now(KST).isoformat(),
                "ticker": w["ticker"],
                "name": w["name"],
                "market": w.get("market", "KR"),
                "action": "hold",
                "confidence": 50,
                "reason": "AI ë¯¸ì—°ê²° â€” ë¶„ì„ ë¶ˆê°€ (API í‚¤ ë“±ë¡ í•„ìš”)",
                "strategy": "auto",
                "analyzed_by": "system",
            }
            signals.insert(0, signal)
        if len(signals) > 200:
            signals = signals[:200]
        _save_data("trading_signals", signals)
        return {"success": True, "signals": signals[:20]}

    # CIO + 4ëª… ì „ë¬¸ê°€ì—ê²Œ ìœ„ì„ (ì‹¤ì œ ë„êµ¬ ì‚¬ìš© + ë³‘ë ¬ ë¶„ì„)
    save_activity_log("cio_manager", f"ğŸ“Š ìë™ë§¤ë§¤ ì‹œê·¸ë„ ìƒì„± â€” {len(watchlist)}ê°œ ì¢…ëª© ë¶„ì„ ì‹œì‘", "info")
    cio_result = await _manager_with_delegation("cio_manager", prompt)

    content = cio_result.get("content", "")
    cost = cio_result.get("cost_usd", 0)
    specialists_used = cio_result.get("specialists_used", 0)

    # CIO ë¶„ì„ ê²°ê³¼ì—ì„œ ì‹œê·¸ë„ íŒŒì‹±
    parsed_signals = _parse_cio_signals(content, watchlist)

    signals = _load_data("trading_signals", [])
    new_signal = {
        "id": f"sig_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}",
        "date": datetime.now(KST).isoformat(),
        "analysis": content,
        "tickers": [w["ticker"] for w in watchlist[:10]],
        "parsed_signals": parsed_signals,
        "strategy": "cio_analysis",
        "analyzed_by": f"CIO + ì „ë¬¸ê°€ {specialists_used}ëª…",
        "cost_usd": cost,
    }
    signals.insert(0, new_signal)
    if len(signals) > 200:
        signals = signals[:200]
    _save_data("trading_signals", signals)

    buy_count = len([s for s in parsed_signals if s.get("action") == "buy"])
    sell_count = len([s for s in parsed_signals if s.get("action") == "sell"])
    save_activity_log("cio_manager",
        f"ğŸ“Š CIO ì‹œê·¸ë„ ì™„ë£Œ: {len(watchlist)}ê°œ ì¢…ëª© (ë§¤ìˆ˜ {buy_count}, ë§¤ë„ {sell_count}, ë¹„ìš© ${cost:.4f})",
        "info")

    return {"success": True, "signal": new_signal, "parsed_signals": parsed_signals}


def _parse_cio_signals(content: str, watchlist: list) -> list:
    """CIO ë¶„ì„ ê²°ê³¼ì—ì„œ ì¢…ëª©ë³„ ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ ì‹œê·¸ë„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    import re
    parsed = []

    # [ì‹œê·¸ë„] íŒ¨í„´ ë§¤ì¹­
    pattern = r'\[ì‹œê·¸ë„\]\s*(.+?)\s*\((.+?)\)\s*\|\s*(ë§¤ìˆ˜|ë§¤ë„|ê´€ë§|buy|sell|hold)\s*\|\s*(\d+)%?\s*\|\s*(.+)'
    matches = re.findall(pattern, content, re.IGNORECASE)

    for name, ticker, action, confidence, reason in matches:
        action_map = {"ë§¤ìˆ˜": "buy", "ë§¤ë„": "sell", "ê´€ë§": "hold", "buy": "buy", "sell": "sell", "hold": "hold"}
        market = "US" if any(c.isalpha() and c.isupper() for c in ticker) and not ticker.isdigit() else "KR"
        parsed.append({
            "ticker": ticker.strip(),
            "name": name.strip(),
            "market": market,
            "action": action_map.get(action.lower(), "hold"),
            "confidence": int(confidence),
            "reason": reason.strip(),
        })

    # [ì‹œê·¸ë„] íŒ¨í„´ì´ ì—†ìœ¼ë©´ ê´€ì‹¬ì¢…ëª© ê¸°ë°˜ìœ¼ë¡œ í‚¤ì›Œë“œ íŒŒì‹±
    if not parsed:
        for w in watchlist:
            action = "hold"
            confidence = 50
            reason = ""
            name = w.get("name", w["ticker"])
            if name in content or w["ticker"] in content:
                lower_content = content.lower()
                if any(k in content for k in ["ë§¤ìˆ˜", "ì ê·¹ ë§¤ìˆ˜", "buy", "ì§„ì…"]):
                    action = "buy"
                    confidence = 65
                elif any(k in content for k in ["ë§¤ë„", "sell", "ì²­ì‚°", "ìµì ˆ"]):
                    action = "sell"
                    confidence = 65
                # ê·¼ê±° ì¶”ì¶œ (ì¢…ëª©ëª… ì£¼ë³€ ë¬¸ì¥)
                idx = content.find(name)
                if idx >= 0:
                    reason = content[idx:idx+100].split("\n")[0]
            parsed.append({
                "ticker": w["ticker"],
                "name": name,
                "market": w.get("market", "KR"),
                "action": action,
                "confidence": confidence,
                "reason": reason or "CIO ì¢…í•© ë¶„ì„ ì°¸ì¡°",
            })

    return parsed


@app.get("/api/trading/settings")
async def get_trading_settings():
    """ìë™ë§¤ë§¤ ì„¤ì •."""
    return _load_data("trading_settings", _default_trading_settings())


@app.post("/api/trading/settings")
async def save_trading_settings(request: Request):
    """ìë™ë§¤ë§¤ ì„¤ì • ì €ì¥."""
    body = await request.json()
    settings = _load_data("trading_settings", _default_trading_settings())
    settings.update(body)
    _save_data("trading_settings", settings)
    save_activity_log("system", "âš™ï¸ ìë™ë§¤ë§¤ ì„¤ì • ì—…ë°ì´íŠ¸", "info")
    return {"success": True, "settings": settings}


@app.post("/api/trading/bot/toggle")
async def toggle_trading_bot():
    """ìë™ë§¤ë§¤ ë´‡ ON/OFF í† ê¸€."""
    global _trading_bot_active, _trading_bot_task

    _trading_bot_active = not _trading_bot_active

    if _trading_bot_active:
        if _trading_bot_task is None or _trading_bot_task.done():
            _trading_bot_task = asyncio.create_task(_trading_bot_loop())
        save_activity_log("system", "ğŸ¤– ìë™ë§¤ë§¤ ë´‡ ê°€ë™ ì‹œì‘!", "info")
        _log("[TRADING] ìë™ë§¤ë§¤ ë´‡ ì‹œì‘ âœ…")
    else:
        save_activity_log("system", "â¹ï¸ ìë™ë§¤ë§¤ ë´‡ ì¤‘ì§€", "info")
        _log("[TRADING] ìë™ë§¤ë§¤ ë´‡ ì¤‘ì§€")

    return {"success": True, "bot_active": _trading_bot_active}


@app.get("/api/trading/bot/status")
async def get_trading_bot_status():
    """ìë™ë§¤ë§¤ ë´‡ ìƒíƒœ."""
    return {
        "active": _trading_bot_active,
        "task_running": _trading_bot_task is not None and not _trading_bot_task.done() if _trading_bot_task else False,
        "settings": _load_data("trading_settings", _default_trading_settings()),
    }


def _is_market_open(settings: dict) -> tuple[bool, str]:
    """í•œêµ­/ë¯¸êµ­ ì¥ ì‹œê°„ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤. (ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì—´ë ¤ìˆìœ¼ë©´ True)"""
    now = datetime.now(KST)
    now_min = now.hour * 60 + now.minute

    # í•œêµ­ ì¥ (09:00 ~ 15:20 KST)
    kr = settings.get("trading_hours_kr", settings.get("trading_hours", {}))
    kr_start = sum(int(x) * m for x, m in zip(kr.get("start", "09:00").split(":"), [60, 1]))
    kr_end = sum(int(x) * m for x, m in zip(kr.get("end", "15:20").split(":"), [60, 1]))
    if kr_start <= now_min < kr_end:
        return True, "KR"

    # ë¯¸êµ­ ì¥ (22:30 ~ 05:00 KST, ë‹¤ìŒë‚ ë¡œ ë„˜ì–´ê°)
    us = settings.get("trading_hours_us", {})
    us_start = sum(int(x) * m for x, m in zip(us.get("start", "22:30").split(":"), [60, 1]))
    us_end = sum(int(x) * m for x, m in zip(us.get("end", "05:00").split(":"), [60, 1]))
    if us_start <= now_min or now_min < us_end:  # ìì • ë„˜ê¹€ ì²˜ë¦¬
        return True, "US"

    return False, ""


async def _trading_bot_loop():
    """ìë™ë§¤ë§¤ ë´‡ ë£¨í”„ â€” CIO(íˆ¬ìë¶„ì„ì²˜ì¥) + 4ëª… ì „ë¬¸ê°€ê°€ ë¶„ì„ â†’ ìë™ ë§¤ë§¤.

    íë¦„:
    1. 5ë¶„ë§ˆë‹¤ ì¥ ì‹œê°„ ì²´í¬ (í•œêµ­ 09:00~15:20, ë¯¸êµ­ 22:30~05:00 KST)
    2. ê´€ì‹¬ì¢…ëª©ì´ ìˆìœ¼ë©´ CIO íŒ€ì—ê²Œ ë¶„ì„ ìœ„ì„
    3. CIOê°€ 4ëª… ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì·¨í•©í•˜ì—¬ ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ íŒë‹¨
    4. ì‹ ë¢°ë„ 70% ì´ìƒ ì‹œê·¸ë„ë§Œ ìë™ ì£¼ë¬¸ ì‹¤í–‰ (auto_execute=Trueì¼ ë•Œë§Œ)
    5. ëª¨ì˜íˆ¬ì ëª¨ë“œ(paper_trading=True)ì—ì„œëŠ” ê°€ìƒ í¬íŠ¸í´ë¦¬ì˜¤ë§Œ ì—…ë°ì´íŠ¸
    """
    logger = logging.getLogger("corthex.trading")
    logger.info("ìë™ë§¤ë§¤ ë´‡ ë£¨í”„ ì‹œì‘ (CIO ì—°ë™)")

    while _trading_bot_active:
        try:
            await asyncio.sleep(300)  # 5ë¶„ë§ˆë‹¤ ì²´í¬
            if not _trading_bot_active:
                break

            settings = _load_data("trading_settings", _default_trading_settings())
            is_open, market = _is_market_open(settings)

            if not is_open:
                continue

            # ê´€ì‹¬ì¢…ëª© í™•ì¸
            watchlist = _load_data("trading_watchlist", [])
            if not watchlist:
                continue

            # í•´ë‹¹ ì‹œì¥ì˜ ê´€ì‹¬ì¢…ëª©ë§Œ í•„í„° (í•œêµ­ ì¥ì´ë©´ í•œêµ­ ì¢…ëª©, ë¯¸êµ­ ì¥ì´ë©´ ë¯¸êµ­ ì¢…ëª©)
            market_watchlist = [w for w in watchlist if w.get("market", "KR") == market]
            if not market_watchlist:
                continue

            market_name = "í•œêµ­" if market == "KR" else "ë¯¸êµ­"
            logger.info("[TRADING BOT] %sì¥ ì˜¤í”ˆ â€” %dê°œ ì¢…ëª© CIO ë¶„ì„ ì‹œì‘", market_name, len(market_watchlist))
            save_activity_log("cio_manager",
                f"ğŸ¤– ìë™ë§¤ë§¤ ë´‡: {market_name}ì¥ {len(market_watchlist)}ê°œ ì¢…ëª© CIO ë¶„ì„ ì‹œì‘",
                "info")

            # CIO + ì „ë¬¸ê°€ íŒ€ì—ê²Œ ë¶„ì„ ìœ„ì„
            tickers_info = ", ".join([f"{w['name']}({w['ticker']})" for w in market_watchlist[:10]])
            strategies = _load_data("trading_strategies", [])
            active = [s for s in strategies if s.get("active")]
            strats_info = ", ".join([s["name"] for s in active[:5]]) or "ê¸°ë³¸ ì „ëµ"

            prompt = f"""[ìë™ë§¤ë§¤ ë´‡ â€” {market_name}ì¥ ì •ê¸° ë¶„ì„]

## ë¶„ì„ ëŒ€ìƒ ({len(market_watchlist)}ê°œ ì¢…ëª©)
{tickers_info}

## í™œì„± ì „ëµ: {strats_info}

## ë¶„ì„ ìš”ì²­
ê° ì „ë¬¸ê°€ì—ê²Œ ì•„ë˜ ë¶„ì„ì„ ì§€ì‹œí•˜ì„¸ìš”:
- **ì‹œí™©ë¶„ì„**: {'ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ ì§€ìˆ˜ íë¦„, ì™¸êµ­ì¸/ê¸°ê´€ ë™í–¥, ê¸ˆë¦¬/í™˜ìœ¨' if market == 'KR' else 'S&P500/ë‚˜ìŠ¤ë‹¥ ì§€ìˆ˜, ë¯¸êµ­ ê¸ˆë¦¬/ê³ ìš©ì§€í‘œ, ë‹¬ëŸ¬ ê°•ì„¸'}
- **ì¢…ëª©ë¶„ì„**: ê° ì¢…ëª© ì¬ë¬´ ê±´ì „ì„±, PER/PBR, ìµœê·¼ ì‹¤ì 
- **ê¸°ìˆ ì ë¶„ì„**: RSI, MACD, ì´ë™í‰ê· ì„ , ë³¼ë¦°ì €ë°´ë“œ
- **ë¦¬ìŠ¤í¬ê´€ë¦¬**: ì†ì ˆê°€, ì ì • í¬ì§€ì…˜ í¬ê¸°, ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬

## ìµœì¢… ì‚°ì¶œë¬¼ (ë°˜ë“œì‹œ ì´ í˜•ì‹ìœ¼ë¡œ)
[ì‹œê·¸ë„] ì¢…ëª©ëª… (ì¢…ëª©ì½”ë“œ) | ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ | ì‹ ë¢°ë„ 0~100% | ê·¼ê±° í•œì¤„"""

            cio_result = await _manager_with_delegation("cio_manager", prompt)
            content = cio_result.get("content", "")
            cost = cio_result.get("cost_usd", 0)

            # ì‹œê·¸ë„ íŒŒì‹±
            parsed_signals = _parse_cio_signals(content, market_watchlist)

            # ì‹œê·¸ë„ ì €ì¥
            signals = _load_data("trading_signals", [])
            new_signal = {
                "id": f"sig_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}",
                "date": datetime.now(KST).isoformat(),
                "market": market,
                "analysis": content,
                "tickers": [w["ticker"] for w in market_watchlist[:10]],
                "parsed_signals": parsed_signals,
                "strategy": "cio_bot_analysis",
                "analyzed_by": f"CIO + ì „ë¬¸ê°€ {cio_result.get('specialists_used', 0)}ëª…",
                "cost_usd": cost,
                "auto_bot": True,
            }
            signals.insert(0, new_signal)
            if len(signals) > 200:
                signals = signals[:200]
            _save_data("trading_signals", signals)

            # ìë™ ì£¼ë¬¸ ì‹¤í–‰ (auto_execute=True + ì‹ ë¢°ë„ ì¶©ì¡± ì‹œ)
            auto_execute = settings.get("auto_execute", False)
            min_confidence = settings.get("min_confidence", 70)
            order_size = settings.get("order_size", 1_000_000)

            if auto_execute:
                for sig in parsed_signals:
                    if sig["action"] in ("buy", "sell") and sig.get("confidence", 0) >= min_confidence:
                        # ì£¼ë¬¸ ê°€ê²©ì€ í˜„ì¬ê°€ ê¸°ì¤€ (ëª¨ì˜íˆ¬ìì´ë¯€ë¡œ ëª©í‘œê°€ ë˜ëŠ” ê¸°ë³¸ê°€ ì‚¬ìš©)
                        target_w = next((w for w in market_watchlist if w["ticker"] == sig["ticker"]), None)
                        price = target_w.get("target_price", 0) if target_w else 0
                        if price <= 0:
                            price = 50000  # ê°€ê²© ë¯¸ì„¤ì • ì‹œ ê¸°ë³¸ê°’

                        qty = max(1, int(order_size / price))

                        # ë‚´ë¶€ì ìœ¼ë¡œ ì£¼ë¬¸ ì‹¤í–‰ (ëª¨ì˜íˆ¬ì)
                        from starlette.testclient import TestClient  # noqa
                        try:
                            portfolio = _load_data("trading_portfolio", _default_portfolio())
                            if sig["action"] == "buy" and portfolio["cash"] >= price * qty:
                                # ë§¤ìˆ˜ ë¡œì§ (execute_trading_orderì™€ ë™ì¼)
                                holding = next((h for h in portfolio["holdings"] if h["ticker"] == sig["ticker"]), None)
                                total_amount = qty * price
                                if holding:
                                    old_total = holding["avg_price"] * holding["qty"]
                                    new_total = old_total + total_amount
                                    holding["qty"] += qty
                                    holding["avg_price"] = int(new_total / holding["qty"])
                                    holding["current_price"] = price
                                else:
                                    portfolio["holdings"].append({
                                        "ticker": sig["ticker"], "name": sig["name"],
                                        "qty": qty, "avg_price": price, "current_price": price,
                                        "market": sig.get("market", market),
                                    })
                                portfolio["cash"] -= total_amount
                                portfolio["updated_at"] = datetime.now(KST).isoformat()
                                _save_data("trading_portfolio", portfolio)

                                # ê±°ë˜ ë‚´ì—­ ì €ì¥
                                history = _load_data("trading_history", [])
                                history.insert(0, {
                                    "id": f"auto_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{sig['ticker']}",
                                    "date": datetime.now(KST).isoformat(),
                                    "ticker": sig["ticker"], "name": sig["name"],
                                    "action": "buy", "qty": qty, "price": price,
                                    "total": total_amount, "pnl": 0,
                                    "strategy": f"CIO ìë™ë§¤ë§¤ (ì‹ ë¢°ë„ {sig['confidence']}%)",
                                    "status": "executed", "market": sig.get("market", market),
                                })
                                _save_data("trading_history", history)

                                save_activity_log("cio_manager",
                                    f"ğŸ“ˆ ìë™ë§¤ìˆ˜: {sig['name']} {qty}ì£¼ Ã— {price:,.0f}ì› (ì‹ ë¢°ë„ {sig['confidence']}%)",
                                    "info")

                            elif sig["action"] == "sell":
                                holding = next((h for h in portfolio["holdings"] if h["ticker"] == sig["ticker"]), None)
                                if holding and holding["qty"] > 0:
                                    sell_qty = min(qty, holding["qty"])
                                    total_amount = sell_qty * price
                                    pnl = (price - holding["avg_price"]) * sell_qty
                                    holding["qty"] -= sell_qty
                                    if holding["qty"] == 0:
                                        portfolio["holdings"] = [h for h in portfolio["holdings"] if h["ticker"] != sig["ticker"]]
                                    portfolio["cash"] += total_amount
                                    portfolio["updated_at"] = datetime.now(KST).isoformat()
                                    _save_data("trading_portfolio", portfolio)

                                    history = _load_data("trading_history", [])
                                    history.insert(0, {
                                        "id": f"auto_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{sig['ticker']}",
                                        "date": datetime.now(KST).isoformat(),
                                        "ticker": sig["ticker"], "name": sig["name"],
                                        "action": "sell", "qty": sell_qty, "price": price,
                                        "total": total_amount, "pnl": pnl,
                                        "strategy": f"CIO ìë™ë§¤ë§¤ (ì‹ ë¢°ë„ {sig['confidence']}%)",
                                        "status": "executed", "market": sig.get("market", market),
                                    })
                                    _save_data("trading_history", history)

                                    pnl_str = f"{'+'if pnl>=0 else ''}{pnl:,.0f}ì›"
                                    save_activity_log("cio_manager",
                                        f"ğŸ“‰ ìë™ë§¤ë„: {sig['name']} {sell_qty}ì£¼ Ã— {price:,.0f}ì› (ì†ìµ {pnl_str})",
                                        "info")
                        except Exception as order_err:
                            logger.error("[TRADING BOT] ìë™ì£¼ë¬¸ ì˜¤ë¥˜: %s", order_err)

            buy_count = len([s for s in parsed_signals if s.get("action") == "buy"])
            sell_count = len([s for s in parsed_signals if s.get("action") == "sell"])
            logger.info("[TRADING BOT] CIO ë¶„ì„ ì™„ë£Œ: ë§¤ìˆ˜ %d, ë§¤ë„ %d (ë¹„ìš© $%.4f)", buy_count, sell_count, cost)

        except Exception as e:
            logger.error("[TRADING BOT] ì—ëŸ¬: %s", e)

    logger.info("ìë™ë§¤ë§¤ ë´‡ ë£¨í”„ ì¢…ë£Œ")


@app.post("/api/trading/portfolio/reset")
async def reset_trading_portfolio(request: Request):
    """í¬íŠ¸í´ë¦¬ì˜¤ ì´ˆê¸°í™” (ëª¨ì˜íˆ¬ì ë¦¬ì…‹)."""
    body = await request.json()
    initial_cash = body.get("initial_cash", 50_000_000)
    portfolio = {
        "cash": initial_cash,
        "initial_cash": initial_cash,
        "holdings": [],
        "updated_at": datetime.now(KST).isoformat(),
    }
    _save_data("trading_portfolio", portfolio)
    _save_data("trading_history", [])
    _save_data("trading_signals", [])
    save_activity_log("system", f"ğŸ”„ ëª¨ì˜íˆ¬ì ë¦¬ì…‹: ì´ˆê¸° ìê¸ˆ {initial_cash:,.0f}ì›", "info")
    return {"success": True, "portfolio": portfolio}


# â”€â”€ ì§€ì‹íŒŒì¼ ê´€ë¦¬ â”€â”€

@app.get("/api/knowledge")
async def get_knowledge():
    entries = []
    if KNOWLEDGE_DIR.exists():
        for folder in sorted(KNOWLEDGE_DIR.iterdir()):
            if folder.is_dir() and not folder.name.startswith("."):
                for f in sorted(folder.iterdir()):
                    if f.is_file() and f.suffix == ".md":
                        entries.append({
                            "folder": folder.name,
                            "filename": f.name,
                            "size": f.stat().st_size,
                            "modified": datetime.fromtimestamp(f.stat().st_mtime, KST).isoformat(),
                        })
    return {"entries": entries, "total": len(entries)}


@app.get("/api/knowledge/{folder}/{filename}")
async def get_knowledge_file(folder: str, filename: str):
    """ì§€ì‹ íŒŒì¼ ë‚´ìš© ì½ê¸°."""
    file_path = KNOWLEDGE_DIR / folder / filename
    if file_path.exists() and file_path.is_file():
        content = file_path.read_text(encoding="utf-8")
        return {"folder": folder, "filename": filename, "content": content}
    return {"error": "not found"}


@app.post("/api/knowledge")
async def save_knowledge(request: Request):
    """ì§€ì‹ íŒŒì¼ ì €ì¥/ì—…ë¡œë“œ."""
    body = await request.json()
    folder = body.get("folder", "shared")
    filename = body.get("filename", "untitled.md")
    content = body.get("content", "")
    folder_path = KNOWLEDGE_DIR / folder
    folder_path.mkdir(parents=True, exist_ok=True)
    file_path = folder_path / filename
    file_path.write_text(content, encoding="utf-8")
    return {"success": True, "folder": folder, "filename": filename}


@app.delete("/api/knowledge/{folder}/{filename}")
async def delete_knowledge(folder: str, filename: str):
    """ì§€ì‹ íŒŒì¼ ì‚­ì œ."""
    file_path = KNOWLEDGE_DIR / folder / filename
    if file_path.exists() and file_path.is_file():
        file_path.unlink()
        return {"success": True}
    return {"success": False, "error": "not found"}


# â”€â”€ ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ â”€â”€

@app.get("/api/memory/{agent_id}")
async def get_memory(agent_id: str):
    all_memories = _load_data("memories", {})
    # ìˆ˜ë™ ê¸°ì–µ + ìë™ ì¶”ì¶œëœ ì¹´í…Œê³ ë¦¬ ê¸°ì–µ í•¨ê»˜ ë°˜í™˜
    categorized = load_setting(f"memory_categorized_{agent_id}", {})
    return {
        "memories": all_memories.get(agent_id, []),
        "categorized": categorized,
    }


@app.post("/api/memory/{agent_id}")
async def add_memory(agent_id: str, request: Request):
    """ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ì¶”ê°€."""
    body = await request.json()
    all_memories = _load_data("memories", {})
    if agent_id not in all_memories:
        all_memories[agent_id] = []
    memory_id = f"mem_{datetime.now(KST).strftime('%Y%m%d%H%M%S')}_{len(all_memories[agent_id])}"
    memory = {
        "id": memory_id,
        "content": body.get("content", ""),
        "created_at": datetime.now(KST).isoformat(),
    }
    all_memories[agent_id].append(memory)
    _save_data("memories", all_memories)
    return {"success": True, "memory": memory}


@app.delete("/api/memory/{agent_id}/categorized")
async def delete_categorized_memory(agent_id: str):
    """ì—ì´ì „íŠ¸ ìë™ ì¶”ì¶œ ì¹´í…Œê³ ë¦¬ ê¸°ì–µ ì´ˆê¸°í™”."""
    save_setting(f"memory_categorized_{agent_id}", {})
    return {"success": True}


@app.delete("/api/memory/{agent_id}/{memory_id}")
async def delete_memory(agent_id: str, memory_id: str):
    """ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ì‚­ì œ."""
    all_memories = _load_data("memories", {})
    if agent_id in all_memories:
        all_memories[agent_id] = [m for m in all_memories[agent_id] if m.get("id") != memory_id]
        _save_data("memories", all_memories)
    return {"success": True}


# â”€â”€ í”¼ë“œë°± â”€â”€

@app.get("/api/feedback")
async def get_feedback():
    return _load_data("feedback", {"good": 0, "bad": 0, "total": 0})


@app.post("/api/feedback")
async def send_feedback(request: Request):
    """í”¼ë“œë°± ì „ì†¡/ì·¨ì†Œ/ë³€ê²½.

    action íŒŒë¼ë¯¸í„°:
      - "send" (ê¸°ë³¸): ìƒˆ í”¼ë“œë°± ì¶”ê°€ (ì¹´ìš´íŠ¸ +1)
      - "cancel": ê¸°ì¡´ í”¼ë“œë°± ì·¨ì†Œ (ì¹´ìš´íŠ¸ -1)
      - "change": ê¸°ì¡´ í”¼ë“œë°± ë³€ê²½ (ì´ì „ ì¹´ìš´íŠ¸ -1 + ìƒˆ ì¹´ìš´íŠ¸ +1)
    """
    body = await request.json()
    feedback = _load_data("feedback", {"good": 0, "bad": 0, "total": 0})
    rating = body.get("rating", "")
    action = body.get("action", "send")  # "send", "cancel", "change"
    previous_rating = body.get("previous_rating")  # ë³€ê²½ ì‹œ ì´ì „ ê°’

    if not rating:
        return {"success": False, "error": "rating is required"}

    if action == "cancel":
        # í”¼ë“œë°± ì·¨ì†Œ: í•´ë‹¹ ì¹´ìš´íŠ¸ 1 ê°ì†Œ (0 ì´í•˜ë¡œ ë‚´ë ¤ê°€ì§€ ì•ŠìŒ)
        if rating == "good":
            feedback["good"] = max(0, feedback.get("good", 0) - 1)
        elif rating == "bad":
            feedback["bad"] = max(0, feedback.get("bad", 0) - 1)
    elif action == "change":
        # í”¼ë“œë°± ë³€ê²½: ì´ì „ í”¼ë“œë°± ì¹´ìš´íŠ¸ 1 ê°ì†Œ + ìƒˆ í”¼ë“œë°± ì¹´ìš´íŠ¸ 1 ì¦ê°€
        if previous_rating == "good":
            feedback["good"] = max(0, feedback.get("good", 0) - 1)
        elif previous_rating == "bad":
            feedback["bad"] = max(0, feedback.get("bad", 0) - 1)
        if rating == "good":
            feedback["good"] = feedback.get("good", 0) + 1
        elif rating == "bad":
            feedback["bad"] = feedback.get("bad", 0) + 1
    else:  # action == "send" (ê¸°ë³¸ê°’)
        if rating == "good":
            feedback["good"] = feedback.get("good", 0) + 1
        elif rating == "bad":
            feedback["bad"] = feedback.get("bad", 0) + 1

    feedback["total"] = feedback.get("good", 0) + feedback.get("bad", 0)
    _save_data("feedback", feedback)
    return {"success": True, **feedback}


# â”€â”€ ëŒ€í™” â”€â”€

@app.get("/api/conversation")
async def get_conversation():
    """ëŒ€í™” ê¸°ë¡ì„ DBì—ì„œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    messages = load_conversation_messages(limit=100)
    return messages


@app.post("/api/conversation/save")
async def save_conversation(data: dict = Body(...)):
    """ëŒ€í™” ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤.

    ìš”ì²­ ë³¸ë¬¸:
    - type: "user" ë˜ëŠ” "result"
    - user íƒ€ì…: text í•„ë“œ í•„ìˆ˜
    - result íƒ€ì…: content, sender_id ë“± í•„ë“œ ì „ë‹¬
    """
    try:
        message_type = data.get("type")
        if not message_type:
            return {"success": False, "error": "type í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤"}

        # type ì œì™¸í•œ ë‚˜ë¨¸ì§€ í•„ë“œë“¤ì„ kwargsë¡œ ì „ë‹¬
        kwargs = {k: v for k, v in data.items() if k != "type"}

        row_id = save_conversation_message(message_type, **kwargs)
        return {"success": True, "id": row_id}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.delete("/api/conversation")
async def delete_conversation():
    """ëŒ€í™” ê¸°ë¡ì„ ëª¨ë‘ ì‚­ì œí•©ë‹ˆë‹¤."""
    try:
        clear_conversation_messages()
        return {"success": True}
    except Exception as e:
        return {"success": False, "error": str(e)}


# â”€â”€ ì•„ì¹´ì´ë¸Œ (DB ê¸°ë°˜ â€” í•˜ë‹¨ activity-logs/archive API ì„¹ì…˜ì—ì„œ ì •ì˜ë¨) â”€â”€


# â”€â”€ SNS ì—°ë™ â”€â”€

_SNS_PLATFORMS = ["instagram", "youtube", "tistory", "naver_blog", "naver_cafe", "daum_cafe"]

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ìœ ë¬´ë¡œ ì—°ê²° ìƒíƒœ íŒë‹¨ (ì‹¤ì œ ë³´ìœ  í‚¤ ê¸°ì¤€)
_SNS_ENV_MAP = {
    "instagram": "INSTAGRAM_ACCESS_TOKEN",
    "youtube": "GOOGLE_CLIENT_ID",
    "tistory": "KAKAO_ID",
    "naver_blog": "NAVER_ID",
    "naver_cafe": "NAVER_CLIENT_ID",
    "daum_cafe": "DAUM_ID",
}


@app.get("/api/sns/status")
async def get_sns_status():
    """SNS í”Œë«í¼ ì—°ê²° ìƒíƒœ â€” í™˜ê²½ë³€ìˆ˜ì— API í‚¤ê°€ ìˆìœ¼ë©´ connected: True."""
    result = {}
    for p in _SNS_PLATFORMS:
        env_key = _SNS_ENV_MAP.get(p, "")
        has_key = bool(os.getenv(env_key, ""))
        result[p] = {"connected": has_key, "username": os.getenv(f"{p.upper()}_USERNAME", "")}
    return result


@app.get("/api/sns/oauth/status")
async def get_sns_oauth_status():
    """SNS OAuth ì¸ì¦ ìƒíƒœ."""
    result = {}
    for p in _SNS_PLATFORMS:
        env_key = _SNS_ENV_MAP.get(p, "")
        result[p] = {"authenticated": bool(os.getenv(env_key, ""))}
    return result


@app.get("/api/sns/auth/{platform}")
async def sns_auth(platform: str):
    """SNS í”Œë«í¼ ì¸ì¦ (ë¯¸êµ¬í˜„ â€” OAuth ì„¤ì • í•„ìš”)."""
    return {"success": False, "error": f"{platform} OAuth ì—°ë™ì´ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”."}


@app.post("/api/sns/instagram/photo")
async def post_instagram_photo(request: Request):
    return {"success": False, "error": "ì¸ìŠ¤íƒ€ê·¸ë¨ APIê°€ ì•„ì§ ì—°ë™ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}


@app.post("/api/sns/instagram/reel")
async def post_instagram_reel(request: Request):
    return {"success": False, "error": "ì¸ìŠ¤íƒ€ê·¸ë¨ APIê°€ ì•„ì§ ì—°ë™ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}


@app.post("/api/sns/youtube/upload")
async def post_youtube_video(request: Request):
    return {"success": False, "error": "ìœ íŠœë¸Œ APIê°€ ì•„ì§ ì—°ë™ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}


@app.get("/api/sns/queue")
async def get_sns_queue():
    """SNS ê²Œì‹œ ëŒ€ê¸°ì—´."""
    return _load_data("sns_queue", [])


@app.post("/api/sns/approve/{item_id}")
async def approve_sns(item_id: str):
    return {"success": False, "error": "SNS APIê°€ ì•„ì§ ì—°ë™ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}


@app.post("/api/sns/reject/{item_id}")
async def reject_sns(item_id: str):
    queue = _load_data("sns_queue", [])
    queue = [q for q in queue if q.get("id") != item_id]
    _save_data("sns_queue", queue)
    return {"success": True}


@app.get("/api/sns/events")
async def get_sns_events(limit: int = 50):
    """SNS ì´ë²¤íŠ¸ ë¡œê·¸."""
    return _load_data("sns_events", [])[:limit]


# â”€â”€ ì¸ì¦ (Phase 3: ë¹„ë°€ë²ˆí˜¸ ë¡œê·¸ì¸) â”€â”€

_sessions: dict[str, float] = {}  # token â†’ ë§Œë£Œ ì‹œê°„
_SESSION_TTL = 86400 * 7  # 7ì¼


def _check_auth(request: Request) -> bool:
    """ìš”ì²­ì˜ ì¸ì¦ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    token = request.headers.get("Authorization", "").replace("Bearer ", "")
    if not token:
        token = request.query_params.get("token", "")
    if token and token in _sessions:
        if _sessions[token] > time.time():
            return True
        del _sessions[token]
    return False


@app.post("/api/auth/login")
async def login(request: Request):
    """ë¹„ë°€ë²ˆí˜¸ ë¡œê·¸ì¸."""
    body = await request.json()
    pw = body.get("password", "")
    stored_pw = load_setting("admin_password") or "corthex2026"
    if pw != stored_pw:
        return JSONResponse({"success": False, "error": "ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦½ë‹ˆë‹¤"}, status_code=401)
    token = str(_uuid.uuid4())
    _sessions[token] = time.time() + _SESSION_TTL
    return {"success": True, "token": token, "user": {"role": "ceo", "name": "CEO"}}


@app.post("/api/auth/logout")
async def logout(request: Request):
    """ë¡œê·¸ì•„ì›ƒ."""
    token = request.headers.get("Authorization", "").replace("Bearer ", "")
    if token in _sessions:
        del _sessions[token]
    return {"success": True}


@app.get("/api/auth/check")
async def auth_check(request: Request):
    """í† í° ìœ íš¨ì„± í™•ì¸."""
    if _check_auth(request):
        return {"authenticated": True, "role": "ceo"}
    return JSONResponse({"authenticated": False}, status_code=401)


@app.post("/api/auth/change-password")
async def change_password(request: Request):
    """ë¹„ë°€ë²ˆí˜¸ ë³€ê²½."""
    if not _check_auth(request):
        return JSONResponse({"success": False, "error": "ì¸ì¦ í•„ìš”"}, status_code=401)
    body = await request.json()
    current = body.get("current", "")
    new_pw = body.get("new_password", "")
    stored_pw = load_setting("admin_password") or "corthex2026"
    if current != stored_pw:
        return JSONResponse({"success": False, "error": "í˜„ì¬ ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦½ë‹ˆë‹¤"}, status_code=401)
    if len(new_pw) < 4:
        return {"success": False, "error": "ë¹„ë°€ë²ˆí˜¸ëŠ” 4ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤"}
    save_setting("admin_password", new_pw)
    return {"success": True}


# â”€â”€ í—¬ìŠ¤ì²´í¬ â”€â”€

@app.get("/api/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸."""
    return {
        "status": "ok",
        "mode": "ARM ì„œë²„",
        "agents": len(AGENTS),
        "telegram": _telegram_available and _telegram_app is not None,
        "timestamp": datetime.now(KST).isoformat(),
    }


# í’ˆì§ˆê²€ìˆ˜ ê·œì¹™: DB ì˜¤ë²„ë¼ì´ë“œ ìš°ì„ , ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ
_QUALITY_RULES: dict = load_setting("config_quality_rules") or _load_config("quality_rules")

# ë¶€ì„œ ID â†’ í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
_DIVISION_LABELS: dict[str, str] = {
    "default": "ê¸°ë³¸ (ì „ì²´ ê³µí†µ)",
    "secretary": "ë¹„ì„œì‹¤",
    "leet_master.tech": "ê¸°ìˆ ê°œë°œíŒ€ (CTO)",
    "leet_master.strategy": "ì „ëµê¸°íšíŒ€ (CSO)",
    "leet_master.legal": "ë²•ë¬´íŒ€ (CLO)",
    "leet_master.marketing": "ë§ˆì¼€íŒ…íŒ€ (CMO)",
    "finance.investment": "ê¸ˆìœµë¶„ì„íŒ€ (CIO)",
    "publishing": "ì½˜í…ì¸ íŒ€ (CPO)",
}

# ë¶€ì„œ ëª©ë¡ (default ì œì™¸)
_KNOWN_DIVISIONS: list[str] = [
    "secretary",
    "leet_master.tech",
    "leet_master.strategy",
    "leet_master.legal",
    "leet_master.marketing",
    "finance.investment",
    "publishing",
]


@app.get("/api/quality-rules")
async def get_quality_rules():
    rules = _QUALITY_RULES.get("rules", {})
    rubrics = _QUALITY_RULES.get("rubrics", {})
    return {
        "rules": rules,
        "rubrics": rubrics,
        "known_divisions": _KNOWN_DIVISIONS,
        "division_labels": _DIVISION_LABELS,
    }


# â”€â”€ í’ˆì§ˆê²€ìˆ˜: ë£¨ë¸Œë¦­ ì €ì¥/ì‚­ì œ + ê·œì¹™ ì €ì¥ â”€â”€

@app.put("/api/quality-rules/rubric/{division}")
async def save_rubric(division: str, request: Request):
    """ë¶€ì„œë³„ ë£¨ë¸Œë¦­(ê²€ìˆ˜ ê¸°ì¤€) ì €ì¥."""
    body = await request.json()
    rubric = {
        "name": body.get("name", ""),
        "prompt": body.get("prompt", ""),
        "model": body.get("model", ""),
        "reasoning_effort": body.get("reasoning_effort", ""),
    }
    if "rubrics" not in _QUALITY_RULES:
        _QUALITY_RULES["rubrics"] = {}
    _QUALITY_RULES["rubrics"][division] = rubric
    _save_config_file("quality_rules", _QUALITY_RULES)
    return {"success": True, "division": division}


@app.delete("/api/quality-rules/rubric/{division}")
async def delete_rubric(division: str):
    """ë¶€ì„œë³„ ë£¨ë¸Œë¦­ ì‚­ì œ (defaultëŠ” ì‚­ì œ ë¶ˆê°€)."""
    if division == "default":
        return {"success": False, "error": "ê¸°ë³¸ ë£¨ë¸Œë¦­ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
    rubrics = _QUALITY_RULES.get("rubrics", {})
    if division in rubrics:
        del rubrics[division]
        _save_config_file("quality_rules", _QUALITY_RULES)
    return {"success": True}


@app.put("/api/quality-rules/model")
async def save_review_model(request: Request):
    """í’ˆì§ˆê²€ìˆ˜ì— ì‚¬ìš©í•  AI ëª¨ë¸ ë³€ê²½."""
    body = await request.json()
    if "rules" not in _QUALITY_RULES:
        _QUALITY_RULES["rules"] = {}
    _QUALITY_RULES["rules"]["review_model"] = body.get("model", "claude-sonnet-4-6")
    _save_config_file("quality_rules", _QUALITY_RULES)
    return {"success": True}


@app.put("/api/quality-rules/rules")
async def save_quality_rules(request: Request):
    """í’ˆì§ˆê²€ìˆ˜ ê·œì¹™ ì €ì¥ (ìµœì†Œ ê¸¸ì´, ì¬ì‹œë„ íšŸìˆ˜ ë“±)."""
    body = await request.json()
    if "rules" not in _QUALITY_RULES:
        _QUALITY_RULES["rules"] = {}
    for key in ("min_length", "max_retry", "check_hallucination", "check_relevance", "review_model"):
        if key in body:
            _QUALITY_RULES["rules"][key] = body[key]
    _save_config_file("quality_rules", _QUALITY_RULES)
    return {"success": True}


# â”€â”€ ì—ì´ì „íŠ¸ ì„¤ì •: ì†Œìš¸/ëª¨ë¸/ì¶”ë¡  ì €ì¥ â”€â”€

@app.put("/api/agents/bulk-model")
async def bulk_change_model(request: Request):
    """ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ëª¨ë¸ì„ í•œë²ˆì— ë³€ê²½."""
    body = await request.json()
    new_model = body.get("model_name", "")
    reasoning = body.get("reasoning_effort", "")
    if not new_model:
        return {"error": "model_name í•„ìˆ˜"}
    overrides = _load_data("agent_overrides", {})
    changed = 0
    for a in AGENTS:
        aid = a["agent_id"]
        a["model_name"] = new_model
        if aid in _AGENTS_DETAIL:
            _AGENTS_DETAIL[aid]["model_name"] = new_model
            _AGENTS_DETAIL[aid]["reasoning_effort"] = reasoning
        if aid not in overrides:
            overrides[aid] = {}
        overrides[aid]["model_name"] = new_model
        overrides[aid]["reasoning_effort"] = reasoning
        changed += 1
    _save_data("agent_overrides", overrides)
    return {"success": True, "changed": changed, "model_name": new_model, "reasoning_effort": reasoning}


@app.put("/api/agents/{agent_id}/soul")
async def save_agent_soul(agent_id: str, request: Request):
    """ì—ì´ì „íŠ¸ ì†Œìš¸(ì„±ê²©) ì €ì¥. DBì— ì˜êµ¬ ì €ì¥ë¨."""
    body = await request.json()
    soul_text = body.get("soul") or body.get("system_prompt", "")
    # DBì— ì €ì¥ (ì¬ë°°í¬í•´ë„ ìœ ì§€)
    save_setting(f"soul_{agent_id}", soul_text)
    return {"success": True, "agent_id": agent_id}


@app.put("/api/agents/{agent_id}/model")
async def save_agent_model(agent_id: str, request: Request):
    """ì—ì´ì „íŠ¸ì— ë°°ì •ëœ AI ëª¨ë¸ ë³€ê²½."""
    body = await request.json()
    new_model = body.get("model_name") or body.get("model", "")
    # ë©”ëª¨ë¦¬ ë‚´ AGENTS ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
    for a in AGENTS:
        if a["agent_id"] == agent_id:
            a["model_name"] = new_model
            break
    # agents.yaml ìƒì„¸ ì •ë³´ë„ ì—…ë°ì´íŠ¸
    if agent_id in _AGENTS_DETAIL:
        _AGENTS_DETAIL[agent_id]["model_name"] = new_model
    # ë°ì´í„° íŒŒì¼ì— ë³€ê²½ì‚¬í•­ ì €ì¥ (ì„œë²„ ì¬ì‹œì‘ ì‹œ ë³µì›ìš©)
    overrides = _load_data("agent_overrides", {})
    if agent_id not in overrides:
        overrides[agent_id] = {}
    overrides[agent_id]["model_name"] = new_model
    _save_data("agent_overrides", overrides)
    return {"success": True, "agent_id": agent_id, "model": new_model}


@app.put("/api/agents/{agent_id}/reasoning")
async def save_agent_reasoning(agent_id: str, request: Request):
    """ì—ì´ì „íŠ¸ ì¶”ë¡  ë°©ì‹(reasoning effort) ë³€ê²½."""
    body = await request.json()
    effort = body.get("reasoning_effort", "")
    if agent_id in _AGENTS_DETAIL:
        _AGENTS_DETAIL[agent_id]["reasoning_effort"] = effort
    overrides = _load_data("agent_overrides", {})
    if agent_id not in overrides:
        overrides[agent_id] = {}
    overrides[agent_id]["reasoning_effort"] = effort
    _save_data("agent_overrides", overrides)
    return {"success": True, "agent_id": agent_id, "reasoning_effort": effort}


# â”€â”€ ì˜ˆì‚° ì„¤ì • ì €ì¥ â”€â”€

@app.put("/api/budget")
async def save_budget(request: Request):
    """ì¼ì¼/ì›”ê°„ ì˜ˆì‚° í•œë„ ë³€ê²½."""
    body = await request.json()
    if "daily_limit" in body:
        save_setting("daily_budget_usd", float(body["daily_limit"]))
    if "monthly_limit" in body:
        save_setting("monthly_budget_usd", float(body["monthly_limit"]))
    daily = float(load_setting("daily_budget_usd") or 7.0)
    monthly = float(load_setting("monthly_budget_usd") or 300.0)
    return {"success": True, "daily_limit": daily, "monthly_limit": monthly}


@app.get("/api/available-models")
async def get_available_models():
    return [
        # Anthropic (Claude) ëª¨ë¸ë“¤ - ì„ì›ê¸‰/ë§¤ë‹ˆì €ê¸‰
        {
            "name": "claude-opus-4-6",
            "provider": "anthropic",
            "tier": "executive",
            "cost_input": 15.0,
            "cost_output": 75.0,
            "reasoning_levels": ["low", "medium", "high"],
        },
        {
            "name": "claude-sonnet-4-6",
            "provider": "anthropic",
            "tier": "manager",
            "cost_input": 3.0,
            "cost_output": 15.0,
            "reasoning_levels": ["low", "medium", "high"],
        },
        {
            "name": "claude-haiku-4-5-20251001",
            "provider": "anthropic",
            "tier": "specialist",
            "cost_input": 0.25,
            "cost_output": 1.25,
            "reasoning_levels": [],
        },
        # OpenAI (GPT) ëª¨ë¸ë“¤ - ì„ì›ê¸‰/ë§¤ë‹ˆì €ê¸‰/ì „ë¬¸ê°€ê¸‰
        {
            "name": "gpt-5.2-pro",
            "provider": "openai",
            "tier": "executive",
            "cost_input": 18.0,
            "cost_output": 90.0,
            "reasoning_levels": ["medium", "high", "xhigh"],
        },
        {
            "name": "gpt-5.2",
            "provider": "openai",
            "tier": "manager",
            "cost_input": 5.0,
            "cost_output": 25.0,
            "reasoning_levels": ["none", "low", "medium", "high", "xhigh"],
        },
        {
            "name": "gpt-5",
            "provider": "openai",
            "tier": "specialist",
            "cost_input": 2.5,
            "cost_output": 10.0,
            "reasoning_levels": ["none", "low", "medium", "high"],
        },
        {
            "name": "gpt-5-mini",
            "provider": "openai",
            "tier": "specialist",
            "cost_input": 0.5,
            "cost_output": 2.0,
            "reasoning_levels": ["low", "medium", "high"],
        },
        # Google (Gemini) ëª¨ë¸ë“¤
        # Gemini 3: thinking_level íŒŒë¼ë¯¸í„° (low/highë§Œ ì§€ì›)
        {
            "name": "gemini-3-pro-preview",
            "provider": "google",
            "tier": "executive",
            "cost_input": 2.5,
            "cost_output": 15.0,
            "reasoning_levels": ["low", "high"],
        },
        # Gemini 2.5: thinking_budget íŒŒë¼ë¯¸í„° (í† í° ìˆ˜ ì¡°ì ˆ)
        # 2.5 Pro: ìµœì†Œ 128 í† í°, ëŒ ìˆ˜ ì—†ìŒ
        {
            "name": "gemini-2.5-pro",
            "provider": "google",
            "tier": "manager",
            "cost_input": 1.25,
            "cost_output": 10.0,
            "reasoning_levels": ["low", "medium", "high"],
        },
        # 2.5 Flash: 0~24576 í† í°, ëŒ ìˆ˜ ìˆìŒ (budget=0)
        {
            "name": "gemini-2.5-flash",
            "provider": "google",
            "tier": "specialist",
            "cost_input": 0.15,
            "cost_output": 0.60,
            "reasoning_levels": ["none", "low", "medium", "high"],
        },
    ]


# â”€â”€ í™œë™ ë¡œê·¸ API â”€â”€
@app.get("/api/activity-logs")
async def get_activity_logs(limit: int = 50, agent_id: str = None):
    logs = list_activity_logs(limit=limit, agent_id=agent_id)
    return logs


# â”€â”€ í˜‘ì—… ë¡œê·¸ API â”€â”€

@app.get("/api/delegation-log")
async def get_delegation_log(agent: str = None, limit: int = 100):
    """ì—ì´ì „íŠ¸ ê°„ ìœ„ì„/í˜‘ì—… ë¡œê·¸ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    ?agent=ë¹„ì„œì‹¤ì¥ ì²˜ëŸ¼ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì •í•˜ë©´ í•´ë‹¹ ì—ì´ì „íŠ¸ ê´€ë ¨ ë¡œê·¸ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        from db import list_delegation_logs
        logs = list_delegation_logs(agent=agent, limit=limit)
        return logs
    except Exception as e:
        return []


@app.post("/api/delegation-log")
async def post_delegation_log(request: Request):
    """ì—ì´ì „íŠ¸ ê°„ ìœ„ì„/í˜‘ì—… ë¡œê·¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

    body: {sender, receiver, message, task_id?, log_type?}
    """
    try:
        from db import save_delegation_log
        body = await request.json()
        sender = body.get("sender", "")
        receiver = body.get("receiver", "")
        message = body.get("message", "")
        if not sender or not receiver or not message:
            return {"success": False, "error": "sender, receiver, messageëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤."}
        row_id = save_delegation_log(
            sender=sender,
            receiver=receiver,
            message=message,
            task_id=body.get("task_id"),
            log_type=body.get("log_type", "delegation"),
        )
        return {"success": True, "id": row_id}
    except Exception as e:
        return {"success": False, "error": str(e)}


# â”€â”€ ì•„ì¹´ì´ë¸Œ API â”€â”€
@app.delete("/api/archive/all")
async def delete_all_archives_api():
    """ëª¨ë“  ê¸°ë°€ë¬¸ì„œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
    try:
        from db import delete_all_archives
        count = delete_all_archives()
        save_activity_log("system", f"ğŸ—‘ï¸ ê¸°ë°€ë¬¸ì„œ ì „ì²´ ì‚­ì œ: {count}ê±´", "warning")
        return {"success": True, "deleted": count}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/archive")
async def get_archive_list(division: str = None, limit: int = 100):
    return list_archives(division=division, limit=limit)


@app.get("/api/archive/{division}/{filename}")
async def get_archive_file(division: str, filename: str):
    doc = db_get_archive(division, filename)
    if not doc:
        return {"error": "not found"}
    return doc


@app.delete("/api/archive/{division}/{filename}")
async def delete_archive_api(division: str, filename: str):
    """ê¸°ë°€ë¬¸ì„œ ë³´ê³ ì„œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
    ok = db_delete_archive(division, filename)
    if not ok:
        return {"success": False, "error": "ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
    save_activity_log("system", f"ğŸ—‘ ê¸°ë°€ë¬¸ì„œ ì‚­ì œ: {division}/{filename}", "info")
    return {"success": True}


# â”€â”€ ì§„ë‹¨ API (í…”ë ˆê·¸ë¨ ë´‡ ë””ë²„ê¹…ìš©) â”€â”€
@app.get("/api/telegram-status")
async def telegram_status():
    """í…”ë ˆê·¸ë¨ ë´‡ ì§„ë‹¨ ì •ë³´ ë°˜í™˜."""
    return {
        **_diag,
        "tg_app_exists": _telegram_app is not None,
        "tg_available": _telegram_available,
        "env_token_set": bool(os.getenv("TELEGRAM_BOT_TOKEN", "")),
        "env_ceo_id": os.getenv("TELEGRAM_CEO_CHAT_ID", ""),
    }


# â”€â”€ í…”ë ˆê·¸ë¨ ë´‡ â”€â”€
# ì£¼ì˜: python-telegram-bot ë¯¸ì„¤ì¹˜ ì‹œì—ë„ ì„œë²„ê°€ ì •ìƒ ì‘ë™í•´ì•¼ í•¨
# ëª¨ë“  í…”ë ˆê·¸ë¨ ê´€ë ¨ ì½”ë“œëŠ” _telegram_available ì²´í¬ í›„ì—ë§Œ ì‹¤í–‰

_telegram_app = None  # telegram.ext.Application ì¸ìŠ¤í„´ìŠ¤


async def _start_telegram_bot() -> None:
    """í…”ë ˆê·¸ë¨ ë´‡ì„ ì‹œì‘í•©ë‹ˆë‹¤ (FastAPI ì´ë²¤íŠ¸ ë£¨í”„ ì•ˆì—ì„œ ì‹¤í–‰)."""
    global _telegram_app

    _log(f"[TG] ë´‡ ì‹œì‘ ì‹œë„ (_telegram_available={_telegram_available})")

    if not _telegram_available:
        _log("[TG] âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ â€” ê±´ë„ˆëœ€")
        return

    token = os.getenv("TELEGRAM_BOT_TOKEN", "")
    _log(f"[TG] í† í° ì¡´ì¬: {bool(token)} (ê¸¸ì´: {len(token)})")
    if not token:
        _log("[TG] âŒ í† í° ë¯¸ì„¤ì • â€” ê±´ë„ˆëœ€")
        _diag["tg_error"] = "TELEGRAM_BOT_TOKEN í™˜ê²½ë³€ìˆ˜ ì—†ìŒ"
        return

    try:
        _log("[TG] Application ë¹Œë“œ ì¤‘...")
        _telegram_app = Application.builder().token(token).build()

        # â”€â”€ í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë“¤ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ëœ ê²½ìš°ì—ë§Œ ì •ì˜) â”€â”€

        async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            chat_id = update.effective_chat.id
            ceo_id = os.getenv("TELEGRAM_CEO_CHAT_ID", "")
            if not ceo_id:
                logger.info("í…”ë ˆê·¸ë¨ chat_id ê°ì§€: %s", chat_id)
                await update.message.reply_text(
                    f"CORTHEX HQ í…”ë ˆê·¸ë¨ ë´‡ì…ë‹ˆë‹¤.\n\n"
                    f"ë‹¹ì‹ ì˜ chat_id: `{chat_id}`\n\n"
                    f"ì„œë²„ í™˜ê²½ë³€ìˆ˜ì— TELEGRAM_CEO_CHAT_ID={chat_id} ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.",
                    parse_mode="Markdown",
                )
                return
            if str(chat_id) != ceo_id:
                await update.message.reply_text("ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            await update.message.reply_text(
                "*CORTHEX HQ í…”ë ˆê·¸ë¨ ë´‡*\n\n"
                "CEO ì¸ì¦ ì™„ë£Œ.\n"
                "24ì‹œê°„ ì„œë²„ì—ì„œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.\n\n"
                "/help ë¡œ ì‚¬ìš©ë²•ì„ í™•ì¸í•˜ì„¸ìš”.",
                parse_mode="Markdown",
            )

        async def cmd_help(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            await update.message.reply_text(
                "*CORTHEX HQ ì‚¬ìš©ë²•*\n\n"
                "*ì •ë³´*\n"
                "/agents â€” ì—ì´ì „íŠ¸ ëª©ë¡\n"
                "/health â€” ì„œë²„ ìƒíƒœ\n"
                "/status â€” ë°°ì¹˜ ì§„í–‰ í˜„í™©\n"
                "/budget â€” ì˜¤ëŠ˜ ë¹„ìš© / í•œë„ ë³€ê²½\n\n"
                "*ëª¨ë“œ ì „í™˜*\n"
                "/rt â€” ì‹¤ì‹œê°„ ëª¨ë“œ (AI ì¦‰ì‹œ ë‹µë³€)\n"
                "/batch â€” ë°°ì¹˜ ëª¨ë“œ\n\n"
                "*ì„¤ì •*\n"
                "/models â€” ì „ì› ëª¨ë¸ ë³€ê²½ (3ë‹¨ê³„ ë²„íŠ¼)\n"
                "/pause â€” AI ì²˜ë¦¬ ì¤‘ë‹¨\n"
                "/resume â€” AI ì²˜ë¦¬ ì¬ê°œ\n\n"
                "ì¼ë°˜ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ë©´ AIê°€ ë‹µë³€í•©ë‹ˆë‹¤.",
                parse_mode="Markdown",
            )

        async def cmd_agents(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            divisions = {}
            for a in AGENTS:
                div = a.get("division", "ê¸°íƒ€")
                divisions.setdefault(div, []).append(a)
            lines = ["*CORTHEX HQ ì—ì´ì „íŠ¸ ëª©ë¡*\n"]
            div_labels = {
                "secretary": "ë¹„ì„œì‹¤",
                "leet_master.tech": "ê¸°ìˆ ê°œë°œì²˜ (CTO)",
                "leet_master.strategy": "ì‚¬ì—…ê¸°íšì²˜ (CSO)",
                "leet_master.legal": "ë²•ë¬´Â·IPì²˜ (CLO)",
                "leet_master.marketing": "ë§ˆì¼€íŒ…Â·ê³ ê°ì²˜ (CMO)",
                "finance.investment": "íˆ¬ìë¶„ì„ì²˜ (CIO)",
                "publishing": "ì¶œíŒÂ·ê¸°ë¡ì²˜ (CPO)",
            }
            for div, agents_list in divisions.items():
                label = div_labels.get(div, div)
                lines.append(f"\n*{label}* ({len(agents_list)}ëª…)")
                for a in agents_list:
                    icon = "ğŸ‘”" if a["role"] == "manager" else "ğŸ‘¤"
                    lines.append(f"  {icon} {a['name_ko']}")
            lines.append(f"\nì´ {len(AGENTS)}ëª…")
            await update.message.reply_text("\n".join(lines), parse_mode="Markdown")

        async def cmd_health(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            now = datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")
            await update.message.reply_text(
                f"*ì„œë²„ ìƒíƒœ*\n\n"
                f"ìƒíƒœ: ì •ìƒ ìš´ì˜ ì¤‘\n"
                f"ì„œë²„: Oracle Cloud (ì¶˜ì²œ)\n"
                f"ì—ì´ì „íŠ¸: {len(AGENTS)}ëª… ëŒ€ê¸° ì¤‘\n"
                f"ì‹œê°„: {now} KST",
                parse_mode="Markdown",
            )

        async def cmd_rt(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            """ì‹¤ì‹œê°„ ëª¨ë“œ ì „í™˜ (/rt)."""
            if not _is_tg_ceo(update):
                return
            save_setting("tg_mode", "realtime")
            await update.message.reply_text(
                "ğŸ”´ *ì‹¤ì‹œê°„ ëª¨ë“œ*ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.\n\n"
                "ì´ì œ ë³´ë‚´ì‹œëŠ” ë©”ì‹œì§€ì— AIê°€ ì¦‰ì‹œ ë‹µë³€í•©ë‹ˆë‹¤.",
                parse_mode="Markdown",
            )

        async def cmd_batch(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            """ë°°ì¹˜ ëª¨ë“œ ì „í™˜ (/batch)."""
            if not _is_tg_ceo(update):
                return
            save_setting("tg_mode", "batch")
            await update.message.reply_text(
                "ğŸ“¦ *ë°°ì¹˜ ëª¨ë“œ*ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.\n\n"
                "ë©”ì‹œì§€ë¥¼ ì ‘ìˆ˜ë§Œ í•˜ê³ , AI ì²˜ë¦¬ëŠ” í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                parse_mode="Markdown",
            )

        # â”€â”€ /status â€” ë°°ì¹˜ ì§„í–‰ ëª©ë¡ â”€â”€
        async def cmd_status(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            chains = load_setting("batch_chains") or []
            active = [c for c in chains if c.get("status") in ("running", "pending")]
            if not active:
                await update.message.reply_text("í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            lines = [f"*ì§„í–‰ ì¤‘ì¸ ë°°ì¹˜ ({len(active)}ê±´)*\n"]
            for c in active[:10]:
                step = c.get("step", "?")
                text_preview = c.get("text", "")[:40]
                chain_id = c.get("chain_id", "?")[:8]
                lines.append(f"â€¢ `{chain_id}` | {step} | {text_preview}")
            await update.message.reply_text("\n".join(lines), parse_mode="Markdown")

        # â”€â”€ /budget â€” ì˜¤ëŠ˜ ì§€ì¶œ í™•ì¸/ë³€ê²½ â”€â”€
        async def cmd_budget(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            args = (update.message.text or "").split()
            today_cost = get_today_cost()
            daily_limit = load_setting("daily_budget_usd") or 10
            if len(args) >= 2:
                try:
                    new_limit = float(args[1])
                    save_setting("daily_budget_usd", new_limit)
                    await update.message.reply_text(
                        f"ğŸ’° ì¼ì¼ ì˜ˆì‚°ì„ *${new_limit:.2f}*ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\nì˜¤ëŠ˜ ì‚¬ìš©: ${today_cost:.4f}",
                        parse_mode="Markdown",
                    )
                    return
                except ValueError:
                    pass
            pct = (today_cost / daily_limit * 100) if daily_limit > 0 else 0
            await update.message.reply_text(
                f"ğŸ’° *ì˜¤ëŠ˜ ë¹„ìš© í˜„í™©*\n\n"
                f"ì‚¬ìš©: ${today_cost:.4f}\n"
                f"í•œë„: ${daily_limit:.2f}\n"
                f"ì‚¬ìš©ë¥ : {pct:.1f}%\n\n"
                f"í•œë„ ë³€ê²½: `/budget 15` (15ë‹¬ëŸ¬ë¡œ ë³€ê²½)",
                parse_mode="Markdown",
            )

        # â”€â”€ /pause, /resume â€” AI ì²˜ë¦¬ ì¤‘ë‹¨/ì¬ê°œ â”€â”€
        async def cmd_pause(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            save_setting("ai_paused", True)
            await update.message.reply_text("â¸ *AI ì²˜ë¦¬ë¥¼ ì¼ì‹œ ì¤‘ë‹¨*í–ˆìŠµë‹ˆë‹¤.\n\n`/resume`ìœ¼ë¡œ ì¬ê°œí•˜ì„¸ìš”.", parse_mode="Markdown")

        async def cmd_resume(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            save_setting("ai_paused", False)
            await update.message.reply_text("â–¶ï¸ *AI ì²˜ë¦¬ë¥¼ ì¬ê°œ*í–ˆìŠµë‹ˆë‹¤.", parse_mode="Markdown")

        # â”€â”€ /models â€” 3ë‹¨ê³„ ì¸ë¼ì¸ ë²„íŠ¼ìœ¼ë¡œ ëª¨ë¸ ë³€ê²½ â”€â”€
        # í”„ë¡œë°”ì´ë”ë³„ ëª¨ë¸ ëª©ë¡ (ì½”ë“œ ë‚´ _MODEL_CATALOGê³¼ ë™ê¸°í™”)
        _TG_MODELS = {
            "Anthropic": [
                ("claude-opus-4-6", "Opus 4.6", ["xhigh", "high", "low", "ì—†ìŒ"]),
                ("claude-sonnet-4-6", "Sonnet 4.6", ["high", "medium", "low", "ì—†ìŒ"]),
                ("claude-haiku-4-5-20251001", "Claude Haiku 4.5", []),
            ],
            "OpenAI": [
                ("gpt-5.2-pro", "GPT-5.2 Pro", ["xhigh", "high", "medium", "ì—†ìŒ"]),
                ("gpt-5.2", "GPT-5.2", ["xhigh", "high", "medium", "low", "ì—†ìŒ"]),
                ("gpt-5", "GPT-5", ["xhigh", "high", "low", "ì—†ìŒ"]),
                ("gpt-5-mini", "GPT-5 Mini", []),
            ],
            "Google": [
                ("gemini-3-pro-preview", "Gemini 3 Pro Preview", ["high", "low", "ì—†ìŒ"]),
                ("gemini-2.5-pro", "Gemini 2.5 Pro", ["high", "low", "ì—†ìŒ"]),
                ("gemini-2.5-flash", "Gemini 2.5 Flash", []),
            ],
        }

        async def cmd_models(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            current = load_setting("global_model_override") or {}
            cur_model = current.get("model", "ì—†ìŒ")
            cur_reason = current.get("reasoning", "ì—†ìŒ")
            buttons = [
                [InlineKeyboardButton("ğŸŸ£ Anthropic", callback_data="mdl_p_Anthropic")],
                [InlineKeyboardButton("ğŸŸ¢ OpenAI", callback_data="mdl_p_OpenAI")],
                [InlineKeyboardButton("ğŸ”µ Google", callback_data="mdl_p_Google")],
            ]
            await update.message.reply_text(
                f"*ì „ì› ëª¨ë¸ ë³€ê²½*\n\ní˜„ì¬: `{cur_model}` (ì¶”ë¡ : {cur_reason})\n\ní”„ë¡œë°”ì´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                parse_mode="Markdown",
                reply_markup=InlineKeyboardMarkup(buttons),
            )

        async def models_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            query = update.callback_query
            await query.answer()
            data = query.data

            # 1ë‹¨ê³„: í”„ë¡œë°”ì´ë” ì„ íƒ â†’ ëª¨ë¸ ëª©ë¡ í‘œì‹œ
            if data.startswith("mdl_p_"):
                provider = data[6:]
                models_list = _TG_MODELS.get(provider, [])
                buttons = []
                for model_id, label, _ in models_list:
                    buttons.append([InlineKeyboardButton(label, callback_data=f"mdl_m_{model_id}")])
                buttons.append([InlineKeyboardButton("Â« ë’¤ë¡œ", callback_data="mdl_back")])
                await query.edit_message_text(
                    f"*{provider}* ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:",
                    parse_mode="Markdown",
                    reply_markup=InlineKeyboardMarkup(buttons),
                )

            # 2ë‹¨ê³„: ëª¨ë¸ ì„ íƒ â†’ ì¶”ë¡  ê°•ë„ í‘œì‹œ (ë˜ëŠ” ë°”ë¡œ ì €ì¥)
            elif data.startswith("mdl_m_"):
                model_id = data[6:]
                # ëª¨ë¸ì˜ ì¶”ë¡  ë ˆë²¨ ì°¾ê¸°
                reasoning_levels = []
                for provider, models_list in _TG_MODELS.items():
                    for mid, label, levels in models_list:
                        if mid == model_id:
                            reasoning_levels = levels
                            break

                if not reasoning_levels:
                    # ì¶”ë¡  ì—†ìŒ â†’ ë°”ë¡œ ì €ì¥ (ì›¹ê³¼ ë™ì¼í•œ í‚¤ ì‚¬ìš© â†’ ë™ê¸°í™”)
                    save_setting("model_mode", "manual")
                    save_setting("model_override", model_id)
                    save_setting("global_model_override", {"model": model_id, "reasoning": "ì—†ìŒ"})
                    await query.edit_message_text(f"âœ… ì „ì› ëª¨ë¸ì„ `{model_id}` ìœ¼ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\n(ì¶”ë¡ : ì—†ìŒ)", parse_mode="Markdown")
                else:
                    # ì¶”ë¡  ë ˆë²¨ ì„ íƒ ë²„íŠ¼
                    context.user_data["pending_model"] = model_id
                    buttons = []
                    for level in reasoning_levels:
                        buttons.append([InlineKeyboardButton(level, callback_data=f"mdl_r_{level}")])
                    buttons.append([InlineKeyboardButton("Â« ë’¤ë¡œ", callback_data="mdl_back")])
                    await query.edit_message_text(
                        f"*{model_id}*\nì¶”ë¡  ê°•ë„ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                        parse_mode="Markdown",
                        reply_markup=InlineKeyboardMarkup(buttons),
                    )

            # 3ë‹¨ê³„: ì¶”ë¡  ê°•ë„ ì„ íƒ â†’ ì €ì¥
            elif data.startswith("mdl_r_"):
                level = data[6:]
                model_id = context.user_data.get("pending_model", "")
                if model_id:
                    # ì›¹ê³¼ ë™ì¼í•œ í‚¤ ì‚¬ìš© â†’ ë™ê¸°í™”
                    save_setting("model_mode", "manual")
                    save_setting("model_override", model_id)
                    save_setting("global_model_override", {"model": model_id, "reasoning": level})
                    await query.edit_message_text(
                        f"âœ… ì „ì› ëª¨ë¸ì„ `{model_id}` ìœ¼ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\n(ì¶”ë¡ : {level})",
                        parse_mode="Markdown",
                    )
                else:
                    await query.edit_message_text("âŒ ëª¨ë¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. /modelsë¥¼ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")

            # ë’¤ë¡œê°€ê¸°
            elif data == "mdl_back":
                current = load_setting("global_model_override") or {}
                cur_model = current.get("model", "ì—†ìŒ")
                cur_reason = current.get("reasoning", "ì—†ìŒ")
                buttons = [
                    [InlineKeyboardButton("ğŸŸ£ Anthropic", callback_data="mdl_p_Anthropic")],
                    [InlineKeyboardButton("ğŸŸ¢ OpenAI", callback_data="mdl_p_OpenAI")],
                    [InlineKeyboardButton("ğŸ”µ Google", callback_data="mdl_p_Google")],
                ]
                await query.edit_message_text(
                    f"*ì „ì› ëª¨ë¸ ë³€ê²½*\n\ní˜„ì¬: `{cur_model}` (ì¶”ë¡ : {cur_reason})\n\ní”„ë¡œë°”ì´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                    parse_mode="Markdown",
                    reply_markup=InlineKeyboardMarkup(buttons),
                )

        async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
            if not _is_tg_ceo(update):
                return
            text = update.message.text.strip()
            if not text:
                return

            # í•œêµ­ì–´ ëª…ë ¹ì–´ ì²˜ë¦¬ (í…”ë ˆê·¸ë¨ CommandHandlerëŠ” ì˜ì–´ë§Œ ì§€ì›í•˜ë¯€ë¡œ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬)
            if text in ("ì‹¤ì‹œê°„", "/ì‹¤ì‹œê°„"):
                save_setting("tg_mode", "realtime")
                await update.message.reply_text(
                    "ğŸ”´ *ì‹¤ì‹œê°„ ëª¨ë“œ*ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.\n\n"
                    "ì´ì œ ë³´ë‚´ì‹œëŠ” ë©”ì‹œì§€ì— AIê°€ ì¦‰ì‹œ ë‹µë³€í•©ë‹ˆë‹¤.",
                    parse_mode="Markdown",
                )
                return
            if text in ("ë°°ì¹˜", "/ë°°ì¹˜"):
                save_setting("tg_mode", "batch")
                await update.message.reply_text(
                    "ğŸ“¦ *ë°°ì¹˜ ëª¨ë“œ*ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.\n\n"
                    "ë©”ì‹œì§€ë¥¼ ì ‘ìˆ˜ë§Œ í•˜ê³ , AI ì²˜ë¦¬ëŠ” í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                    parse_mode="Markdown",
                )
                return

            chat_id = str(update.effective_chat.id)
            # DBì— ë©”ì‹œì§€ + ì‘ì—… ì €ì¥
            task = create_task(text, source="telegram")
            save_message(text, source="telegram", chat_id=chat_id,
                         task_id=task["task_id"])

            # AI ì¼ì‹œ ì¤‘ë‹¨ ì²´í¬
            if load_setting("ai_paused"):
                await update.message.reply_text("â¸ AI ì²˜ë¦¬ê°€ ì¼ì‹œ ì¤‘ë‹¨ëœ ìƒíƒœì…ë‹ˆë‹¤.\n`/resume`ìœ¼ë¡œ ì¬ê°œí•˜ì„¸ìš”.", parse_mode="Markdown")
                return

            # ëª¨ë“œ í™•ì¸
            mode = load_setting("tg_mode") or "realtime"
            now = datetime.now(KST).strftime("%H:%M")
            result = {}  # ì›¹ì†Œì¼“ ë¸Œë¡œë“œìºìŠ¤íŠ¸ìš©

            if mode == "realtime" and is_ai_ready():
                # ì‹¤ì‹œê°„ ëª¨ë“œ: AIê°€ ë‹µë³€
                update_task(task["task_id"], status="running")
                await update.message.reply_text(f"â³ ì²˜ë¦¬ ì¤‘... (#{task['task_id']})")

                result = await _process_ai_command(text, task["task_id"])

                if "error" in result:
                    await update.message.reply_text(f"âŒ {result['error']}")
                else:
                    content = result.get("content", "")
                    cost = result.get("cost_usd", 0)
                    model = result.get("model", "")
                    # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (4096ì)
                    if len(content) > 3900:
                        content = content[:3900] + "\n\n... (ê²°ê³¼ê°€ ì˜ë ¸ìŠµë‹ˆë‹¤. ì›¹ì—ì„œ ì „ì²´ í™•ì¸)"
                    delegation = result.get("delegation", "")
                    model_short = model.split("-")[1] if "-" in model else model
                    # ë¹„ì„œì‹¤ì¥ ìœ„ì„ í‘œì‹œ: "ë¹„ì„œì‹¤ì¥ â†’ CTO" ë˜ëŠ” "ë¹„ì„œì‹¤ì¥"
                    footer_who = delegation if delegation else "ë¹„ì„œì‹¤ì¥"
                    await update.message.reply_text(
                        f"{content}\n\n"
                        f"â”€â”€â”€â”€â”€\n"
                        f"ğŸ‘¤ {footer_who} | ğŸ’° ${cost:.4f} | ğŸ¤– {model_short}",
                        parse_mode=None,
                    )
            elif mode == "batch" and is_ai_ready():
                # ë°°ì¹˜ ëª¨ë“œ + AI ì—°ê²°ë¨ â†’ ì‹¤ì œ ë°°ì¹˜ ì²´ì¸ ì‹¤í–‰
                update_task(task["task_id"], status="pending",
                            result_summary="ğŸ“¦ [ë°°ì¹˜ ì²´ì¸] ì‹œì‘ ì¤‘...")
                await update.message.reply_text(
                    f"ğŸ“¦ ë°°ì¹˜ ì ‘ìˆ˜ ì™„ë£Œ (#{task['task_id']})\n"
                    f"ë°°ì¹˜ ì²´ì¸ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n"
                    f"ì™„ë£Œ ì‹œ ê²°ê³¼ë¥¼ ì—¬ê¸°ë¡œ ë³´ë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                    parse_mode=None,
                )

                # ë°°ì¹˜ ì²´ì¸ì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰
                async def _tg_run_batch(text_arg, task_id_arg, chat_id_arg):
                    try:
                        chain_result = await _start_batch_chain(text_arg, task_id_arg)
                        if "error" in chain_result and _telegram_app:
                            try:
                                await _telegram_app.bot.send_message(
                                    chat_id=int(chat_id_arg),
                                    text=f"âŒ ë°°ì¹˜ ì‹œì‘ ì‹¤íŒ¨: {chain_result['error']}",
                                )
                            except Exception:
                                pass
                    except Exception as e:
                        _log(f"[TG] ë°°ì¹˜ ì²´ì¸ ì˜¤ë¥˜: {e}")

                asyncio.create_task(_tg_run_batch(text, task["task_id"], chat_id))
            else:
                # AI ë¯¸ì—°ê²° â†’ ì ‘ìˆ˜ë§Œ
                update_task(task["task_id"], status="completed",
                            result_summary="AI ë¯¸ì—°ê²° â€” ì ‘ìˆ˜ë§Œ ì™„ë£Œ",
                            success=1, time_seconds=0.1)
                await update.message.reply_text(
                    f"ğŸ“‹ ì ‘ìˆ˜í–ˆìŠµë‹ˆë‹¤. ({now})\n"
                    f"ì‘ì—… ID: `{task['task_id']}`\n"
                    f"ìƒíƒœ: AI ë¯¸ì—°ê²°",
                    parse_mode="Markdown",
                )

            # í™œë™ ë¡œê·¸ ì €ì¥ + ì›¹ì†Œì¼“ ë¸Œë¡œë“œìºìŠ¤íŠ¸ (ì›¹ ì±„íŒ…ì—ë„ ëŒ€í™” í‘œì‹œ)
            log_entry = save_activity_log(
                "chief_of_staff",
                f"[í…”ë ˆê·¸ë¨] CEO ì§€ì‹œ: {text[:50]}{'...' if len(text) > 50 else ''} (#{task['task_id']})",
            )
            for ws in connected_clients[:]:
                try:
                    await ws.send_json({"event": "task_accepted", "data": task})
                    await ws.send_json({"event": "activity_log", "data": log_entry})
                    # í…”ë ˆê·¸ë¨ ëŒ€í™”ë¥¼ ì›¹ ì±„íŒ…ì—ë„ í‘œì‹œ
                    await ws.send_json({
                        "event": "telegram_message",
                        "data": {"type": "user", "text": text, "source": "telegram"}
                    })
                    if "error" not in result:
                        await ws.send_json({
                            "event": "result",
                            "data": {
                                "content": result.get("content", ""),
                                "sender_id": result.get("agent_id", "chief_of_staff"),
                                "handled_by": result.get("handled_by", "ë¹„ì„œì‹¤ì¥"),
                                "delegation": result.get("delegation", ""),
                                "time_seconds": result.get("time_seconds", 0),
                                "cost": result.get("total_cost_usd", result.get("cost_usd", 0)),
                                "model": result.get("model", ""),
                                "routing_method": result.get("routing_method", ""),
                                "source": "telegram",
                            }
                        })
                    else:
                        await ws.send_json({
                            "event": "result",
                            "data": {
                                "content": f"âŒ {result['error']}",
                                "sender_id": "chief_of_staff",
                                "handled_by": "ë¹„ì„œì‹¤ì¥",
                                "time_seconds": 0, "cost": 0,
                                "source": "telegram",
                            }
                        })
                except Exception:
                    pass

        def _is_tg_ceo(update: Update) -> bool:
            if not update.effective_chat or not update.message:
                return False
            ceo_id = os.getenv("TELEGRAM_CEO_CHAT_ID", "")
            if not ceo_id:
                return False
            if str(update.effective_chat.id) != ceo_id:
                asyncio.create_task(update.message.reply_text("ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤."))
                return False
            return True

        # í•¸ë“¤ëŸ¬ ë“±ë¡
        _telegram_app.add_handler(CommandHandler("start", cmd_start))
        _telegram_app.add_handler(CommandHandler("help", cmd_help))
        _telegram_app.add_handler(CommandHandler("agents", cmd_agents))
        _telegram_app.add_handler(CommandHandler("health", cmd_health))
        _telegram_app.add_handler(CommandHandler("rt", cmd_rt))
        _telegram_app.add_handler(CommandHandler("batch", cmd_batch))
        _telegram_app.add_handler(CommandHandler("status", cmd_status))
        _telegram_app.add_handler(CommandHandler("budget", cmd_budget))
        _telegram_app.add_handler(CommandHandler("pause", cmd_pause))
        _telegram_app.add_handler(CommandHandler("resume", cmd_resume))
        _telegram_app.add_handler(CommandHandler("models", cmd_models))
        _telegram_app.add_handler(CallbackQueryHandler(models_callback, pattern=r"^mdl_"))
        _telegram_app.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message)
        )

        # ë´‡ ëª…ë ¹ì–´ ë©”ë‰´ ì„¤ì •
        await _telegram_app.bot.set_my_commands([
            BotCommand("start", "ë´‡ ì‹œì‘"),
            BotCommand("help", "ì‚¬ìš©ë²•"),
            BotCommand("agents", "ì—ì´ì „íŠ¸ ëª©ë¡"),
            BotCommand("health", "ì„œë²„ ìƒíƒœ"),
            BotCommand("rt", "ì‹¤ì‹œê°„ ëª¨ë“œ"),
            BotCommand("batch", "ë°°ì¹˜ ëª¨ë“œ"),
            BotCommand("models", "ì „ì› ëª¨ë¸ ë³€ê²½"),
            BotCommand("status", "ë°°ì¹˜ ì§„í–‰ ìƒíƒœ"),
            BotCommand("budget", "ì˜¤ëŠ˜ ë¹„ìš© / í•œë„ ë³€ê²½"),
            BotCommand("pause", "AI ì²˜ë¦¬ ì¤‘ë‹¨"),
            BotCommand("resume", "AI ì²˜ë¦¬ ì¬ê°œ"),
        ])

        _log("[TG] í•¸ë“¤ëŸ¬ ë“±ë¡ ì™„ë£Œ, initialize()...")
        await _telegram_app.initialize()
        _log("[TG] start()...")
        await _telegram_app.start()
        _log("[TG] polling ì‹œì‘...")
        await _telegram_app.updater.start_polling(drop_pending_updates=True)

        ceo_id = os.getenv("TELEGRAM_CEO_CHAT_ID", "")
        _diag["tg_started"] = True
        _log(f"[TG] âœ… ë´‡ ì‹œì‘ ì™„ë£Œ! (CEO: {ceo_id or 'ë¯¸ì„¤ì •'})")
    except Exception as e:
        _diag["tg_error"] = str(e)
        _log(f"[TG] âŒ ë´‡ ì‹œì‘ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        _telegram_app = None


async def _stop_telegram_bot() -> None:
    """í…”ë ˆê·¸ë¨ ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."""
    global _telegram_app
    if _telegram_app:
        try:
            await _telegram_app.updater.stop()
            await _telegram_app.stop()
            await _telegram_app.shutdown()
            logger.info("í…”ë ˆê·¸ë¨ ë´‡ ì¢…ë£Œ ì™„ë£Œ")
        except Exception as e:
            logger.warning("í…”ë ˆê·¸ë¨ ë´‡ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: %s", e)
        _telegram_app = None


# â”€â”€ AI ì—ì´ì „íŠ¸ ìœ„ì„ ì‹œìŠ¤í…œ (Phase 5) â”€â”€

# ë¶€ì„œë³„ í‚¤ì›Œë“œ ë¼ìš°íŒ… í…Œì´ë¸”
_ROUTING_KEYWORDS: dict[str, list[str]] = {
    "cto_manager": [
        "ì½”ë“œ", "ë²„ê·¸", "í”„ë¡ íŠ¸", "ë°±ì—”ë“œ", "API", "ì„œë²„", "ë°°í¬",
        "ì›¹ì‚¬ì´íŠ¸", "í™ˆí˜ì´ì§€", "ë””ìì¸", "UI", "UX", "ë°ì´í„°ë² ì´ìŠ¤",
        "ê°œë°œ", "í”„ë¡œê·¸ë˜ë°", "ê¹ƒí—ˆë¸Œ", "github", "ë¦¬íŒ©í† ë§",
    ],
    "cso_manager": [
        "ì‹œì¥", "ê²½ìŸì‚¬", "ì‚¬ì—…ê³„íš", "ë§¤ì¶œ", "ì˜ˆì¸¡", "ì „ëµ",
        "ë¹„ì¦ˆë‹ˆìŠ¤", "BM", "ìˆ˜ìµ", "ì‚¬ì—…", "ê¸°íš", "ì„±ì¥",
    ],
    "clo_manager": [
        "ì €ì‘ê¶Œ", "íŠ¹í—ˆ", "ìƒí‘œ", "ì•½ê´€", "ê³„ì•½", "ë²•ë¥ ", "ì†Œì†¡", "IP",
        "ê·œì œ", "ë¼ì´ì„ ìŠ¤", "ë²•ì ", "ë²•ë¬´",
    ],
    "cmo_manager": [
        "ë§ˆì¼€íŒ…", "ê´‘ê³ ", "SNS", "ì¸ìŠ¤íƒ€", "ìœ íŠœë¸Œ", "ê³ ê°",
        "ì„¤ë¬¸", "ë¸Œëœë”©", "ì½˜í…ì¸ ", "í™ë³´", "í”„ë¡œëª¨ì…˜", "ìº í˜ì¸",
    ],
    "cio_manager": [
        "ì‚¼ì„±", "ì• í”Œ", "ì£¼ì‹", "íˆ¬ì", "ì¢…ëª©", "ì°¨íŠ¸", "ì‹œí™©",
        "ì½”ìŠ¤í”¼", "ë‚˜ìŠ¤ë‹¥", "í¬íŠ¸í´ë¦¬ì˜¤", "ê¸ˆë¦¬", "í™˜ìœ¨", "ì±„ê¶Œ",
        "ETF", "í€ë“œ", "ë°°ë‹¹", "í…ŒìŠ¬ë¼", "ì—”ë¹„ë””ì•„",
        "ë§¤ìˆ˜", "ë§¤ë„", "ìë™ë§¤ë§¤", "í‚¤ì›€", "ë°±í…ŒìŠ¤íŠ¸", "ì „ëµ",
        "ì†ì ˆ", "ìµì ˆ", "ì‹œê°€ì´ì•¡", "PER", "RSI", "MACD",
    ],
    "cpo_manager": [
        "ê¸°ë¡", "ë¹Œë”©ë¡œê·¸", "ì—°ëŒ€ê¸°", "ë¸”ë¡œê·¸", "ì¶œíŒ", "í¸ì§‘", "íšŒê³ ",
        "ì•„ì¹´ì´ë¸Œ", "ë¬¸ì„œí™”", "íšŒì˜ë¡",
    ],
}

# ì—ì´ì „íŠ¸ ID â†’ í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
_AGENT_NAMES: dict[str, str] = {
    "chief_of_staff": "ë¹„ì„œì‹¤ì¥",
    "cto_manager": "CTO (ê¸°ìˆ ê°œë°œì²˜ì¥)",
    "cso_manager": "CSO (ì‚¬ì—…ê¸°íšì²˜ì¥)",
    "clo_manager": "CLO (ë²•ë¬´IPì²˜ì¥)",
    "cmo_manager": "CMO (ë§ˆì¼€íŒ…ê³ ê°ì²˜ì¥)",
    "cio_manager": "CIO (íˆ¬ìë¶„ì„ì²˜ì¥)",
    "cpo_manager": "CPO (ì¶œíŒê¸°ë¡ì²˜ì¥)",
}

# â”€â”€ ë…¸ì…˜ API ì—°ë™ (ì—ì´ì „íŠ¸ ì‚°ì¶œë¬¼ ìë™ ì €ì¥) â”€â”€

_NOTION_API_KEY = os.getenv("NOTION_API_KEY", "")
# ë¹„ì„œì‹¤ DB (CEO ëª…ë ¹ ê´€ë¦¬)
_NOTION_DB_SECRETARY = os.getenv("NOTION_DB_SECRETARY", "36880ed0-a7e9-4eb8-8bd3-0f206c2e95d6")
# ì—ì´ì „íŠ¸ ì‚°ì¶œë¬¼ DB (ë³´ê³ ì„œ ì•„ì¹´ì´ë¸Œ)
_NOTION_DB_OUTPUT = os.getenv("NOTION_DB_OUTPUT", "4c20dd05-b740-461c-9189-f1e74362b365")
# í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ í™˜ê²½ë³€ìˆ˜ë„ ì§€ì›
_NOTION_DB_ID = os.getenv("NOTION_DEFAULT_DB_ID", _NOTION_DB_OUTPUT)

# ë…¸ì…˜ ë¡œê·¸ (ìµœê·¼ 20ê°œ, /api/notion-logì—ì„œ ì¡°íšŒ ê°€ëŠ¥)
_notion_log: list[dict] = []

def _add_notion_log(status: str, title: str, db: str = "", url: str = "", error: str = ""):
    """ë…¸ì…˜ ì‘ì—… ë¡œê·¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤ (ìµœê·¼ 20ê°œ)."""
    global _notion_log
    _notion_log.append({
        "time": datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S"),
        "status": status,
        "title": title[:60],
        "db": db,
        "url": url,
        "error": error[:200] if error else "",
    })
    _notion_log = _notion_log[-20:]

# ì—ì´ì „íŠ¸ ID â†’ ë¶€ì„œëª… ë§¤í•‘
_AGENT_DIVISION: dict[str, str] = {}
for _a in AGENTS:
    if _a.get("division"):
        _AGENT_DIVISION[_a["agent_id"]] = _a["division"]


async def _save_to_notion(agent_id: str, title: str, content: str,
                          report_type: str = "ë³´ê³ ì„œ",
                          db_target: str = "output") -> str | None:
    """ì—ì´ì „íŠ¸ ì‚°ì¶œë¬¼ì„ ë…¸ì…˜ DBì— ì €ì¥í•©ë‹ˆë‹¤.

    db_target: "output" = ì—ì´ì „íŠ¸ ì‚°ì¶œë¬¼ DB, "secretary" = ë¹„ì„œì‹¤ DB
    Python ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬(urllib)ë§Œ ì‚¬ìš© â€” ì¶”ê°€ íŒ¨í‚¤ì§€ ë¶ˆí•„ìš”.
    ì‹¤íŒ¨í•´ë„ ì—ëŸ¬ë§Œ ë¡œê¹…í•˜ê³  None ë°˜í™˜ (ì„œë²„ ë™ì‘ì— ì˜í–¥ ì—†ìŒ).
    """
    if not _NOTION_API_KEY:
        _add_notion_log("SKIP", title, error="API í‚¤ ì—†ìŒ")
        return None

    db_id = _NOTION_DB_SECRETARY if db_target == "secretary" else _NOTION_DB_ID
    db_name = "ë¹„ì„œì‹¤" if db_target == "secretary" else "ì‚°ì¶œë¬¼"

    division = _AGENT_DIVISION.get(agent_id, "")
    agent_name = _AGENT_NAMES.get(agent_id, _SPECIALIST_NAMES.get(agent_id, agent_id))
    now_str = datetime.now(KST).strftime("%Y-%m-%d")

    # ë…¸ì…˜ í˜ì´ì§€ í”„ë¡œí¼í‹° êµ¬ì„±
    properties: dict = {
        "Name": {"title": [{"text": {"content": title[:100]}}]},
    }
    # ì„ íƒ ì†ì„±ë“¤ (DBì— í•´ë‹¹ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë…¸ì…˜ì´ ë¬´ì‹œí•¨ â€” ìœ ì—°í•œ êµ¬ì¡°)
    if agent_name:
        properties["ì‘ì„±ì"] = {"rich_text": [{"text": {"content": agent_name}}]}
    if division:
        properties["ë¶€ì„œ"] = {"rich_text": [{"text": {"content": division}}]}
    if report_type:
        properties["ë³´ê³  ìœ í˜•"] = {"rich_text": [{"text": {"content": report_type}}]}
    properties["ìƒíƒœ"] = {"rich_text": [{"text": {"content": "ì™„ë£Œ"}}]}
    properties["ë‚ ì§œ"] = {"date": {"start": now_str}}

    # ë³¸ë¬¸ â†’ ë…¸ì…˜ ë¸”ë¡ (ìµœëŒ€ 2000ì, ë…¸ì…˜ ë¸”ë¡ í¬ê¸° ì œí•œ)
    children = []
    text_chunks = [content[i:i+1900] for i in range(0, min(len(content), 8000), 1900)]
    for chunk in text_chunks:
        children.append({
            "object": "block",
            "type": "paragraph",
            "paragraph": {"rich_text": [{"text": {"content": chunk}}]},
        })

    body = json.dumps({
        "parent": {"database_id": db_id},
        "properties": properties,
        "children": children,
    }).encode("utf-8")

    headers = {
        "Authorization": f"Bearer {_NOTION_API_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28",
    }

    def _do_request():
        req = urllib.request.Request(
            "https://api.notion.com/v1/pages",
            data=body, headers=headers, method="POST",
        )
        try:
            with urllib.request.urlopen(req, timeout=10) as resp:
                return json.loads(resp.read().decode("utf-8"))
        except urllib.error.HTTPError as e:
            err_body = e.read().decode("utf-8", errors="replace")[:200]
            _log(f"[Notion] HTTP {e.code} ì˜¤ë¥˜: {err_body}")
            _add_notion_log("FAIL", title, db=db_name, error=f"HTTP {e.code}: {err_body}")
            return None
        except Exception as e:
            _log(f"[Notion] ìš”ì²­ ì‹¤íŒ¨: {e}")
            _add_notion_log("FAIL", title, db=db_name, error=str(e))
            return None

    try:
        result = await asyncio.to_thread(_do_request)
        if result and result.get("url"):
            _log(f"[Notion] ì €ì¥ ì™„ë£Œ ({db_name}): {title[:50]} â†’ {result['url']}")
            _add_notion_log("OK", title, db=db_name, url=result["url"])
            return result["url"]
        else:
            _add_notion_log("FAIL", title, db=db_name, error="ì‘ë‹µì— URL ì—†ìŒ")
    except Exception as e:
        _log(f"[Notion] ë¹„ë™ê¸° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        _add_notion_log("FAIL", title, db=db_name, error=str(e))

    return None


@app.get("/api/notion-log")
async def get_notion_log():
    """ë…¸ì…˜ ì €ì¥ ë¡œê·¸ ì¡°íšŒ (ìµœê·¼ 20ê±´)."""
    return {
        "logs": _notion_log,
        "total": len(_notion_log),
        "api_key_set": bool(_NOTION_API_KEY),
        "db_secretary": _NOTION_DB_SECRETARY[:8] + "..." if _NOTION_DB_SECRETARY else "",
        "db_output": _NOTION_DB_ID[:8] + "..." if _NOTION_DB_ID else "",
    }


# ë¸Œë¡œë“œìºìŠ¤íŠ¸ í‚¤ì›Œë“œ (ëª¨ë“  ë¶€ì„œì— ë™ì‹œ ì „ë‹¬í•˜ëŠ” ëª…ë ¹)
_BROADCAST_KEYWORDS = [
    "ì „ì²´", "ëª¨ë“  ë¶€ì„œ", "ì¶œì„", "íšŒì˜", "í˜„í™© ë³´ê³ ",
    "ì´ê´„", "ì „ì›", "ê° ë¶€ì„œ", "ì¶œì„ì²´í¬", "ë¸Œë¦¬í•‘",
]

# ì²˜ì¥/ë¹„ì„œì‹¤ì¥ â†’ ì†Œì† ì „ë¬¸ê°€ ë§¤í•‘
_MANAGER_SPECIALISTS: dict[str, list[str]] = {
    "chief_of_staff": ["report_specialist", "schedule_specialist", "relay_specialist"],
    "cto_manager": ["frontend_specialist", "backend_specialist", "infra_specialist", "ai_model_specialist"],
    "cso_manager": ["market_research_specialist", "business_plan_specialist", "financial_model_specialist"],
    "clo_manager": ["copyright_specialist", "patent_specialist"],
    "cmo_manager": ["survey_specialist", "content_specialist", "community_specialist"],
    "cio_manager": ["market_condition_specialist", "stock_analysis_specialist", "technical_analysis_specialist", "risk_management_specialist"],
    "cpo_manager": ["chronicle_specialist", "editor_specialist", "archive_specialist"],
}

# ì „ë¬¸ê°€ ID â†’ í•œêµ­ì–´ ì´ë¦„ (AGENTS ë¦¬ìŠ¤íŠ¸ì—ì„œ ìë™ êµ¬ì¶•)
_SPECIALIST_NAMES: dict[str, str] = {}
for _a in AGENTS:
    if _a["role"] == "specialist":
        _SPECIALIST_NAMES[_a["agent_id"]] = _a["name_ko"]


def _is_broadcast_command(text: str) -> bool:
    """ë¸Œë¡œë“œìºìŠ¤íŠ¸ ëª…ë ¹ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return any(kw in text for kw in _BROADCAST_KEYWORDS)


async def _broadcast_status(agent_id: str, status: str, progress: float, detail: str = ""):
    """ì—ì´ì „íŠ¸ ìƒíƒœë¥¼ ëª¨ë“  WebSocket í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡í•©ë‹ˆë‹¤.

    í”„ë¡ íŠ¸ì—”ë“œì˜ ìƒíƒœ í‘œì‹œë“±(ì´ˆë¡ë¶ˆ ê¹œë¹¡ì„)ì„ ì œì–´í•©ë‹ˆë‹¤.
    status: 'working' | 'done' | 'idle'
    """
    for c in connected_clients[:]:
        try:
            await c.send_json({
                "event": "agent_status",
                "data": {
                    "agent_id": agent_id,
                    "status": status,
                    "progress": progress,
                    "detail": detail,
                }
            })
        except Exception:
            pass


async def _extract_and_save_memory(agent_id: str, task: str, response: str):
    """ëŒ€í™” í›„ ê¸°ì–µí•  ì •ë³´ ì¶”ì¶œ â†’ save_settingì— ì €ì¥ (ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œ)."""
    try:
        extraction_prompt = (
            "ì•„ë˜ ëŒ€í™”ì—ì„œ ì—ì´ì „íŠ¸ê°€ ê¸°ì–µí•´ì•¼ í•  ì •ë³´ê°€ ìˆìœ¼ë©´ JSONìœ¼ë¡œ ì¶”ì¶œí•´ë¼. "
            "ì—†ìœ¼ë©´ ë¹ˆ dict {} ë°˜í™˜.\n\n"
            f"[ëŒ€í™”]\nì‚¬ìš©ì: {task[:400]}\nì—ì´ì „íŠ¸: {response[:400]}\n\n"
            "[ì¶”ì¶œ í•­ëª©]\n"
            "- ceo_preferences: CEOê°€ ì„ í˜¸í•˜ê±°ë‚˜ ì‹«ì–´í•˜ëŠ” ê²ƒ (ìˆìœ¼ë©´)\n"
            "- decisions: '~í•˜ê¸°ë¡œ ê²°ì •', '~ë¡œ í™•ì •' ë“± ì¤‘ìš” ê²°ì • (ìˆìœ¼ë©´)\n"
            "- warnings: ì´ ë°©ë²•ì€ ì•ˆ ë¨, CEOê°€ ì‹«ë‹¤ê³  í•¨ ë“± ì£¼ì˜ì‚¬í•­ (ìˆìœ¼ë©´)\n"
            "- context: í”„ë¡œì íŠ¸ ìƒíƒœ, ê±°ë˜ì²˜, ì¼ì • ë“± ì¤‘ìš” ë§¥ë½ (ìˆìœ¼ë©´)\n\n"
            "JSONë§Œ ë°˜í™˜ (ì„¤ëª… ì—†ì´):"
        )

        result = await ask_ai(
            user_message=extraction_prompt,
            model="claude-sonnet-4-6",
            max_tokens=400,
            system_prompt="JSONë§Œ ë°˜í™˜. ì„¤ëª… ì—†ì´."
        )

        text_resp = result.get("content", "") if isinstance(result, dict) else str(result)
        text_resp = text_resp.strip()
        # JSON ë¸”ë¡ ì¶”ì¶œ
        if "```" in text_resp:
            text_resp = text_resp.split("```")[1].strip()
            if text_resp.startswith("json"):
                text_resp = text_resp[4:].strip()

        new_facts = json.loads(text_resp)
        if new_facts and isinstance(new_facts, dict):
            existing = load_setting(f"memory_categorized_{agent_id}", {})
            for key, val in new_facts.items():
                if val and val not in ("null", "ì—†ìŒ", ""):
                    prev = existing.get(key, "")
                    existing[key] = (prev + " | " + str(val)).strip(" |") if prev else str(val)
            save_setting(f"memory_categorized_{agent_id}", existing)
    except Exception as e:
        logger.debug(f"ê¸°ì–µ ì¶”ì¶œ ê±´ë„ˆëœ€ ({agent_id}): {e}")


async def _call_agent(agent_id: str, text: str) -> dict:
    """ë‹¨ì¼ ì—ì´ì „íŠ¸ì—ê²Œ AI í˜¸ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ìƒíƒœ ì´ë²¤íŠ¸ + í™œë™ ë¡œê·¸ + ë„êµ¬ ìë™í˜¸ì¶œ í¬í•¨)."""
    agent_name = _AGENT_NAMES.get(agent_id, _SPECIALIST_NAMES.get(agent_id, agent_id))
    await _broadcast_status(agent_id, "working", 0.1, f"{agent_name} ì‘ì—… ì¤€ë¹„ ì¤‘...")

    # í™œë™ ë¡œê·¸ â€” ëˆ„ê°€ ì¼í•˜ëŠ”ì§€ ê¸°ë¡
    log_entry = save_activity_log(agent_id, f"[{agent_name}] ì‘ì—… ì‹œì‘: {text[:40]}...")
    for c in connected_clients[:]:
        try:
            await c.send_json({"event": "activity_log", "data": log_entry})
        except Exception:
            pass

    soul = _load_agent_prompt(agent_id)

    # â”€â”€ ì—ì´ì „íŠ¸ ê¸°ì–µ ì£¼ì… (ì¹´í…Œê³ ë¦¬ë³„ ê¸°ì–µ â†’ system_prompt ì•ì— ì‚½ì…) â”€â”€
    mem = load_setting(f"memory_categorized_{agent_id}", {})
    if mem:
        mem_lines = []
        if mem.get("ceo_preferences"):
            mem_lines.append(f"- CEO ì·¨í–¥/ì„ í˜¸: {mem['ceo_preferences']}")
        if mem.get("decisions"):
            mem_lines.append(f"- ì£¼ìš” ê²°ì •: {mem['decisions']}")
        if mem.get("warnings"):
            mem_lines.append(f"- ì£¼ì˜ì‚¬í•­: {mem['warnings']}")
        if mem.get("context"):
            mem_lines.append(f"- ì¤‘ìš” ë§¥ë½: {mem['context']}")
        if mem_lines:
            memory_block = "[ì—ì´ì „íŠ¸ ê¸°ì–µ]\n" + "\n".join(mem_lines) + "\n\n"
            soul = memory_block + soul

    override = _get_model_override(agent_id)
    model = select_model(text, override=override)

    # â”€â”€ ë„êµ¬ ìë™í˜¸ì¶œ (Function Calling) â”€â”€
    # ì—ì´ì „íŠ¸ë³„ í—ˆìš© ë„êµ¬ ëª©ë¡ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆë¥¼ ë¡œë“œí•˜ê³ , ë„êµ¬ ì‹¤í–‰ í•¨ìˆ˜ë¥¼ ì „ë‹¬
    tool_schemas = None
    tool_executor_fn = None
    tools_used: list[str] = []  # ì‚¬ìš©í•œ ë„êµ¬ ì´ë¦„ ì¶”ì 
    detail = _AGENTS_DETAIL.get(agent_id, {})
    allowed = detail.get("allowed_tools", [])
    if allowed:
        schemas = _load_tool_schemas(allowed_tools=allowed)
        if schemas.get("anthropic"):
            tool_schemas = schemas["anthropic"]  # ask_ai ë‚´ë¶€ì—ì„œ í”„ë¡œë°”ì´ë”ë³„ ë³€í™˜

            _MAX_TOOL_CALLS = 5  # ë¬´í•œ ë£¨í”„ ë°©ì§€ ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜

            async def _tool_executor(tool_name: str, tool_input: dict):
                """ToolPoolì„ í†µí•´ ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
                tools_used.append(tool_name)
                call_count = len(tools_used)
                # ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜ ê¸°ë°˜ ì§„í–‰ë¥  ê³„ì‚° (1íšŒ=20%, 2íšŒ=40%, ..., 5íšŒ=100%)
                tool_progress = 0.3 + min(call_count / _MAX_TOOL_CALLS, 1.0) * 0.35
                tool_progress_pct = int(tool_progress * 100)

                # ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜ í¬í•¨ agent_status ì´ë²¤íŠ¸ ë°œì†¡
                for _c in connected_clients[:]:
                    try:
                        await _c.send_json({
                            "event": "agent_status",
                            "data": {
                                "agent_id": agent_id,
                                "status": "working",
                                "progress": round(tool_progress, 2),
                                "detail": f"{tool_name} ë„êµ¬ ì‹¤í–‰ ì¤‘...",
                                "tool_calls": call_count,
                                "max_calls": _MAX_TOOL_CALLS,
                            },
                        })
                    except Exception:
                        pass

                pool = _init_tool_pool()
                if pool and hasattr(pool, '_tools') and tool_name in pool._tools:
                    tool_obj = pool._tools[tool_name]
                    # ë„êµ¬ì˜ execute ë©”ì„œë“œ í˜¸ì¶œ
                    if asyncio.iscoroutinefunction(getattr(tool_obj, 'execute', None)):
                        return await tool_obj.execute(**tool_input)
                    elif hasattr(tool_obj, 'execute'):
                        return await asyncio.to_thread(tool_obj.execute, **tool_input)
                # ToolPoolì— ì—†ìœ¼ë©´ ë‹¨ìˆœ ì„¤ëª… ë°˜í™˜
                return f"ë„êµ¬ '{tool_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            tool_executor_fn = _tool_executor

    await _broadcast_status(agent_id, "working", 0.3, "AI ì‘ë‹µ ìƒì„± ì¤‘...")
    result = await ask_ai(text, system_prompt=soul, model=model,
                          tools=tool_schemas, tool_executor=tool_executor_fn)
    await _broadcast_status(agent_id, "working", 0.7, "ì‘ë‹µ ì²˜ë¦¬ ì¤‘...")

    # agent_calls í…Œì´ë¸”ì— AI í˜¸ì¶œ ê¸°ë¡ ì €ì¥
    try:
        from db import save_agent_call
        save_agent_call(
            agent_id=agent_id,
            model=result.get("model", "") if isinstance(result, dict) else "",
            provider=result.get("provider", "") if isinstance(result, dict) else "",
            cost_usd=result.get("cost_usd", 0) if isinstance(result, dict) else 0,
            input_tokens=result.get("input_tokens", 0) if isinstance(result, dict) else 0,
            output_tokens=result.get("output_tokens", 0) if isinstance(result, dict) else 0,
            time_seconds=result.get("time_seconds", 0) if isinstance(result, dict) else 0,
        )
    except Exception as e:
        _log(f"[AGENT_CALL] ê¸°ë¡ ì‹¤íŒ¨: {e}")

    if "error" in result:
        await _broadcast_status(agent_id, "done", 1.0, "ì˜¤ë¥˜ ë°œìƒ")
        return {"agent_id": agent_id, "name": agent_name, "error": result["error"], "cost_usd": 0}

    await _broadcast_status(agent_id, "working", 0.9, "ì €ì¥ ì™„ë£Œ...")
    await _broadcast_status(agent_id, "done", 1.0, "ì™„ë£Œ")

    # ì™„ë£Œ ë¡œê·¸
    cost = result.get("cost_usd", 0)
    content = result.get("content", "")
    log_done = save_activity_log(agent_id, f"[{agent_name}] ì‘ì—… ì™„ë£Œ (${cost:.4f})")
    for c in connected_clients[:]:
        try:
            await c.send_json({"event": "activity_log", "data": log_done})
        except Exception:
            pass

    # â”€â”€ ë¹„ìš© ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ (í”„ë¡ íŠ¸ì—”ë“œ ìš°ì¸¡ ìƒë‹¨ ê¸ˆì•¡ ì‹¤ì‹œê°„ ë°˜ì˜) â”€â”€
    try:
        today_cost = get_today_cost()
    except Exception:
        today_cost = cost
    for c in connected_clients[:]:
        try:
            await c.send_json({
                "event": "cost_update",
                "data": {"total_cost": today_cost, "total_tokens": 0},
            })
        except Exception:
            pass

    # â”€â”€ ê¸°ì–µ ìë™ ì¶”ì¶œ (ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œ â€” ì‘ë‹µì—ì„œ ì¤‘ìš” ì •ë³´ ì €ì¥) â”€â”€
    if content and len(content) > 30:
        asyncio.create_task(_extract_and_save_memory(agent_id, text, content))

    # ì‚°ì¶œë¬¼ ì €ì¥ (ë…¸ì…˜ + ì•„ì¹´ì´ë¸Œ DB)
    if content and len(content) > 20:
        # ë…¸ì…˜ì— ì €ì¥ (ë¹„ë™ê¸°, ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ)
        asyncio.create_task(_save_to_notion(
            agent_id=agent_id,
            title=f"[{agent_name}] {text[:50]}",
            content=content,
        ))
        # ì•„ì¹´ì´ë¸Œ DBì— ì €ì¥ (ì˜êµ¬ ë³´ê´€)
        division = _AGENT_DIVISION.get(agent_id, "secretary")
        now_str = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
        # ì‚¬ìš©í•œ ë„êµ¬ ë©”íƒ€ë°ì´í„°ë¥¼ ì½˜í…ì¸  ë§¨ ì•„ë˜ì— ì¶”ê°€
        if tools_used:
            unique_tools = list(dict.fromkeys(tools_used))  # ì¤‘ë³µ ì œê±°, ìˆœì„œ ìœ ì§€
            content += f"\n\n---\nğŸ”§ **ì‚¬ìš©í•œ ë„êµ¬**: {', '.join(unique_tools)}"

        archive_content = f"# [{agent_name}] {text[:60]}\n\n{content}"
        save_archive(
            division=division,
            filename=f"{agent_id}_{now_str}.md",
            content=archive_content,
            agent_id=agent_id,
        )

    return {
        "agent_id": agent_id,
        "name": agent_name,
        "content": content,
        "cost_usd": cost,
        "model": result.get("model", ""),
        "time_seconds": result.get("time_seconds", 0),
        "input_tokens": result.get("input_tokens", 0),
        "output_tokens": result.get("output_tokens", 0),
        "tools_used": tools_used,
    }


async def _delegate_to_specialists(manager_id: str, text: str) -> list[dict]:
    """ì²˜ì¥ì´ ì†Œì† ì „ë¬¸ê°€ë“¤ì—ê²Œ ë³‘ë ¬ë¡œ ìœ„ì„í•©ë‹ˆë‹¤.

    asyncio.gatherë¡œ ì „ë¬¸ê°€ë“¤ì„ ë™ì‹œì— í˜¸ì¶œ â†’ ìƒíƒœ í‘œì‹œë“± ì „ë¶€ ê¹œë¹¡ì„.
    ìœ„ì„ ë°œìƒ ì‹œ delegation_logì— ìë™ ê¸°ë¡í•©ë‹ˆë‹¤.
    """
    specialists = _MANAGER_SPECIALISTS.get(manager_id, [])
    if not specialists:
        return []

    # ìœ„ì„ ë¡œê·¸ ìë™ ê¸°ë¡
    try:
        from db import save_delegation_log
        mgr_name = _AGENT_NAMES.get(manager_id, manager_id)
        for spec_id in specialists:
            spec_name = _SPECIALIST_NAMES.get(spec_id, spec_id)
            save_delegation_log(
                sender=mgr_name,
                receiver=spec_name,
                message=text[:500],
                log_type="delegation",
            )
    except Exception:
        pass

    tasks = [_call_agent(spec_id, text) for spec_id in specialists]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    processed = []
    for i, r in enumerate(results):
        spec_id = specialists[i]
        if isinstance(r, Exception):
            processed.append({"agent_id": spec_id, "name": _SPECIALIST_NAMES.get(spec_id, spec_id), "error": str(r)[:100], "cost_usd": 0})
        else:
            # ì „ë¬¸ê°€ ê²°ê³¼ ë³´ê³  ë¡œê·¸ ìë™ ê¸°ë¡
            try:
                from db import save_delegation_log
                spec_name = _SPECIALIST_NAMES.get(spec_id, spec_id)
                mgr_name = _AGENT_NAMES.get(manager_id, manager_id)
                content_preview = r.get("content", "")[:300] if isinstance(r, dict) else str(r)[:300]
                save_delegation_log(
                    sender=spec_name,
                    receiver=mgr_name,
                    message=content_preview,
                    log_type="report",
                )
            except Exception:
                pass
            processed.append(r)
    return processed


async def _manager_with_delegation(manager_id: str, text: str) -> dict:
    """ì²˜ì¥ì´ ì „ë¬¸ê°€ì—ê²Œ ìœ„ì„ â†’ ê²°ê³¼ ì¢…í•©(ê²€ìˆ˜) â†’ ë³´ê³ ì„œ ì‘ì„±.

    íë¦„: ì²˜ì¥ ë¶„ì„ ì‹œì‘ â†’ ì „ë¬¸ê°€ ë³‘ë ¬ í˜¸ì¶œ â†’ ì²˜ì¥ì´ ê²°ê³¼ ì¢…í•© + ê²€ìˆ˜ â†’ ë³´ê³ ì„œ ë°˜í™˜
    ê²€ìˆ˜: ì²˜ì¥ì´ ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì½ê³  ì¢…í•©í•˜ëŠ” ê³¼ì • ìì²´ê°€ í’ˆì§ˆ ê²€ìˆ˜ ì—­í• ì„ í•©ë‹ˆë‹¤.
    """
    mgr_name = _AGENT_NAMES.get(manager_id, manager_id)
    specialists = _MANAGER_SPECIALISTS.get(manager_id, [])
    spec_names = [_SPECIALIST_NAMES.get(s, s) for s in specialists]

    # ì²˜ì¥ ìƒíƒœ: ëª…ë ¹ ë¶„ì„ ì¤‘
    await _broadcast_status(manager_id, "working", 0.1, "ëª…ë ¹ ë¶„ì„ â†’ ì „ë¬¸ê°€ ìœ„ì„ ì¤‘...")

    # ì²˜ì¥ í™œë™ ë¡œê·¸ â€” ì „ë¬¸ê°€ì—ê²Œ ìœ„ì„
    if specialists:
        log_mgr = save_activity_log(manager_id, f"[{mgr_name}] ì „ë¬¸ê°€ {len(specialists)}ëª…ì—ê²Œ ìœ„ì„: {', '.join(spec_names)}")
        for c in connected_clients[:]:
            try:
                await c.send_json({"event": "activity_log", "data": log_mgr})
            except Exception:
                pass

    # ì „ë¬¸ê°€ë“¤ì—ê²Œ ë³‘ë ¬ ìœ„ì„
    spec_results = await _delegate_to_specialists(manager_id, text)

    if not spec_results:
        # ì „ë¬¸ê°€ê°€ ì—†ìœ¼ë©´ ì²˜ì¥ì´ ì§ì ‘ ì²˜ë¦¬
        return await _call_agent(manager_id, text)

    # ì „ë¬¸ê°€ ê²°ê³¼ ì·¨í•©
    spec_parts = []
    spec_cost = 0.0
    spec_time = 0.0
    for r in spec_results:
        name = r.get("name", r.get("agent_id", "?"))
        if "error" in r:
            spec_parts.append(f"[{name}] ì˜¤ë¥˜: {r['error'][:80]}")
        else:
            spec_parts.append(f"[{name}]\n{r.get('content', 'ì‘ë‹µ ì—†ìŒ')}")
            spec_cost += r.get("cost_usd", 0)
            spec_time = max(spec_time, r.get("time_seconds", 0))

    # ì²˜ì¥ì´ ì¢…í•© + ê²€ìˆ˜ (ì „ë¬¸ê°€ ê²°ê³¼ë¥¼ ì½ê³  CEOì—ê²Œ ë³´ê³ ì„œ ì‘ì„±)
    synthesis_prompt = (
        f"ë‹¹ì‹ ì€ {mgr_name}ì…ë‹ˆë‹¤. ì†Œì† ì „ë¬¸ê°€ë“¤ì´ ì•„ë˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì œì¶œí–ˆìŠµë‹ˆë‹¤.\n"
        f"ì´ë¥¼ ê²€ìˆ˜í•˜ê³  ì¢…í•©í•˜ì—¬ CEOì—ê²Œ ë³´ê³ í•  ê°„ê²°í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
        f"ì „ë¬¸ê°€ ì˜ê²¬ ì¤‘ ë¶€ì¡±í•˜ê±°ë‚˜ ì˜ëª»ëœ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì§€ì í•˜ê³  ë³´ì™„í•˜ì„¸ìš”.\n\n"
        f"## CEO ì›ë³¸ ëª…ë ¹\n{text}\n\n"
        f"## ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼\n" + "\n\n".join(spec_parts)
    )

    soul = _load_agent_prompt(manager_id)
    override = _get_model_override(manager_id)
    model = select_model(synthesis_prompt, override=override)

    await _broadcast_status(manager_id, "working", 0.7, "ì „ë¬¸ê°€ ê²°ê³¼ ê²€ìˆ˜ + ì¢…í•© ì¤‘...")
    synthesis = await ask_ai(synthesis_prompt, system_prompt=soul, model=model)

    await _broadcast_status(manager_id, "done", 1.0, "ë³´ê³  ì™„ë£Œ")

    if "error" in synthesis:
        # ì¢…í•© ì‹¤íŒ¨ ì‹œ ì „ë¬¸ê°€ ê²°ê³¼ë§Œ ë°˜í™˜
        content = f"**{mgr_name} ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼**\n\n" + "\n\n---\n\n".join(spec_parts)
        return {"agent_id": manager_id, "name": mgr_name, "content": content, "cost_usd": spec_cost}

    total_cost = spec_cost + synthesis.get("cost_usd", 0)
    specialists_used = len([r for r in spec_results if "error" not in r])
    synth_content = synthesis.get("content", "")

    # ì¢…í•© ë³´ê³ ì„œ ì €ì¥ (ë…¸ì…˜ + ì•„ì¹´ì´ë¸Œ DB)
    if synth_content and len(synth_content) > 20:
        asyncio.create_task(_save_to_notion(
            agent_id=manager_id,
            title=f"[{mgr_name}] ì¢…í•©ë³´ê³ : {text[:40]}",
            content=synth_content,
            report_type="ì¢…í•©ë³´ê³ ì„œ",
        ))
        # ì•„ì¹´ì´ë¸Œ DBì— ì €ì¥
        division = _AGENT_DIVISION.get(manager_id, "secretary")
        now_str = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
        archive_content = f"# [{mgr_name}] ì¢…í•©ë³´ê³ : {text[:50]}\n\n{synth_content}"
        save_archive(
            division=division,
            filename=f"{manager_id}_synthesis_{now_str}.md",
            content=archive_content,
            agent_id=manager_id,
        )

    return {
        "agent_id": manager_id,
        "name": mgr_name,
        "content": synth_content,
        "cost_usd": total_cost,
        "model": synthesis.get("model", ""),
        "time_seconds": round(spec_time + synthesis.get("time_seconds", 0), 2),
        "specialists_used": specialists_used,
    }


def _determine_routing_level(text: str) -> tuple[int, str | None]:
    """ì§ˆë¬¸ ë³µì¡ë„ì— ë”°ë¼ Level 1~4ì™€ ëŒ€ìƒ ì²˜ì¥ ID ë°˜í™˜.

    Returns: (level, manager_id_or_None)
    - Level 1: ê°„ë‹¨í•œ ì¸ì‚¬/ë‹¨ìˆœ ì§ˆë¬¸ â†’ ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬ (ì²˜ì¥ í˜¸ì¶œ ì—†ìŒ)
    - Level 2: íŠ¹ì • ë¶€ì„œ ì „ë¬¸ ì§ˆë¬¸ â†’ ì²˜ì¥ 1ëª…ë§Œ í˜¸ì¶œ
    - Level 3: íŠ¹ì • ë¶€ì„œ ì‹¬ì¸µ ë¶„ì„ â†’ ì²˜ì¥ 1ëª… + spawn_agent ììœ¨ ì „ë¬¸ê°€ ì„ íƒ
    - Level 4: ë³µí•©/ì „ì‚¬ ì§ˆë¬¸ â†’ ì „ì› ë³‘ë ¬ í˜¸ì¶œ (ê¸°ì¡´ ë¸Œë¡œë“œìºìŠ¤íŠ¸)
    """
    t = text.lower()

    # Level 1: ê°„ë‹¨í•œ ìš”ì²­ â€” ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬
    SIMPLE_KEYWORDS = ["ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”", "ê³ ë§ˆì›Œ", "ê°ì‚¬í•©ë‹ˆë‹¤", "ì¼ì •", "ë­ì•¼",
                       "ì–¸ì œì•¼", "ë­”ê°€ìš”", "ì•Œë ¤ì¤˜", "ì°¾ì•„ì¤˜", "í™•ì¸í•´ì¤˜"]
    if len(text) < 50 and any(k in t for k in SIMPLE_KEYWORDS):
        return (1, None)

    # Level 2/3: íŠ¹ì • ë¶€ì„œ ì „ë¬¸ ì§ˆë¬¸
    MANAGER_KEYWORDS = {
        "cto_manager": ["ê¸°ìˆ ", "ê°œë°œ", "ì½”ë“œ", "api", "ì„œë²„", "ì•±", "ì›¹", "í”„ë¡ íŠ¸", "ë°±ì—”ë“œ", "ì¸í”„ë¼", "ai ëª¨ë¸", "ë°ì´í„°ë² ì´ìŠ¤"],
        "cso_manager": ["ì‚¬ì—…", "ì‹œì¥", "ì¬ë¬´", "ì „ëµ", "ë¹„ì¦ˆë‹ˆìŠ¤", "ê³„íš", "ìˆ˜ìµ", "ë§¤ì¶œ", "íˆ¬ì ê³„íš"],
        "clo_manager": ["ë²•", "ê³„ì•½", "ì €ì‘ê¶Œ", "íŠ¹í—ˆ", "ì•½ê´€", "ë²•ë¥ ", "ip"],
        "cmo_manager": ["ë§ˆì¼€íŒ…", "ê³ ê°", "ì½˜í…ì¸ ", "sns", "ê´‘ê³ ", "ì»¤ë®¤ë‹ˆí‹°", "ë¸Œëœë”©"],
        "cio_manager": ["íˆ¬ì", "ì£¼ì‹", "ì½”ìŠ¤í”¼", "ì‹œí™©", "ì¢…ëª©", "ë¦¬ìŠ¤í¬", "í¬íŠ¸í´ë¦¬ì˜¤", "etf", "ì±„ê¶Œ"],
        "cpo_manager": ["ê¸°ë¡", "ì¶œíŒ", "ë¸”ë¡œê·¸", "ì—°ëŒ€ê¸°", "íšŒê³ ", "í¸ì§‘", "ì•„ì¹´ì´ë¸Œ"],
    }

    matched_manager = None
    for mgr_id, keywords in MANAGER_KEYWORDS.items():
        if any(k in t for k in keywords):
            matched_manager = mgr_id
            break

    if matched_manager:
        DEEP_KEYWORDS = ["ë¶„ì„", "ë³´ê³ ì„œ", "ì „ëµ", "ê³„íšì„œ", "ê²€í† ", "í‰ê°€", "ë¹„êµ", "ì˜ˆì¸¡", "ì „ë§"]
        if any(k in t for k in DEEP_KEYWORDS):
            return (3, matched_manager)
        return (2, matched_manager)

    return (4, None)


async def _manager_with_delegation_autonomous(manager_id: str, text: str) -> dict:
    """ì²˜ì¥ì´ spawn_agent ë„êµ¬ë¡œ í•„ìš”í•œ ì „ë¬¸ê°€ë§Œ ììœ¨ ì„ íƒí•˜ì—¬ í˜¸ì¶œ (Level 3ìš©)."""
    agent_cfg = next((a for a in AGENTS if a.get("agent_id") == manager_id), None)
    if not agent_cfg:
        return {"content": f"ì—ì´ì „íŠ¸ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {manager_id}", "error": True}

    soul = _load_agent_prompt(manager_id)
    specialists_pool = _MANAGER_SPECIALISTS.get(manager_id, [])

    # spawn_agent ë„êµ¬ ìŠ¤í‚¤ë§ˆ
    spawn_tool = {
        "name": "spawn_agent",
        "description": (
            f"ì†Œì† ì „ë¬¸ê°€ë¥¼ í˜¸ì¶œí•˜ì—¬ íŠ¹ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. "
            f"ì‚¬ìš© ê°€ëŠ¥í•œ ì „ë¬¸ê°€ ID: {', '.join(specialists_pool)}"
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "agent_id": {
                    "type": "string",
                    "description": "í˜¸ì¶œí•  ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ ID",
                    "enum": specialists_pool,
                },
                "task": {
                    "type": "string",
                    "description": "ì „ë¬¸ê°€ì—ê²Œ ì§€ì‹œí•  êµ¬ì²´ì ì¸ ì‘ì—… ë‚´ìš©",
                }
            },
            "required": ["agent_id", "task"]
        }
    }

    specialist_results: dict[str, str] = {}

    async def _spawn_executor(tool_name: str, tool_input: dict) -> str:
        if tool_name == "spawn_agent":
            sid = tool_input.get("agent_id", "")
            task = tool_input.get("task", "")
            if sid in specialists_pool:
                logger.info("spawn_agent: %s â†’ %s", manager_id, sid)
                await _broadcast_status(manager_id, "working", 0.5, f"ì „ë¬¸ê°€ {_SPECIALIST_NAMES.get(sid, sid)} í˜¸ì¶œ ì¤‘...")
                result = await _call_agent(sid, task)
                content = result.get("content", "")
                specialist_results[sid] = content
                return content
        return "ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬ì…ë‹ˆë‹¤."

    mgr_name = _AGENT_NAMES.get(manager_id, manager_id)
    await _broadcast_status(manager_id, "working", 0.2, f"{mgr_name} ë¶„ì„ ì¤‘ (ììœ¨ ì „ë¬¸ê°€ ì„ íƒ)...")

    override = _get_model_override(manager_id)
    model = select_model(text, override=override)

    result = await ask_ai(
        text,
        system_prompt=soul,
        model=model,
        tools=[spawn_tool],
        tool_executor=_spawn_executor,
    )

    await _broadcast_status(manager_id, "done", 1.0, "ë³´ê³  ì™„ë£Œ")

    return {
        "content": result.get("content", ""),
        "specialist_results": specialist_results,
        "manager_id": manager_id,
        "cost_usd": result.get("cost_usd", 0),
        "time_seconds": result.get("time_seconds", 0),
    }


async def _chief_finalize(original_text: str, manager_results: dict) -> dict:
    """Level 2/3 ì™„ë£Œ í›„ ë¹„ì„œì‹¤ì¥ì´ ìµœì¢… ë³´ê³ ì„œ 1ê°œ ì‘ì„±."""
    chief_cfg = next((a for a in AGENTS if a.get("agent_id") == "chief_of_staff"), None)
    if not chief_cfg:
        # fallback: ì²˜ì¥ ê²°ê³¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
        combined = "\n\n".join(r.get("content", "") for r in manager_results.values())
        return {"content": combined}

    results_text = "\n\n".join(
        f"[{mgr_id} ë³´ê³ ]\n{res.get('content', '')}"
        for mgr_id, res in manager_results.items()
    )

    synthesis_prompt = (
        f"CEO ì§ˆë¬¸: {original_text}\n\n"
        f"ì²˜ì¥ ë³´ê³  ë‚´ìš©:\n{results_text}\n\n"
        "ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ CEOì—ê²Œ ë“œë¦´ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”. "
        "í•µì‹¬ ê²°ë¡ ì„ ë¨¼ì €, ì„¸ë¶€ ë‚´ìš©ì„ ë’¤ì— ì •ë¦¬í•˜ì„¸ìš”."
    )

    soul = _load_agent_prompt("chief_of_staff")
    override = _get_model_override("chief_of_staff")
    model = select_model(synthesis_prompt, override=override)

    result = await ask_ai(
        synthesis_prompt,
        system_prompt=soul,
        model=model,
    )

    return {"content": result.get("content", ""), "routing_level": "finalized", "cost_usd": result.get("cost_usd", 0)}


async def _broadcast_to_managers_all(text: str, task_id: str) -> dict:
    """Level 4: ê¸°ì¡´ ë°©ì‹ â€” ëª¨ë“  ì²˜ì¥ + ë³´ì¢Œê´€ ë³‘ë ¬ í˜¸ì¶œ (ë¸Œë¡œë“œìºìŠ¤íŠ¸)."""
    managers = ["cto_manager", "cso_manager", "clo_manager", "cmo_manager", "cio_manager", "cpo_manager"]
    staff_specialists = ["report_specialist", "schedule_specialist", "relay_specialist"]

    # ë¹„ì„œì‹¤ì¥ ìƒíƒœ: ì „ë‹¬ ì¤‘
    await _broadcast_status("chief_of_staff", "working", 0.1, "6ê°œ ë¶€ì„œ + ë¹„ì„œì‹¤ ë³´ì¢Œê´€ì—ê²Œ ëª…ë ¹ í•˜ë‹¬ ì¤‘...")

    # í™œë™ ë¡œê·¸
    log_entry = save_activity_log("chief_of_staff", f"[ë¹„ì„œì‹¤ì¥] 6ê°œ ì²˜ì¥ + ë³´ì¢Œê´€ 3ëª…ì—ê²Œ ëª…ë ¹ ì „ë‹¬: {text[:40]}...")
    for c in connected_clients[:]:
        try:
            await c.send_json({"event": "activity_log", "data": log_entry})
        except Exception:
            pass

    # â”€â”€ 1ë‹¨ê³„: 6ê°œ ì²˜ì¥ + ë¹„ì„œì‹¤ ë³´ì¢Œê´€ 3ëª… ë™ì‹œ í˜¸ì¶œ â”€â”€
    mgr_tasks = [_manager_with_delegation(mgr_id, text) for mgr_id in managers]
    staff_tasks = [_call_agent(spec_id, text) for spec_id in staff_specialists]
    all_results = await asyncio.gather(*(mgr_tasks + staff_tasks), return_exceptions=True)

    mgr_results = all_results[:6]
    staff_results = all_results[6:]

    # â”€â”€ 2ë‹¨ê³„: ì²˜ì¥ ê²°ê³¼ ì •ë¦¬ (ê¸°ë°€ë¬¸ì„œì—ëŠ” ì´ë¯¸ _manager_with_delegationì—ì„œ ì €ì¥ë¨) â”€â”€
    mgr_summaries = []  # ë¹„ì„œì‹¤ì¥ì—ê²Œ ì „ë‹¬í•  ìš”ì•½
    total_cost = 0.0
    total_time = 0.0
    success_count = 0
    total_specialists = 0

    for i, result in enumerate(mgr_results):
        mgr_id = managers[i]
        mgr_name = _AGENT_NAMES.get(mgr_id, mgr_id)

        if isinstance(result, Exception):
            mgr_summaries.append(f"[{mgr_name}] ì˜¤ë¥˜: {str(result)[:100]}")
        elif "error" in result:
            mgr_summaries.append(f"[{mgr_name}] ì˜¤ë¥˜: {result['error'][:200]}")
        else:
            specs = result.get("specialists_used", 0)
            total_specialists += specs
            mgr_summaries.append(f"[{mgr_name}] (ì „ë¬¸ê°€ {specs}ëª…)\n{result.get('content', 'ì‘ë‹µ ì—†ìŒ')}")
            total_cost += result.get("cost_usd", 0)
            total_time = max(total_time, result.get("time_seconds", 0))
            success_count += 1

    # ë³´ì¢Œê´€ ê²°ê³¼ ì •ë¦¬
    staff_summaries = []
    for i, result in enumerate(staff_results):
        spec_id = staff_specialists[i]
        spec_name = _SPECIALIST_NAMES.get(spec_id, spec_id)

        if isinstance(result, Exception):
            staff_summaries.append(f"[{spec_name}] ì˜¤ë¥˜: {str(result)[:100]}")
        elif "error" in result:
            staff_summaries.append(f"[{spec_name}] ì˜¤ë¥˜: {result['error'][:200]}")
        else:
            staff_summaries.append(f"[{spec_name}]\n{result.get('content', 'ì‘ë‹µ ì—†ìŒ')}")
            total_cost += result.get("cost_usd", 0)
            total_time = max(total_time, result.get("time_seconds", 0))

    # â”€â”€ 3ë‹¨ê³„: ë¹„ì„œì‹¤ì¥ì´ AIë¡œ ì¢…í•© ë³´ê³ ì„œ ì‘ì„± â”€â”€
    await _broadcast_status("chief_of_staff", "working", 0.8, "ì¢…í•© ë³´ê³ ì„œ ì‘ì„± ì¤‘...")

    synthesis_input = (
        f"CEO ì›ë³¸ ëª…ë ¹: {text}\n\n"
        f"## 6ê°œ ë¶€ì„œ ì²˜ì¥ ë³´ê³ ì„œ\n\n"
        + "\n\n---\n\n".join(mgr_summaries)
        + f"\n\n## ë¹„ì„œì‹¤ ë³´ì¢Œê´€ ë³´ê³ \n\n"
        + "\n\n".join(staff_summaries)
    )

    synthesis_system = (
        "ë‹¹ì‹ ì€ ë¹„ì„œì‹¤ì¥ì…ë‹ˆë‹¤. 6ê°œ ë¶€ì„œ ì²˜ì¥ê³¼ ë¹„ì„œì‹¤ ë³´ì¢Œê´€ 3ëª…ì˜ ë³´ê³ ë¥¼ ê²€í† í•˜ê³ , "
        "CEOì—ê²Œ ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n\n"
        "## ë°˜ë“œì‹œ ì•„ë˜ êµ¬ì¡°ë¥¼ ë”°ë¥¼ ê²ƒ\n\n"
        "### í•µì‹¬ ìš”ì•½\n"
        "(ì „ì²´ ìƒí™©ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½)\n\n"
        "### ë¶€ì„œë³„ í•œì¤„ ìš”ì•½\n"
        "| ë¶€ì„œ | í•µì‹¬ ë‚´ìš© | ìƒíƒœ |\n"
        "|------|----------|------|\n"
        "| CTO (ê¸°ìˆ ê°œë°œ) | ... | ì •ìƒ/ì£¼ì˜/ìœ„í—˜ |\n"
        "(6ê°œ ë¶€ì„œ ì „ë¶€)\n\n"
        "### CEO ê²°ì¬/ê²°ì • í•„ìš” ì‚¬í•­\n"
        "(ê° ì²˜ì¥ ë³´ê³ ì„œì—ì„œ CEOê°€ ê²°ì •í•´ì•¼ í•  ê²ƒë§Œ ì¶”ì¶œ. ì²´í¬ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)\n"
        "- [ ] ë¶€ì„œëª…: ê²°ì • ì‚¬í•­ â€” ë°°ê²½ ì„¤ëª…\n"
        "(ê²°ì¬í•  ê²ƒì´ ì—†ìœ¼ë©´ 'í˜„ì¬ ê²°ì¬ ëŒ€ê¸° ì‚¬í•­ ì—†ìŒ')\n\n"
        "### íŠ¹ì´ì‚¬í•­ / ë¦¬ìŠ¤í¬\n"
        "(ê° ë³´ê³ ì„œì—ì„œ ë¦¬ìŠ¤í¬ ìš”ì†Œë§Œ ì¶”ì¶œ. ì—†ìœ¼ë©´ 'íŠ¹ì´ì‚¬í•­ ì—†ìŒ')\n\n"
        "### ë¹„ì„œì‹¤ ë³´ì¢Œê´€ ë³´ê³ \n"
        "- ê¸°ë¡ ë³´ì¢Œê´€: (1ì¤„ ìš”ì•½)\n"
        "- ì¼ì • ë³´ì¢Œê´€: (1ì¤„ ìš”ì•½)\n"
        "- ì†Œí†µ ë³´ì¢Œê´€: (1ì¤„ ìš”ì•½)\n\n"
        "## ê·œì¹™\n"
        "- í•œêµ­ì–´ë¡œ ì‘ì„±\n"
        "- ê°„ê²°í•˜ê²Œ. CEOê°€ 30ì´ˆ ì•ˆì— í•µì‹¬ì„ íŒŒì•…í•  ìˆ˜ ìˆê²Œ\n"
        "- ì¤‘ìš”í•œ ìˆ«ì/ë°ì´í„°ëŠ” ë°˜ë“œì‹œ í¬í•¨\n"
        "- ì²˜ì¥ ë³´ê³ ì„œë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ê³ , í•µì‹¬ë§Œ ì¶”ì¶œí•˜ì—¬ ì¬êµ¬ì„±\n"
    )

    soul = _load_agent_prompt("chief_of_staff")
    override = _get_model_override("chief_of_staff")
    model = select_model(synthesis_input, override=override)

    chief_synthesis = await ask_ai(
        synthesis_input,
        system_prompt=synthesis_system + "\n\n" + soul,
        model=model,
    )

    await _broadcast_status("chief_of_staff", "done", 1.0, "ì¢…í•© ë³´ê³  ì™„ë£Œ")

    # ì¢…í•© ë³´ê³ ì„œ ë¹„ìš© ì¶”ê°€
    if "error" not in chief_synthesis:
        total_cost += chief_synthesis.get("cost_usd", 0)

    # â”€â”€ 4ë‹¨ê³„: ìµœì¢… ì¶œë ¥ = ë¹„ì„œì‹¤ì¥ ì¢…í•© ë³´ê³ ì„œë§Œ â”€â”€
    if "error" in chief_synthesis:
        # ì¢…í•© ì‹¤íŒ¨ ì‹œ ì²˜ì¥ ìš”ì•½ë§Œ ê°„ë‹¨íˆ í‘œì‹œ
        chief_content = "âš ï¸ ë¹„ì„œì‹¤ì¥ ì¢…í•© ë³´ê³ ì„œ ì‘ì„± ì‹¤íŒ¨\n\n" + "\n\n---\n\n".join(
            f"**{_AGENT_NAMES.get(managers[i], managers[i])}**: "
            + (mgr_results[i].get("content", "")[:100] + "..." if not isinstance(mgr_results[i], Exception) else "ì˜¤ë¥˜")
            for i in range(6)
        )
    else:
        chief_content = chief_synthesis.get("content", "")

    # ë§¨ ì•„ë˜ ì•ˆë‚´ ì¶”ê°€
    final_content = (
        f"ğŸ“‹ **ë¹„ì„œì‹¤ì¥ ì¢…í•© ë³´ê³ ** "
        f"(6ê°œ ì²˜ì¥ + ì „ë¬¸ê°€ {total_specialists}ëª… + ë³´ì¢Œê´€ 3ëª… ë™ì›)\n\n"
        f"{chief_content}\n\n"
        f"---\n\n"
        f"ğŸ“‚ **ìƒì„¸ ë³´ê³ ì„œ {success_count}ê±´ì´ ê¸°ë°€ë¬¸ì„œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.** "
        f"ê¸°ë°€ë¬¸ì„œ íƒ­ì—ì„œ ë¶€ì„œë³„ í•„í„°ë¡œ ê° ì²˜ì¥ì˜ ì „ì²´ ë³´ê³ ì„œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

    # ë¹„ì„œì‹¤ì¥ ì¢…í•© ë³´ê³ ì„œë„ ì•„ì¹´ì´ë¸Œì— ì €ì¥
    now_str = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
    save_archive(
        division="secretary",
        filename=f"chief_of_staff_broadcast_{now_str}.md",
        content=f"# [ë¹„ì„œì‹¤ì¥] ì¢…í•© ë³´ê³ : {text[:50]}\n\n{chief_content}",
        agent_id="chief_of_staff",
    )

    # DB ì—…ë°ì´íŠ¸
    update_task(task_id, status="completed",
                result_summary=f"ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì™„ë£Œ ({success_count}/6 ë¶€ì„œ, ì „ë¬¸ê°€ {total_specialists}ëª…, ë³´ì¢Œê´€ 3ëª…)",
                result_data=final_content,
                success=1,
                cost_usd=total_cost,
                time_seconds=round(total_time, 2),
                agent_id="chief_of_staff")

    return {
        "content": final_content,
        "agent_id": "chief_of_staff",
        "handled_by": "ë¹„ì„œì‹¤ì¥ â†’ 6ê°œ ì²˜ì¥ + ë³´ì¢Œê´€ 3ëª…",
        "delegation": "ë¹„ì„œì‹¤ì¥ â†’ ì²˜ì¥ â†’ ì „ë¬¸ê°€",
        "total_cost_usd": round(total_cost, 6),
        "time_seconds": round(total_time, 2),
        "model": "multi-agent",
        "routing_method": "ë¸Œë¡œë“œìºìŠ¤íŠ¸",
    }


# â”€â”€ í† ë¡  ì‹œìŠ¤í…œ (ì„ì› íšŒì˜ ë°©ì‹ ë‹¤ë¼ìš´ë“œ í† ë¡ ) â”€â”€

DEBATE_ROTATION = [
    ["cio_manager", "cto_manager", "cso_manager", "cmo_manager", "clo_manager", "cpo_manager"],
    ["cto_manager", "cso_manager", "cio_manager", "clo_manager", "cmo_manager", "cpo_manager"],
    ["cso_manager", "cmo_manager", "cto_manager", "cio_manager", "cpo_manager", "clo_manager"],
]


async def _call_agent_debate(agent_id: str, topic: str, history: str, extra_instruction: str) -> str:
    """í† ë¡ ìš© ì—ì´ì „íŠ¸ í˜¸ì¶œ â€” ì£¼ì œ + ì´ì „ ë°œì–¸ + ì¶”ê°€ ì§€ì‹œë¥¼ ê²°í•©í•˜ì—¬ í˜¸ì¶œ."""
    prompt = (
        f"[í† ë¡  ì£¼ì œ]\n{topic}\n\n"
        f"[ì´ì „ ë°œì–¸ë“¤]\n{history if history else '(ì²« ë°œì–¸, ë…ë¦½ì ìœ¼ë¡œ ì˜ê²¬ ì œì‹œ)'}\n\n"
        f"{extra_instruction}"
    )
    result = await _call_agent(agent_id, prompt)
    return result.get("content", str(result)) if isinstance(result, dict) else str(result)


async def _broadcast_with_debate(ceo_message: str, rounds: int = 2) -> dict:
    """ì„ì› íšŒì˜ ë°©ì‹ í† ë¡  â€” CEO ë©”ì‹œì§€ë¥¼ ì²˜ì¥ë“¤ì´ ë‹¤ë‹¨ê³„ í† ë¡  í›„ ë¹„ì„œì‹¤ì¥ì´ ì¢…í•©."""
    debate_history = ""

    # ì°¸ê°€ ì²˜ì¥ ëª©ë¡ (ì„¤ì •ì— ì¡´ì¬í•˜ëŠ” ì²˜ì¥ë§Œ)
    all_managers = ["cio_manager", "cto_manager", "cso_manager", "cmo_manager", "clo_manager", "cpo_manager"]
    manager_ids = [m for m in all_managers if m in _AGENTS_DETAIL]

    for round_num in range(1, rounds + 1):
        rotation_idx = (round_num - 1) % len(DEBATE_ROTATION)
        ordered_managers = [m for m in DEBATE_ROTATION[rotation_idx] if m in manager_ids]

        if round_num == 1:
            # ë¼ìš´ë“œ 1: ë³‘ë ¬ â€” ì„œë¡œ ëª¨ë¥´ê³  ë…ë¦½ ì˜ê²¬ ì œì‹œ
            debate_append = (
                "\n\n[í† ë¡  ê·œì¹™]\n"
                "ì´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹¹ì‹ ì˜ ë…ë¦½ì ì¸ ì „ë¬¸ ì˜ê²¬ì„ ì œì‹œí•˜ì„¸ìš”. "
                "ë°˜ë“œì‹œ ë‹¹ì‹  ë¶€ì„œì˜ ê´€ì ì—ì„œ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”."
            )
            tasks = [_call_agent_debate(mid, ceo_message, "", debate_append) for mid in ordered_managers]
            responses = await asyncio.gather(*tasks, return_exceptions=True)
            for mid, resp in zip(ordered_managers, responses):
                if not isinstance(resp, Exception):
                    mgr_name = _AGENT_NAMES.get(mid, mid)
                    debate_history += f"\n[{mgr_name}ì˜ 1ë¼ìš´ë“œ ì˜ê²¬]\n{resp}\n"
        else:
            # ë¼ìš´ë“œ 2+: ìˆœì°¨ â€” ì´ì „ ë¼ìš´ë“œ ì „ì²´ë¥¼ ì½ê³  ë°˜ë°•/ë³´ê°•
            rebuttal_instruction = (
                "\n\n[ì¬ë°˜ë°• ë¼ìš´ë“œ]\nì´ì „ ë°œì–¸ë“¤ì„ ì½ê³ :\n"
                "1. ë‹¤ë¥¸ ì²˜ì¥ ì˜ê²¬ ì¤‘ ë¬¸ì œì  ìµœì†Œ 1ê°€ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì \n"
                "2. 'ë™ì˜í•©ë‹ˆë‹¤', 'ì¢‹ì€ ì˜ê²¬ì…ë‹ˆë‹¤' ê°™ì€ ë¹ˆ ë™ì˜ í‘œí˜„ì€ ì ˆëŒ€ ê¸ˆì§€\n"
                "3. ìì‹ ì˜ ì…ì¥ì„ ë” ëª…í™•íˆ ê°•í™”í•˜ê±°ë‚˜ ìˆ˜ì •"
            )
            for mid in ordered_managers:
                mgr_name = _AGENT_NAMES.get(mid, mid)
                resp = await _call_agent_debate(mid, ceo_message, debate_history, rebuttal_instruction)
                debate_history += f"\n[{mgr_name}ì˜ {round_num}ë¼ìš´ë“œ ë°œì–¸]\n{resp}\n"

    # ë¹„ì„œì‹¤ì¥ì´ í† ë¡  ê²°ê³¼ ì¢…í•©
    synthesis_prompt = (
        f"[í† ë¡  ì£¼ì œ]\n{ceo_message}\n\n"
        f"[ì²˜ì¥ë“¤ì˜ í† ë¡  ë‚´ìš©]\n{debate_history}\n\n"
        "ìœ„ í† ë¡ ì„ ë°”íƒ•ìœ¼ë¡œ:\n"
        "1. í•µì‹¬ í•©ì˜ ì‚¬í•­ (ì²˜ì¥ë“¤ì´ ê³µí†µìœ¼ë¡œ ë™ì˜í•œ ì )\n"
        "2. ì£¼ìš” ì´ê²¬ (ì²˜ì¥ë“¤ ê°„ ëŒ€ë¦½ëœ ê´€ì )\n"
        "3. CEOë¥¼ ìœ„í•œ ìµœì¢… ê¶Œê³ ì‚¬í•­\n"
        "ì„ ì •ë¦¬í•´ì„œ ë³´ê³ í•´ì£¼ì„¸ìš”."
    )

    final_result = await _call_agent("chief_of_staff", synthesis_prompt)
    final_content = final_result.get("content", str(final_result)) if isinstance(final_result, dict) else str(final_result)

    return {
        "content": (
            f"## ì„ì› í† ë¡  ê²°ê³¼ ({rounds}ë¼ìš´ë“œ)\n\n"
            f"{final_content}\n\n"
            f"---\n\n"
            f"<details><summary>ì „ì²´ í† ë¡  ë‚´ì—­ ë³´ê¸°</summary>\n\n{debate_history}\n</details>"
        ),
        "debate_rounds": rounds,
        "participants": manager_ids,
        "agent_id": "chief_of_staff",
        "handled_by": f"ì„ì› í† ë¡  ({rounds}ë¼ìš´ë“œ, {len(manager_ids)}ëª… ì°¸ì—¬)",
    }


async def _broadcast_to_managers(text: str, task_id: str, target_agent_id: str | None = None) -> dict:
    """ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…: Levelì— ë”°ë¼ ì ì ˆí•œ ì—ì´ì „íŠ¸ë§Œ í˜¸ì¶œ.

    Level 1: ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬ (ì²˜ì¥ í˜¸ì¶œ ì—†ìŒ)
    Level 2: ì²˜ì¥ 1ëª…ë§Œ í˜¸ì¶œ (ì „ë¬¸ê°€ ìœ„ì„ ì—†ìŒ)
    Level 3: ì²˜ì¥ 1ëª… + spawn_agent ììœ¨ ì „ë¬¸ê°€ ì„ íƒ
    Level 4: ì „ì› ë³‘ë ¬ í˜¸ì¶œ (ê¸°ì¡´ ë¸Œë¡œë“œìºìŠ¤íŠ¸)
    """
    # CEO ì§ì ‘ ê°œì…: íŠ¹ì • ì—ì´ì „íŠ¸ì—ê²Œ ì§ì ‘ ì „ë‹¬
    if target_agent_id:
        logger.info("CEO ì§ì ‘ ê°œì…: â†’ %s", target_agent_id)
        return await _call_agent(target_agent_id, text)

    level, manager_id = _determine_routing_level(text)
    logger.info("ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… Level %d, ì²˜ì¥: %s", level, manager_id)

    if level == 1:
        # ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬
        return await _call_agent("chief_of_staff", text)

    elif level == 2:
        # ì²˜ì¥ 1ëª…ë§Œ í˜¸ì¶œ (ì „ë¬¸ê°€ ìœ„ì„ ì—†ìŒ)
        mgr_result = await _call_agent(manager_id, text)
        return await _chief_finalize(text, {manager_id: mgr_result})

    elif level == 3:
        # ì²˜ì¥ + spawn_agent ììœ¨ ì „ë¬¸ê°€ ì„ íƒ
        mgr_result = await _manager_with_delegation_autonomous(manager_id, text)
        return await _chief_finalize(text, {manager_id: mgr_result})

    else:  # level == 4
        return await _broadcast_to_managers_all(text, task_id)


async def _sequential_collaboration(text: str, task_id: str, agent_order: list[str] | None = None) -> dict:
    """ì—ì´ì „íŠ¸ ê°„ ìˆœì°¨ í˜‘ì—… â€” ë¹„ì„œì‹¤ì¥ì´ í—ˆë¸Œë¡œ ë¶€ì„œ ê°„ ìˆœì°¨ ì‘ì—…ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•©ë‹ˆë‹¤.

    íë¦„:
    1) ë¹„ì„œì‹¤ì¥ì´ AIë¡œ ì‘ì—… ìˆœì„œ ê²°ì • (ë˜ëŠ” CEOê°€ ì§ì ‘ ì§€ì •)
    2) ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ì—ê²Œ ì›ë³¸ ëª…ë ¹ ì „ë‹¬
    3) ì´ì „ ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì—ì´ì „íŠ¸ì—ê²Œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬
    4) ëª¨ë“  ì—ì´ì „íŠ¸ ì™„ë£Œ í›„ ë¹„ì„œì‹¤ì¥ì´ ì¢…í•© ë³´ê³ 

    ì˜ˆ: "CPOê°€ ë°ì´í„° ìˆ˜ì§‘ â†’ CMOê°€ ë§ˆì¼€íŒ… ì½˜í…ì¸  ì‘ì„±" ê°™ì€ ìˆœì°¨ ì‘ì—…
    """
    await _broadcast_status("chief_of_staff", "working", 0.1, "ìˆœì°¨ í˜‘ì—… ê³„íš ìˆ˜ë¦½ ì¤‘...")

    # ì—ì´ì „íŠ¸ ìˆœì„œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ AIê°€ ê²°ì •
    if not agent_order:
        order_prompt = (
            f"CEO ëª…ë ¹: {text}\n\n"
            "ì´ ì‘ì—…ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì–´ë–¤ ë¶€ì„œê°€ ì–´ë–¤ ìˆœì„œë¡œ ì‘ì—…í•´ì•¼ í•˜ëŠ”ì§€ ê²°ì •í•˜ì„¸ìš”.\n"
            "ê°€ëŠ¥í•œ ë¶€ì„œ: cto_manager(ê¸°ìˆ ), cso_manager(ì‚¬ì—…), clo_manager(ë²•ë¬´), "
            "cmo_manager(ë§ˆì¼€íŒ…), cio_manager(íˆ¬ì), cpo_manager(ê¸°íš)\n\n"
            "JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€:\n"
            '{"order": ["ì²«ë²ˆì§¸_agent_id", "ë‘ë²ˆì§¸_agent_id"], "reason": "ì´ìœ "}\n'
            "ìµœì†Œ 2ê°œ, ìµœëŒ€ 4ê°œ ë¶€ì„œë§Œ ì„ íƒí•˜ì„¸ìš”. ê´€ë ¨ ì—†ëŠ” ë¶€ì„œëŠ” ì œì™¸."
        )
        soul = _load_agent_prompt("chief_of_staff")
        override = _get_model_override("chief_of_staff")
        model = select_model(order_prompt, override=override)
        plan_result = await ask_ai(order_prompt, system_prompt=soul, model=model)

        if "error" not in plan_result:
            try:
                raw = plan_result.get("content", "")
                if "```" in raw:
                    raw = raw.split("```")[1]
                    if raw.startswith("json"):
                        raw = raw[4:]
                parsed = json.loads(raw)
                agent_order = parsed.get("order", [])
            except (json.JSONDecodeError, IndexError):
                pass

        if not agent_order:
            agent_order = ["cto_manager", "cso_manager"]

    # ìœ íš¨í•œ ì—ì´ì „íŠ¸ë§Œ í•„í„°ë§
    valid_agents = set(_AGENT_NAMES.keys())
    agent_order = [a for a in agent_order if a in valid_agents]
    if not agent_order:
        agent_order = ["chief_of_staff"]

    # ìˆœì°¨ ì‹¤í–‰
    chain_context = f"CEO ì›ë³¸ ëª…ë ¹: {text}"
    results = []
    total_cost = 0.0
    total_time = 0.0

    for i, agent_id in enumerate(agent_order):
        agent_name = _AGENT_NAMES.get(agent_id, agent_id)
        step_label = f"[{i+1}/{len(agent_order)}]"

        await _broadcast_status("chief_of_staff", "working", (i + 0.5) / len(agent_order),
                                f"ìˆœì°¨ í˜‘ì—… {step_label} {agent_name} ì‘ì—… ì¤‘...")

        # ì´ì „ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬í•¨í•˜ì—¬ í˜¸ì¶œ
        if i == 0:
            agent_input = text
        else:
            prev_results = "\n\n".join(
                f"[{r['name']}ì˜ ì‘ì—… ê²°ê³¼]\n{r['content'][:500]}"
                for r in results
            )
            agent_input = (
                f"{text}\n\n"
                f"## ì´ì „ ë‹¨ê³„ ì‘ì—… ê²°ê³¼ (ì°¸ê³ í•˜ì—¬ ì‘ì—…í•˜ì„¸ìš”)\n{prev_results}"
            )

        result = await _manager_with_delegation(agent_id, agent_input)

        if isinstance(result, Exception):
            results.append({"agent_id": agent_id, "name": agent_name, "content": f"ì˜¤ë¥˜: {result}", "cost_usd": 0})
        elif "error" in result:
            results.append({"agent_id": agent_id, "name": agent_name, "content": f"ì˜¤ë¥˜: {result['error']}", "cost_usd": 0})
        else:
            results.append(result)
            total_cost += result.get("cost_usd", 0)
            total_time += result.get("time_seconds", 0)

    # ë¹„ì„œì‹¤ì¥ ì¢…í•©
    await _broadcast_status("chief_of_staff", "working", 0.9, "ìˆœì°¨ í˜‘ì—… ì¢…í•© ë³´ê³ ì„œ ì‘ì„± ì¤‘...")

    chain_summary = "\n\n---\n\n".join(
        f"### {i+1}ë‹¨ê³„: {r.get('name', r.get('agent_id', '?'))}\n{r.get('content', 'ê²°ê³¼ ì—†ìŒ')}"
        for i, r in enumerate(results)
    )

    synthesis_prompt = (
        f"CEO ëª…ë ¹: {text}\n\n"
        f"ì•„ë˜ëŠ” {len(results)}ê°œ ë¶€ì„œê°€ ìˆœì°¨ì ìœ¼ë¡œ ì‘ì—…í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n"
        f"ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ë‹¤ìŒ ë‹¨ê³„ê°€ ì°¸ê³ í•˜ì—¬ ì‘ì—…í–ˆìŠµë‹ˆë‹¤.\n\n"
        f"{chain_summary}\n\n"
        f"ìœ„ ìˆœì°¨ í˜‘ì—… ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ CEOì—ê²Œ ê°„ê²°í•œ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
    )

    soul = _load_agent_prompt("chief_of_staff")
    override = _get_model_override("chief_of_staff")
    model = select_model(synthesis_prompt, override=override)
    synthesis = await ask_ai(synthesis_prompt, system_prompt=soul, model=model)

    await _broadcast_status("chief_of_staff", "done", 1.0, "ìˆœì°¨ í˜‘ì—… ì™„ë£Œ")

    if "error" in synthesis:
        chief_content = f"âš ï¸ ì¢…í•© ë³´ê³ ì„œ ì‘ì„± ì‹¤íŒ¨\n\n{chain_summary}"
    else:
        chief_content = synthesis.get("content", "")
        total_cost += synthesis.get("cost_usd", 0)

    order_names = " â†’ ".join(_AGENT_NAMES.get(a, a) for a in agent_order)
    final_content = (
        f"ğŸ”— **ìˆœì°¨ í˜‘ì—… ë³´ê³ ** ({order_names})\n\n"
        f"{chief_content}\n\n---\n\n"
        f"ğŸ“‚ ìƒì„¸ ë³´ê³ ì„œ {len(results)}ê±´ì´ ê¸°ë°€ë¬¸ì„œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
    )

    # ì•„ì¹´ì´ë¸Œ ì €ì¥
    now_str = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
    save_archive(
        division="secretary",
        filename=f"sequential_collab_{now_str}.md",
        content=f"# [ìˆœì°¨ í˜‘ì—…] {text[:50]}\n\nì‘ì—… ìˆœì„œ: {order_names}\n\n{chain_summary}",
        agent_id="chief_of_staff",
    )

    update_task(task_id, status="completed",
                result_summary=f"ìˆœì°¨ í˜‘ì—… ì™„ë£Œ ({order_names})",
                result_data=final_content,
                success=1, cost_usd=total_cost,
                time_seconds=round(total_time, 2),
                agent_id="chief_of_staff")

    return {
        "content": final_content,
        "agent_id": "chief_of_staff",
        "handled_by": f"ë¹„ì„œì‹¤ì¥ â†’ {order_names}",
        "delegation": f"ìˆœì°¨ í˜‘ì—…: {order_names}",
        "total_cost_usd": round(total_cost, 6),
        "time_seconds": round(total_time, 2),
        "model": "multi-agent-sequential",
        "routing_method": "ìˆœì°¨ í˜‘ì—…",
    }


# ìˆœì°¨ í˜‘ì—… íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ
_SEQUENTIAL_KEYWORDS = ["ìˆœì°¨", "í˜‘ì—…", "ìˆœì„œëŒ€ë¡œ", "ë‹¨ê³„ë³„", "ë¦´ë ˆì´", "ì—°ê³„"]


def _is_sequential_command(text: str) -> bool:
    """ìˆœì°¨ í˜‘ì—… ëª…ë ¹ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return any(kw in text for kw in _SEQUENTIAL_KEYWORDS)


def _classify_by_keywords(text: str) -> str | None:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ë¥˜. ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜."""
    for agent_id, keywords in _ROUTING_KEYWORDS.items():
        if any(kw in text for kw in keywords):
            return agent_id
    return None


async def _route_task(text: str) -> dict:
    """CEO ëª…ë ¹ì„ ì í•©í•œ ì—ì´ì „íŠ¸ì—ê²Œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.

    1ë‹¨ê³„: í‚¤ì›Œë“œ ë§¤ì¹­ (ë¬´ë£Œ, ì¦‰ì‹œ)
    2ë‹¨ê³„: AI ë¶„ë¥˜ (Haiku, ~$0.001)
    3ë‹¨ê³„: í´ë°± â†’ ë¹„ì„œì‹¤ì¥
    """
    # 1ë‹¨ê³„: í‚¤ì›Œë“œ ë¶„ë¥˜
    agent_id = _classify_by_keywords(text)
    if agent_id:
        return {
            "agent_id": agent_id,
            "method": "í‚¤ì›Œë“œ",
            "cost_usd": 0.0,
            "reason": "í‚¤ì›Œë“œ ë§¤ì¹­",
        }

    # 2ë‹¨ê³„: AI ë¶„ë¥˜ (í‚¤ì›Œë“œ ì‹¤íŒ¨ ì‹œ)
    result = await classify_task(text)
    if result.get("agent_id") and result["agent_id"] != "chief_of_staff":
        return {
            "agent_id": result["agent_id"],
            "method": "AIë¶„ë¥˜",
            "cost_usd": result.get("cost_usd", 0),
            "reason": result.get("reason", "AI ë¶„ë¥˜"),
        }

    # 3ë‹¨ê³„: í´ë°± â€” ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬
    return {
        "agent_id": "chief_of_staff",
        "method": "ì§ì ‘",
        "cost_usd": result.get("cost_usd", 0),
        "reason": result.get("reason", "ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬"),
    }


def _get_tool_descriptions(agent_id: str) -> str:
    """ì—ì´ì „íŠ¸ì— í• ë‹¹ëœ ë„êµ¬ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    detail = _AGENTS_DETAIL.get(agent_id, {})
    allowed = detail.get("allowed_tools", [])
    if not allowed:
        return ""

    # ë„êµ¬ ID â†’ ì„¤ëª… ë§¤í•‘
    tool_map = {t.get("tool_id"): t for t in _TOOLS_LIST}
    descs = []
    for tid in allowed:
        t = tool_map.get(tid)
        if t:
            name = t.get("name_ko") or t.get("name", tid)
            desc = t.get("description", "")[:150]
            descs.append(f"- **{name}**: {desc}")

    if not descs:
        return ""

    return (
        "\n\n## ì‚¬ìš© ê°€ëŠ¥í•œ ì „ë¬¸ ë„êµ¬\n"
        "ì•„ë˜ ë„êµ¬ì˜ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ë” ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n"
        + "\n".join(descs)
    )


def _load_agent_prompt(agent_id: str, *, include_tools: bool = True) -> str:
    """ì—ì´ì „íŠ¸ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(ì†Œìš¸) + ë„êµ¬ ì •ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

    ìš°ì„ ìˆœìœ„: DB ì˜¤ë²„ë¼ì´ë“œ > souls/*.md íŒŒì¼ > agents.yaml system_prompt > ê¸°ë³¸ê°’
    include_tools=Trueì´ë©´ ë§ˆì§€ë§‰ì— í• ë‹¹ëœ ë„êµ¬ ì„¤ëª…ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    ë°°ì¹˜ ëª¨ë“œì—ì„œëŠ” include_tools=Falseë¡œ í˜¸ì¶œí•˜ì—¬ ë„êµ¬ ì„¤ëª…ì„ ì œì™¸í•©ë‹ˆë‹¤.
    """
    prompt = ""

    # 1ìˆœìœ„: DB ì˜¤ë²„ë¼ì´ë“œ
    soul = load_setting(f"soul_{agent_id}")
    if soul:
        prompt = soul
    else:
        # 2ìˆœìœ„: souls íŒŒì¼
        soul_path = Path(BASE_DIR).parent / "souls" / "agents" / f"{agent_id}.md"
        if soul_path.exists():
            try:
                prompt = soul_path.read_text(encoding="utf-8")
            except Exception:
                pass

    if not prompt:
        # 3ìˆœìœ„: agents.yamlì˜ system_prompt
        detail = _AGENTS_DETAIL.get(agent_id, {})
        if detail.get("system_prompt"):
            prompt = detail["system_prompt"]

    if not prompt:
        # 4ìˆœìœ„: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        name = _AGENT_NAMES.get(agent_id, _SPECIALIST_NAMES.get(agent_id, agent_id))
        prompt = (
            f"ë‹¹ì‹ ì€ CORTHEX HQì˜ {name}ì…ë‹ˆë‹¤. "
            "CEOì˜ ì—…ë¬´ ì§€ì‹œë¥¼ ë°›ì•„ ì²˜ë¦¬í•˜ê³ , ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤. "
            "í•­ìƒ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤."
        )

    if include_tools:
        # ë„êµ¬ ì„¤ëª… ì¶”ê°€ (ì—ì´ì „íŠ¸ê°€ ìì‹ ì˜ ë„êµ¬ë¥¼ ì¸ì§€í•˜ê³  í™œìš©í•  ìˆ˜ ìˆê²Œ)
        tools_desc = _get_tool_descriptions(agent_id)
        if tools_desc:
            prompt += tools_desc

    return prompt


# ë°°ì¹˜ ëª¨ë“œ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ‘ë¯¸ì‚¬ (ë„êµ¬ í˜¸ì¶œ ë°©ì§€)
_BATCH_MODE_SUFFIX = (
    "\n\n[ë°°ì¹˜ ëª¨ë“œ ì•ˆë‚´] ì´ ìš”ì²­ì€ ë°°ì¹˜ ì²˜ë¦¬ì…ë‹ˆë‹¤. "
    "ë„êµ¬(í•¨ìˆ˜)ë¥¼ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
    "ë³´ìœ í•œ ì§€ì‹ê³¼ ë¶„ì„ ëŠ¥ë ¥ë§Œìœ¼ë¡œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”. "
    "ì½”ë“œ ë¸”ë¡ì´ë‚˜ í•¨ìˆ˜ í˜¸ì¶œ í˜•íƒœ(ì˜ˆ: await, function() ë“±)ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”."
)


_chief_prompt: str = ""


def _load_chief_prompt() -> None:
    """ë¹„ì„œì‹¤ì¥ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤ (ì„œë²„ ì‹œì‘ ì‹œ ìºì‹œ)."""
    global _chief_prompt
    _chief_prompt = _load_agent_prompt("chief_of_staff")
    _log("[AI] ë¹„ì„œì‹¤ì¥ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ")


def _get_model_override(agent_id: str) -> str | None:
    """ëª¨ë¸ ëª¨ë“œì— ë”°ë¼ ì—ì´ì „íŠ¸ì˜ ëª¨ë¸ì„ ê²°ì •í•©ë‹ˆë‹¤.

    - ìë™ ëª¨ë“œ: None ë°˜í™˜ â†’ select_model()ì´ ì§ˆë¬¸ ë‚´ìš©ì— ë”°ë¼ ìë™ ì„ íƒ
    - ìˆ˜ë™ ëª¨ë“œ: í•´ë‹¹ ì—ì´ì „íŠ¸ì— ê°œë³„ ì§€ì •ëœ ëª¨ë¸ì„ ë°˜í™˜
      (ì—ì´ì „íŠ¸ ìƒì„¸ì—ì„œ CEOê°€ ì§ì ‘ ì„¤ì •í•œ ëª¨ë¸)
    - ê¸€ë¡œë²Œ ì˜¤ë²„ë¼ì´ë“œ: í…”ë ˆê·¸ë¨/ì›¹ì—ì„œ ì„¤ì •í•œ ì „ì²´ ëª¨ë¸ ë³€ê²½ë„ ë°˜ì˜
    """
    mode = load_setting("model_mode") or "auto"
    if mode != "manual":
        return None
    # ìˆ˜ë™ ëª¨ë“œ â†’ ì—ì´ì „íŠ¸ë³„ ê°œë³„ ì§€ì • ëª¨ë¸ ìš°ì„ 
    detail = _AGENTS_DETAIL.get(agent_id, {})
    agent_model = detail.get("model_name")
    if agent_model:
        return agent_model
    # AGENTS ë¦¬ìŠ¤íŠ¸ì—ì„œë„ í™•ì¸
    for a in AGENTS:
        if a["agent_id"] == agent_id and a.get("model_name"):
            return a["model_name"]
    # ê¸€ë¡œë²Œ ì˜¤ë²„ë¼ì´ë“œ (í…”ë ˆê·¸ë¨ /models ë˜ëŠ” ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ ì„¤ì •í•œ ì „ì²´ ëª¨ë¸)
    global_override = load_setting("model_override")
    if global_override:
        return global_override
    return None


async def _process_ai_command(text: str, task_id: str, target_agent_id: str | None = None) -> dict:
    """CEO ëª…ë ¹ì„ ì í•©í•œ ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„í•˜ê³  AI ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    íë¦„:
      ì˜ˆì‚° í™•ì¸ â†’ ë¸Œë¡œë“œìºìŠ¤íŠ¸ í™•ì¸ â†’ ë¼ìš°íŒ…(ë¶„ë¥˜) â†’ ìƒíƒœ ì „ì†¡
      â†’ ì²˜ì¥+ì „ë¬¸ê°€ í’€ ì²´ì¸ ìœ„ì„ â†’ ê²€ìˆ˜ â†’ DB ì €ì¥

    ë¸Œë¡œë“œìºìŠ¤íŠ¸ ëª¨ë“œ: "ì „ì²´", "ì¶œì„ì²´í¬" ë“± â†’ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… (Level 1~4)
    ë‹¨ì¼ ìœ„ì„ ëª¨ë“œ: í‚¤ì›Œë“œ/AI ë¶„ë¥˜ â†’ ì²˜ì¥+ì „ë¬¸ê°€ ì²´ì¸ í˜¸ì¶œ
    ì§ì ‘ ì²˜ë¦¬: ë¹„ì„œì‹¤ì¥ì´ ì§ì ‘ ë‹µë³€ (ë‹¨ìˆœ ì§ˆë¬¸)
    target_agent_id: CEOê°€ íŠ¹ì • ì—ì´ì „íŠ¸ë¥¼ ì§ì ‘ ì§€ì •í•œ ê²½ìš°
    """
    # 1) ì˜ˆì‚° í™•ì¸
    limit = float(load_setting("daily_budget_usd") or 7.0)
    today = get_today_cost()
    if today >= limit:
        update_task(task_id, status="failed",
                    result_summary=f"ì¼ì¼ ì˜ˆì‚° ì´ˆê³¼ (${today:.2f}/${limit:.0f})",
                    success=0)
        return {"error": f"ì¼ì¼ ì˜ˆì‚°ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ (${today:.2f}/${limit:.0f})"}

    # â”€â”€ ìŠ¬ë˜ì‹œ ëª…ë ¹ì–´ ì‹œìŠ¤í…œ â”€â”€
    text_lower = text.strip().lower()
    text_stripped = text.strip()

    # /ëª…ë ¹ì–´ ë˜ëŠ” /ë„ì›€ë§ â€” ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ ëª©ë¡
    if text_lower in ("/ëª…ë ¹ì–´", "/ë„ì›€ë§", "/help", "/commands"):
        content = (
            "ğŸ“‹ **ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´**\n\n"
            "| ëª…ë ¹ì–´ | ì„¤ëª… |\n"
            "|--------|------|\n"
            "| `/í† ë¡  [ì£¼ì œ]` | ì„ì› í† ë¡  (2ë¼ìš´ë“œ: ë…ë¦½ ì˜ê²¬ â†’ ì¬ë°˜ë°•) |\n"
            "| `/ì‹¬ì¸µí† ë¡  [ì£¼ì œ]` | ì‹¬ì¸µ ì„ì› í† ë¡  (3ë¼ìš´ë“œ: ë” ê¹Šì€ ë°˜ë°•) |\n"
            "| `/ì „ì²´ [ë©”ì‹œì§€]` | 29ëª… ì—ì´ì „íŠ¸ ë™ì‹œ ê°€ë™ (ë¸Œë¡œë“œìºìŠ¤íŠ¸) |\n"
            "| `/ìˆœì°¨ [ë©”ì‹œì§€]` | ì—ì´ì „íŠ¸ ë¦´ë ˆì´ (ìˆœì„œëŒ€ë¡œ ì‘ì—…) |\n"
            f"| `/ë„êµ¬ì ê²€` | {len(_TOOLS_LIST)}ê°œ ë„êµ¬ ìƒíƒœ ì ê²€ |\n"
            "| `/ë°°ì¹˜ì‹¤í–‰` | ëŒ€ê¸° ì¤‘ì¸ ë°°ì¹˜ ì‘ì—… ì‹¤í–‰ |\n"
            "| `/ë°°ì¹˜ìƒíƒœ` | ë°°ì¹˜ ì²˜ë¦¬ í˜„í™© |\n"
            "| `/ëª…ë ¹ì–´` | ì´ ë„ì›€ë§ |\n\n"
            "**ì¼ë°˜ ë©”ì‹œì§€**ëŠ” ë¹„ì„œì‹¤ì¥ì´ ìë™ìœ¼ë¡œ ì í•©í•œ ë¶€ì„œì— ìœ„ì„í•©ë‹ˆë‹¤."
        )
        update_task(task_id, status="completed", result_summary=content[:500], success=1)
        return {"content": content, "handled_by": "ë¹„ì„œì‹¤ì¥", "agent_id": "chief_of_staff"}

    # /í† ë¡  [ì£¼ì œ] â€” ì„ì› í† ë¡  (2ë¼ìš´ë“œ: ë…ë¦½ ì˜ê²¬ + ì¬ë°˜ë°•)
    if text_stripped.startswith("/í† ë¡ "):
        topic = text_stripped[len("/í† ë¡ "):].strip() or "CORTHEX ì „ëµ ë°©í–¥"
        result = await _broadcast_with_debate(topic, rounds=2)
        update_task(task_id, status="completed", result_summary=f"ì„ì› í† ë¡  ì™„ë£Œ (2ë¼ìš´ë“œ)", success=1)
        result["handled_by"] = result.get("handled_by", "ì„ì› í† ë¡ ")
        return result

    # /ì‹¬ì¸µí† ë¡  [ì£¼ì œ] â€” ì‹¬ì¸µ ì„ì› í† ë¡  (3ë¼ìš´ë“œ: ë” ê¹Šì€ ë°˜ë°•)
    if text_stripped.startswith("/ì‹¬ì¸µí† ë¡ "):
        topic = text_stripped[len("/ì‹¬ì¸µí† ë¡ "):].strip() or "CORTHEX ì „ëµ ë°©í–¥"
        result = await _broadcast_with_debate(topic, rounds=3)
        update_task(task_id, status="completed", result_summary=f"ì‹¬ì¸µ ì„ì› í† ë¡  ì™„ë£Œ (3ë¼ìš´ë“œ)", success=1)
        result["handled_by"] = result.get("handled_by", "ì‹¬ì¸µ ì„ì› í† ë¡ ")
        return result

    # /ì „ì²´ [ë©”ì‹œì§€] â€” ë¸Œë¡œë“œìºìŠ¤íŠ¸ (29ëª… ë™ì‹œ ê°€ë™) â€” í•­ìƒ Level 4 ì „ì› í˜¸ì¶œ
    if text_stripped.startswith("/ì „ì²´"):
        broadcast_text = text_stripped[len("/ì „ì²´"):].strip()
        if not broadcast_text:
            broadcast_text = "ì „ì²´ ì¶œì„ ë³´ê³ "
        return await _broadcast_to_managers_all(broadcast_text, task_id)

    # /ìˆœì°¨ [ë©”ì‹œì§€] â€” ìˆœì°¨ í˜‘ì—… (ì—ì´ì „íŠ¸ ë¦´ë ˆì´)
    if text_stripped.startswith("/ìˆœì°¨"):
        seq_text = text_stripped[len("/ìˆœì°¨"):].strip()
        if not seq_text:
            content = "âš ï¸ `/ìˆœì°¨` ë’¤ì— ì‘ì—… ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆ: `/ìˆœì°¨ CORTHEX ì›¹ì‚¬ì´íŠ¸ ê¸°ìˆ â†’ë³´ì•ˆâ†’ì‚¬ì—…ì„± ë¶„ì„`"
            update_task(task_id, status="completed", result_summary=content[:500], success=1)
            return {"content": content, "handled_by": "ë¹„ì„œì‹¤ì¥", "agent_id": "chief_of_staff"}
        return await _sequential_collaboration(seq_text, task_id)

    # /ë„êµ¬ì ê²€ â€” ë„êµ¬ ê±´ê°• ì ê²€
    if text_lower in ("/ë„êµ¬ì ê²€", "/ë„êµ¬ìƒíƒœ", "/tools_health", "ì „ì²´ ë„êµ¬ ì ê²€", "ë„êµ¬ ì ê²€", "ë„êµ¬ ìƒíƒœ"):
        import urllib.request as _ur
        try:
            req = _ur.Request("http://127.0.0.1:8000/api/tools/health")
            with _ur.urlopen(req, timeout=10) as resp:
                health = json.loads(resp.read().decode("utf-8"))
        except Exception as e:
            health = {"total": 0, "ready": 0, "missing_key": 0, "not_loaded": 0, "tools": [], "error": str(e)}

        content = f"ğŸ”§ **ì „ì²´ ë„êµ¬ ì ê²€ ê²°ê³¼**\n\n"
        content += f"| í•­ëª© | ìˆ˜ëŸ‰ |\n|------|------|\n"
        content += f"| ì „ì²´ ë„êµ¬ | {health.get('total', 0)}ê°œ |\n"
        content += f"| ì •ìƒ (ready) | {health.get('ready', 0)}ê°œ |\n"
        content += f"| API í‚¤ ë¯¸ì„¤ì • | {health.get('missing_key', 0)}ê°œ |\n"
        content += f"| ë¯¸ë¡œë“œ | {health.get('not_loaded', 0)}ê°œ |\n"
        content += f"| ToolPool | {health.get('pool_status', 'unknown')} |\n\n"

        missing = [t for t in health.get("tools", []) if t.get("status") == "missing_key"]
        if missing:
            content += "### âš ï¸ API í‚¤ í•„ìš”í•œ ë„êµ¬\n"
            for t in missing[:10]:
                content += f"- **{t['name']}** (`{t['tool_id']}`) â€” í™˜ê²½ë³€ìˆ˜: `{t.get('api_key_env', '?')}`\n"

        ready = [t for t in health.get("tools", []) if t.get("status") == "ready"]
        if ready:
            content += f"\n### âœ… ì •ìƒ ì‘ë™ ë„êµ¬ ({len(ready)}ê°œ ì¤‘ ìƒìœ„ 10ê°œ)\n"
            for t in ready[:10]:
                content += f"- {t['name']} (`{t['tool_id']}`)\n"

        update_task(task_id, status="completed", result_summary=content[:500], success=1)
        return {"content": content, "handled_by": "ë¹„ì„œì‹¤ì¥", "agent_id": "chief_of_staff"}

    # /ë°°ì¹˜ì‹¤í–‰ â€” ë°°ì¹˜ ì‘ì—… ì‹¤í–‰
    if text_lower in ("/ë°°ì¹˜ì‹¤í–‰", "/batch_flush", "ë°°ì¹˜ì‹¤í–‰", "ë°°ì¹˜ ì‹¤í–‰"):
        result = await _flush_batch_api_queue()
        content = f"ğŸ“¦ **ë°°ì¹˜ ì‹¤í–‰ ê²°ê³¼**\n\n"
        if "error" in result:
            content += f"âŒ ì‹¤íŒ¨: {result['error']}"
        elif result.get("batch_id"):
            content += f"âœ… Batch API ì œì¶œ ì™„ë£Œ\n- batch_id: `{result['batch_id']}`\n- ê±´ìˆ˜: {result.get('count', 0)}ê±´\n- í”„ë¡œë°”ì´ë”: {result.get('provider', '?')}"
        else:
            content += result.get("message", "ì²˜ë¦¬ ì™„ë£Œ")
        update_task(task_id, status="completed", result_summary=content[:500], success=1)
        return {"content": content, "handled_by": "ë¹„ì„œì‹¤ì¥", "agent_id": "chief_of_staff"}

    # /ë°°ì¹˜ìƒíƒœ â€” ë°°ì¹˜ í˜„í™©
    if text_lower in ("/ë°°ì¹˜ìƒíƒœ", "/batch_status", "ë°°ì¹˜ìƒíƒœ", "ë°°ì¹˜ ìƒíƒœ"):
        pending_batches = load_setting("pending_batches") or []
        active = [b for b in pending_batches if b.get("status") in ("pending", "processing")]
        queue_count = len(_batch_api_queue)
        content = f"ğŸ“¦ **ë°°ì¹˜ ìƒíƒœ**\n\n"
        content += f"- ëŒ€ê¸°ì—´: {queue_count}ê±´\n"
        content += f"- ì²˜ë¦¬ ì¤‘ì¸ ë°°ì¹˜: {len(active)}ê±´\n"
        for b in active:
            prog = b.get("progress", {})
            content += f"  - `{b['batch_id'][:20]}...` ({b['provider']}) â€” {prog.get('completed', '?')}/{prog.get('total', '?')} ì™„ë£Œ\n"
        update_task(task_id, status="completed", result_summary=content[:500], success=1)
        return {"content": content, "handled_by": "ë¹„ì„œì‹¤ì¥", "agent_id": "chief_of_staff"}

    # â”€â”€ ìŠ¬ë˜ì‹œ ëª…ë ¹ì–´ ì´ì™¸: í‚¤ì›Œë“œ ê¸°ë°˜ ë¸Œë¡œë“œìºìŠ¤íŠ¸ (ê¸°ì¡´ í˜¸í™˜) â”€â”€
    # "ì „ì²´", "ì¶œì„ì²´í¬" ë“±ì˜ í‚¤ì›Œë“œëŠ” ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ì ìš© (Level 1~4)
    if _is_broadcast_command(text):
        return await _broadcast_to_managers(text, task_id, target_agent_id=target_agent_id)

    # 3) ë¼ìš°íŒ… â€” ì í•©í•œ ì—ì´ì „íŠ¸ ê²°ì •
    routing = await _route_task(text)
    target_id = routing["agent_id"]
    routing_cost = routing.get("cost_usd", 0)

    # 4) ë¹„ì„œì‹¤ì¥ ì§ì ‘ ì²˜ë¦¬ (ì¼ë°˜ ì§ˆë¬¸, ì¸ì‚¬ ë“±)
    if target_id == "chief_of_staff":
        await _broadcast_status("chief_of_staff", "working", 0.2, "ì§ì ‘ ì²˜ë¦¬ ì¤‘...")
        soul = _chief_prompt if _chief_prompt else _load_agent_prompt("chief_of_staff")
        override = _get_model_override("chief_of_staff")
        model = select_model(text, override=override)
        result = await ask_ai(text, system_prompt=soul, model=model)

        await _broadcast_status("chief_of_staff", "done", 1.0, "ì™„ë£Œ")

        if "error" in result:
            update_task(task_id, status="failed",
                        result_summary=f"AI ì˜¤ë¥˜: {result['error'][:100]}",
                        success=0, agent_id="chief_of_staff")
            result["handled_by"] = "ë¹„ì„œì‹¤ì¥"
            return result

        total_cost = routing_cost + result.get("cost_usd", 0)
        update_task(task_id, status="completed",
                    result_summary=result["content"][:500],
                    result_data=result["content"],
                    success=1, cost_usd=total_cost,
                    tokens_used=result.get("input_tokens", 0) + result.get("output_tokens", 0),
                    time_seconds=result.get("time_seconds", 0),
                    agent_id="chief_of_staff")
        result["handled_by"] = "ë¹„ì„œì‹¤ì¥"
        result["delegation"] = ""
        result["agent_id"] = "chief_of_staff"
        result["routing_method"] = routing["method"]
        result["total_cost_usd"] = total_cost
        return result

    # 5) ë¶€ì„œ ìœ„ì„ â€” ë¹„ì„œì‹¤ì¥ â†’ ì²˜ì¥ â†’ ì „ë¬¸ê°€
    target_name = _AGENT_NAMES.get(target_id, target_id)
    await _broadcast_status("chief_of_staff", "working", 0.1, f"{target_name}ì—ê²Œ ìœ„ì„ ì¤‘...")

    # ì²˜ì¥ì´ ìê¸° ì „ë¬¸ê°€ë¥¼ í˜¸ì¶œ â†’ ê²°ê³¼ ê²€ìˆ˜ â†’ ì¢…í•© ë³´ê³ ì„œ
    delegation_result = await _manager_with_delegation(target_id, text)

    await _broadcast_status("chief_of_staff", "done", 1.0, "ìœ„ì„ ì™„ë£Œ")

    if "error" in delegation_result:
        update_task(task_id, status="failed",
                    result_summary=f"ìœ„ì„ ì˜¤ë¥˜: {delegation_result['error'][:100]}",
                    success=0, agent_id=target_id)
        delegation_result["handled_by"] = target_name
        return delegation_result

    # 6) ê²°ê³¼ ì •ë¦¬
    total_cost = routing_cost + delegation_result.get("cost_usd", 0)
    specs_used = delegation_result.get("specialists_used", 0)
    delegation_label = f"ë¹„ì„œì‹¤ì¥ â†’ {target_name}"
    if specs_used:
        delegation_label += f" â†’ ì „ë¬¸ê°€ {specs_used}ëª…"

    content = delegation_result.get("content", "")
    header = f"ğŸ“‹ **{target_name}** ë³´ê³ "
    if specs_used:
        header += f" (ì†Œì† ì „ë¬¸ê°€ {specs_used}ëª… ë™ì›)"
    content = f"{header}\n\n---\n\n{content}"

    update_task(task_id, status="completed",
                result_summary=content[:500],
                result_data=content,
                success=1, cost_usd=total_cost,
                time_seconds=delegation_result.get("time_seconds", 0),
                agent_id=target_id)

    return {
        "content": content,
        "agent_id": target_id,
        "handled_by": target_name,
        "delegation": delegation_label,
        "total_cost_usd": round(total_cost, 6),
        "time_seconds": delegation_result.get("time_seconds", 0),
        "model": delegation_result.get("model", ""),
        "routing_method": routing["method"],
    }


# â”€â”€ ë„êµ¬ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸ â”€â”€

def _init_tool_pool():
    """ToolPool ì´ˆê¸°í™” â€” src/tools/ ëª¨ë“ˆì„ ë™ì ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.

    ask_ai()ë¥¼ ModelRouter ì¸í„°í˜ì´ìŠ¤ë¡œ ê°ì‹¸ëŠ” ì–´ëŒ‘í„°ë¥¼ ë§Œë“¤ì–´,
    ê¸°ì¡´ ë„êµ¬ ì½”ë“œë¥¼ ìˆ˜ì • ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
    """
    global _tool_pool
    if _tool_pool is not None:
        return _tool_pool if _tool_pool else None

    try:
        from src.tools.pool import ToolPool
        from src.llm.base import LLMResponse

        class _MiniModelRouter:
            """ask_ai()ë¥¼ ModelRouter.complete() ì¸í„°í˜ì´ìŠ¤ë¡œ ê°ì‹¸ëŠ” ì–´ëŒ‘í„°."""

            class cost_tracker:
                """ë”ë¯¸ ë¹„ìš© ì¶”ì ê¸° (mini_serverëŠ” ìì²´ ë¹„ìš© ì¶”ì  ì‚¬ìš©)."""
                @staticmethod
                def record(*args, **kwargs):
                    pass

            async def complete(self, model_name="", messages=None,
                             temperature=0.3, max_tokens=16384,
                             agent_id="", reasoning_effort=None,
                             use_batch=False):
                messages = messages or []
                system_prompt = ""
                user_message = ""
                for msg in messages:
                    if msg.get("role") == "system":
                        system_prompt = msg["content"]
                    elif msg.get("role") == "user":
                        user_message = msg["content"]

                result = await ask_ai(user_message, system_prompt, model_name)

                if "error" in result:
                    return LLMResponse(
                        content=f"[ë„êµ¬ LLM ì˜¤ë¥˜] {result['error']}",
                        model=model_name,
                        input_tokens=0, output_tokens=0,
                        cost_usd=0.0, provider="unknown",
                    )
                return LLMResponse(
                    content=result["content"],
                    model=result.get("model", model_name),
                    input_tokens=result.get("input_tokens", 0),
                    output_tokens=result.get("output_tokens", 0),
                    cost_usd=result.get("cost_usd", 0.0),
                    provider=result.get("provider", "unknown"),
                )

            async def close(self):
                pass

        router = _MiniModelRouter()
        pool = ToolPool(router)

        tools_config = _load_config("tools")
        pool.build_from_config(tools_config)

        loaded = len(pool._tools)
        _tool_pool = pool
        _log(f"[TOOLS] ToolPool ì´ˆê¸°í™” ì™„ë£Œ: {loaded}ê°œ ë„êµ¬ ë¡œë“œ âœ…")
        return pool

    except Exception as e:
        _log(f"[TOOLS] ToolPool ì´ˆê¸°í™” ì‹¤íŒ¨ (ë„êµ¬ ëª©ë¡ë§Œ í‘œì‹œ): {e}")
        _tool_pool = False
        return None


@app.post("/api/tools/{tool_id}/execute")
async def execute_tool(tool_id: str, request: Request):
    """ë„êµ¬ë¥¼ ì§ì ‘ ì‹¤í–‰í•©ë‹ˆë‹¤.

    ìš”ì²­ body: {"action": "...", "query": "...", ...} (ë„êµ¬ë³„ ìƒì´)
    ì‘ë‹µ: {"result": "...", "tool_id": "...", "cost_usd": 0.0}
    """
    pool = _init_tool_pool()
    if not pool:
        return JSONResponse(
            {"error": "ë„êµ¬ ì‹¤í–‰ ì—”ì§„ ë¯¸ì´ˆê¸°í™” (ToolPool ë¡œë“œ ì‹¤íŒ¨)"},
            status_code=503,
        )

    try:
        body = await request.json()
    except Exception:
        body = {}

    try:
        result = await pool.invoke(tool_id, caller_id="ceo_direct", **body)
        return {"result": result, "tool_id": tool_id, "status": "ok"}
    except Exception as e:
        return JSONResponse(
            {"error": f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)[:300]}", "tool_id": tool_id},
            status_code=400,
        )


@app.get("/api/tools/status")
async def get_tools_status():
    """ë¡œë“œëœ ë„êµ¬ ëª©ë¡ê³¼ ToolPool ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    pool = _init_tool_pool()
    if not pool:
        return {
            "pool_status": "unavailable",
            "loaded_tools": [],
            "total_defined": len(_TOOLS_LIST),
        }

    loaded = list(pool._tools.keys())
    return {
        "pool_status": "ready",
        "loaded_tools": loaded,
        "loaded_count": len(loaded),
        "total_defined": len(_TOOLS_LIST),
    }


@app.get("/api/tools/health")
async def get_tools_health():
    """ëª¨ë“  ë„êµ¬ì˜ ê±´ê°• ìƒíƒœë¥¼ ì ê²€í•©ë‹ˆë‹¤.

    ê° ë„êµ¬ë³„ë¡œ:
    - loaded: ToolPoolì— ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    - api_key_required: API í‚¤ê°€ í•„ìš”í•œ ë„êµ¬ì¸ì§€
    - api_key_set: í•„ìš”í•œ API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€
    - status: ready / missing_key / not_loaded / error
    """
    pool = _init_tool_pool()
    loaded_tools = set(pool._tools.keys()) if pool else set()

    # API í‚¤ í™˜ê²½ë³€ìˆ˜ ë§¤í•‘
    _API_KEY_MAP = {
        "anthropic": "ANTHROPIC_API_KEY",
        "openai": "OPENAI_API_KEY",
        "google": "GOOGLE_API_KEY",
        "notion": "NOTION_API_KEY",
        "telegram": "TELEGRAM_BOT_TOKEN",
        "serpapi": "SERPAPI_KEY",
        "newsapi": "NEWSAPI_KEY",
        "alpha_vantage": "ALPHA_VANTAGE_KEY",
    }

    # ë„êµ¬ â†’ í•„ìš”í•œ ì„œë¹„ìŠ¤ ë§¤í•‘ (ë„êµ¬ ì´ë¦„ì— í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ë¡œ ì¶”ì •)
    _TOOL_SERVICE_HINTS = {
        "notion": "notion", "web_search": "serpapi", "real_web_search": "serpapi",
        "news": "newsapi", "stock": "alpha_vantage", "market": "alpha_vantage",
        "telegram": "telegram",
    }

    results = []
    for tool_def in _TOOLS_LIST:
        tid = tool_def.get("tool_id", "")
        tname = tool_def.get("name_ko", tool_def.get("name", tid))

        is_loaded = tid in loaded_tools

        # API í‚¤ í•„ìš” ì—¬ë¶€ ì¶”ì •
        required_service = None
        for hint, service in _TOOL_SERVICE_HINTS.items():
            if hint in tid.lower():
                required_service = service
                break

        api_key_env = _API_KEY_MAP.get(required_service, "") if required_service else ""
        api_key_set = bool(os.getenv(api_key_env, "")) if api_key_env else True

        if is_loaded and api_key_set:
            status = "ready"
        elif is_loaded and not api_key_set:
            status = "missing_key"
        elif not is_loaded and required_service:
            status = "not_loaded"
        else:
            status = "not_loaded"

        results.append({
            "tool_id": tid,
            "name": tname,
            "loaded": is_loaded,
            "api_key_required": required_service or None,
            "api_key_env": api_key_env or None,
            "api_key_set": api_key_set,
            "status": status,
        })

    # í†µê³„
    ready_count = sum(1 for r in results if r["status"] == "ready")
    missing_key = sum(1 for r in results if r["status"] == "missing_key")
    not_loaded = sum(1 for r in results if r["status"] == "not_loaded")

    return {
        "total": len(results),
        "ready": ready_count,
        "missing_key": missing_key,
        "not_loaded": not_loaded,
        "pool_status": "ready" if pool else "unavailable",
        "tools": results,
    }


@app.on_event("startup")
async def on_startup():
    """ì„œë²„ ì‹œì‘ ì‹œ DB ì´ˆê¸°í™” + AI í´ë¼ì´ì–¸íŠ¸ + í…”ë ˆê·¸ë¨ ë´‡ + í¬ë¡  ì—”ì§„ + ë„êµ¬ í’€ ì‹œì‘."""
    init_db()
    _load_chief_prompt()
    ai_ok = init_ai_client()
    _log(f"[AI] í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”: {'ì„±ê³µ âœ…' if ai_ok else 'ì‹¤íŒ¨ âŒ (ANTHROPIC_API_KEY ë¯¸ì„¤ì •?)'}")
    await _start_telegram_bot()
    # í¬ë¡  ì‹¤í–‰ ì—”ì§„ ì‹œì‘
    global _cron_task
    _cron_task = asyncio.create_task(_cron_loop())
    _log("[CRON] í¬ë¡  ì‹¤í–‰ ì—”ì§„ ì‹œì‘ âœ…")
    # ë„êµ¬ ì‹¤í–‰ ì—”ì§„ ì´ˆê¸°í™” (ë¹„ë™ê¸° ì•„ë‹Œ ë™ê¸° â€” ì²« ìš”ì²­ ì‹œ lazy ë¡œë“œë„ ì§€ì›)
    _init_tool_pool()
    # PENDING ë°°ì¹˜ ë˜ëŠ” ì§„í–‰ ì¤‘ì¸ ì²´ì¸ì´ ìˆìœ¼ë©´ í´ëŸ¬ ì‹œì‘
    pending_batches = load_setting("pending_batches") or []
    active_batches = [b for b in pending_batches if b.get("status") in ("pending", "processing")]
    chains = load_setting("batch_chains") or []
    active_chains = [c for c in chains if c.get("status") in ("running", "pending")]
    if active_batches or active_chains:
        _ensure_batch_poller()
        _log(f"[BATCH] ë¯¸ì™„ë£Œ ë°°ì¹˜ {len(active_batches)}ê°œ + ì²´ì¸ {len(active_chains)}ê°œ ê°ì§€ â€” í´ëŸ¬ ìë™ ì‹œì‘")


@app.on_event("shutdown")
async def on_shutdown():
    """ì„œë²„ ì¢…ë£Œ ì‹œ í…”ë ˆê·¸ë¨ ë´‡ë„ í•¨ê»˜ ì¢…ë£Œ."""
    await _stop_telegram_bot()


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
