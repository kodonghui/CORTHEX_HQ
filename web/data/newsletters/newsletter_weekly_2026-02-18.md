# ğŸ“° CORTHEX ìœ„í´ë¦¬ â€” 02/16 ~ 02/22

> [ë„êµ¬ LLM ì˜¤ë¥˜] AI í˜¸ì¶œ ì‹¤íŒ¨ (openai): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tok

---

## ğŸ“‹ ì£¼ìš” ë‰´ìŠ¤
[ë„êµ¬ LLM ì˜¤ë¥˜] AI í˜¸ì¶œ ì‹¤íŒ¨ (openai): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tok

## ğŸ“Š íŠ¸ë Œë“œ & ë°ì´í„°
[ë„êµ¬ LLM ì˜¤ë¥˜] AI í˜¸ì¶œ ì‹¤íŒ¨ (openai): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tok

## ğŸ’¬ ì»¤ë®¤ë‹ˆí‹° ì´ì•¼ê¸°
[ë„êµ¬ LLM ì˜¤ë¥˜] AI í˜¸ì¶œ ì‹¤íŒ¨ (openai): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tok

## ğŸ’¡ ì´ë²ˆ ì£¼ì˜ íŒ
[ë„êµ¬ LLM ì˜¤ë¥˜] AI í˜¸ì¶œ ì‹¤íŒ¨ (openai): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tok

---

*ì´ ë‰´ìŠ¤ë ˆí„°ëŠ” CORTHEX AIê°€ ìë™ ìƒì„±í–ˆìŠµë‹ˆë‹¤.*
